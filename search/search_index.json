{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#hello","title":"HELLO","text":""},{"location":"docker/docker-compose/","title":"Docker Compose","text":"<pre><code>version: '3.8' # Specify the Docker Compose file format version\n\nservices:\n  webapp:\n    image: nginx:latest | custom-image:tag # Docker image to use\n    build: # Options for building the image\n      context: ./webapp | ./alternative-path # Build context\n      dockerfile: Dockerfile | CustomDockerfile # Dockerfile to use\n    container_name: my-custom-webapp | another-name # Custom name for the container\n    command: [\"nginx\", \"-g\", \"daemon off;\"] | [\"custom\", \"command\"] # Command to run in the container\n    entrypoint: [\"/entrypoint.sh\"] | [\"/alternative.sh\"] # Entrypoint for the container\n    ports: # Ports to expose\n      - \"8080:80\" # Map host port 8080 to container port 80\n      - \"8443:443\" # Map host port 8443 to container port 443\n    expose: # Expose ports without publishing them to the host machine\n      - \"8081\" # Expose port 8081\n    volumes: # Mount volumes\n      - type: bind | volume\n        source: ./app | named-volume\n        target: /app | /alternative-path\n    environment: # Environment variables\n      - ENV_VAR=example | another_variable=value\n    env_file: # Environment file\n      - .env | another.env\n    networks: # Networks to connect to\n      mynetwork | another-network:\n        aliases: # Network aliases\n          - webapp-alias | alternative-alias\n    depends_on: # Specify dependencies\n      database | another-service:\n        condition: service_started | service_healthy\n    stop_grace_period: 30s | 1m # Grace period before stopping the container\n    restart: on-failure | always | no # Restart policy\n    labels: # Labels for the container\n      com.example.label: example | another.label:value\n    logging: # Logging configuration\n      driver: \"json-file\" | \"syslog\" | \"fluentd\" # Logging driver\n      options:\n        max-size: \"10m\" | \"5m\"\n        max-file: \"3\" | \"5\"\n    tmpfs: # Temporary filesystems\n      - /tmp | /another-tmp\n    devices: # Devices to add to the container\n      - \"/dev/sda:/dev/sda\" | \"/dev/sdb:/dev/sdb\"\n    ulimits: # Ulimit options\n      nproc: 65535 | 10000\n      nofile:\n        soft: 4096 | 1024\n        hard: 8192 | 2048\n    cap_add: # Capabilities to add\n      - NET_ADMIN | AUDIT_CONTROL\n    cap_drop: # Capabilities to drop\n      - SYS_ADMIN | NET_RAW\n    security_opt: # Security options\n      - seccomp=unconfined | no-new-privileges\n    network_mode: bridge | host | none # Network mode\n    pid: \"host\" | \"container:name\" # PID namespace to use\n    cpu_shares: 256 | 512 # CPU shares (relative weight)\n    cpu_quota: 50000 | 100000 # CPU CFS quota\n    mem_limit: \"256m\" | \"512m\" # Memory limit\n    mem_reservation: \"128m\" | \"256m\" # Memory soft limit\n    tty: true | false # Allocate a pseudo-TTY\n    privileged: true | false # Extended privileges\n    init: true | false # Use an init process\n    cgroup_parent: my-cgroup | another-cgroup # Parent cgroup\n    shm_size: \"64m\" | \"128m\" # Size of /dev/shm\n    stop_signal: SIGTERM | SIGKILL # Signal to stop the container\n    sysctls: # Kernel parameters\n      - net.core.somaxconn=1024 | net.ipv4.tcp_tw_reuse=1\n      - net.ipv4.tcp_syncookies=0 | net.ipv6.conf.all.disable_ipv6=1\n    isolation: default | process | hyperv # Container isolation level\n    dns: # Custom DNS servers\n      - 8.8.8.8 | 1.1.1.1\n      - 8.8.4.4 | 9.9.9.9\n    dns_search: # DNS search domains\n      - example.com | another-domain.com\n    healthcheck: # Healthcheck configuration\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] | [\"CMD-SHELL\", \"echo 'healthcheck'\"]\n      interval: 10s | 1m # Interval for running the healthcheck\n      timeout: 5s | 10s # Timeout for the healthcheck\n      retries: 3 | 5 # Number of retries for the healthcheck\n    extra_hosts: # Additional hosts\n      - \"otherhost:192.168.1.100\" | \"anotherhost:192.168.1.101\"\n    hostname: my-custom-hostname | alternative-hostname # Hostname of the container\n    domainname: example.com | another-domain.com # Domain name of the container\n    working_dir: /app | /another-directory # Working directory inside the container\n    read_only: true | false # Mount the container's root filesystem as read only\n    user: \"1000:1000\" | \"2000:2000\" # UID:GID to use when running the image\n    secrets: # Secrets to expose to the service\n      - my-secret | another-secret\n    configs: # Configs to expose to the service\n      - my-config | another-config\n    networks:\n    mynetwork | another-network:\n    driver: bridge | overlay # Network driver\n    ipam: # IP Address Management\n    driver: default | custom-driver\n    config:\n    - subnet: \"172.16.238.0/24\" | \"10.0.0.0/16\"\n    external: true | false # Use an external network\n\n    volumes:\n      my_volume | another_volume:\n        driver: local | custom-driver  # Volume driver\n        driver_opts:\n          type: none | btrfs\n          o: bind | nfs\n          device: /path/to/my/data | /another/path\n\n    secrets:\n      my-secret | another-secret:\n        file: ./secrets/my-secret.txt | ./another-secret.txt  # File to use for the secret\n        external: false | true  # Whether the secret is external\n\n    configs:\n      my-config | another-config:\n        file: ./configs/my-config.txt | ./another-config.txt  # File to use for the config\n        external: true | false  # Whether the config is external\n</code></pre>"},{"location":"gitlab/install/","title":"GitLab Server Installation and Configuration","text":"<p>Follow these steps to install and configure a GitLab server:</p> <ol> <li> <p>Install Debian server.</p> </li> <li> <p>Install Docker CE: <pre><code>apt install docker.io\nsystemctl start docker\n</code></pre></p> </li> <li> <p>Install Portainer CE. Ports 9000 is for HTTP and 9443 is for HTTPS: <pre><code>docker run -d -p 8000:8000 -p 9000:9000 -p 9443:9443 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest\n</code></pre></p> </li> <li> <p>Open ports: <pre><code>iptables -t nat -A PREROUTING -i vmbr0 -p tcp --dport 9980 -j DNAT --to 192.168.1.7:9000\niptables -t nat -A PREROUTING -i vmbr0 -p tcp --dport 9981 -j DNAT --to 192.168.1.7:9443\n</code></pre></p> </li> <li> <p>Install GitLab CE in Docker with Portainer. Create a <code>docker-compose.yml</code> file with the following content:</p> </li> </ol> <pre><code>version: '3.8'\n\nservices:\n gitlab:\n   image: 'gitlab/gitlab-ce:latest'\n   restart: 'unless-stopped'\n   hostname: 'gitlab.gitlab'\n   environment:\n     GITLAB_OMNIBUS_CONFIG: |\n       external_url 'https://gitlab.example.com'\n       gitlab_rails['gitlab_ssh_host'] = 'example.com'\n       gitlab_rails['gitlab_shell_ssh_port'] = 9982\n       gitlab_rails['gitlab_port'] = 9983\n       nginx['listen_port'] = 9983\n       nginx['listen_https'] = false\n       gitlab_rails['registry_enabled'] = true\n   ports:\n     - '9983:9983'\n     - '9982:22'\n   volumes:\n     - 'gitlab_config:/etc/gitlab'\n     - 'gitlab_logs:/var/log/gitlab'\n     - 'gitlab_data:/var/opt/gitlab'\n   shm_size: '1gb'\n   networks:\n     default:\n       aliases:\n         - 'gitlab.gitlab'\n\n gitlab-runner:\n   image: 'gitlab/gitlab-runner:latest'\n   restart: 'unless-stopped'\n   container_name: 'gitlab-runner'\n   volumes:\n     - 'gitlab_runner_config:/etc/gitlab-runner'\n     - '/var/run/docker.sock:/var/run/docker.sock'\n   extra_hosts:\n     - \"gitlab.examle.com:192.168.1.5\"\n   networks:\n     - 'default'\n\nnetworks:\n default:\n   driver: 'bridge'\n\nvolumes:\n gitlab_config:\n gitlab_logs:\n gitlab_data:\n Gitlab_runner_config:\n</code></pre> <p>Replace <code>external_url</code> with your Git repository clone HTTPS address, and <code>gitlab_ssh_host</code> and <code>gitlab_shell_ssh_port</code> with your Clone with SSH address.</p> <p>Make sure the IP in <code>extra_hosts</code> for <code>gitlab_runner</code> matches the GitLab server's IP since they are on the same server.</p> <ol> <li> <p>Open ports from the outside: <pre><code>iptables -t nat -A PREROUTING -i vmbr0 -p tcp --dport 9982 -j DNAT --to 192.168.1.7:9982\n</code></pre></p> </li> <li> <p>Create an Nginx configuration file, <code>gitlab.conf</code>, with the following content:</p> </li> </ol> <pre><code>server {\n   listen 80;\n   listen [::]:80;\n   server_name www.example.com\n   server_name www.example.com\n\n   location / {\n       return 301 https://$server_name$request_uri;\n   }\n}\n\nserver {\n   listen 443 ssl http2;\n   listen [::]:443 ssl http2;\n   server_name example.com www.example.com;\n\n   ssl_certificate /etc/letsencrypt/live/www.examole.com/fullchain.pem;\n   ssl_certificate_key /etc/letsencrypt/live/www.example.com/privkey.pem;\n   include /etc/letsencrypt/options-ssl-nginx.conf;\n   ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\n   location / {\n       proxy_pass http://192.168.1.7:9983;\n       proxy_set_header Host $host;\n       proxy_set_header X-Real-IP $remote_addr;\n       proxy_set_header X-Forwarded-Proto https;\n       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n       proxy_redirect off;\n   }\n}\n</code></pre> <p>Note: Let's Encrypt does not work on non-standard ports for GitLab server.</p> <ol> <li> <p>Generate the certificate: <pre><code>certbot --nginx -d www.example.com -d example.com\n</code></pre></p> </li> <li> <p>Create a symlink: <pre><code>ln -sf /etc/nginx/sites-available/gitlab.conf /etc/nginx/sites-enabled/gitlab\n</code></pre></p> </li> </ol> <p>Restart Nginx: <pre><code>systemctl restart nginx\n</code></pre></p> <ol> <li> <p>In GitLab, create a group, user, and repository. Go to the repository settings -&gt; CI/CD -&gt; Runners -&gt; Expand -&gt; Copy the registration token, which is required to register the runner.</p> </li> <li> <p>In Portainer, go to the runner terminal and register the runner:</p> </li> </ol> <pre><code>    gitlab-runner register --non-interactive --executor \"docker\" --docker-image docker:20.10.24-git --url \"https://gitlab.example.com/\" --registration-token \"TOKEN\" --description \"local-runner\" --docker-network-mode gitlab-ce_default --docker-privileged\n</code></pre> <pre><code>Ensure that the `docker-network-mode` value is the same as the network used in the `docker-compose.yml` file.\n</code></pre> <p>Here is a sample <code>.gitlab-ci.yml</code> pipeline configuration:</p> <pre><code>   image: docker:20.10.24-git\n   services:\n     - name: docker:20.10.24-dind\n       alias: docker\n\n   stages:\n     - build\n     - test\n\n   variables:\n     APP_NAME: my-app\n     DOCKER_HOST: tcp://docker:2375\n     DOCKER_DRIVER: overlay2\n     DOCKER_TLS_CERTDIR: \"\"\n     DOCKER_IMAGE_TAG: latest\n     DOCKER_REGISTRY_URL: gitlab.example.com\n     DOCKER_REGISTRY_USERNAME: root\n     DOCKER_REGISTRY_PASSWORD: \n\n   build:\n     stage: build\n     script:\n       - echo $DOCKER_HOST\n       - docker build -t $APP_NAME:$(git rev-parse --short HEAD) .\n\n   test:\n     stage: test\n     script:\n       - echo \"Running tests...\"\n</code></pre>"},{"location":"kubernetes/architecture/","title":"Master Node","text":"<p>The master node is responsible for managing, planning, scheduling, and monitoring nodes in the cluster.</p>"},{"location":"kubernetes/architecture/#kube-apiserver","title":"Kube-apiserver","text":"<p>The kube-apiserver is responsible for orchestrating all actions in the cluster. It is what is behind the <code>kubectl</code> command. It uses HTTP POST requests and can be installed separately as a service at <code>/etc/systemd/system/kube-apiserver.service</code>, or it can be installed automatically as a pod at <code>/etc/kubernetes/manifests/Kube-apiserver.yaml</code>. The kube-apiserver does the following:</p> <ul> <li>Authenticates the user</li> <li>Validates requests</li> <li>Retrieves data</li> <li>Updates the ETCD cluster</li> <li>Assigns a node to the request using the scheduler</li> <li>Sends the assigned node to the kubelet</li> <li>Updates the ETCD cluster with the status of the kubelet</li> </ul>"},{"location":"kubernetes/architecture/#etcd-cluster","title":"ETCD Cluster","text":"<p>The ETCD cluster is a key-value store that is installed on the master node. It stores information about the cluster, including nodes, pods, configs, secrets, accounts, roles, bindings, and other information. It can be configured for high availability by setting up multiple instances. It is a standalone store that is not tied to any specific service.</p>"},{"location":"kubernetes/architecture/#kube-scheduler","title":"Kube-scheduler","text":"<p>The kube-scheduler is responsible for managing the scheduling of containers on nodes. It determines which pods should be run on which nodes. It can be run as a service and uses algorithms to prioritize nodes based on available resources (such as CPU). For example, it may do the following:</p> <ul> <li>Filter nodes based on available resources</li> <li>Rank nodes using a priority algorithm on a scale of 0-10</li> </ul>"},{"location":"kubernetes/architecture/#controllers","title":"Controllers","text":"<p>Controllers are responsible for monitoring the system and ensuring that desired state is maintained. They can be downloaded as a service and run on the master node.</p>"},{"location":"kubernetes/architecture/#node-controllers","title":"Node Controllers","text":"<p>Node controllers are responsible for monitoring the status of nodes and ensuring that they are running. They check the status of nodes every 5 seconds, and if a node becomes unreachable, they wait 40 seconds before marking it as unreachable.</p>"},{"location":"kubernetes/architecture/#replication-controllers","title":"Replication Controllers","text":"<p>Replication controllers are responsible for ensuring that the desired number of pods are running. If there are not enough pods, they will create new ones to meet the desired count.</p>"},{"location":"kubernetes/architecture/#worker-nodes","title":"Worker Nodes","text":"<p>Worker nodes host applications as containers.</p>"},{"location":"kubernetes/architecture/#container-runtime-engine","title":"Container Runtime Engine","text":"<p>The container runtime engine is responsible for running and managing containers on the node. An example of a container runtime engine is Docker.</p>"},{"location":"kubernetes/architecture/#kubelet","title":"Kubelet","text":"<p>The kubelet is an agent that runs or creates pods on the node. It is responsible for registering the node with the cluster.</p>"},{"location":"kubernetes/architecture/#kube-proxy","title":"Kube-proxy","text":"<p>The kube-proxy can be run as a service and is installed on each node in the cluster. It creates iptables rules to facilitate communication between worker nodes.</p>"},{"location":"kubernetes/architecture/#pods","title":"Pods","text":"<p>A pod is the basic execution unit in Kubernetes and is where a container lives. It is recommended to have one container per pod, but helper containers can also be deployed with the main container.</p>"},{"location":"kubernetes/backup/","title":"Backup","text":""},{"location":"kubernetes/backup/#get-all-services","title":"get all services","text":"<p><code>kubectl get all --all-namespaces -o yaml &gt; all-deploy.yaml</code></p>"},{"location":"kubernetes/backup/#tools","title":"Tools","text":"<p>VELERO</p>"},{"location":"kubernetes/backup/#etcd-cluster-backup","title":"ETCD cluster backup","text":"<p>--data-dir  /var/lib/etcd</p> <p><code>etcdctl snapshot save snapshot.db</code></p> <p><code>service kube-apiserver stop</code></p> <p><code>etcdctl snapshot restore snapshot.db --data-dir /var/lib/etcd-from-backup</code></p> <p><code>systemctl daemon-reload</code> <code>systemctl etcd restart</code></p>"},{"location":"kubernetes/backup/#etcd-need-keys-for-that-command","title":"etcd need keys for that command","text":""},{"location":"kubernetes/deployments/","title":"Deployments","text":""},{"location":"kubernetes/deployments/#deployment","title":"Deployment","text":"<p>upgrade pods</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: myapp\n    type: front-end\nspec:\n template:\n    metadata:\n      name: myapp-pod\n      labels:\n        app: myapp\n        type: front-end\n    spec:\n     containers:\n     - name: nginx-container\n       image: nginx\n replicas: 3\n selector:\n   matchLabels:\n    type: front-end\n</code></pre> <p><code>kubectl create -f deployment.yml</code> <code>kubectl get deployments</code> because it automaticly creates replicasets <code>kubectl get replicas</code></p> <p><code>kubectl get pods</code></p> <p><code>kubectl get all</code></p>"},{"location":"kubernetes/deployments/#describe","title":"Describe","text":"<p><code>kubectl describe deployment name</code></p>"},{"location":"kubernetes/deployments/#create-deployment-manually","title":"create deployment manually","text":"<p><code>kubectl create deployment webapp --image=kodekloud/webapp-color --replicas=3</code></p>"},{"location":"kubernetes/image-security/","title":"Image Security","text":""},{"location":"kubernetes/image-security/#image-security","title":"IMAGE security","text":"<p>nginx is the same as nginx/nginx</p> <p>The default registry is docker.io Google's registry is gcr.io</p> <p>To login to a private registry:</p> <pre><code>docker login private-registry\n</code></pre> <p>To create a secret for a private registry:</p> <pre><code>kubectl create secret docker-registry regcred \\\n  --docker-server=private-registry.io \\\n  --docker-username=registry-user \\\n  --docker-password=registry-password \\\n  --docker-email=registry-user@org.com\n</code></pre> <p>To use the secret in a pod:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\nspec:\n  containers:\n  - name: nginx\n    image: private-registry.io/apps/internal-app\n  imagePullSecrets:\n  - name: regcred\n</code></pre> <p>To run a container as a different user:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\nspec:\n  containers:\n  - name: nginx\n    image: private-registry.io/apps/internal-app\n  imagePullSecrets:\n  - name: regcred\n  securityContext:\n    runAsUser: 1000\n    capabilities:\n      add: [\"MAC_ADMIN\"]\n</code></pre>"},{"location":"kubernetes/lifecycle/","title":"Lifecycle","text":""},{"location":"kubernetes/lifecycle/#lifecycle","title":"lifecycle","text":""},{"location":"kubernetes/lifecycle/#rollout-and-versioning","title":"rollout and versioning","text":"<p>when create deploiment it triggers rollout and it creates revision when container updaited new revision is created. this helps tracking of changes end gives ability to rollback</p> <p><code>kubectl rollout status deployment/myapp-deployment</code></p> <p><code>kubectl rollout history deployment/myapp-deployment</code></p>"},{"location":"kubernetes/lifecycle/#deploiment-strategies","title":"deploiment strategies","text":""},{"location":"kubernetes/lifecycle/#recreate","title":"recreate","text":"<p>delete all and crate news</p>"},{"location":"kubernetes/lifecycle/#rolling-update","title":"rolling update","text":"<p>replace one by one</p> <p>new replacasets will be created.</p>"},{"location":"kubernetes/lifecycle/#update-using-kubectl-apply","title":"update using kubectl apply","text":""},{"location":"kubernetes/lifecycle/#kubectl-set-image-but-not-good-idea","title":"kubectl set image == but not good idea","text":""},{"location":"kubernetes/lifecycle/#rollback","title":"Rollback","text":"<p><code>kubectl rollout undo deployment/myapp-deployment</code></p>"},{"location":"kubernetes/lifecycle/#_1","title":"Lifecycle","text":""},{"location":"kubernetes/maintanence/","title":"Maintenance","text":""},{"location":"kubernetes/maintanence/#_1","title":"Maintenance","text":"<p>if node is down 5 minute, it considered as dead if it will be replicated to another node pod eviction is 5 minute</p>"},{"location":"kubernetes/maintanence/#drain-node","title":"Drain node","text":"<p><code>kubectl node drain-1</code> moves nodes node becomes unshedulable reboot <code>kubectl uncordon node-1</code> <code>kubectl cordon node-1</code> -make unshedulable but not move pods</p>"},{"location":"kubernetes/maintanence/#vesionin","title":"Vesionin","text":"<p>v1.1.1 major,minor,patch</p>"},{"location":"kubernetes/maintanence/#upgrade-versions-of-kubernetes","title":"upgrade versions of kubernetes","text":""},{"location":"kubernetes/maintanence/#kubeadm-only-cluseter","title":"kubeadm , only cluseter","text":"<p><code>kubectl upgrade plan</code> <code>kubectl upgrade apply v1.12.0</code></p>"},{"location":"kubernetes/maintanence/#upgdare-master-first","title":"upgdare master first","text":""},{"location":"kubernetes/maintanence/#upgrade-strategies","title":"upgrade strategies","text":""},{"location":"kubernetes/maintanence/#all-nodes-together","title":"all nodes together","text":""},{"location":"kubernetes/maintanence/#upgrade-one-node-at-time","title":"upgrade one node at time","text":"<p>move pords to another nodes</p>"},{"location":"kubernetes/maintanence/#create-new-node-with-new-version","title":"create new node with new version","text":"<p>move pods to that and delete old</p>"},{"location":"kubernetes/maintanence/#take-back-not-for-maintenance","title":"take back not for maintenance","text":"<p><code>kubectl drain node01 --ignore-daemonsets</code> moved pods to another node now we update that node <code>kubectl uncordon node01</code></p>"},{"location":"kubernetes/maintanence/#noschedule-but-keep-apps","title":"noschedule but keep apps","text":"<p><code>kubectl cordon node01</code></p>"},{"location":"kubernetes/maintanence/#cluster-version","title":"Cluster version","text":"<p><code>kubectl get nodes</code></p>"},{"location":"kubernetes/maintanence/#update-version-in-cluster","title":"update version in cluster","text":"<ol> <li>drain nodes</li> <li>upate 3.systemctl restart daemon and kubelet</li> <li>kubectl uncordon</li> </ol>"},{"location":"kubernetes/maintanence/#in-node","title":"in node","text":"<p>we need kubeadm upgrade node too</p>"},{"location":"kubernetes/maintanence/#etcd-backup","title":"ETCD backup","text":"<p><code>ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 \\  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\  --cert=/etc/kubernetes/pki/etcd/server.crt \\  --key=/etc/kubernetes/pki/etcd/server.key \\  snapshot save /opt/snapshot-pre-boot.db</code></p>"},{"location":"kubernetes/maintanence/#etcd-restore","title":"ETCD restore","text":"<p><code>ETCDCTL_API=3 etcdctl  --data-dir /var/lib/etcd-from-backup snapshot restore /opt/snapshot-pre-boot.db</code></p> <p>update /etc/kubernetes/manifests/etcd.yaml  and update volume:hostapath   and VolimeMount</p>"},{"location":"kubernetes/maintanence/#check-membrs-from-external-etcd","title":"check membrs from external etcd","text":"<p><code>ETCDCTL_API=3 etcdctl \\  --endpoints=https://127.0.0.1:2379 \\  --cacert=/etc/etcd/pki/ca.pem \\  --cert=/etc/etcd/pki/etcd.pem \\  --key=/etc/etcd/pki/etcd-key.pem \\   member list</code></p>"},{"location":"kubernetes/maintanence/#get-link-for-snapshot","title":"get link for snapshot","text":"<p><code>kubectl describe  pods -n kube-system etcd-cluster1-controlplane  | grep advertise-client-urls</code></p>"},{"location":"kubernetes/maintanence/#get-all-keys","title":"get all keys","text":"<p><code>kubectl describe  pods -n kube-system etcd-cluster1-controlplane  | grep pki</code></p>"},{"location":"kubernetes/monitoring/","title":"Monitoring","text":""},{"location":"kubernetes/monitoring/#logging-and-monitoring","title":"logging and monitoring","text":"<p>kubelet contains anther tool named Cadvisor whhich monitors perfomance</p>"},{"location":"kubernetes/monitoring/#enable-with-minikube","title":"enable with minikube","text":"<p><code>minikube addons enable  metrics-server</code></p>"},{"location":"kubernetes/monitoring/#other","title":"other","text":"<p><code>git clone https://github.com/kodekloudhub/kubernetes-metrics-server.git</code></p>"},{"location":"kubernetes/monitoring/#show-stats","title":"show stats","text":"<p><code>kubectl top node</code> <code>kubectl top pod</code></p>"},{"location":"kubernetes/monitoring/#docker-logs","title":"docker  logs","text":"<p><code>docker log -f dockername</code></p> <p><code>kubectl logs -f podname</code></p>"},{"location":"kubernetes/monitoring/#if-in-pods-are-miltiple-container-u-have-to-specify-name","title":"if in pods are miltiple container u have to specify name","text":""},{"location":"kubernetes/namespaces/","title":"Namespaces","text":""},{"location":"kubernetes/namespaces/#default-namespace","title":"default namespace","text":"<p>kubernetes default uses namespace named default , kubesystem and kubepublic</p> <p>when service is created dns name automaticly assigned resources in namespace can refer by its name</p> <p><code>.connect(\"db-service\")</code></p>"},{"location":"kubernetes/namespaces/#to-connect-database-in-another-namspace","title":"to connect database in another namspace","text":"<p><code>.connect(\"db-service.namespace.service.domain.domainlocal\")</code></p> <p><code>kubectl get pods --namespace=anothername</code></p>"},{"location":"kubernetes/namespaces/#creating-pods-in-namespace","title":"creating pods in namespace","text":"<p><code>kubectl create -f pod.yml --namespace=dev</code> or add namespace under metadata section in yml</p>"},{"location":"kubernetes/namespaces/#creating-namespaces","title":"creating namespaces","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev\n</code></pre> <p><code>kubectl create -f namespace-dev.yaml</code> <code>kubectl create namespace dev</code></p>"},{"location":"kubernetes/namespaces/#set-default-namespace-for-command","title":"set default namespace for command","text":"<p><code>kubectl config set-context $(kubectl config current-context) --namespace=dev</code> <code>kubectl get pods</code></p>"},{"location":"kubernetes/namespaces/#show-pods-in-all-namespaces","title":"show pods in all namespaces","text":"<p><code>kubectl get pods --all-namespaces</code></p>"},{"location":"kubernetes/namespaces/#limit-resources-in-namespace-using-resourcequota","title":"limit resources in namespace using ResourceQuota","text":"<p><code>`yml `apiVersion: v1 kind: ResourceQuota metadata:   name: compute-quota   namespace: dev spec:   hard:     pods: \"10\"     requests.cpu: \"4\"     requests.memory: 5Gi     limits.cpu: \"10\"     limits.memory: 10Gi</code></p> <p><code>kubectl create -f quota.yml</code></p>"},{"location":"kubernetes/newtwork/","title":"Network","text":"<ul> <li>Ingress   ingress:</li> <li>from:<ul> <li>podSelector:     matchLabels:       role: api-pod ports:</li> <li>protocol: TCP   port: 3306</li> </ul> </li> </ul>"},{"location":"kubernetes/pods/","title":"Pods","text":""},{"location":"kubernetes/pods/#pods-yaml","title":"pods yaml","text":"<pre><code>apiVersion: apps/v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\n    type: front-end\nspec:\n   containers:\n   - name: nginx-container\n     image: nginx\n</code></pre> <p><code>kubectl create -f pod.yml</code></p> <p>show pods <code>kubectl get pods</code></p> <p>show detail info</p>"},{"location":"kubernetes/pods/#create-simple-yml-file","title":"create simple yml file","text":"<p><code>kubectl run redis --image=redis123 --dry-run=client -o yaml &gt; redis-definition.yaml</code></p>"},{"location":"kubernetes/pods/#apply-changes","title":"apply changes","text":"<p><code>kubectl apply -f redis-definition.yaml</code></p>"},{"location":"kubernetes/pods/#add-tolerration-to-pods","title":"add tolerration to pods","text":"<pre><code>apiVersion: apps/v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\n    type: front-end\nspec:\n   containers:\n   - name: nginx-container\n     image: nginx\n\n   tolerration:\n   -key:app \n   operator: \"equal\"\n   value: blue\n   effect: Noschedle | PreferNoSchedule|NoExecute\n</code></pre>"},{"location":"kubernetes/pods/#limit-resource","title":"limit resource","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp-color\n  labels:\n    name: simple-webapp-color\nspec:\n containers:\n - name: simple-webapp-color\n   image: simple-webapp-color\n   ports:\n    - containerPort:  8080\n   resources:\n     requests:\n      memory: \"1Gi\"\n      cpu: \"1\"\n</code></pre>"},{"location":"kubernetes/pods/#default-pods-vcpu-value-is-1-and-512-mi-memory","title":"default pods VCPU value is 1 and 512 Mi memory","text":"<p>pods can use more memory that needed but it  is permanently it will be terminated</p>"},{"location":"kubernetes/pods/#static-pods","title":"Static pods","text":"<p>if we have only kubelet on server ,but kubelet can create pods. we can provide kubelet to read pod definition files.</p> <p>we can add yml files /etc/kubernetes/manifests/ folder and kubelet automaticly create this pods. if we delete that file. pod will be removed. it works only with Pods. we can add service parameter to change path --pod-manifest-path=/home/davit/kubemanifest</p> <p>or kubeconfig.yaml if it is  not service.</p> <p>use docker ps to see pods</p>"},{"location":"kubernetes/pods/#use-custom-sheduler","title":"use custom sheduler","text":"<p>under spec:   schedulerName: custom-scheduler</p>"},{"location":"kubernetes/pods/#view-events","title":"view events","text":"<p><code>kubectl get events</code></p>"},{"location":"kubernetes/pods/#get-all-pods","title":"get all pods","text":"<p><code>kubectl get pods --all-namespaces</code></p>"},{"location":"kubernetes/pods/#pod-sample","title":"pod sample","text":"<p><code>kubectl run redis --image=redis:alpine --dry-run=client -o yaml &gt; redis.yaml</code></p>"},{"location":"kubernetes/pods/#exmpose-pod-directly-nodeport","title":"exmpose pod directly NodePort","text":"<p><code>kubect run custom-nginx --image=ngin --port=8080</code></p>"},{"location":"kubernetes/pods/#expose-pod-clusterip","title":"expose pod ClusterIp","text":"<p><code>kubectl run httpd --image=httpd:alpine --port=80 --expose</code></p>"},{"location":"kubernetes/pods/#get-system-cluster-pods","title":"get system cluster pods","text":"<p><code>kubectl get pods --namespace kube-system</code></p>"},{"location":"kubernetes/pods/#filter-pods-by-selector","title":"filter pods by selector","text":"<p><code>kubectl get pods --selector env=dev</code></p>"},{"location":"kubernetes/pods/#get-all-objects-using-selector","title":"get all objects using selector","text":"<p><code>kubectl get all --selector env=prod</code></p>"},{"location":"kubernetes/pods/#multiple-selectors","title":"multiple selectors","text":"<p><code>kubectl get pods --selector env=prod,bu=finance,tier=frontend</code></p>"},{"location":"kubernetes/pods/#create-yaml-from-running-pod","title":"create yaml from running pod","text":"<p><code>kubectl get pod elephant -o yaml &gt; elep.yaml</code></p>"},{"location":"kubernetes/pods/#replace-pod-by-force","title":"replace pod by force","text":"<p><code>kubectl replace -f elephant.yaml --force</code></p>"},{"location":"kubernetes/pods/#detect-static-pods","title":"detect static pods","text":"<p>controlplane at the end of pods name</p>"},{"location":"kubernetes/pods/#get-wide-info-with-pods","title":"get wide info with pods","text":"<p><code>kubectl get pods -o wide</code></p>"},{"location":"kubernetes/pods/#add-arguments-to-pods","title":"add arguments to pods","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntu-sleeper-pod\nspec:\n containers:\n - name: ubuntu-sleeper\n   image: ubuntu-sleeper\n   command: [\"sleep2.0\"]\n   args: [\"10\"]\n</code></pre>"},{"location":"kubernetes/pods/#add-env-variables-in-yml","title":"add env variables in yml","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp-color\nspec:\n containers:\n - name: simple-webapp-color\n   image: simple-webapp-color\n   ports:\n   - containerPort: 8080\n   env:\n   - name: APP_COLOR\n     value: pink\n</code></pre>"},{"location":"kubernetes/pods/#add-env-with-configmaps","title":"add env with configmaps","text":"<p><code>kubectl create configmap app-config --from-literal=APP_COLOR=blue --from-literal=APP_MODE=prod</code> <code>kubectl create configmap app-config --from-file=app_config.properties (Another way)</code></p> <p>or </p> <p><code>yaml apiVersion: v1 kind: ConfigMap metadata:  name: app-config data:  APP_COLOR: blue  APP_MODE: prod</code></p> <p><code>kubectl get configmaps</code></p>"},{"location":"kubernetes/pods/#map-configmap","title":"map configmap","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp-color\nspec:\n containers:\n - name: simple-webapp-color\n   image: simple-webapp-color\n   ports:\n   - containerPort: 8080\n   envFrom:\n   - configMapRef:\n       name: app-config\n</code></pre>"},{"location":"kubernetes/pods/#we-can-inject-using-volumes-too","title":"we can inject using volumes too","text":""},{"location":"kubernetes/pods/#use-secrets-for-passwords","title":"use Secrets for passwords","text":"<p><code>kubectl create secret generic app-secret --from-literal=DB_Host=mysql --from-literal=DB_User=root --from-literal=DB_Password=paswrd</code> <code>kubectl create secret generic app-secret --from-file=app_secret.properties</code></p> <p><code>echo -n \"mysql\" | base64</code></p> <p><pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n name: app-secret\ndata:\n  DB_Host: bX1zcWw=\n  DB_User: cm9vdA==\n  DB_Password: cGFzd3Jk\n</code></pre> <code>kubectl create -f secret-data.yaml</code></p> <p><code>kubectl get secrets</code></p>"},{"location":"kubernetes/pods/#get-data","title":"get data","text":"<p><code>kubectl get secret app-secret -o yaml</code></p>"},{"location":"kubernetes/pods/#if-it-is-mounted-as-volume","title":"if it is mounted as Volume","text":"<p>each password will we as file like /opt/passwords</p>"},{"location":"kubernetes/pods/#multiple-container-pods","title":"multiple container pods","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp\n  labels:\n    name: simple-webapp\nspec:\n  containers:\n  - name: simple-webapp\n    image: simple-webapp\n    ports:\n    - ContainerPort: 8080\n  - name: log-agent\n    image: log-agent\n</code></pre>"},{"location":"kubernetes/replicasets/","title":"ReplicaSets","text":""},{"location":"kubernetes/replicasets/#replication-controller","title":"replication controller","text":"<p>Replication Controller is the older technology that is being replaced by a ReplicaSet. ReplicaSet is the new way to setup replication. automaticaly bring new pods if needed</p>"},{"location":"kubernetes/replicasets/#load-balancing-scaling","title":"Load balancing &amp; scaling","text":"<pre><code>apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: myapp-rc\n  labels:\n    app: myapp\n    type: front-end\nspec:\n template:\n    metadata:\n      name: myapp-pod\n      labels:\n        app: myapp\n        type: front-end\n    spec:\n     containers:\n     - name: nginx-container\n       image: nginx\n replicas: 3\n</code></pre> <p><code>kubectl create -f replica.yml</code></p> <p><code>kubectl get replicationcontroller</code></p> <pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: myapp-replicaset\n  labels:\n    app: myapp\n    type: front-end\nspec:\n template:\n    metadata:\n      name: myapp-pod\n      labels:\n        app: myapp\n        type: front-end\n    spec:\n     containers:\n     - name: nginx-container\n       image: nginx\n replicas: 3\n selector:\n   matchLabels:\n    type: front-end\n</code></pre> <p>replica set needs selector definition</p>"},{"location":"kubernetes/replicasets/#scale-replica-sets","title":"scale replica sets","text":"<p>update file</p> <p><code>kubectl replace -f replica.yml</code></p> <p><code>kubectl scale --replicas=6 -f replica.yml</code></p> <p><code>kubectl scale --replicas=6 replicaset myapp-replicaset</code></p>"},{"location":"kubernetes/replicasets/#delete-replicaset","title":"delete replicaset","text":"<p><code>kubectl delete replicaset myapp-replicaset</code> <code>kubectl delete --all namespaces</code></p>"},{"location":"kubernetes/replicasets/#get-replicasetso","title":"get replicasetso","text":"<p><code>kubectl get replicasets.apps</code></p>"},{"location":"kubernetes/replicasets/#describe","title":"describe","text":"<p><code>kubectl describe replicasets.apps new-replica-set</code></p>"},{"location":"kubernetes/replicasets/#get-version-of-replicaset","title":"get version of replicaset","text":"<p><code>kubectl explain replicaset | grep VERSION</code></p>"},{"location":"kubernetes/replicasets/#edit-replica-uses-editor-automaticaly","title":"edit replica, uses editor automaticaly","text":"<p><code>kubectl edit replicaset new-replica-set</code></p>"},{"location":"kubernetes/roles/","title":"Roles","text":""},{"location":"kubernetes/roles/#create-role","title":"CREATE ROLE","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: cluster-administrator\nrules:\n- apiGroups: [\"\"] # \"\" indicates the core API group\n  resources: [\"nodes\"]\n  verbs: [\"get\", \"list\", \"delete\", \"create\"]\n</code></pre> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: cluster-admin-role-binding\nsubjects:\n- kind: User\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: cluster-administrator\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/roles/#service-account-as-bot-account","title":"SERVICE ACCOUNT AS BOT ACCOUNT","text":"<p><code>kubectl create serviceaccount dashboard-sa</code> <code>kubectl get serviceaccounts</code></p> <p><code>kubectl describe serviceaccount dashboiard-sa</code></p>"},{"location":"kubernetes/roles/#get-secreet","title":"get secreet","text":"<p><code>kubectl describe secret dashboard-sa-token-kbbdm</code></p>"},{"location":"kubernetes/roles/#secrets-are-mounter-varrunsecretkubernetisioserviceaccount","title":"secrets are mounter /var/run/secret/kubernetis.io/serviceaccount","text":"<p>in Pod xml:   serviceAccount:dashboard-sa   automountServiceAccountToken: false</p>"},{"location":"kubernetes/roles/#get-roles","title":"get roles","text":"<p><code>kubectl get roles</code></p>"},{"location":"kubernetes/roles/#describe-role","title":"describe role","text":"<p><code>kubectl describe role kube-proxy -n kube-system</code></p>"},{"location":"kubernetes/roles/#describe-rolebinding","title":"describe rolebinding","text":"<p><code>kubectl describe rolebinding kube-proxy -n kube-system</code></p>"},{"location":"kubernetes/roles/#use-command-as-different-role","title":"use command as different role","text":"<p><code>--as dev-user</code></p>"},{"location":"kubernetes/roles/#create-role_1","title":"create role","text":"<pre><code>kind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: default\n  name: developer\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"list\", \"create\",\"delete\"]\n</code></pre>"},{"location":"kubernetes/roles/#create-rolebind","title":"create rolebind","text":"<pre><code>kind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: dev-user-binding\nsubjects:\n- kind: User\n  name: dev-user\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: developer\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/security/","title":"Security","text":""},{"location":"kubernetes/security/#cluster-cluster","title":"cluster cluster","text":"<p>who can acess? how: username and password username and tokens certificates externale auth providers - ldap service accounts</p>"},{"location":"kubernetes/security/#authorization","title":"authorization","text":"<p>RBAC - role based  ABAC NODE auth webhook mode</p>"},{"location":"kubernetes/security/#tls-sertificates","title":"TLS sertificates","text":""},{"location":"kubernetes/security/#between-applications","title":"between applications","text":"<p>all can access each other but it can be restricted with network policies</p>"},{"location":"kubernetes/security/#users","title":"Users","text":"<p>we can not create users in kubernetes but we can create service accounts <code>kubectl create service account</code></p>"},{"location":"kubernetes/security/#accounts","title":"accounts","text":"<p>managed by kube-apiserver authenticate user</p>"},{"location":"kubernetes/security/#static-file-auth","title":"static file auth","text":"<p>password,user,user_id,group --basic-auth-file = details.csv</p>"},{"location":"kubernetes/security/#static-token-file","title":"static token file","text":"<p>token,user,uid, group --token-auth-file = token.csv</p>"},{"location":"kubernetes/security/#ssl-tls-sertificates","title":"SSL TLS sertificates","text":""},{"location":"kubernetes/security/#creting-certificates","title":"creting certificates","text":"<p>private key <code>openssl genrsa -out ca.key 2048</code> specify name of what is for. this is signing <code>openssl req -new -key ca.key -subj \"/CN=KUBERNETES-CA\" -out ca.csr</code> sign request. this is self signed <code>openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt</code></p>"},{"location":"kubernetes/security/#generate-client-certificeates","title":"generate client certificeates","text":"<p><code>openssl genrsa -out admin.key 2048</code> this name is for logs mostly <code>openssl req -new -key ca.key -subj \"/CN=kube-admin\" -out admin.csr</code> we must mention group details in signing request <code>openssl x509 -req -in admin.csr -CA ca.crt -CAkey  ca.key -out admin.crt</code></p>"},{"location":"kubernetes/security/#why-we-need-certs","title":"why we need certs","text":"<p>we cen auth to kluster apiserver using this key or in cluster definiton we can add this keys</p>"},{"location":"kubernetes/security/#ca-root-certificates-needed-for-client","title":"CA root certificates needed for client","text":"<p>if there is more dns names we have create openssl conf</p>"},{"location":"kubernetes/security/#user-kubelet-certificates-by-its-node-names","title":"user kubelet certificates by its node names","text":"<p>to dermined which node is requested</p> <p>name: system:node:node01 system:node:node02</p>"},{"location":"kubernetes/security/#view-certificates","title":"view certificates","text":"<p>kubeadm automaitlcy deploys certs</p> <p><code>openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout</code></p>"},{"location":"kubernetes/security/#what-if-new-admin-comes","title":"what if new admin comes","text":"<p>CA server - pair of certificates files certificates key is on CA server.</p>"},{"location":"kubernetes/security/#certificates-api","title":"certificates API","text":"<p>create CertificateeSigningRequest object and can be reviewd approved </p>"},{"location":"kubernetes/security/#how-it-is-done","title":"how it is done","text":"<p><code>openssl genrsa -out jane.key 204</code></p> <p><code>openssl req -new -key jane.key -subj =\"/CN=jane\" out -jane.csr</code></p> <pre><code>apiVersion: certificates.k8s.io/v1beta1\nkind: CertificateSigningRequest\nmetadata:\n  name: jane\nspec:\n  groups:\n  - system:authenticated\n  usages:\n  - digital signature\n  - key encipherment\n  - server auth\n  request:\n    &lt;certificate-goes-here&gt;\n</code></pre> <p><code>cat jane.csr |base64</code> &gt; and paster in requet above </p>"},{"location":"kubernetes/security/#show-request","title":"show request","text":"<p><code>kubectl get csr</code></p>"},{"location":"kubernetes/security/#aprove-requests","title":"aprove requests","text":"<p><code>kubectl certificate approve jane</code></p> <p>it automaticly generates  client certificates</p> <p><code>kubectl get csr jane -o yaml</code></p> <p><code>echo cert| base --decode</code> and share to user</p>"},{"location":"kubernetes/security/#all-the-certificates-are-managed-by-controller-manager","title":"all the certificates are managed by controller manager","text":""},{"location":"kubernetes/security/#kubeconfigtes","title":"kubeconfigtes","text":"<p>default config <code>.kube/config</code></p> <ul> <li>clusters</li> <li>development</li> <li>production</li> <li>google</li> <li>contexts</li> <li>admin@production</li> <li>google@production</li> <li>Users</li> <li>admin</li> <li>dev</li> </ul>"},{"location":"kubernetes/security/#view-config","title":"view config","text":"<p><code>kubectl config view</code> <code>kubectl config use-context prod-user@production</code> <code>kubectl config -h</code></p>"},{"location":"kubernetes/security/#config-namespaces","title":"config namespaces","text":"<p>add namespace in config to switch automaticly</p>"},{"location":"kubernetes/security/#api-group","title":"api group","text":"<p>curl http://localhost:6443 -k and add certs</p> <p>or kubectl proxy  it is not kube proxy</p>"},{"location":"kubernetes/security/#authorization-what-they-can-do","title":"authorization - what they can do","text":""},{"location":"kubernetes/security/#different-types-of-authorization","title":"different types of authorization","text":"<ul> <li>node</li> <li>abac</li> <li>can view pod</li> <li>can delete pod</li> <li>needs policie definiton file</li> <li>it is bad practice</li> <li>RBAC</li> <li>we define role</li> <li>associate role to users</li> <li>webhook</li> <li>we need auth to be managed to another tool</li> <li> <p>for example open policy agent</p> </li> <li> <p>AlwaysAllow</p> </li> <li>AllwaysDeny systemctl - &gt; --authorization-mode= </li> </ul>"},{"location":"kubernetes/security/#authorization_1","title":"authorization","text":""},{"location":"kubernetes/security/#abac","title":"abac","text":"<p>dev-user - access using policy file in json format. every time we need change we have to change file and restart server</p>"},{"location":"kubernetes/security/#rbac","title":"RBAC","text":"<ul> <li>create roles and add users to this role</li> </ul>"},{"location":"kubernetes/security/#webhook","title":"webhook","text":"<p>openpolycyagent third party auth</p>"},{"location":"kubernetes/security/#alwaysallow-and-allwaysdeny","title":"AlwaysAllow and AllwaysDeny","text":"<p>by default is AlwaysAllow</p> <p>--authorization-mode=None,RBAC,Webhook</p>"},{"location":"kubernetes/security/#certificate-apprval-example","title":"certificate apprval example","text":"<p><code>cat akshay.csr | base64 -w 0</code> -w - wrap 0 `--- apiVersion: certificates.k8s.io/v1 kind: CertificateSigningRequest metadata:   name: akshay spec:   groups:   - system:authenticated   request: CCCCCCC   signerName: kubernetes.io/kube-apiserver-client   usages:   - client auth`` ```</p>"},{"location":"kubernetes/security/#check-status","title":"check status","text":"<p><code>kubectl get csr</code></p>"},{"location":"kubernetes/security/#approve-csr","title":"approve csr","text":"<p><code>kubectl certificate approve akshay</code></p>"},{"location":"kubernetes/security/#get-detals-of-cst","title":"get  detals of cst","text":"<p><code>kubectl get csr agent-smith -o yaml</code></p>"},{"location":"kubernetes/security/#deny-reject","title":"deny reject","text":"<p><code>kubectl certificate deny agent-smith</code></p>"},{"location":"kubernetes/security/#delete-csr","title":"delete csr","text":"<p><code>kubectl delete csr agent-smith</code></p>"},{"location":"kubernetes/services/","title":"Services","text":""},{"location":"kubernetes/services/#services","title":"Services","text":"<p>Services enables communication between various components within and outside of the application.</p>"},{"location":"kubernetes/services/#service-types","title":"Service types","text":""},{"location":"kubernetes/services/#nodeport","title":"NodePort","text":"<p>Where the service makes an internal POD accessible on a POD on the NODE. Where the service makes an internal POD accessible on a POD on the NODE. </p> <p><pre><code>apiVersion: v1\nkind: Service\nmetadata:\n name: myapp-service\nspec:\n types: NodePort\n ports:\n - targetPort: 80\n   port: 80\n   nodePort: 30008\n selector:\n   app:myapp\n   type:front-end\n</code></pre> if there is multiple pods in same node it will load balance</p> <p>else we can access it like ip:port</p> <p><code>kubectl create -f service-definition.yaml</code> <code>kubectl get services</code></p>"},{"location":"kubernetes/services/#cluserip","title":"CluserIP","text":"<p>in nodes if there is multiple applications like fronted backend , db they need to communicate to each other. but communicate with ip is not opation they will change CluserIP gives ability to group this pods under one name and give other pods to access with name.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n name: back-end\nspec:\n types: ClusterIP\n ports:\n - targetPort: 80\n   port: 80\n selector:\n   app: myapp\n   type: back-end\n</code></pre> <p><code>kubectl get services</code></p>"},{"location":"kubernetes/services/#loadbalacer","title":"LoadBalacer","text":"<p>we can instlal load balancer  like HA or nginx and add node ports . we can user native cloud balancer  useing LoadBalacer service. </p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n name: back-end\nspec:\n types: LoadBalacer\n ports:\n - targetPort: 80\n   port: 80\n selector:\n   app: myapp\n   type: back-end\n</code></pre>"},{"location":"kubernetes/services/#create-sample-yaml-file","title":"create sample yaml file","text":"<p><code>kubectl run redis --image=redis:alpine --dry-run=client -o yaml &gt; redis.yaml</code></p>"},{"location":"kubernetes/services/#create-service-from-command-line","title":"create service from command line","text":"<p><code>kubectl expose pod redis --name redis-service --port=3839</code></p>"},{"location":"kubernetes/sheduler/","title":"Scheduler","text":""},{"location":"kubernetes/sheduler/#sheduler","title":"sheduler","text":""},{"location":"kubernetes/sheduler/#manual-schedulin","title":"manual schedulin","text":"<p>every yml file pod definiton has nodename sheduler looks who doesnot have it and runs scheduling algorithm and binds pod to node</p> <p>if there is not scheduler pods will be in a pending state</p> <pre><code>spec:\n  nodeName: node02\n</code></pre> <p>we cann not update it after pod creation but we can update it with post request</p>"},{"location":"kubernetes/sheduler/#labels-and-selectors","title":"Labels and selectors","text":"<p>Labels are properties attached to items</p> <p>selectors help to filter labels</p> <pre><code> apiVersion: v1\n kind: Pod\n metadata:\n  name: simple-webapp\n  labels:\n    app: App1\n    function: Front-end\n spec:\n  containers:\n  - name: simple-webapp\n    image: simple-webapp\n    ports:\n    - containerPort: 8080\n</code></pre> <p><code>kubectl get pods --selector app=App1</code></p>"},{"location":"kubernetes/sheduler/#to-creaate-replicaset-with-connected-to-pods","title":"to creaate replicaset with connected to pods","text":"<pre><code> apiVersion: apps/v1\n kind: ReplicaSet\n metadata:\n   name: simple-webapp\n   labels:\n     app: App1\n     function: Front-end\n spec:\n  replicas: 3\n  selector:\n    matchLabels:\n     app: App1\n template:\n   metadata:\n     labels:\n       app: App1\n       function: Front-end\n   spec:\n     containers:\n     - name: simple-webapp\n       image: simple-webapp   \n</code></pre>"},{"location":"kubernetes/sheduler/#annotations","title":"annotations","text":"<p>annotations:   buildversion: 1.2 record other details for info </p>"},{"location":"kubernetes/sheduler/#taint-and-tolerations","title":"taint and tolerations","text":"<p>allow certain nodes to accept only specific pods</p> <p><code>kubectl taint nodes node1 app=blue:Noschedule</code></p>"},{"location":"kubernetes/sheduler/#node-affinity","title":"node affinity","text":"<p>certain pods to exact node</p> <p>in master taint automaticly is added</p> <p><code>kubectl describe node kubemaster | grep Taint</code></p>"},{"location":"kubernetes/sheduler/#node-selectors","title":"Node selectors","text":"<p>add nodeSelector in pods spec size: Large</p>"},{"location":"kubernetes/sheduler/#label-nodes","title":"label nodes","text":"<p><code>kubectl label nodes nodename size=Large</code></p> <p>limitation u can not  small or medium</p>"},{"location":"kubernetes/sheduler/#node-affinity_1","title":"node affinity","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n name: myapp-pod\nspec:\n containers:\n - name: data-processor\n   image: data-processor\n affinity:\n   nodeAffinity:\n     requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: size\n            operator: In\n            values: \n            - Large\n            - Medium\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n name: myapp-pod\nspec:\n containers:\n - name: data-processor\n   image: data-processor\n affinity:\n   nodeAffinity:\n     requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: size\n            operator: NotIn\n            values: \n            - Small\n            ```\n\n## requiredDuringSchedulingIgnoredDuringExecution \n\nonly this type of node\n\n## prefferedDuringSchedulingIgnoredDuringExecution \nif not found sheduler ignore affinity rules\n\n\n## requiredDuringSchedulingRequirdDuringExecution\nbad pods automaticly will be deleted\n\n\n## taint and toleration together\nto place exacly where we want\n\n## Daemon Sets\n\nfor example we want logging agent in all cluster and node\nor kube-proxy can be deployed as daemon set\n\n```yml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: monitoring-daemon\n  labels:\n    app: nginx\nspec:\n  selector:\n    matchLabels:\n      app: monitoring-agent\n  template:\n    metadata:\n     labels:\n       app: monitoring-agent\n    spec:\n      containers:\n      - name: monitoring-agent\n        image: monitoring-agent\n</code></pre> <p><code>kubectl get daemonset</code> <code>kubectl describe daemonset</code></p> <p>deemon sets uses node affinity and taint after 1.x verion before was nodeName:</p>"},{"location":"kubernetes/sheduler/#what-we-want-custom-sheduling-program","title":"what we want custom sheduling program.","text":"<p>kubernetes cluster can have multiple shedulers</p> <p>service options: --scheduler-name:custom-scheduler</p> <p>or name int /etc/kubernetes/manifest/kube-sheduler/yaml</p> <p>and add in command: --scheduler-name=custom-scheduler</p>"},{"location":"kubernetes/sheduler/#if-there-is-multiple-replicas-sheduler-only-one-is-active","title":"if there is multiple replicas sheduler only one is active","text":"<p>there is election process who will be leader</p> <p>where is parameter to aviod newly created schedulers to get leaders</p> <p>--lock-object-name=custom-scheduler</p>"},{"location":"kubernetes/sheduler/#get-logs","title":"get logs","text":"<p><code>kubectl logs custom-scheduler --name-space=kube-system</code></p>"},{"location":"kubernetes/sheduler/#add-taint-node","title":"add taint node","text":"<p><code>kubectl taint nodes nodes01 spray=mortein:NoSchedule</code></p>"},{"location":"kubernetes/sheduler/#remove-taint-node","title":"remove taint node","text":"<p><code>kubectl taint nodes controlplane node-role.kubernetes.io/master:NoSchedule-</code></p>"},{"location":"kubernetes/sheduler/#add-label-to-node","title":"add label to node","text":"<p><code>kubectl label node node01 color=blue</code></p>"},{"location":"kubernetes/sheduler/#get-all-daemonsets","title":"get all daemonsets","text":"<p><code>kubectl get daemonsets --all-namespaces</code></p>"},{"location":"kubernetes/sheduler/#describe-daemon-shedulet-pods","title":"describe daemon shedulet pods","text":"<p><code>kubectl describe daemonset kube-proxy --namespace=kube-system</code></p>"},{"location":"kubernetes/sheduler/#create-daemonset-yaml","title":"create daemonset yaml","text":"<p><code>kubectl create deployment elasticsearch --image=k8s.gcr.io/fluentd-elasticsearch:1.20 -n kube-system --dry-run=client -o yaml &gt; fluentd.yaml</code></p>"},{"location":"kubernetes/sheduler/#create-addidional-scheduler-from-file","title":"create addidional scheduler from file","text":"<p><code>kubectl create -n kube-system configmap my-scheduler-config --from-file=/root/my-scheduler-config.yaml</code></p>"},{"location":"openai/llm_perfomance/","title":"promt engineering","text":"<p>clear instructions split complex task into smaller sub task give gpt time to think test changes systematicly</p> <p>and provide reference text and use external tools</p>"},{"location":"openai/llm_perfomance/#knowledge-optmisation-rag","title":"knowledge optmisation (RAG)","text":""},{"location":"postgresql/tricks/","title":"PostgreSQL Speed Optimization for Advanced Programmers","text":"<p>When it comes to optimizing PostgreSQL, understanding the nuances of configuration, storage, and query structures is essential. This tutorial delves into some advanced tips and tricks to enhance your PostgreSQL's performance. </p>"},{"location":"postgresql/tricks/#1-connection-optimization","title":"1. Connection Optimization","text":""},{"location":"postgresql/tricks/#use-unix-socket-instead-of-tcpip-connection","title":"Use Unix Socket Instead of TCP/IP Connection","text":"<p>By default, local connections in PostgreSQL are made using a Unix-domain socket. If you're connecting to a server on the same machine, a Unix socket can be faster than a TCP/IP connection.</p> <p>Example: To benchmark the difference, you can use <code>pg_bench</code>.</p> <pre><code># Using TCP/IP\npg_bench -h localhost -U your_username your_database\n\n# Using Unix socket\npg_bench -h /var/run/postgresql -U your_username your_database\n</code></pre>"},{"location":"postgresql/tricks/#2-store-data-effectively","title":"2. Store Data Effectively","text":"<p>Storing data in an optimized manner can significantly speed up your queries.</p> <p>Example: Your initial table creation:</p> <pre><code>CREATE TABLE t_test(\n    v1 varchar(100),\n    i1 int,\n    v2 varchar(100),\n    i2 int\n);\n</code></pre> <p>A better way is to group similar data types together:</p> <p><pre><code>CREATE TABLE t_test(\n    v1 varchar(100),\n    v2 varchar(100),\n    i1 int,\n    i2 int\n);\n</code></pre> This can lead to better data locality and cache utilization.</p>"},{"location":"postgresql/tricks/#3-indexing-strategies","title":"3. Indexing Strategies","text":""},{"location":"postgresql/tricks/#add-indexes","title":"Add Indexes","text":"<p>Adding indexes can greatly speed up data retrieval times. However, they also add overhead to write operations. Thus, use them judiciously.</p> <p>Tip: If the text column is long, consider using the <code>hashtext</code> function to speed up operations.</p>"},{"location":"postgresql/tricks/#use-full-text-indexes","title":"Use Full Text Indexes","text":"<p>Full-text search is a technique to search a full-text database against user queries. PostgreSQL provides a way to both store and efficiently search through large volumes of text data.</p> <p>Example:</p> <pre><code>CREATE INDEX idx_gin ON t_test USING gin(to_tsvector('english', v1));\n\n-- Remember to adjust autovacuum settings for performance\nALTER TABLE t_test SET (autovacuum_vacuum_scale_factor = 0.02);\nALTER TABLE t_test SET (autovacuum_analyze_scale_factor = 0.01);\n</code></pre>"},{"location":"postgresql/tricks/#4-query-optimization","title":"4. Query Optimization","text":""},{"location":"postgresql/tricks/#composite-time-trickery","title":"Composite Time Trickery","text":"<p>Rather than unpacking the composite type in the SELECT clause, do it in the FROM clause for better readability and sometimes performance.</p> <p>Example:</p> <p>Instead of: <pre><code>SELECT (pgstattuple('t_email')).* as x;\n</code></pre></p> <p>Use: <pre><code>SELECT (x).* FROM pgstattuple('t_email') AS x;\n</code></pre></p>"},{"location":"postgresql/tricks/#use-fetch-size","title":"Use Fetch Size","text":"<p>When querying large datasets, consider adjusting the fetch size to improve retrieval performance.</p> <p>Example:</p> <pre><code>ALTER FOREIGN TABLE t_email OPTIONS (fetch_size '10000');\n</code></pre> <p>This will retrieve 10,000 rows in each batch from the foreign server, reducing the number of network round-trips required.</p>"},{"location":"postgresql/tricks/#5-regular-maintenance","title":"5. Regular Maintenance","text":"<p>Regular maintenance activities like running <code>VACUUM</code>, <code>ANALYZE</code>, and <code>REINDEX</code> can help in keeping your database optimized. Set up autovacuum processes, so these tasks are done automatically.</p> <p>Example:</p> <pre><code>-- Adjust autovacuum settings for a particular table\nALTER TABLE t_test SET (autovacuum_vacuum_scale_factor = 0.05);\nALTER TABLE t_test SET (autovacuum_analyze_scale_factor = 0.025);\n</code></pre>"},{"location":"postgresql/tricks/#6-partitioning-large-tables","title":"6. Partitioning Large Tables","text":"<p>Partitioning can be particularly useful for tables with a large amount of data. It allows the data to be broken down into smaller, more manageable pieces, and can improve query performance.</p> <p>Example: Using range partitioning on a date column:</p> <pre><code>CREATE TABLE t_orders (\n    order_id int,\n    order_date date,\n    ...\n) PARTITION BY RANGE (order_date);\n\nCREATE TABLE t_orders_2022 PARTITION OF t_orders FOR VALUES FROM ('2022-01-01') TO ('2023-01-01');\nCREATE TABLE t_orders_2023 PARTITION OF t_orders FOR VALUES FROM ('2023-01-01') TO ('2024-01-01');\n</code></pre>"},{"location":"postgresql/tricks/#7-using-connection-pooling","title":"7. Using Connection Pooling","text":"<p>Maintaining a large number of connections can be resource-intensive. Connection pooling can be a solution to manage connections and reduce overhead.</p> <p>Tip: Consider using <code>pgBouncer</code> or similar tools for connection pooling.</p>"},{"location":"postgresql/tricks/#8-offload-read-queries","title":"8. Offload Read Queries","text":"<p>If you have read-intensive workloads, consider using read replicas. They can offload the main database and lead to faster query executions.</p>"},{"location":"postgresql/tricks/#9-efficient-use-of-json-data","title":"9. Efficient Use of JSON Data","text":"<p>PostgreSQL has robust support for JSON and JSONB data types. Using the right functions and operators can help in optimizing queries on JSON data.</p> <p>Example: Create an index on a JSONB column:</p> <pre><code>CREATE INDEX idx_jsonb_data ON t_test USING gin(data jsonb_path_ops);\n</code></pre>"},{"location":"postgresql/tricks/#10-caching-strategy","title":"10. Caching Strategy","text":"<p>The effective use of caching mechanisms like <code>pg_stat_statements</code> can help in identifying and optimizing frequently executed queries.</p> <p>Example: To view the most frequently executed queries:</p> <pre><code>SELECT * FROM pg_stat_statements ORDER BY calls DESC;\n</code></pre>"},{"location":"postgresql/tricks/#11-use-materialized-views","title":"11. Use Materialized Views","text":"<p>Materialized views are a way to cache the result of a query physically and can be refreshed periodically. They can improve performance for repetitive and complex queries.</p> <p>Example:</p> <pre><code>CREATE MATERIALIZED VIEW mat_view_sales AS \nSELECT product_id, SUM(sales) \nFROM sales_data \nGROUP BY product_id;\n\n-- Refresh the view periodically\nREFRESH MATERIALIZED VIEW mat_view_sales;\n</code></pre>"},{"location":"postgresql/tricks/#12-monitoring-and-logging","title":"12. Monitoring and Logging","text":"<p>Keeping an eye on the logs and using tools like <code>pg_stat_activity</code> and <code>pgBadger</code> can provide insights into slow queries and other performance issues.</p>"},{"location":"postgresql/tricks/#more-tricks","title":"More Tricks","text":"<p>Slow Query 1: <pre><code>SELECT developper.name\nFROM developper\nLEFT JOIN talent ON developper.id = talent.foreign_id\nWHERE talent.id IS NULL;\n</code></pre></p> <p>Fast Query 1: <pre><code>SELECT developper.name\nFROM developper\nWHERE NOT EXISTS (SELECT 1 FROM talent WHERE developper.id = talent.foreign_id);\n</code></pre></p> <p>Slow Query 2: <pre><code>SELECT DISTINCT developper.name\nFROM developper, project\nWHERE developper.id = project.developer_id;\n</code></pre></p> <p>Fast Query 2: <pre><code>SELECT developper.name\nFROM developper\nJOIN project ON developper.id = project.developer_id;\n</code></pre></p> <p>Slow Query 3: <pre><code>SELECT * \nFROM developper\nORDER BY name DESC \nLIMIT 10;\n</code></pre></p> <p>Fast Query 3: <pre><code>SELECT * \nFROM developper \nORDER BY name \nLIMIT 10 OFFSET (SELECT COUNT(*) - 10 FROM developper);\n</code></pre></p> <p>Slow Query 4: <pre><code>SELECT developper.name\nFROM developper\nWHERE age &gt;= 20 AND age &lt;= 30;\n</code></pre></p> <p>Fast Query 4: <pre><code>SELECT developper.name\nFROM developper\nWHERE age BETWEEN 20 AND 30;\n</code></pre></p> <p>Slow Query 5: <pre><code>SELECT COUNT(*)\nFROM developper\nWHERE name IS NULL;\n</code></pre></p> <p>Fast Query 5: <pre><code>SELECT COUNT(name) - COUNT(*)\nFROM developper;\n</code></pre></p> <p>Slow Query 6: <pre><code>SELECT developper.name\nFROM developper\nWHERE name LIKE 'John%';\n</code></pre></p> <p>Fast Query 6: <pre><code>SELECT developper.name\nFROM developper\nWHERE name &gt;= 'John' AND name &lt; 'Joho';\n</code></pre></p> <p>Slow Query 7: <pre><code>SELECT *\nFROM developper\nWHERE id IN (SELECT developer_id FROM project WHERE status = 'completed');\n</code></pre></p> <p>Fast Query 7: <pre><code>SELECT developper.*\nFROM developper\nJOIN project ON developper.id = project.developer_id\nWHERE project.status = 'completed';\n</code></pre></p> <p>Slow Query 8: <pre><code>SELECT SUM(salary)\nFROM developper\nGROUP BY department_id\nHAVING SUM(salary) &gt; 10000;\n</code></pre></p> <p>Fast Query 8: <pre><code>SELECT department_id, SUM(salary) as total_salary\nFROM developper\nGROUP BY department_id\nHAVING total_salary &gt; 10000;\n</code></pre></p> <p>Slow Query 9: <pre><code>SELECT developper.name\nFROM developper, project\nWHERE developper.id = project.developer_id AND project.status = 'active';\n</code></pre></p> <p>Fast Query 9: <pre><code>SELECT developper.name\nFROM developper\nJOIN project ON developper.id = project.developer_id\nWHERE project.status = 'active';\n</code></pre></p> <p>Slow Query 10: <pre><code>SELECT developper.name\nFROM developper\nLEFT JOIN project ON developper.id = project.developer_id\nWHERE project.id IS NULL;\n</code></pre></p> <p>Fast Query 10: <pre><code>SELECT developper.name\nFROM developper\nWHERE NOT EXISTS (SELECT 1 FROM project WHERE developper.id = project.developer_id);\n</code></pre></p> <p>Slow Query 11: <pre><code>SELECT developper.name\nFROM developper\nWHERE UPPER(name) = 'JOHN';\n</code></pre></p> <p>Fast Query 11: <pre><code>-- Assuming there is an index on the `name` column.\nSELECT developper.name\nFROM developper\nWHERE name = 'John';\n</code></pre></p> <p>Slow Query 12: <pre><code>SELECT name, SUM(salary) \nFROM developper\nGROUP BY name\nORDER BY SUM(salary) DESC;\n</code></pre></p> <p>Fast Query 12: <pre><code>-- Use an alias to avoid computing SUM(salary) twice.\nSELECT name, SUM(salary) as total_salary \nFROM developper\nGROUP BY name\nORDER BY total_salary DESC;\n</code></pre></p> <p>Slow Query 13: <pre><code>SELECT developper.name\nFROM developper, skills\nWHERE developper.id = skills.developer_id AND skills.name = 'Python';\n</code></pre></p> <p>Fast Query 13: <pre><code>SELECT developper.name\nFROM developper\nJOIN skills ON developper.id = skills.developer_id\nWHERE skills.name = 'Python';\n</code></pre></p> <p>Slow Query 14: <pre><code>SELECT developper.name\nFROM developper\nWHERE id IN (SELECT developer_id FROM project WHERE status NOT IN ('completed', 'active'));\n</code></pre></p> <p>Fast Query 14: <pre><code>SELECT developper.name\nFROM developper\nJOIN project ON developper.id = project.developer_id\nWHERE project.status NOT IN ('completed', 'active');\n</code></pre></p> <p>Slow Query 15: <pre><code>SELECT developper.name\nFROM developper\nLEFT JOIN project ON developper.id = project.developer_id\nWHERE project.name IS NULL;\n</code></pre></p> <p>Fast Query 15: <pre><code>SELECT developper.name\nFROM developper\nWHERE NOT EXISTS (SELECT 1 FROM project WHERE developper.id = project.developer_id);\n</code></pre></p> <p>Slow Query 16: <pre><code>SELECT developper.name, COUNT(project.id)\nFROM developper, project\nWHERE developper.id = project.developer_id\nGROUP BY developper.name;\n</code></pre></p> <p>Fast Query 16: <pre><code>SELECT developper.name, COUNT(project.id)\nFROM developper\nJOIN project ON developper.id = project.developer_id\nGROUP BY developper.name;\n</code></pre></p> <p>Slow Query 17: <pre><code>SELECT developper.name\nFROM developper\nWHERE CHAR_LENGTH(name) &gt; 5;\n</code></pre></p> <p>Fast Query 17: <pre><code>-- Assuming there is an index on the `name` column.\nSELECT developper.name\nFROM developper\nWHERE LENGTH(name) &gt; 5;\n</code></pre></p> <p>Slow Query 18: <pre><code>SELECT developper.name\nFROM developper, project\nWHERE developper.id = project.developer_id AND project.status LIKE 'act%';\n</code></pre></p> <p>Fast Query 18: <pre><code>SELECT developper.name\nFROM developper\nJOIN project ON developper.id = project.developer_id\nWHERE project.status LIKE 'act%';\n</code></pre></p> <p>Slow Query 19: <pre><code>SELECT developper.name\nFROM developper\nWHERE age &gt; 20\nORDER BY age;\n</code></pre></p> <p>Fast Query 19: <pre><code>-- If there's an index on age, this will be faster.\nSELECT developper.name\nFROM developper\nWHERE age &gt; 20\nORDER BY age ASC;\n</code></pre></p> <p>Slow Query 20: <pre><code>SELECT developper.name\nFROM developper\nWHERE name &lt;&gt; '';\n</code></pre></p> <p>Fast Query 20: <pre><code>SELECT developper.name\nFROM developper\nWHERE name IS NOT NULL AND name != '';\n</code></pre></p>"},{"location":"programming/ai/","title":"Introduction to AI and its Subfields","text":"<p>Artificial Intelligence (AI) has become a cornerstone of modern technology and is shaping the future of numerous industries such as healthcare, finance, entertainment, and transportation. In this section, we'll delve into the history and evolution of AI and explore its various subfields.</p>"},{"location":"programming/ai/#history-and-evolution-of-ai","title":"History and Evolution of AI","text":"<p>The concept of AI isn't new. It dates back to ancient times, where myths and stories talked about artificial beings endowed with intelligence. However, the real pursuit of AI began in the mid-20th century.</p> <p>John McCarthy, widely known as the \"father of AI\", coined the term 'Artificial Intelligence' in 1956. Early AI research focused on problem-solving and symbolic methods. It wasn't until the 1990s and 2000s, with the advent of machine learning and subsequently deep learning, that we've seen the explosion of AI applications we have today.</p>"},{"location":"programming/ai/#subfields-of-ai","title":"Subfields of AI","text":"<p>Artificial Intelligence is a broad field and comprises several subfields. Here are a few key ones:</p>"},{"location":"programming/ai/#machine-learning-ml","title":"Machine Learning (ML)","text":"<p>Machine learning is a subset of AI that gives computers the ability to learn without being explicitly programmed. This learning is achieved by training algorithms on data. Machine learning includes various techniques like linear regression, decision trees, and support vector machines.</p>"},{"location":"programming/ai/#deep-learning-dl","title":"Deep Learning (DL)","text":"<p>Deep Learning is a subset of machine learning that uses artificial neural networks with several layers (hence the term \"deep\"). These models are inspired by the human brain and are designed to replicate the way humans learn.</p>"},{"location":"programming/ai/#natural-language-processing-nlp","title":"Natural Language Processing (NLP)","text":"<p>NLP is a subfield of AI that focuses on the interaction between computers and humans through language. It involves several tasks, including language translation, sentiment analysis, and speech recognition.</p>"},{"location":"programming/ai/#reinforcement-learning-rl","title":"Reinforcement Learning (RL)","text":"<p>Reinforcement Learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to achieve a goal. The agent learns from the consequences of its actions, rather than from being taught explicitly.</p> <p>In the upcoming sections, we will explore these topics in depth, providing you with a comprehensive understanding of each field and how they contribute to the larger AI landscape.</p>"},{"location":"programming/ai/#mathematical-foundations","title":"Mathematical Foundations","text":"<p>Before we delve deep into AI and Machine Learning, it's crucial to understand the mathematical foundations that form the basis of these technologies. This section will help you revise some basics and learn new concepts in linear algebra, probability, statistics, and calculus. No worries if you haven't done math for a while, we'll start with the basics and gradually progress to more advanced topics.</p>"},{"location":"programming/ai/#linear-algebra","title":"Linear Algebra","text":"<p>Linear algebra is fundamental in the field of machine learning. Concepts like vectors, matrices, and tensors form the data structures in machine learning, while operations such as dot product, matrix multiplication, and eigendecomposition are essential for understanding how machine learning algorithms work.</p>"},{"location":"programming/ai/#vectors-matrices-and-tensors","title":"Vectors, Matrices, and Tensors","text":"<p>Vectors are a sequence of numbers, matrices are 2D arrays of numbers, and tensors are n-dimensional arrays with n&gt;2. In Python, you can create vectors, matrices, and tensors using the numpy library.</p> <pre><code>import numpy as np\n\n# Creating a vector\nv = np.array([1, 2, 3])\nprint(\"Vector:\\n\", v)\n\n# Creating a matrix\nm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(\"Matrix:\\n\", m)\n\n# Creating a tensor\nt = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n              [[10, 11, 12], [13, 14, 15], [16, 17, 18]],\n              [[19, 20, 21], [22, 23, 24], [25, 26, 27]]])\nprint(\"Tensor:\\n\", t)\n</code></pre> <p>(Note: More advanced linear algebra topics will be continued...)</p>"},{"location":"programming/ai/#probability-and-statistics","title":"Probability and Statistics","text":"<p>Probability theory is the mathematical foundation of statistical machine learning. Concepts like random variables, probability distributions, expectation, and variance give us the tools to model the uncertainty inherent in machine learning algorithms.</p> <p>Statistics is the discipline that allows us to make inferences and decisions under uncertainty. Descriptive statistics summarize and organize characteristics of a data set. Inferential statistics, on the other hand, allow us to make inferences and predictions based on data.</p> <p>(Note: More advanced probability and statistics topics will be continued...)</p>"},{"location":"programming/ai/#calculus","title":"Calculus","text":"<p>Calculus, especially differential calculus, plays a vital role in machine learning. Many machine learning algorithms involve optimization. To find the optimal solution, we need to understand concepts like derivatives and gradients.</p> <p>(Note: More advanced calculus topics will be continued...)</p> <p>This concludes the introduction to mathematical foundations for AI. The upcoming sections will dive deeper into each of these areas, equipping you with the necessary mathematical knowledge to excel in AI.</p>"},{"location":"programming/ai/#introduction-to-deep-learning","title":"Introduction to Deep Learning","text":"<p>Deep Learning is a subset of machine learning that makes the computation of complex functions feasible by using artificial neural networks with many layers (hence the term \"deep\"). These methods have dramatically improved the state-of-the-art in fields like image recognition and speech recognition.</p>"},{"location":"programming/ai/#concept-of-artificial-neural-networks","title":"Concept of Artificial Neural Networks","text":"<p>The fundamental building block of deep learning is the artificial neural network. These networks are inspired by the structure of the human brain, where interconnected neurons work together to process and learn from information.</p> <p>A neural network consists of layers of nodes, where each node in a layer is connected to all nodes in the previous and next layers. Each connection has a weight, which the network adjusts during learning to minimize the difference between its predictions and actual values.</p> <pre><code># A simple example of creating a neural network using the keras library\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Initialize the constructor\nmodel = Sequential()\n\n# Add an input layer \nmodel.add(Dense(12, activation='relu', input_shape=(10,)))\n\n# Add one hidden layer \nmodel.add(Dense(8, activation='relu'))\n\n# Add an output layer \nmodel.add(Dense(1, activation='sigmoid'))\n</code></pre>"},{"location":"programming/ai/#forward-propagation-and-backpropagation","title":"Forward Propagation and Backpropagation","text":"<p>Forward propagation is the process by which the neural network generates predictions. It starts from the input layer and moves through the hidden layers, applying the weights and activation functions, until it reaches the output layer.</p> <p>Backpropagation, on the other hand, is the method used to update the weights in the neural network. After forward propagation, the network calculates the error between its prediction and the actual value. This error is then propagated backward through the network, adjusting the weights along the way.</p> <p>(Note: More detailed explanation on forward propagation and backpropagation will be continued...)</p>"},{"location":"programming/ai/#types-of-neural-networks","title":"Types of Neural Networks","text":"<p>There are several types of neural networks used in deep learning, including:</p>"},{"location":"programming/ai/#multi-layer-perceptrons-mlp","title":"Multi-Layer Perceptrons (MLP)","text":"<p>MLP, also known as vanilla neural networks, are the simplest form of artificial neural network. They consist of at least three layers: an input layer, an output layer, and one or more hidden layers.</p>"},{"location":"programming/ai/#convolutional-neural-networks-cnn","title":"Convolutional Neural Networks (CNN)","text":"<p>CNNs are primarily used for image processing, pattern recognition, and image classification. They consist of convolutional and pooling layers, followed by fully connected layers.</p>"},{"location":"programming/ai/#recurrent-neural-networks-rnn","title":"Recurrent Neural Networks (RNN)","text":"<p>RNNs are designed to recognize patterns in sequences of data, such as text, genomes, handwriting, or the spoken word. Unlike traditional neural networks, RNNs have \"memory\" in the sense that information cycles through a loop, allowing information to persist.</p>"},{"location":"programming/ai/#long-short-term-memory-lstm","title":"Long Short-Term Memory (LSTM)","text":"<p>LSTMs are a special kind of RNN that are capable of learning long-term dependencies. They're widely used in tasks that require remembering information for long periods.</p> <p>(Note: More detailed information on types of neural networks will be continued...)</p>"},{"location":"programming/ai/#training-deep-learning-models","title":"Training Deep Learning Models","text":"<p>Training a deep learning model involves feeding data through the network (forward propagation), calculating the error, and then adjusting the weights to minimize this error (backpropagation). This process is repeated for a number of iterations or until the model's performance is satisfactory.</p> <p>(Note: More advanced topics on training deep learning models will be continued...)</p> <p>This concludes the introduction to deep learning. The subsequent sections will elaborate more on these topics, allowing you to understand and apply deep learning techniques effectively.</p>"},{"location":"programming/ai/#specific-deep-learning-architectures","title":"Specific Deep Learning Architectures","text":"<p>In deep learning, different architectures of neural networks are suitable for different types of tasks. In this section, we'll explore a few significant deep learning architectures including CNNs, Transformers, and GANs.</p>"},{"location":"programming/ai/#cnn-architectures","title":"CNN Architectures","text":"<p>Convolutional Neural Networks (CNNs) have been instrumental in the field of computer vision. Over the years, researchers have proposed numerous CNN architectures. Let's look at a few:</p>"},{"location":"programming/ai/#resnet-residual-network","title":"ResNet (Residual Network)","text":"<p>ResNet, introduced by Microsoft, is famous for its \"skip connection\" feature, allowing it to have over a hundred layers without suffering from the vanishing gradient problem.</p>"},{"location":"programming/ai/#vgg-visual-geometry-group","title":"VGG (Visual Geometry Group)","text":"<p>VGG, developed by the Visual Geometry Group at Oxford, is known for its uniform architecture. It's straightforward and great at generalization but it's also resource-heavy.</p>"},{"location":"programming/ai/#inception","title":"Inception","text":"<p>The Inception network, also known as GoogLeNet, was developed by researchers at Google. It introduced the inception module, a building block that, among other things, allows for more efficient computation and deeper networks.</p> <p>(Note: More detailed explanation on CNN architectures will be continued...)</p>"},{"location":"programming/ai/#transformer-model","title":"Transformer Model","text":"<p>The Transformer model, introduced in the paper \"Attention is All You Need\", is a type of neural network architecture primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models handle variable-length input using only attention mechanisms, leading to more parallelizable computation.</p> <p>(Note: More detailed explanation on Transformer model will be continued...)</p>"},{"location":"programming/ai/#generative-adversarial-networks-gans","title":"Generative Adversarial Networks (GANs)","text":"<p>Generative Adversarial Networks (GANs) are a class of AI algorithms used in unsupervised machine learning, which involves two neural networks competing against each other. GANs can generate new data that follows the same patterns as the training set. This feature makes them useful in a variety of applications, including image synthesis, semantic image editing, style transfer, and image super-resolution.</p> <p>(Note: More detailed explanation on GANs will be continued...)</p> <p>The architectures mentioned above have led to substantial improvements in tasks such as image recognition, object detection, and language understanding. The upcoming sections will delve deeper into these architectures, helping you understand the inner workings and how to implement them.</p>"},{"location":"programming/ai/#natural-language-processing","title":"Natural Language Processing","text":"<p>Natural Language Processing (NLP) is a branch of AI that helps computers understand, interpret and manipulate human language. This section will introduce you to the basics of NLP and various text representation techniques, as well as more advanced NLP models and techniques.</p>"},{"location":"programming/ai/#basics-of-nlp-and-text-representation-techniques","title":"Basics of NLP and Text Representation Techniques","text":"<p>Processing natural language data involves several steps, starting from basic tokenization to complex parsing and semantic analysis. After processing, we often need to represent the text in a form that can be input to a machine learning or deep learning model.</p>"},{"location":"programming/ai/#bag-of-words","title":"Bag of Words","text":"<p>Bag of Words (BoW) is a simple and commonly used way to represent text for use in machine learning, which ignores syntax and even word order, but is effective for several tasks.</p>"},{"location":"programming/ai/#tf-idf","title":"TF-IDF","text":"<p>Term Frequency-Inverse Document Frequency (TF-IDF) is another way to represent text. It gives more weight to the more important words (i.e., words that are frequent in a document but not across documents).</p>"},{"location":"programming/ai/#word-embeddings","title":"Word Embeddings","text":"<p>Word Embeddings are dense vector representations where words with similar meanings are mapped to similar vectors.</p> <p>(Note: More advanced topics on text representation techniques will be continued...)</p>"},{"location":"programming/ai/#advanced-nlp-models-and-techniques","title":"Advanced NLP Models and Techniques","text":""},{"location":"programming/ai/#rnns-and-lstms","title":"RNNs and LSTMs","text":"<p>Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are effective for tasks involving sequential data, and they have been widely used in NLP for tasks such as text generation, sentiment analysis, and machine translation.</p>"},{"location":"programming/ai/#transformer-model_1","title":"Transformer Model","text":"<p>The Transformer model, as previously discussed, is a type of architecture that uses self-attention mechanisms and has become the go-to model for many NLP tasks.</p>"},{"location":"programming/ai/#language-models-like-gpt-and-bert","title":"Language Models like GPT and BERT","text":"<p>GPT (Generative Pre-trained Transformer) and BERT (Bidirectional Encoder Representations from Transformers) are large language models that have achieved state-of-the-art results on a variety of NLP tasks.</p> <p>(Note: More detailed topics on advanced NLP models and techniques will be continued...)</p> <p>This concludes the introduction to Natural Language Processing. The following sections will dive deeper into these areas, equipping you with the knowledge and skills needed to tackle various NLP tasks.</p>"},{"location":"programming/ai/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>Reinforcement Learning (RL) is an aspect of machine learning where an agent learns to behave in an environment, by performing certain actions and observing the results/rewards of those actions. This section will introduce key concepts in reinforcement learning and some fundamental algorithms.</p>"},{"location":"programming/ai/#concepts-of-agents-environment-states-actions-and-rewards","title":"Concepts of Agents, Environment, States, Actions, and Rewards","text":"<p>In RL, an agent takes actions in an environment to achieve a goal. The environment presents a state to the agent, the agent takes action based on this state, and then the environment presents a new state and a reward to the agent. The agent's objective is to learn to take actions that maximize the cumulative reward over time.</p> <pre><code># An illustrative example using OpenAI's gym library.\nimport gym\n\n# Create the environment\nenv = gym.make('CartPole-v1')\n\n# Initialize state\nstate = env.reset()\n\nfor t in range(1000):\n    env.render()  # You can visualize the environment using render\n    action = env.action_space.sample()  # Here we're just sampling random actions\n    state, reward, done, info = env.step(action)  # The agent takes a step in the environment\n    if done:\n        print(\"Episode finished after {} timesteps\".format(t+1))\n        break\n</code></pre>"},{"location":"programming/ai/#model-based-vs-model-free-reinforcement-learning","title":"Model-Based vs Model-Free Reinforcement Learning","text":"<p>In model-based RL, the agent has a model of the environment, i.e., it knows or learns the probabilities of landing in any state given the current state and action. In model-free RL, the agent doesn't have this knowledge and must learn entirely from trial-and-error.</p>"},{"location":"programming/ai/#algorithms-q-learning-sarsa-and-dqn","title":"Algorithms: Q-Learning, SARSA, and DQN","text":"<p>There are various algorithms for implementing reinforcement learning. Q-Learning and SARSA (State-Action-Reward-State-Action) are fundamental model-free methods that learn the value of taking each action in each state. Deep Q-Network (DQN) extends Q-Learning to large state-action spaces by using neural networks to approximate the Q-function.</p> <p>(Note: More detailed topics on RL algorithms will be continued...)</p> <p>This introduction provides a glimpse into the fascinating world of Reinforcement Learning. Subsequent sections will elaborate further on these topics, providing a deeper understanding and practical applications of various RL techniques.</p>"},{"location":"programming/ai/#calculus-extended","title":"CALCULUS EXTENDED","text":""},{"location":"programming/ai/#dot-product","title":"Dot Product","text":"<p>The dot product, or scalar product, is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors) and returns a single number. It is an essential operation in machine learning as it measures the similarity between vectors.</p> <p>In Python, you can compute the dot product between two vectors using the <code>numpy.dot()</code> function:</p> <pre><code>import numpy as np\n\n# Define two vectors\nv1 = np.array([1, 2, 3])\nv2 = np.array([4, 5, 6])\n\n# Compute the dot product\ndot_product = np.dot(v1, v2)\nprint(\"Dot Product:\\n\", dot_product)\n</code></pre>"},{"location":"programming/ai/#matrix-multiplication","title":"Matrix Multiplication","text":"<p>Matrix multiplication, also known as the matrix dot product, is a binary operation that produces a matrix from two matrices. It's a fundamental operation in machine learning and deep learning, often used for transforming data, training models, and more.</p> <p>In Python, you can compute the matrix multiplication between two matrices using the <code>numpy.matmul()</code> or <code>numpy.dot()</code> function:</p> <pre><code>import numpy as np\n\n# Define two matrices\nm1 = np.array([[1, 2], [3, 4]])\nm2 = np.array([[5, 6], [7, 8]])\n\n# Compute the matrix multiplication\nmat_mul = np.matmul(m1, m2)\nprint(\"Matrix Multiplication:\\n\", mat_mul)\n</code></pre>"},{"location":"programming/ai/#eigendecomposition","title":"Eigendecomposition","text":"<p>Eigendecomposition is the factorization of a matrix into a canonical form, whereby the matrix is represented in terms of its eigenvalues and eigenvectors. Only diagonalizable matrices can be factorized in this way. This is a common operation used for dimensionality reduction techniques like PCA.</p> <p>In Python, you can perform the eigendecomposition of a matrix using the <code>numpy.linalg.eig()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Compute the eigendecomposition\neigenvalues, eigenvectors = np.linalg.eig(m)\nprint(\"Eigenvalues:\\n\", eigenvalues)\nprint(\"Eigenvectors:\\n\", eigenvectors)\n</code></pre>"},{"location":"programming/ai/#vectormatrix-norms","title":"Vector/Matrix Norms","text":"<p>A vector norm is a measure of the \"length\" of a vector. For a matrix, the norm is a measure of \"magnitude\". The most common norm, often simply called \"the norm\" of a vector, is the L2 norm or Euclidean norm.</p> <p>In Python, you can calculate the norm of a vector or matrix using the <code>numpy.linalg.norm()</code> function:</p> <pre><code>import numpy as np\n\n# Define a vector and a matrix\nv = np.array([1, 2, 3])\nm = np.array([[1, 2], [3, 4]])\n\n# Compute the L2 norm (Euclidean norm)\nv_norm = np.linalg.norm(v)\nm_norm = np.linalg.norm(m)\nprint(\"Vector L2 norm:\\n\", v_norm)\nprint(\"Matrix Frobenius norm:\\n\", m_norm)\n</code></pre>"},{"location":"programming/ai/#inverse-of-a-matrix","title":"Inverse of a Matrix","text":"<p>The inverse of a matrix A is a matrix denoted as A^-1, such that when A is multiplied by A^-1 the result is the identity matrix I. Not all matrices have an inverse. This concept is crucial for solving systems of linear equations.</p> <p>In Python, you can compute the inverse of a matrix using the <code>numpy.linalg.inv()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[4, 7], [2, 6]])\n\n# Compute the inverse of the matrix\nm_inv = np.linalg.inv(m)\nprint(\"Inverse of Matrix:\\n\", m_inv)\n</code></pre>"},{"location":"programming/ai/#singular-value-decomposition-svd","title":"Singular Value Decomposition (SVD)","text":"<p>SVD is a factorization of a real or complex matrix. It has many practical applications in signal processing and statistics. In machine learning, it's often used for dimensionality reduction, noise reduction, and recommendation systems.</p> <p>In Python, you can perform the SVD of a matrix using the <code>numpy.linalg.svd()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Compute the Singular Value Decomposition\nU, S, VT = np.linalg.svd(m)\nprint(\"U:\\n\", U)\nprint(\"S:\\n\", S)\nprint(\"VT:\\n\", VT)\n</code></pre>"},{"location":"programming/ai/#vectormatrix-norms_1","title":"Vector/Matrix Norms","text":"<p>A vector norm is a measure of the \"length\" of a vector. For a matrix, the norm is a measure of \"magnitude\". The most common norm, often simply called \"the norm\" of a vector, is the L2 norm or Euclidean norm.</p> <p>In Python, you can calculate the norm of a vector or matrix using the <code>numpy.linalg.norm()</code> function:</p> <pre><code>import numpy as np\n\n# Define a vector and a matrix\nv = np.array([1, 2, 3])\nm = np.array([[1, 2], [3, 4]])\n\n# Compute the L2 norm (Euclidean norm)\nv_norm = np.linalg.norm(v)\nm_norm = np.linalg.norm(m)\nprint(\"Vector L2 norm:\\n\", v_norm)\nprint(\"Matrix Frobenius norm:\\n\", m_norm)\n</code></pre>"},{"location":"programming/ai/#inverse-of-a-matrix_1","title":"Inverse of a Matrix","text":"<p>The inverse of a matrix A is a matrix denoted as A^-1, such that when A is multiplied by A^-1 the result is the identity matrix I. Not all matrices have an inverse. This concept is crucial for solving systems of linear equations.</p> <p>In Python, you can compute the inverse of a matrix using the <code>numpy.linalg.inv()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[4, 7], [2, 6]])\n\n# Compute the inverse of the matrix\nm_inv = np.linalg.inv(m)\nprint(\"Inverse of Matrix:\\n\", m_inv)\n</code></pre>"},{"location":"programming/ai/#singular-value-decomposition-svd_1","title":"Singular Value Decomposition (SVD)","text":"<p>SVD is a factorization of a real or complex matrix. It has many practical applications in signal processing and statistics. In machine learning, it's often used for dimensionality reduction, noise reduction, and recommendation systems.</p> <p>In Python, you can perform the SVD of a matrix using the <code>numpy.linalg.svd()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Compute the Singular Value Decomposition\nU, S, VT = np.linalg.svd(m)\nprint(\"U:\\n\", U)\nprint(\"S:\\n\", S)\nprint(\"VT:\\n\", VT)\n</code></pre>"},{"location":"programming/ai/#orthogonal-vectors-and-matrices","title":"Orthogonal Vectors and Matrices","text":"<p>Two vectors are orthogonal to each other if their dot product equals zero. An orthogonal matrix is a square matrix whose columns and rows are orthogonal unit vectors (i.e., orthonormal vectors).</p> <p>In Python, you can check the orthogonality of two vectors or matrices:</p> <pre><code>import numpy as np\n\n# Define two orthogonal vectors\nv1 = np.array([0, 1])\nv2 = np.array([1, 0])\n\n# Their dot product should be zero\nprint(\"Dot Product:\\n\", np.dot(v1, v2))\n\n# Define an orthogonal matrix\nQ = np.array([[1, 0], [0, -1]])\n\n# Its transpose should be equal to its inverse\nprint(\"Q Transpose equals Q Inverse:\\n\", np.allclose(Q.T, np.linalg.inv(Q)))\n</code></pre>"},{"location":"programming/ai/#rank-of-a-matrix","title":"Rank of a Matrix","text":"<p>The rank of a matrix is the maximum number of linearly independent column vectors in the matrix. It's a fundamental concept in linear algebra, giving the dimension of the vector space generated (or spanned) by its columns.</p> <p>In Python, you can calculate the rank of a matrix using the <code>numpy.linalg.matrix_rank()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Compute the rank of the matrix\nrank = np.linalg.matrix_rank(m)\nprint(\"Rank of Matrix:\\n\", rank)\n</code></pre>"},{"location":"programming/ai/#trace-of-a-matrix","title":"Trace of a Matrix","text":"<p>The trace of an n-by-n square matrix A is the sum of the elements on the main diagonal. The trace of a matrix is invariant under rotation (i.e., it remains the same if the matrix is rotated).</p> <p>In Python, you can calculate the trace of a matrix using the <code>numpy.trace()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Compute the trace of the matrix\ntrace = np.trace(m)\nprint(\"Trace of Matrix:\\n\", trace)\n</code></pre>"},{"location":"programming/ai/#determinant-of-a-matrix","title":"Determinant of a Matrix","text":"<p>The determinant is a special number that can be calculated from a square matrix. It provides important information about the matrix and can be used to solve systems of equations, to find the inverse of a matrix, and to describe the geometric transformations caused by the matrix.</p> <p>In Python, you can compute the determinant of a matrix using the <code>numpy.linalg.det()</code> function:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2], [3, 4]])\n\n# Compute the determinant of the matrix\ndet = np.linalg.det(m)\nprint(\"Determinant of Matrix:\\n\", det)\n</code></pre>"},{"location":"programming/ai/#matrix-transpose","title":"Matrix Transpose","text":"<p>Transposing a matrix is the process of swapping the row and column indices of each element, essentially reflecting the elements across the main diagonal. It's a fundamental operation in linear algebra and finds many uses in computations related to machine learning.</p> <p>In Python, you can compute the transpose of a matrix using the <code>numpy.transpose()</code> function or <code>T</code> attribute:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Compute the transpose of the matrix\nm_t = np.transpose(m)\n# or\nm_t = m.T\nprint(\"Transpose of Matrix:\\n\", m_t)\n</code></pre>"},{"location":"programming/ai/#introduction-to-linear-transformations","title":"Introduction to Linear Transformations","text":"<p>Linear transformations are a cornerstone of linear algebra. They are functions that map one vector space to another, preserving the operations of vector addition and scalar multiplication. In the context of machine learning, linear transformations are often used for feature scaling, dimensionality reduction, etc.</p> <p>For instance, let's scale a vector by a factor of 2 and rotate it by 90 degrees:</p> <pre><code>import numpy as np\n\n# Define a vector\nv = np.array([1, 0])\n\n# Scaling transformation\nscale_factor = 2\nv_scaled = scale_factor * v\nprint(\"Scaled Vector:\\n\", v_scaled)\n\n# Rotation transformation\ntheta = np.radians(90)  # convert degrees to radians\nrotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], \n                            [np.sin(theta),  np.cos(theta)]])  # rotation matrix\nv_rotated = np.dot(rotation_matrix, v)\nprint(\"Rotated Vector:\\n\", v_rotated)\n</code></pre>"},{"location":"programming/ai/#matrix-factorization","title":"Matrix Factorization","text":"<p>Matrix Factorization techniques are usually a step in dimensionality reduction or latent semantic analysis. They are essential in recommendation systems, where they are used to predict user interaction with items.</p> <p>For example, Singular Value Decomposition (SVD) is a type of matrix factorization. In Python, you can use the <code>numpy.linalg.svd()</code> function to factorize a matrix:</p> <pre><code>import numpy as np\n\n# Define a matrix\nm = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Compute the Singular Value Decomposition\nU, S, VT = np.linalg.svd(m)\nprint(\"U:\\n\", U)\nprint(\"S:\\n\", S)\nprint(\"VT:\\n\", VT)\n</code></pre>"},{"location":"programming/ai/#tensors-in-deep-learning","title":"Tensors in Deep Learning","text":"<p>A tensor is a container that can house data in N dimensions. They are a generalization of matrices. In the context of tensors, dimensions are often called \"axes.\"</p> <p>In deep learning, we use tensors pretty much exclusively, as they are a primary data structure that you'll work with as inputs, outputs, and transformations.</p> <p>In Python, using libraries such as TensorFlow or PyTorch, you can create and manipulate tensors:</p> <pre><code>import tensorflow as tf\n\n# Create a tensor\nt = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)\n\n# Multiply tensors\nresult = tf.multiply(t, t)\nprint(\"Tensor multiplication:\\n\", result)\n\n# Reduce_sum\nresult = tf.reduce_sum(t)\nprint(\"Tensor reduce_sum:\\n\", result)\n\n# Expand dimensions\nexpanded = tf.expand_dims(t, axis=1)\nprint(\"Expanded tensor shape:\\n\", expanded.shape)\n</code></pre>"},{"location":"programming/ai/#activation-functions","title":"Activation Functions","text":"<p>In an artificial neural network, an activation function defines the output of a neuron given an input or set of inputs. Activation functions are vital for a neural network to learn and make sense of something really complicated.</p> <p>Commonly used activation functions include:</p> <ul> <li> <p>Sigmoid: This activation function squashes values into a range between 0 and 1. It is especially useful for models where we have to predict the probability as an output.</p> </li> <li> <p>Tanh: The hyperbolic tangent function is similar to the sigmoid but squashes values between -1 and 1.</p> </li> <li> <p>ReLU: The Rectified Linear Unit is the most widely used activation function. It gives an output x if x is positive and 0 otherwise.</p> </li> </ul> <pre><code># An example of using different activation functions in a neural network\nfrom tensorflow.keras.layers import Activation\n\nmodel = Sequential()\n\n# Using ReLU\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\n# Using sigmoid\nmodel.add(Dense(64))\nmodel.add(Activation('sigmoid'))\n\n# Using tanh\nmodel.add(Dense(64))\nmodel.add(Activation('tanh'))\n</code></pre>"},{"location":"programming/ai/#cost-functions","title":"Cost Functions","text":"<p>A cost function, also known as a loss function, measures how well the neural network predictions match the actual values. During training, the neural network aims to minimize this cost function.</p> <p>Commonly used cost functions include Mean Squared Error for regression tasks and Cross Entropy Loss for classification tasks.</p> <pre><code># An example of compiling a model with a cost function\nfrom tensorflow.keras.losses import BinaryCrossentropy\n\nmodel.compile(loss=BinaryCrossentropy(from_logits=True), optimizer='adam')\n</code></pre>"},{"location":"programming/ai/#gradient-descent-and-optimizers","title":"Gradient Descent and Optimizers","text":"<p>Gradient descent is an optimization algorithm used to minimize the cost function. It works by iteratively adjusting the parameters (weights) of the model in the direction that minimally increases the cost function.</p> <p>In practice, variations of gradient descent such as Stochastic Gradient Descent (SGD), RMSprop, or Adam are commonly used.</p> <pre><code># An example of compiling a model with Adam optimizer\nfrom tensorflow.keras.optimizers import Adam\n\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n</code></pre>"},{"location":"programming/ai/#overfitting-underfitting-and-regularization","title":"Overfitting, Underfitting and Regularization","text":"<p>In machine learning, overfitting occurs when a model learns the detail and noise in the training data to the extent that it performs poorly on new, unseen data. Underfitting, on the other hand, occurs when a model is too simple to learn the underlying structure of the data.</p> <p>Regularization techniques are used to prevent overfitting. This includes methods like L1 and L2 regularization and dropout.</p> <pre><code># An example of using dropout regularization\nfrom tensorflow.keras.layers import Dropout\n\nmodel = Sequential()\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n</code></pre>"},{"location":"programming/ai/#practical-example-building-a-deep-neural-network-for-image-classification","title":"Practical Example: Building a Deep Neural Network for Image Classification","text":"<p>Let's implement a deep neural network for classifying images from the CIFAR-10 dataset. This dataset contains 60,000 32x32 color images in 10 different classes.</p> <pre><code># Import necessary libraries\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\n# Load data\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Normalize pixel values to be between 0 and 1\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Convert class vectors to binary class matrices\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\n\n# Define the model architecture\nmodel = Sequential()\nmodel.add(Dense(512, activation='relu', input_shape=(32, 32, 3)))\nmodel.add(Dense(10, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n\n# Evaluate the model\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n</code></pre>"},{"location":"programming/ai/#advanced-neural-networks","title":"Advanced Neural Networks","text":"<p>With the foundation of neural networks covered, we can now delve into more advanced architectures. Let's look at Convolutional Neural Networks and Recurrent Neural Networks in detail.</p>"},{"location":"programming/ai/#convolutional-neural-networks-cnn_1","title":"Convolutional Neural Networks (CNN)","text":"<p>CNNs are primarily used for image processing, pattern recognition, and image classification. They are designed to automatically and adaptively learn spatial hierarchies of features from tasks with grid-like topology.</p> <p>A CNN consists of an input and an output layer, as well as multiple hidden layers. The hidden layers of a CNN typically consist of convolutional layers, pooling layers, fully connected layers, and normalization layers.</p> <p>Here is a simple example of a CNN architecture using Keras:</p> <pre><code>from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n\nmodel = Sequential()\n\n# The first convolution layer\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n\n# The first pooling layer\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# The second convolution layer\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n\n# The second pooling layer\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Flattening the 2D arrays for fully connected layers\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation='relu'))\n\n# The output layer\nmodel.add(Dense(1, activation='sigmoid'))\n</code></pre>"},{"location":"programming/ai/#recurrent-neural-networks-rnn_1","title":"Recurrent Neural Networks (RNN)","text":"<p>RNNs are a type of artificial neural network designed to recognize patterns in sequences of data, such as text, genomes, handwriting, or the spoken word. They are called recurrent because they perform the same task for every element of a sequence, with the output depending on the previous computations.</p> <p>One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task. If you want to predict the next word in a sentence you better know which words came before it.</p> <pre><code>from tensorflow.keras.layers import SimpleRNN\n\nmodel = Sequential()\n\nmodel.add(SimpleRNN(32, return_sequences=True, input_shape=(100,1)))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n</code></pre>"},{"location":"programming/ai/#long-short-term-memory-lstm_1","title":"Long Short-Term Memory (LSTM)","text":"<p>LSTM is a special kind of RNN capable of learning long-term dependencies. They work tremendously well on a large variety of problems, and are now widely used. LSTM networks are well-suited to classifying, processing and making predictions based on time series data.</p> <pre><code>from tensorflow.keras.layers import LSTM\n\nmodel = Sequential()\n\nmodel.add(LSTM(32, return_sequences=True, input_shape=(100,1)))\nmodel.add(LSTM(32))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n</code></pre>"},{"location":"programming/ai/#specific-deep-learning-architectures_1","title":"Specific Deep Learning Architectures","text":"<p>Deep learning has led to the development of a variety of innovative neural network architectures that are tailored to different types of tasks. Let's delve deeper into these architectures and understand their mechanics.</p>"},{"location":"programming/ai/#cnn-architectures_1","title":"CNN Architectures","text":"<p>Convolutional Neural Networks (CNNs) have been at the forefront of many breakthroughs in the field of computer vision. Different CNN architectures have been proposed over the years. </p>"},{"location":"programming/ai/#resnet-residual-network_1","title":"ResNet (Residual Network)","text":"<p>Introduced by Microsoft, the ResNet architecture is unique due to its \"skip connection\" feature. This allows the model to have a large number of layers (even over 100) without suffering from the vanishing gradient problem.</p> <pre><code>from tensorflow.keras.applications import ResNet50\n\n# Initialize a ResNet50 model with pre-trained weights\nmodel = ResNet50(weights='imagenet')\n\n# If you want to customize\nbase_model = ResNet50(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#vgg-visual-geometry-group_1","title":"VGG (Visual Geometry Group)","text":"<p>The VGG architecture, developed by the Visual Geometry Group at Oxford, stands out due to its uniformity. It is simple, and great at generalization, but can be resource-heavy.</p> <pre><code>from tensorflow.keras.applications import VGG16\n\n# Initialize a VGG16 model with pre-trained weights\nmodel = VGG16(weights='imagenet')\n\n# If you want to customize\nbase_model = VGG16(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#inception_1","title":"Inception","text":"<p>Inception, also known as GoogLeNet, was developed by researchers at Google. The inception module, a unique building block of this architecture, allows for more efficient computation and deeper networks.</p> <pre><code>from tensorflow.keras.applications import InceptionV3\n\n# Initialize an InceptionV3 model with pre-trained weights\nmodel = InceptionV3(weights='imagenet')\n\n# If you want to customize\nbase_model = InceptionV3(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#transformer-model_2","title":"Transformer Model","text":"<p>The Transformer model is primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models use only attention mechanisms to handle variable-length input, making computation more parallelizable.</p> <p>The most famous implementation of the Transformer model is probably the BERT (Bidirectional Encoder Representations from Transformers) model by Google.</p> <pre><code>from transformers import BertModel, BertTokenizer\n\n# Load pre-trained model and tokenizer\nmodel = BertModel.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n</code></pre>"},{"location":"programming/ai/#generative-adversarial-networks-gans_1","title":"Generative Adversarial Networks (GANs)","text":"<p>Generative Adversarial Networks (GANs) involve two neural networks competing against each other in unsupervised machine learning tasks. GANs can generate new data that mimics the patterns of the training set. </p> <p>Let's look at an example of implementing a simple GAN architecture:</p> <pre><code>from tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\n\n# The generator network\ng_input = Input(shape=[100])\nG = model_generator(g_input)\nG.summary()\n\n# The discriminator network\nd_input = Input(shape=[28, 28, 1])\nD = model_discriminator(d_input)\nD.summary()\n\n# The GAN\nGAN = Model(g_input, D(G(g_input)))\nGAN.summary()\n</code></pre> <p>This code creates a simple GAN using Keras' functional API. The generator network <code>G</code> takes random noise as input and generates an image, while the discriminator network <code>D</code> takes an image (real or generated) as input and outputs a probability indicating how \"real\" the image is. The GAN model <code>GAN</code> chains the generator and the discriminator together: given random noise, it outputs the discriminator's assessment of the realism of the generated image.</p> <p>Each of the architectures mentioned above has played a significant role in driving advancements in tasks such as image recognition, object detection, and language understanding. By delving deeper into these architectures, you will better understand their mechanics and learn how to leverage them in your own projects.</p>"},{"location":"programming/ai/#specific-deep-learning-architectures_2","title":"Specific Deep Learning Architectures","text":"<p>Deep learning has led to the development of a variety of innovative neural network architectures that are tailored to different types of tasks. Let's delve deeper into these architectures and understand their mechanics.</p>"},{"location":"programming/ai/#cnn-architectures_2","title":"CNN Architectures","text":"<p>Convolutional Neural Networks (CNNs) have been at the forefront of many breakthroughs in the field of computer vision. Different CNN architectures have been proposed over the years. </p>"},{"location":"programming/ai/#resnet-residual-network_2","title":"ResNet (Residual Network)","text":"<p>Introduced by Microsoft, the ResNet architecture is unique due to its \"skip connection\" feature. This allows the model to have a large number of layers (even over 100) without suffering from the vanishing gradient problem.</p> <pre><code>from tensorflow.keras.applications import ResNet50\n\n# Initialize a ResNet50 model with pre-trained weights\nmodel = ResNet50(weights='imagenet')\n\n# If you want to customize\nbase_model = ResNet50(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#vgg-visual-geometry-group_2","title":"VGG (Visual Geometry Group)","text":"<p>The VGG architecture, developed by the Visual Geometry Group at Oxford, stands out due to its uniformity. It is simple, and great at generalization, but can be resource-heavy.</p> <pre><code>from tensorflow.keras.applications import VGG16\n\n# Initialize a VGG16 model with pre-trained weights\nmodel = VGG16(weights='imagenet')\n\n# If you want to customize\nbase_model = VGG16(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#inception_2","title":"Inception","text":"<p>Inception, also known as GoogLeNet, was developed by researchers at Google. The inception module, a unique building block of this architecture, allows for more efficient computation and deeper networks.</p> <pre><code>from tensorflow.keras.applications import InceptionV3\n\n# Initialize an InceptionV3 model with pre-trained weights\nmodel = InceptionV3(weights='imagenet')\n\n# If you want to customize\nbase_model = InceptionV3(weights='imagenet', include_top=False)\n</code></pre>"},{"location":"programming/ai/#transformer-model_3","title":"Transformer Model","text":"<p>The Transformer model is primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models use only attention mechanisms to handle variable-length input, making computation more parallelizable.</p> <p>The most famous implementation of the Transformer model is probably the BERT (Bidirectional Encoder Representations from Transformers) model by Google.</p> <pre><code>from transformers import BertModel, BertTokenizer\n\n# Load pre-trained model and tokenizer\nmodel = BertModel.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n</code></pre>"},{"location":"programming/ai/#generative-adversarial-networks-gans_2","title":"Generative Adversarial Networks (GANs)","text":"<p>Generative Adversarial Networks (GANs) involve two neural networks competing against each other in unsupervised machine learning tasks. GANs can generate new data that mimics the patterns of the training set. </p> <p>Let's look at an example of implementing a simple GAN architecture:</p> <pre><code>from tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\n\n# The generator network\ng_input = Input(shape=[100])\nG = model_generator(g_input)\nG.summary()\n\n# The discriminator network\nd_input = Input(shape=[28, 28, 1])\nD = model_discriminator(d_input)\nD.summary()\n\n# The GAN\nGAN = Model(g_input, D(G(g_input)))\nGAN.summary()\n</code></pre> <p>This code creates a simple GAN using Keras' functional API. The generator network <code>G</code> takes random noise as input and generates an image, while the discriminator network <code>D</code> takes an image (real or generated) as input and outputs a probability indicating how \"real\" the image is. The GAN model <code>GAN</code> chains the generator and the discriminator together: given random noise, it outputs the discriminator's assessment of the realism of the generated image.</p> <p>Each of the architectures mentioned above has played a significant role in driving advancements in tasks such as image recognition, object detection, and language understanding. By delving deeper into these architectures, you will better understand their mechanics and learn how to leverage them in your own projects.</p> <p>User \u10ea\u10dd\u10dc\u10e2\u10d8\u10dc\u10e3\u10d4 ChatGPT</p> <p>vbnet</p>"},{"location":"programming/ai/#transformer-model-continued","title":"Transformer Model - Continued","text":"<p>One of the main innovations of the Transformer model is the self-attention mechanism. Self-attention, sometimes called intra-attention, is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. In simple terms, self-attention allows the model to consider other words in the sentence when processing a word.</p> <p>To illustrate this, let's delve a bit more into the BERT (Bidirectional Encoder Representations from Transformers) model. BERT has brought about a revolution in the way we approach NLP tasks. Its bidirectional training, which is essentially a read of the entire sentence rather than word-by-word, makes it stand out.</p> <pre><code>from transformers import BertForSequenceClassification, AdamW\n\n# Assume we're training on a binary classification problem\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = 2, # The number of output labels--2 for binary classification.\n)\n\n# AdamW is a class from the huggingface library, it is the optimizer we're using\noptimizer = AdamW(model.parameters(), lr = 2e-5)\n</code></pre> <p>In this example, we use the BERT model for a simple binary classification task. We initialize the model with pre-trained weights and then specify that we're dealing with a binary classification problem (thus, <code>num_labels = 2</code>).</p>"},{"location":"programming/ai/#generative-adversarial-networks-gans-continued","title":"Generative Adversarial Networks (GANs) - Continued","text":"<p>Let's now take a look at a specific GAN architecture, the DCGAN (Deep Convolutional GAN). DCGAN applies convolutional neural networks to the GAN architecture, which is particularly successful in generating high-quality images.</p> <pre><code>from tensorflow.keras.layers import Reshape, Conv2DTranspose\n\n# Generator in DCGAN\nmodel = Sequential()\nmodel.add(Dense(7 * 7 * 128, input_dim=100))\nmodel.add(LeakyReLU(0.2))\nmodel.add(Reshape((7, 7, 128)))\nmodel.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\nmodel.add(LeakyReLU(0.2))\nmodel.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n</code></pre> <p>In this example, the generator network starts with a dense layer that reshapes its input into a 7x7x128 tensor. It then uses two <code>Conv2DTranspose</code> layers (a type of layer that performs up-convolution) to upscale this tensor into a 28x28x1 image. This network uses <code>LeakyReLU</code> activation functions and outputs images with pixel values in the range [-1, 1] (as indicated by the <code>tanh</code> activation function).</p>"},{"location":"programming/ai/#basics-of-nlp-and-text-representation-techniques-continued","title":"Basics of NLP and Text Representation Techniques - Continued","text":"<p>To better understand the techniques used to represent text data, let's look at some Python code examples:</p>"},{"location":"programming/ai/#bag-of-words_1","title":"Bag of Words","text":"<pre><code>from sklearn.feature_extraction.text import CountVectorizer\n\n# Initialize the CountVectorizer\nvectorizer = CountVectorizer()\n\n# Corpus of data\ncorpus = ['This is the first document.',\n          'This document is the second document.',\n          'And this is the third one.',\n          'Is this the first document?']\n\n# Fit and transform the corpus\nX = vectorizer.fit_transform(corpus)\n\n# Convert to array and print the result\nprint(X.toarray())\n</code></pre> <p>In this example, we use the <code>CountVectorizer</code> class from the <code>sklearn.feature_extraction.text</code> module, which implements the Bag of Words method. The <code>fit_transform</code> function learns the vocabulary dictionary and returns a Document-Term matrix.</p>"},{"location":"programming/ai/#tf-idf_1","title":"TF-IDF","text":"<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize the TfidfVectorizer\nvectorizer = TfidfVectorizer()\n\n# Fit and transform the corpus\nX = vectorizer.fit_transform(corpus)\n\n# Convert to array and print the result\nprint(X.toarray())\n</code></pre> <p>Here, we use the <code>TfidfVectorizer</code> class, also from the <code>sklearn.feature_extraction.text</code> module. It converts a collection of raw documents to a matrix of TF-IDF features.</p>"},{"location":"programming/ai/#word-embeddings_1","title":"Word Embeddings","text":"<p>For word embeddings, we often use pre-trained models. One of the most common is Word2Vec, trained on a large corpus of text. Gensim is a popular library for using Word2Vec in Python.</p> <pre><code>from gensim.models import Word2Vec\n\n# Assuming that 'sentences' is a list of lists of tokens \n# For example: sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n#                           ['this', 'is', 'the', 'second', 'sentence']]\n\n# Train a Word2Vec model\nmodel = Word2Vec(sentences, min_count=1)\n\n# Get the vector for a word\nprint(model.wv['sentence'])\n</code></pre> <p>This script trains a Word2Vec model on a small corpus and prints the vector for the word 'sentence'.</p>"},{"location":"programming/ai/#advanced-nlp-models-and-techniques-continued","title":"Advanced NLP Models and Techniques - Continued","text":""},{"location":"programming/ai/#rnns-and-lstms-in-nlp","title":"RNNs and LSTMs in NLP","text":"<p>RNNs are particularly suitable for handling sequence data. Let's look at an example of an LSTM for text generation:</p> <pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.optimizers import RMSprop\n\n# Assume that 'maxlen' is the sequence length, 'chars' is the list of unique characters, and 'char_indices' and 'indices_char' are dictionaries mapping characters to their indices and vice versa\nmodel = Sequential()\nmodel.add(LSTM(128, input_shape=(maxlen, len(chars))))\nmodel.add(Dense(len(chars), activation='softmax'))\n\noptimizer = RMSprop(learning_rate=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer)\n</code></pre> <p>This script creates an LSTM model for text generation. It assumes that you've already preprocessed the text into sequences of characters and created mappings of characters to numeric indices.</p>"},{"location":"programming/ai/#using-transformers-in-nlp","title":"Using Transformers in NLP","text":"<p>As discussed before, the transformer model, specifically BERT and GPT, has been very effective in various NLP tasks. For example, we can use the BERT model for text classification as follows:</p> <pre><code>from transformers import BertForSequenceClassification, AdamW\n\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\",\n    num_labels=2,\n)\noptimizer = AdamW(model.parameters(), lr=2e-5)\n</code></pre> <p>This script loads a pre-trained BERT model for a binary classification task. It uses the AdamW optimizer with a learning rate of 2e-5.</p>"},{"location":"programming/ai/#reinforcement-learning_1","title":"Reinforcement Learning","text":"<p>Reinforcement Learning (RL) is another significant area of Machine Learning where an agent learns to behave in an environment, by performing certain actions and observing the rewards/results which it gets from those actions.</p>"},{"location":"programming/ai/#basics-of-reinforcement-learning","title":"Basics of Reinforcement Learning","text":"<p>The key components of Reinforcement Learning are as follows:</p> <ul> <li> <p>Environment: This is the world through which the agent moves. The environment takes the agent's current state and action as input, and returns the agent's reward and next state.</p> </li> <li> <p>Agent: This is the algorithm that learns from trial and error.</p> </li> <li> <p>State: This is the current situation of the agent.</p> </li> <li> <p>Action: What the agent can do.</p> </li> <li> <p>Reward: Feedback from the environment.</p> </li> </ul> <p>Here is a simple example of an RL implementation using Python and the <code>gym</code> library, which is a popular toolkit for developing and comparing RL algorithms:</p> <pre><code>import gym\n\n# Create the CartPole game environment\nenv = gym.make(\"CartPole-v1\")\n\n# Number of episodes\nfor i_episode in range(20):\n    # Reset state\n    state = env.reset()\n    for t in range(100):\n        env.render()\n        # Take a random action\n        action = env.action_space.sample()\n        state, reward, done, info = env.step(action)\n        if done:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            break\nenv.close()\n</code></pre> <p>In this example, we're using a simple game environment called \"CartPole-v1\". The agent takes random actions in the environment and receives feedback.</p> <p>(Note: More advanced topics on reinforcement learning will be continued...)</p>"},{"location":"programming/ai/#deep-reinforcement-learning","title":"Deep Reinforcement Learning","text":"<p>Deep Reinforcement Learning (DRL) combines neural networks with reinforcement learning. The neural network takes in observations, processes them, and outputs actions to take. These actions are then used in the reinforcement learning component.</p>"},{"location":"programming/ai/#q-learning","title":"Q-Learning","text":"<p>Q-Learning is a values based algorithm in reinforcement learning. Value based algorithms update the value function based on the Bellman Equation. The algorithm helps the agent to decide what action to take under what circumstances.</p>"},{"location":"programming/ai/#deep-q-networks","title":"Deep Q-Networks","text":"<p>Deep Q-Networks (DQN) is the combination of Q-Learning and Deep Learning. In DQN, we use a neural network to approximate the Q-value function, and the network is trained to output the maximum expected future rewards for each action, given a specific state.</p>"},{"location":"programming/ai/#policy-gradients","title":"Policy Gradients","text":"<p>Policy Gradients (PG) are a type of reinforcement learning algorithm that directly optimizes the policy\u2014the function that decides what actions to take\u2014by estimating the gradient of the expected rewards.</p>"},{"location":"programming/algorithms/","title":"Advanced Programming Algorithms","text":""},{"location":"programming/algorithms/#1-sliding-window","title":"1. Sliding Window","text":"<p>The sliding window is a technique that involves creating a \"window\" in your data and then \"sliding\" it in a certain direction to perform operations on the data within the window.</p> <p>Here's a Python example of finding the maximum sum of a subarray of size <code>k</code> in an array:</p> <p><pre><code>def max_sub_array_of_size_k(k, arr):\n    max_sum , window_sum = 0, 0\n    window_start = 0\n\n    for window_end in range(len(arr)):\n        window_sum += arr[window_end]  # add the next element\n\n        # slide the window, we don't need to slide if we've not hit the required window size of 'k'\n        if window_end &gt;= k-1:\n            max_sum = max(max_sum, window_sum)\n            window_sum -= arr[window_start]  # subtract the element going out\n            window_start += 1  # slide the window ahead\n\n    return max_sum\n</code></pre> Real world example: Sliding window algorithms can be used in data stream processing to calculate rolling metrics, such as a moving average.</p>"},{"location":"programming/algorithms/#2-two-pointers","title":"2. Two Pointers","text":"<p>Two Pointers is a pattern where two pointers iterate through the data structure in tandem until one or both of the pointers meet a certain condition.</p> <p>Python example for reversing a string:</p> <pre><code>def reverse_string(s):\n    left, right = 0, len(s) - 1\n    while left &lt; right:\n        # Swap s[left] and s[right]\n        s[left], s[right] = s[right], s[left]\n        left, right = left + 1, right - 1\n    return s\n</code></pre> <p>Real world example: Two pointers can be used in situations where you have to find pairs of elements that meet a certain condition, like in a music playlist to match songs of certain lengths together.</p>"},{"location":"programming/algorithms/#3-binary-search","title":"3. Binary Search","text":"<p>Binary Search is a divide and conquer algorithm used to find a specific item in a sorted array.</p> <p>Python example:</p> <p><pre><code>def binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n        if arr[mid] == target:\n            return mid  # target found\n        if arr[mid] &lt; target:\n            left = mid + 1  # search in the right half\n        else:\n            right = mid - 1  # search in the left half\n    return -1  # target not found\n</code></pre> Real world example: Binary search is used in debugging (e.g., git bisect) to find faulty code commit. </p>"},{"location":"programming/algorithms/#4-fast-and-slow-pointers","title":"4. Fast and Slow Pointers","text":"<p>The Fast and Slow pointer approach, also known as the Hare and Tortoise algorithm, is used to determine if a linked list is a circular linked list.</p> <p>Python example:</p> <p><pre><code>class Node:\n    def __init__(self, value, next=None):\n        self.value = value\n        self.next = next\n\ndef has_cycle(head):\n    slow, fast = head, head\n    while fast is not None and fast.next is not None:\n        fast = fast.next.next\n        slow = slow.next\n        if slow == fast:\n            return True  # found the cycle\n    return False\n</code></pre> Real world example: This algorithm can be used to detect cycles in a computer network.</p>"},{"location":"programming/algorithms/#5-merge-intervals","title":"5. Merge Intervals","text":"<p>Merge Intervals is a problem where given a collection of intervals, we need to merge all overlapping intervals.</p> <p>Python example:</p> <p><pre><code>def merge(intervals):\n    if len(intervals) &lt; 2:\n        return intervals\n\n    # sort the intervals on the start time\n    intervals.sort(key=lambda x: x[0])\n\n    mergedIntervals = []\n    start = intervals[0][0]\n    end = intervals[0][1]\n    for i in range(1, len(intervals)):\n        if intervals[i][0] &lt;= end:  # overlapping intervals\n            end = max(end, intervals[i][1])  # adjust the 'end'\n        else:  # non-overlapping interval\n            mergedIntervals.append([start, end])\n            start = intervals[i][0]\n            end = intervals[i][1]\n\n    # add the last interval\n    mergedIntervals.append([start, end])\n    return mergedIntervals\n</code></pre> Real world example: In calendar systems, to find free or busy time slots, we need to merge all overlapping intervals.</p>"},{"location":"programming/algorithms/#6-top-k-elements","title":"6. Top K Elements","text":"<p>To find the top 'K' elements among a given set. This pattern can be easily recognized from questions such as \"find the top K numbers\" or \"find the most frequent K numbers\".</p> <p>Python example:</p> <p><pre><code>import heapq\n\ndef find_k_largest_numbers(nums, k):\n    minHeap = []\n    # put first 'K' numbers in the min heap\n    for i in range(k):\n        heapq.heappush(minHeap, nums[i])\n\n    # go through the remaining numbers of the array, if the number from the array is bigger than the\n    # top(smallest) number of the min-heap, remove the top number from heap and add the number from array\n    for i in range(k, len(nums)):\n        if nums[i] &gt; minHeap[0]:\n            heapq.heappop(minHeap)\n            heapq.heappush(minHeap, nums[i])\n\n    # the heap has the top 'K' numbers, return them in a list\n    return list(minHeap)\n</code></pre> Real world example: Top K elements can be used in real-time online voting results, showing only top K candidates.</p>"},{"location":"programming/algorithms/#7-k-way-merge","title":"7. K-way Merge","text":"<p>K-way merge pattern is an efficient way to merge data from multiple sources. The pattern works by comparing the smallest elements of each source and repeatedly choosing the smallest until there are no more elements left.</p> <p>Python example (Merging K Sorted Lists):</p> <p><pre><code>import heapq\nfrom typing import List\n\nclass ListNode:\n    def __init__(self, value, next=None):\n        self.value = value\n        self.next = next\n\ndef merge_lists(lists: List[ListNode]) -&gt; ListNode:\n    min_heap = []\n\n    # put the root of each list in the min heap\n    for root in lists:\n        if root is not None:\n            heapq.heappush(min_heap, (root.val, root))\n\n    # take the smallest (top) element from the min-heap and add it to the result\n    # if the top element has a next element add it to the heap\n    prehead = point = ListNode(-1)\n    while min_heap:\n        val, node = heapq.heappop(min_heap)\n        point.next = ListNode(val)\n        point = point.next\n        node = node.next\n        if node is not None:\n            heapq.heappush(min_heap, (node.val, node))\n\n    return prehead.next\n</code></pre> Real world example: K-way merge is used in big data processing for merging large datasets from multiple sources.</p>"},{"location":"programming/algorithms/#8-breadth-first-search-bfs","title":"8. Breadth-First Search (BFS)","text":"<p>BFS is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root and explores all of the neighbor nodes at the present depth prior to moving on to nodes at the next depth level.</p> <p>Python example:</p> <p><pre><code>from collections import deque\n\ndef bfs(graph, root):\n    visited = set()\n    queue = deque([root])\n\n    while queue:\n        vertex = queue.popleft()\n        print(str(vertex) + \" \", end=\"\")\n\n        # add neighbours to the queue\n        for neighbour in graph[vertex]:\n            if neighbour not in visited:\n                visited.add(neighbour)\n                queue.append(neighbour)\n</code></pre> Real world example: BFS is often used in AI for finding the shortest path in a graph (like Google Maps to find shortest route).</p>"},{"location":"programming/algorithms/#9-depth-first-search-dfs","title":"9. Depth-First Search (DFS)","text":"<p>DFS is an algorithm for traversing or searching tree or graph data structures. The algorithm starts at the root node and explores as far as possible along each branch before backtracking.</p> <p>Python example:</p> <p><pre><code>def dfs(graph, start, visited=None):\n    if visited is None:\n        visited = set()\n    visited.add(start)\n\n    print(start, end=' ')\n\n    for next in graph[start] - visited:\n        dfs(graph, next, visited)\n    return visited\n</code></pre> Real world example: DFS can be used to solve puzzles such as mazes.</p>"},{"location":"programming/algorithms/#10-backtracking","title":"10. Backtracking","text":"<p>Backtracking is a strategy for finding all (or some) solutions to computational problems, notably constraint satisfaction problems, by incrementally building candidates to the solutions, and abandoning a candidate as soon as it's determined that it cannot be extended to a valid solution.</p> <p>Python example (Generating all possible permutations of a list):</p> <p><pre><code>def generate_permutations(nums):\n    def backtrack(start):\n        # if we are at the end of the array, we have a complete permutation\n        if start == len(nums):\n            output.append(nums[:])\n            return\n        for i in range(start, len(nums)):\n            # swap the current index with the start\n            nums[start], nums[i] = nums[i], nums[start]\n            # continue building the permutation\n            backtrack(start + 1)\n            # undo the swap\n            nums[start], nums[i] = nums[i], nums[start]\n\n    output = []\n    backtrack(0)\n    return output\n</code></pre> Real world example: Backtracking is used in many algorithms for searching and constraint satisfaction problems, such as Sudoku.</p>"},{"location":"programming/algorithms/#11-dynamic-programming-dp","title":"11. Dynamic Programming (DP)","text":"<p>Dynamic Programming is a method for solving a complex problem by breaking it down into simpler subproblems, solving each of those subproblems just once, and storing their solutions to avoid duplicate work.</p> <p>Python example (Finding the nth Fibonacci number):</p> <p><pre><code>def fibonacci(n):\n    dp = [0, 1] + [0]*(n-1)\n    for i in range(2, n+1):\n        dp[i] = dp[i-1] + dp[i-2]\n    return dp[n]\n</code></pre> Real world example: DP is used in many areas of computer science, such as in optimizing the operation of a network or the performance of a computer program.</p>"},{"location":"programming/algorithms/#12-kadanes-algorithm","title":"12. Kadane's Algorithm","text":"<p>Kadane's algorithm is a Dynamic Programming approach to solve \"the largest contiguous elements in an array\" with runtime of O(n).</p> <p>Python example:</p> <p><pre><code>def max_sub_array(nums):\n    if not nums:\n        return 0\n\n    cur_sum = max_sum = nums[0]\n\n    for num in nums[1:]:\n        cur_sum = max(num, cur_sum + num)\n        max_sum = max(max_sum, cur_sum)\n\n    return max_sum\n</code></pre> Real world example: Kadane's algorithm can be used in computer vision to detect the largest area of a certain color in an image.</p>"},{"location":"programming/algorithms/#13-knapsack-problem","title":"13. Knapsack Problem","text":"<p>The knapsack problem is a problem in combinatorial optimization. Given a set of items, each with a weight and a value, the goal is to determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible.</p> <p>Python example:</p> <p><pre><code>def knapSack(W, wt, val, n):\n    K = [[0 for w in range(W + 1)]\n            for i in range(n + 1)]\n\n    # Build table K[][] in bottom\n    # up manner\n    for i in range(n + 1):\n        for w in range(W + 1):\n            if i == 0 or w == 0:\n                K[i][w] = 0\n            elif wt[i - 1] &lt;= w:\n                K[i][w] = max(val[i - 1]\n                  + K[i - 1][w - wt[i - 1]],\n                               K[i - 1][w])\n            else:\n                K[i][w] = K[i - 1][w]\n\n    return K[n][W]\n</code></pre> Real world example: The knapsack problem appears in resource allocation in computing. For example, given a set of servers, each with a certain capacity and cost, the goal is to find the least costly way to fulfill a client's resource request.</p>"},{"location":"programming/algorithms/#14-tree-depth-first-search","title":"14. Tree Depth-First Search","text":"<p>This is an algorithm for traversing or searching tree data structures. The algorithm starts at the root and explores as far as possible along each branch before backtracking.</p> <p>Python example:</p> <p><pre><code>class Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\ndef dfs(node):\n    if node is None:\n        return\n    print(node.value, end=' ')\n    dfs(node.left)\n    dfs(node.right)\n</code></pre> Real world example: DFS can be used in games like chess where you need to forecast player's moves ahead of time.</p>"},{"location":"programming/algorithms/#15-tree-breadth-first-search","title":"15. Tree Breadth-First Search","text":"<p>This is an algorithm for traversing or searching tree data structures. It starts at the tree root and explores all of the neighbor nodes at the present depth prior to moving on to nodes at the next depth level.</p> <p>Python example:</p> <p><pre><code>from collections import deque\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\ndef bfs(root):\n    queue = deque([root])\n    while queue:\n        node = queue.popleft()\n        print(node.value, end=' ')\n        if node.left:\n            queue.append(node.left)\n        if node.right:\n            queue.append(node.right)\n</code></pre> Real world example: BFS can be used in social networking sites when suggesting people you may know, as it looks at closest connections first.</p>"},{"location":"programming/algorithms/#16-topological-sort","title":"16. Topological Sort","text":"<p>Topological sort is used to find a linear ordering of elements that have dependencies on each other. For instance, if task 'a' is dependent on task 'b', in the sorted order, 'b' comes before 'a'.</p> <p>Python example:</p> <p><pre><code>from collections import defaultdict, deque\n\ndef topological_sort(vertices, edges):\n    sorted_order = []\n    if vertices &lt;= 0:\n        return sorted_order\n\n    # a. Initialize the graph\n    in_degree = {i: 0 for i in range(vertices)}  # count of incoming edges\n    graph = defaultdict(list)  # adjacency list graph\n\n    # b. Build the graph\n    for edge in edges:\n        parent, child = edge[0], edge[1]\n        graph[parent].append(child)  # put the child into parent's list\n        in_degree[child] += 1  # increment child's inDegree\n\n    # c. Find all sources i.e., all vertices with 0 in-degrees\n    sources = deque()\n    for key in in_degree:\n        if in_degree[key] == 0:\n            sources.append(key)\n\n    # d. For each source, add it to the sortedOrder and subtract one from all of its children's in-degrees\n    # if a child's in-degree becomes zero, add it to the sources queue\n    while sources:\n        vertex = sources.popleft()\n        sorted_order.append(vertex)\n        for child in graph[vertex]:  # get the node's children to decrement their in-degrees\n            in_degree[child] -= 1\n            if in_degree[child] == 0:\n                sources.append(child)\n\n    # topological sort is not possible as the graph has a cycle\n    if len(sorted_order) != vertices:\n        return []\n\n    return sorted_order\n</code></pre> Real world example: Topological Sort can be used in scheduling tasks, determining the order of courses to take, etc.</p>"},{"location":"programming/algorithms/#17-trie","title":"17. Trie","text":"<p>A Trie, also called digital tree and sometimes radix tree or prefix tree, is a kind of search tree\u2014an ordered tree data structure used to store a dynamic set or associative array where the keys are usually strings.</p> <p>Python example:</p> <p><pre><code>class TrieNode:\n    def __init__(self):\n        self.children = {}\n        self.endOfString = False\n\nclass Trie:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def insert_word(self, word):\n        current = self.root\n        for char in word:\n            node = current.children.get(char)\n            if not node:\n                node = TrieNode()\n                current.children[char] = node\n            current = node\n        current.endOfString = True\n\n    def search_word(self, word):\n        current = self.root\n        for char in word:\n            node = current.children.get(char)\n            if not node:\n                return False\n            current = node\n        return current.endOfString\n</code></pre> Real world example: Tries are used in search engines for text autocompletion.</p>"},{"location":"programming/algorithms/#18-graph-bipartite-check","title":"18. Graph - Bipartite Check","text":"<p>A Bipartite graph is a graph whose vertices can be divided into two independent sets, U and V such that every edge (u, v) either connects a vertex from U to V or a vertex from V to U.</p> <p>Python example:</p> <p><pre><code>def is_bipartite(graph):\n    color = {}\n    for node in range(len(graph)):\n        if node not in color:\n            stack = [node]\n            color[node] = 0\n            while stack:\n                node = stack.pop()\n                for neighbour in graph[node]:\n                    if neighbour not in color:\n                        stack.append(neighbour)\n                        color[neighbour] = color[node] ^ 1\n                    elif color[neighbour] == color[node]:\n                        return False\n    return True\n</code></pre> Real world example: Bipartite graphs are used in matching algorithms, such as in job allocation where jobs can be matched to job-seekers.</p>"},{"location":"programming/algorithms/#19-bitwise-xor","title":"19. Bitwise XOR","text":"<p>XOR is a binary operation that takes two bit patterns of equal length and performs the logical exclusive OR operation on each pair of corresponding bits. The result in each position is 1 if only the first bit is 1 OR only the second bit is 1, but will be 0 if both are 0 or both are 1.</p> <p>Python example:</p> <p><pre><code>def find_single_number(arr):\n    num = 0\n    for i in arr:\n        num ^= i\n    return num\n</code></pre> Real world example: Bitwise XOR can be used in cryptography, error detection and correction algorithms.</p>"},{"location":"programming/algorithms/#20-sliding-window-optimal","title":"20. Sliding Window - Optimal","text":"<p>The sliding window pattern is used to perform a required operation on a specific window size of a given large dataset or array. This window could either be a subarray or a subset of data that you are taking from a defined set of data.</p> <p>Python example (Finding maximum sum of a subarray of size 'k'):</p> <p><pre><code>def max_sub_array_of_size_k(k, arr):\n    max_sum = 0\n    window_sum = 0\n\n    for i in range(len(arr) - k + 1):\n        window_sum = sum(arr[i:i+k])\n        max_sum = max(max_sum, window_sum)\n\n    return max_sum\n</code></pre> Real world example: The sliding window concept is used in TCP data transmission for flow control and congestion control.</p>"},{"location":"programming/algorithms/#21-quick-sort","title":"21. Quick Sort","text":"<p>QuickSort is a Divide and Conquer algorithm, which picks an element as pivot and partitions the given array around the picked pivot.</p> <p>Python example:</p> <pre><code>def quick_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x &lt; pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x &gt; pivot]\n    return quick_sort(left) + middle + quick_sort(right)\n</code></pre>"},{"location":"programming/algorithms/#22-merge-sort","title":"22. Merge Sort","text":"<p>Merge Sort is a Divide and Conquer algorithm, which works by dividing the unsorted list into n sublists, each containing one element, and then repeatedly merging sublists to produce new sorted sublists until there is only one sublist remaining.</p> <p>Python example:</p> <pre><code>def merge_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n\n    def merge(left, right):\n        if not left:\n            return right\n        if not right:\n            return left\n        if left[0] &lt; right[0]:\n            return [left[0]] + merge(left[1:], right)\n        return [right[0]] + merge(left, right[1:])\n\n    mid = len(arr) // 2\n    return merge(merge_sort(arr[:mid]), merge_sort(arr[mid:]))\n</code></pre>"},{"location":"programming/algorithms/#23-heap-sort","title":"23. Heap Sort","text":"<p>Heap sort is a comparison-based sorting algorithm that uses a binary heap data structure. </p> <p>Python example:</p> <pre><code>import heapq\n\ndef heap_sort(arr):\n    heapq.heapify(arr)\n    return [heapq.heappop(arr) for _ in range(len(arr))]\n</code></pre>"},{"location":"programming/algorithms/#24-insertion-sort","title":"24. Insertion Sort","text":"<p>Insertion sort is a simple sorting algorithm that works similar to the way you sort playing cards in your hands. The array is virtually split into a sorted and an unsorted region.</p> <p>Python example:</p> <pre><code>def insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j &gt;= 0 and key &lt; arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n</code></pre>"},{"location":"programming/algorithms/#25-binary-search","title":"25. Binary Search","text":"<p>Binary search is an efficient algorithm for finding an item from a sorted list of items. It works by repeatedly dividing in half the portion of the list that could contain the item, until you've narrowed down the possible locations to just one.</p> <p>Python example:</p> <pre><code>def binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return -1\n</code></pre>"},{"location":"programming/algorithms/#26-breadth-first-search-graphs","title":"26. Breadth-First Search (Graphs)","text":"<p>Breadth-first search (BFS) is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root and explores all of the neighbor nodes at the present depth prior to moving on to nodes at the next depth level.</p> <p>Python example (Using adjacency list representation of graph):</p> <pre><code>from collections import deque\n\ndef bfs(graph, root):\n    visited = set()\n    queue = deque([root])\n\n    while queue:\n        vertex = queue.popleft()\n        print(vertex, end=\" \")\n\n        for neighbour in graph[vertex]:\n            if neighbour not in visited:\n                visited.add(neighbour)\n                queue.append(neighbour)\n</code></pre>"},{"location":"programming/algorithms/#27-depth-first-search-graphs","title":"27. Depth-First Search (Graphs)","text":"<p>Depth-first search (DFS) is an algorithm for traversing or searching tree or graph data structures. The algorithm starts at the root node and explores as far as possible along each branch before backtracking.</p> <p>Python example (Using adjacency list representation of graph):</p> <pre><code>def dfs(graph, root, visited=None):\n    if visited is None:\n        visited = set()\n    visited.add(root)\n    print(root, end=\" \")\n\n    for neighbour in graph[root]:\n        if neighbour not in visited:\n            dfs(graph, neighbour, visited)\n    return visited\n</code></pre>"},{"location":"programming/algorithms/#28-dijkstras-algorithm","title":"28. Dijkstra's Algorithm","text":"<p>Dijkstra\u2019s algorithm is a shortest path algorithm that works on a weighted graph. The shortest path in this case is based on the weight of the edges.</p> <p>Python example:</p> <pre><code>import heapq\n\ndef dijkstras(graph, start):\n    distances = {node: float('infinity') for node in graph}\n    distances[start] = 0\n    pq = [(0, start)]\n\n    while pq:\n        current_distance, current_node = heapq.heappop(pq)\n\n        if current_distance &gt; distances[current_node]:\n            continue\n\n        for neighbour, weight in graph[current_node].items():\n            distance = current_distance + weight\n\n            if distance &lt; distances[neighbour]:\n                distances[neighbour] = distance\n                heapq.heappush(pq, (distance, neighbour))\n\n    return distances\n</code></pre>"},{"location":"programming/algorithms/#29-a-search-algorithm","title":"29. A* Search Algorithm","text":"<p>A* is a graph traversal and path search algorithm, which is often used in many fields of computer science due to its completeness, optimality, and optimal efficiency.</p> <p>Python example (Implementing A* to solve a 2D grid-based pathfinding problem would be too large to fit here due to the need for a suitable heuristic function and priority queue data structure.)</p>"},{"location":"programming/algorithms/#30-floyd-warshall-algorithm","title":"30. Floyd-Warshall Algorithm","text":"<p>The Floyd-Warshall algorithm is a shortest path algorithm for graphs. It's used to find the shortest paths between all pairs of vertices in a graph, which may represent, for example, road networks.</p> <p>Python example:</p> <pre><code>def floyd_warshall(graph):\n    distance = dict()\n\n    for vertex in graph:\n        distance[vertex] = dict()\n        for neighbour in graph:\n            distance[vertex][neighbour] = graph[vertex][neighbour]\n\n    for intermediate_vertex in graph:\n        for vertex in graph:\n            for neighbour in graph:\n                if distance[vertex][intermediate_vertex] + distance[intermediate_vertex][neighbour] &lt; distance[vertex][neighbour]:\n                    distance[vertex][neighbour] = distance[vertex][intermediate_vertex] + distance[intermediate_vertex][neighbour]\n\n    return distance\n</code></pre>"},{"location":"programming/algorithms/#31-knapsack-problem","title":"31. Knapsack Problem","text":"<p>The knapsack problem is a problem in combinatorial optimization: Given a set of items, each with a weight and a value, determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible.</p> <p>Python example (0/1 Knapsack Problem):</p> <pre><code>def knapSack(W, wt, val, n):\n    K = [[0 for w in range(W+1)] for i in range(n+1)]\n\n    for i in range(n+1):\n        for w in range(W+1):\n            if i == 0 or w == 0:\n                K[i][w] = 0\n            elif wt[i-1] &lt;= w:\n                K[i][w] = max(val[i-1] + K[i-1][w-wt[i-1]], K[i-1][w])\n            else:\n                K[i][w] = K[i-1][w]\n\n    return K[n][W]\n</code></pre>"},{"location":"programming/algorithms/#32-travelling-salesman-problem","title":"32. Travelling Salesman Problem","text":"<p>The travelling salesman problem (TSP) asks the following question: \"Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?\"</p> <p>Python example (Simple approach for TSP):</p> <pre><code>from itertools import permutations\n\ndef travellingSalesmanProblem(graph, s):\n    vertex = []\n    for i in range(len(graph)):\n        if i != s:\n            vertex.append(i)\n\n    min_path = float('inf')\n    next_permutation=permutations(vertex)\n    for i in next_permutation:\n        current_pathweight = 0\n\n        k = s\n        for j in i:\n            current_pathweight += graph[k][j]\n            k = j\n        current_pathweight += graph[k][s]\n\n        min_path = min(min_path, current_pathweight)\n\n    return min_path\n</code></pre>"},{"location":"programming/algorithms/#33-kruskals-algorithm","title":"33. Kruskal\u2019s Algorithm","text":"<p>Kruskal's algorithm finds a minimum spanning forest of an undirected edge-weighted graph. If the graph is connected, it finds a minimum spanning tree.</p> <p>Python example (too long to fit due to the need for a disjoint set data structure)</p>"},{"location":"programming/algorithms/#34-prims-algorithm","title":"34. Prim's Algorithm","text":"<p>Prim's algorithm is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph.</p> <p>Python example (too long to fit due to the need for a priority queue data structure)</p>"},{"location":"programming/algorithms/#35-bellman-ford-algorithm","title":"35. Bellman-Ford Algorithm","text":"<p>The Bellman\u2013Ford algorithm is an algorithm that computes shortest paths from a single source vertex to all of the other vertices in a weighted digraph.</p> <p>Python example:</p> <pre><code>def bellman_ford(graph, source_vertex):\n    distance, predecessor = dict(), dict()\n\n    for node in graph:\n        distance[node], predecessor[node] = float('inf'), None\n    distance[source_vertex] = 0\n\n    for _ in range(len(graph) - 1):\n        for node in graph:\n            for neighbour in graph[node]:\n                if distance[neighbour] &gt; distance[node] + graph[node][neighbour]:\n                    distance[neighbour], predecessor[neighbour] = distance[node] + graph[node][neighbour], node\n\n    for node in graph:\n        for neighbour in graph[node]:\n            assert distance[neighbour] &lt;= distance[node] + graph[node][neighbour], \"Negative Cycle\"\n\n    return distance, predecessor\n</code></pre>"},{"location":"programming/algorithms/#36-z-algorithm-pattern-searching","title":"36. Z-algorithm (Pattern Searching)","text":"<p>Z algorithm is a linear time string matching algorithm which runs in O(n) complexity. It is used to find all occurrences of a pattern in a string, which is common string searching problem.</p> <p>Python example:</p> <pre><code>def getZarr(string, z):\n    n = len(string)\n    l, r, k = 0, 0, 0\n\n    for i in range(1, n):\n        if i &gt; r:\n            l, r = i, i\n            while r &lt; n and string[r - l] == string[r]:\n                r += 1\n            z[i] = r - l\n            r -= 1\n        else:\n            k = i - l\n            if z[k] &lt; r - i + 1:\n                z[i] = z[k]\n            else:\n                l = i\n                while r &lt; n and string[r - l] == string[r]:\n                    r += 1\n                z[i] = r - l\n                r -= 1\n</code></pre>"},{"location":"programming/algorithms/#37-kmp-knuth-morris-pratt-pattern-searching","title":"37. KMP (Knuth Morris Pratt) Pattern Searching","text":"<p>The KMP matching algorithm uses degenerating property (pattern having same sub-patterns appearing more than once in the pattern) of the pattern and improves the worst-case complexity to O(n).</p> <p>Python example:</p> <pre><code>def KMPSearch(pat, txt):\n    M = len(pat)\n    N = len(txt)\n    lps = [0]*M\n    j = 0\n    computeLPSArray(pat, M, lps)\n    i = 0\n    while i &lt; N:\n        if pat[j] == txt[i]:\n            i += 1\n            j += 1\n        if j == M:\n            print(\"Found pattern at index \" + str(i-j))\n            j = lps[j-1]\n        elif i &lt; N and pat[j] != txt[i]:\n            if j != 0:\n                j = lps[j-1]\n            else:\n                i += 1\n</code></pre>"},{"location":"programming/algorithms/#38-rabin-karp-algorithm-for-pattern-searching","title":"38. Rabin-Karp Algorithm for Pattern Searching","text":"<p>Rabin-Karp is a pattern searching algorithm to find the pattern in a more efficient way. It checks the pattern by moving window one by one, but without checking all characters for all cases, it finds the hash value. When the hash value is matched, then only it tries to check each character.</p> <p>Python example:</p> <pre><code>def search(pattern, txt, q):\n    M = len(pattern)\n    N = len(txt)\n    i = 0\n    j = 0\n    p = 0\n    t = 0\n    h = 1\n    d = 256\n    for i in range(M-1):\n        h = (h*d)%q\n    for i in range(M):\n        p = (d*p + ord(pattern[i]))%q\n        t = (d*t + ord(txt[i]))%q\n    for i in range(N-M+1):\n        if p==t:\n            for j in range(M):\n                if txt[i+j] != pattern[j]:\n                    break\n            j+=1\n            if j==M:\n                print(\"Pattern found at index \" + str(i))\n        if i &lt; N-M:\n            t = (d*(t-ord(txt[i])*h) + ord(txt[i+M]))%q\n            if t &lt; 0:\n                t = t+q\n</code></pre>"},{"location":"programming/algorithms/#39-kosarajus-algorithm-to-find-strongly-connected-components-in-a-graph","title":"39. Kosaraju's algorithm to find strongly connected components in a graph","text":"<p>Kosaraju's algorithm performs two passes over a graph to identify its strongly connected components. It's used in graph theory to identify clusters or related groups within the graph.</p> <p>Python example (due to its complexity, the full implementation is not provided here).</p>"},{"location":"programming/algorithms/#40-boyer-moore-algorithm-for-pattern-searching","title":"40. Boyer Moore Algorithm for Pattern Searching","text":"<p>Boyer Moore is a combination of following two approaches. 1) Bad Character Heuristic 2) Good Suffix Heuristic</p> <p>Python example:</p> <pre><code>NO_OF_CHARS = 256\ndef badCharHeuristic(string, size):\n    badChar = [-1]*NO_OF_CHARS\n    for i in range(size):\n        badChar[ord(string[i])] = i;\n    return badChar\n\ndef search(txt, pat):\n    m = len(pat)\n    n = len(txt)\n    badChar = badCharHeuristic(pat, m)\n    s = 0\n    while(s &lt;= n-m):\n        j = m-1\n        while j&gt;=0 and pat[j] == txt[s+j]:\n            j -= 1\n        if j&lt;0:\n            print(\"Pattern occur at shift = {}\".format(s))\n            s += (m-badChar[ord(txt[s+m])] if s+m&lt;n else 1)\n        else:\n            s += max(1, j-badChar[ord(txt[s+j])])\n</code></pre>"},{"location":"programming/code_review/","title":"Code Review","text":"<pre><code> Are CI builds passing? If no, why?\n\n\nIs the code easily understood?\nDoes the code work? Does it perform its intended function, the logic is correct, etc?\nDoes the error handling work?\nIs memory usage acceptable, even with large inputs?\n\n\nIs code covered by functional or unit tests?\nAre error paths covered by functional or unit tests? All errors which are relatively easy to check must be checked: error conditions like \u201copen() failed after stat() was successfull\u201d or \u201carray size greater then INT_MAX\u201d may be ignored for being just as unlikely as uneasy to test, but otherwise having bugs in code which does error handling is way too common to be ignored.\nFor new code, are unit tests written where needed?\n\n\nAre invalid parameter values handled where needed?\nCan any global/static variables be replaced?\nAre variables/functions named intuitively?\nCan any function attributes be used?\n\n\nIs there any redundant or duplicate code?\nIs the code modular enough?\nCan any of the code be replaced with library functions?\nDo loops have a set length and correct termination conditions?\nCan any logging or debugging code be removed?\nAre there any unneeded assert statements?\n\n\nDoes the code conform to the style guide?\nOptimization that makes code harder to read should only be implemented if a profiler or other tool has indicated that the routine stands to gain from optimization. These kinds of optimizations should be well-documented and code that performs the same task simply should be preserved somewhere.\n\n\nAre return values being checked?\nAre there any use after frees?\nAre there any resource leaks? Memory leaks, unclosed sockets, etc.\nAre there any null pointer dereferences?\nAre any uninitialized variables used?\nAre there any cases of possible arithmetic overflow?\n</code></pre> <p>Documentation</p> <pre><code>Are there any superfluous comments?\nWhere needed, do comments exist and describe the intent of the code?\nAre any comments made outdated by the new code?\nIs any unusual behavior or edge-case handling described?\nAre complex algorithms explained and justified?\nIs code that depends on non-obvious behavior in external libraries documented with reference to external documentation?\nIs the use and function of API functions documented?\nAre data structures/typedefs explained?\nIs there any incomplete code, e.g., code marked TODO, FIXME, or XXX?\n</code></pre>"},{"location":"programming/orm_sql/","title":"Advanced ORM Tutorial: Django, SQLAlchemy &amp; Raw SQL","text":""},{"location":"programming/orm_sql/#1-filtering-records-with-conditional-logic","title":"1. Filtering Records with Conditional Logic","text":""},{"location":"programming/orm_sql/#django-orm","title":"Django ORM:","text":"<pre><code>from django.models import Q\nYourModel.objects.filter(Q(field1=\"value1\") | Q(field2=\"value2\"))\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import or_\nsession.query(YourModel).filter(or_(YourModel.field1 == 'value1', YourModel.field2 == 'value2'))\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model WHERE field1 = 'value1' OR field2 = 'value2';\n</code></pre>"},{"location":"programming/orm_sql/#2-aggregating-data","title":"2. Aggregating Data","text":""},{"location":"programming/orm_sql/#django-orm_1","title":"Django ORM:","text":"<pre><code>from django.db.models import Sum\nYourModel.objects.aggregate(Sum('field1'))\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_1","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import func\nsession.query(func.sum(YourModel.field1)).scalar()\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_1","title":"Raw SQL:","text":"<pre><code>SELECT SUM(field1) FROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#3-joining-tables","title":"3. Joining Tables","text":""},{"location":"programming/orm_sql/#django-orm_2","title":"Django ORM:","text":"<pre><code>YourModel.objects.select_related('related_model')\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_2","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel, RelatedModel).join(RelatedModel)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_2","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model JOIN related_model ON your_model.related_id = related_model.id;\n</code></pre>"},{"location":"programming/orm_sql/#4-grouping-records","title":"4. Grouping Records","text":""},{"location":"programming/orm_sql/#django-orm_3","title":"Django ORM:","text":"<pre><code>from django.db.models import Count\nYourModel.objects.values('field1').annotate(Count('field2'))\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_3","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import func\nsession.query(YourModel.field1, func.count(YourModel.field2)).group_by(YourModel.field1)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_3","title":"Raw SQL:","text":"<pre><code>SELECT field1, COUNT(field2) FROM your_model GROUP BY field1;\n</code></pre>"},{"location":"programming/orm_sql/#5-complex-subqueries","title":"5. Complex Subqueries","text":""},{"location":"programming/orm_sql/#django-orm_4","title":"Django ORM:","text":"<pre><code>subquery = YourModel.objects.filter(field1=\"value1\").values('field2')\nresult = OtherModel.objects.filter(field3__in=subquery)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_4","title":"SQLAlchemy:","text":"<pre><code>subquery = session.query(YourModel.field2).filter(YourModel.field1 == 'value1').subquery()\nresult = session.query(OtherModel).filter(OtherModel.field3.in_(subquery))\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_4","title":"Raw SQL:","text":"<pre><code>SELECT * FROM other_model WHERE field3 IN (SELECT field2 FROM your_model WHERE field1 = 'value1');\n</code></pre>"},{"location":"programming/orm_sql/#6-limiting-and-offsetting-results","title":"6. Limiting and Offsetting Results","text":""},{"location":"programming/orm_sql/#django-orm_5","title":"Django ORM:","text":"<pre><code>YourModel.objects.all()[5:10]\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_5","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel).limit(5).offset(5)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_5","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model LIMIT 5 OFFSET 5;\n</code></pre>"},{"location":"programming/orm_sql/#7-transactions","title":"7. Transactions","text":""},{"location":"programming/orm_sql/#django-orm_6","title":"Django ORM:","text":"<pre><code>from django.db import transaction\n\nwith transaction.atomic():\n    YourModel.objects.create(field1=\"value1\")\n    YourModel.objects.create(field1=\"value2\")\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_6","title":"SQLAlchemy:","text":"<pre><code>with session.begin():\n    new_record1 = YourModel(field1=\"value1\")\n    new_record2 = YourModel(field1=\"value2\")\n    session.add(new_record1)\n    session.add(new_record2)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_6","title":"Raw SQL:","text":"<pre><code>BEGIN;\nINSERT INTO your_model (field1) VALUES ('value1');\nINSERT INTO your_model (field1) VALUES ('value2');\nCOMMIT;\n</code></pre>"},{"location":"programming/orm_sql/#8-custom-fields-expressions","title":"8. Custom Fields &amp; Expressions","text":""},{"location":"programming/orm_sql/#django-orm_7","title":"Django ORM:","text":"<pre><code>from django.db.models import F, ExpressionWrapper, IntegerField\nYourModel.objects.annotate(new_field=ExpressionWrapper(F('field1') + F('field2'), output_field=IntegerField()))\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_7","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import func\nsession.query(YourModel, (YourModel.field1 + YourModel.field2).label('new_field'))\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_7","title":"Raw SQL:","text":"<pre><code>SELECT *, (field1 + field2) AS new_field FROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#9-case-and-conditional-expressions","title":"9. Case and Conditional Expressions","text":""},{"location":"programming/orm_sql/#django-orm_8","title":"Django ORM:","text":"<pre><code>from django.db.models import Case, When, Value, CharField\nYourModel.objects.annotate(\n    field_status=Case(\n        When(field1=\"value1\", then=Value('status1')),\n        When(field1=\"value2\", then=Value('status2')),\n        default=Value('unknown'),\n        output_field=CharField()\n    )\n)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_8","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy.sql.expression import case\nsession.query(YourModel,\n    case([\n        (YourModel.field1 == \"value1\", \"status1\"),\n        (YourModel.field1 == \"value2\", \"status2\"),\n    ], else_=\"unknown\").label('field_status')\n)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_8","title":"Raw SQL:","text":"<pre><code>SELECT *,\n    CASE\n        WHEN field1 = 'value1' THEN 'status1'\n        WHEN field1 = 'value2' THEN 'status2'\n        ELSE 'unknown'\n    END AS field_status\nFROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#10-raw-sql-in-orm","title":"10. Raw SQL in ORM","text":""},{"location":"programming/orm_sql/#django-orm_9","title":"Django ORM:","text":"<pre><code>YourModel.objects.raw('SELECT * FROM your_model WHERE field1 = %s', ['value1'])\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_9","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel).from_statement(\"SELECT * FROM your_model WHERE field1 = :value\").params(value=\"value1\")\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_9","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model WHERE field1 = 'value1';\n</code></pre>"},{"location":"programming/orm_sql/#advanced-orm-optimization-techniques-django-sqlalchemy-raw-sql","title":"Advanced ORM Optimization Techniques: Django, SQLAlchemy &amp; Raw SQL","text":""},{"location":"programming/orm_sql/#1-avoiding-n1-queries-problem","title":"1. Avoiding <code>n+1</code> Queries Problem","text":""},{"location":"programming/orm_sql/#django-orm_10","title":"Django ORM:","text":"<pre><code># Using select_related for ForeignKey and OneToOneField relations\nYourModel.objects.select_related('related_model').all()\n\n# Using prefetch_related for ManyToManyField and reverse ForeignKey relations\nYourModel.objects.prefetch_related('related_model_set').all()\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_10","title":"SQLAlchemy:","text":"<pre><code># Using joinedload for JOINed loading\nfrom sqlalchemy.orm import joinedload\nsession.query(YourModel).options(joinedload(YourModel.related_model))\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_10","title":"Raw SQL:","text":"<pre><code>SELECT * FROM your_model \nJOIN related_model ON your_model.related_id = related_model.id;\n</code></pre>"},{"location":"programming/orm_sql/#2-only-fetch-what-you-need","title":"2. Only Fetch What You Need","text":""},{"location":"programming/orm_sql/#django-orm_11","title":"Django ORM:","text":"<pre><code>YourModel.objects.only('field1', 'field2')\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_11","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel.field1, YourModel.field2)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_11","title":"Raw SQL:","text":"<pre><code>SELECT field1, field2 FROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#3-using-database-indexes","title":"3. Using Database Indexes","text":""},{"location":"programming/orm_sql/#django-orm_12","title":"Django ORM:","text":"<pre><code># When defining the model, use db_index=True\nclass YourModel(models.Model):\n    field1 = models.CharField(max_length=100, db_index=True)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_12","title":"SQLAlchemy:","text":"<pre><code># Define the index within the table\nfrom sqlalchemy import Index, create_engine, MetaData\n\nmeta = MetaData()\nyour_table = Table('your_model', meta,\n    Column('field1', String, index=True)\n)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_12","title":"Raw SQL:","text":"<pre><code>CREATE INDEX index_name ON your_model (field1);\n</code></pre>"},{"location":"programming/orm_sql/#4-batch-inserts","title":"4. Batch Inserts","text":""},{"location":"programming/orm_sql/#django-orm_13","title":"Django ORM:","text":"<pre><code># Using bulk_create\nYourModel.objects.bulk_create([YourModel(field1=value) for value in value_list])\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_13","title":"SQLAlchemy:","text":"<pre><code>session.bulk_insert_mappings(YourModel, [{'field1': value} for value in value_list])\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_13","title":"Raw SQL:","text":"<pre><code>INSERT INTO your_model (field1) VALUES (value1), (value2), ...;\n</code></pre>"},{"location":"programming/orm_sql/#5-optimizing-count-queries","title":"5. Optimizing Count Queries","text":""},{"location":"programming/orm_sql/#django-orm_14","title":"Django ORM:","text":"<pre><code>YourModel.objects.filter(some_criteria=True).count()\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_14","title":"SQLAlchemy:","text":"<pre><code>session.query(func.count(YourModel.id)).filter(YourModel.some_criteria == True)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_14","title":"Raw SQL:","text":"<pre><code>SELECT COUNT(id) FROM your_model WHERE some_criteria = TRUE;\n</code></pre>"},{"location":"programming/orm_sql/#6-use-exists-for-presence-checks","title":"6. Use EXISTS for Presence Checks","text":""},{"location":"programming/orm_sql/#django-orm_15","title":"Django ORM:","text":"<pre><code>if YourModel.objects.filter(field1=value).exists():\n    # Do something\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_15","title":"SQLAlchemy:","text":"<pre><code>if session.query(YourModel).filter(YourModel.field1 == value).limit(1).first():\n    # Do something\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_15","title":"Raw SQL:","text":"<pre><code>SELECT EXISTS(SELECT 1 FROM your_model WHERE field1 = value);\n</code></pre>"},{"location":"programming/orm_sql/#7-use-database-functions-for-computation","title":"7. Use Database Functions for Computation","text":""},{"location":"programming/orm_sql/#django-orm_16","title":"Django ORM:","text":"<pre><code>from django.db.models.functions import Coalesce\nYourModel.objects.update(field2=Coalesce('field2', 0) + 1)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_16","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy.sql.expression import func\nsession.query(YourModel).update({YourModel.field2: func.coalesce(YourModel.field2, 0) + 1})\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_16","title":"Raw SQL:","text":"<pre><code>UPDATE your_model SET field2 = COALESCE(field2, 0) + 1;\n</code></pre>"},{"location":"programming/orm_sql/#8-avoiding-orm-overhead-for-large-data-sets","title":"8. Avoiding ORM Overhead for Large Data Sets","text":""},{"location":"programming/orm_sql/#django-orm_17","title":"Django ORM:","text":"<pre><code>YourModel.objects.values('field1', 'field2')\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_17","title":"SQLAlchemy:","text":"<pre><code>session.query(YourModel.field1, YourModel.field2).yield_per(1000)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_17","title":"Raw SQL:","text":"<pre><code>SELECT field1, field2 FROM your_model;\n</code></pre>"},{"location":"programming/orm_sql/#9-de-normalization-for-faster-reads","title":"9. De-normalization for Faster Reads","text":""},{"location":"programming/orm_sql/#django-orm_18","title":"Django ORM:","text":"<pre><code># Using annotated fields or computed properties\nclass YourModel(models.Model):\n    field1 = models.IntegerField()\n    field2 = models.IntegerField()\n    total = models.IntegerField(editable=False)\n\n    def save(self, *args, **kwargs):\n        self.total = self.field1 + self.field2\n        super().save(*args, **kwargs)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_18","title":"SQLAlchemy:","text":"<pre><code>from sqlalchemy import Column, Integer, event\n\nclass YourModel(Base):\n    __tablename__ = 'your_model'\n\n    id = Column(Integer, primary_key=True)\n    field1 = Column(Integer)\n    field2 = Column(Integer)\n    total = Column(Integer)\n\n@event.listens_for(YourModel, 'before_insert')\ndef before_insert(mapper, connection, target):\n    target.total = target.field1 + target.field2\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_18","title":"Raw SQL:","text":"<pre><code>-- Assuming the total column is already added to your_model\nUPDATE your_model SET total = field1 + field2;\n</code></pre>"},{"location":"programming/orm_sql/#10-caching-expensive-queries","title":"10. Caching Expensive Queries","text":""},{"location":"programming/orm_sql/#django-orm_19","title":"Django ORM:","text":"<pre><code># Using Django's cache framework\nfrom django.core.cache import cache\n\nkey = \"your_cache_key\"\ndata = cache.get(key)\n\nif data is None:\n    data = YourModel.objects.filter(some_criteria=True)\n    cache.set(key, data)\n</code></pre>"},{"location":"programming/orm_sql/#sqlalchemy_19","title":"SQLAlchemy:","text":"<pre><code># Using dogpile.cache for SQLAlchemy\nfrom dogpile.cache import make_region\n\nregion = make_region().configure('dogpile.cache.memory', expiration_time=3600)\nkey = \"your_cache_key\"\ndata = region.get(key)\n\nif data is None:\n    data = session.query(YourModel).filter(YourModel.some_criteria == True).all()\n    region.set(key, data)\n</code></pre>"},{"location":"programming/orm_sql/#raw-sql_19","title":"Raw SQL:","text":"<pre><code>-- This varies by the database and specific caching solutions. Typically, databases have their internal caching mechanisms for frequent queries.\n\n# Deep Dive into Advanced ORM Techniques: Django, SQLAlchemy &amp; Raw SQL\n\n## 11. Composite Primary Keys\n\n### Django ORM:\n</code></pre>"},{"location":"programming/orm_sql/#django-does-not-natively-support-composite-primary-keys-however-you-can-use-a-unique-constraint","title":"Django does not natively support composite primary keys. However, you can use a unique constraint.","text":"<p>class YourModel(models.Model):     field1 = models.IntegerField()     field2 = models.IntegerField()</p> <pre><code>class Meta:\n    constraints = [\n        models.UniqueConstraint(fields=['field1', 'field2'], name='unique_field1_field2')\n    ]\n</code></pre> <p>``` </p>"},{"location":"programming/orm_sql/#sqlalchemy_20","title":"SQLAlchemy:","text":"<p>``` from sqlalchemy import Column, Integer, PrimaryKeyConstraint</p> <p>class YourModel(Base):     tablename = 'your_model'</p> <pre><code>field1 = Column(Integer)\nfield2 = Column(Integer)\n\n__table_args__ = (\n    PrimaryKeyConstraint('field1', 'field2'),\n)\n</code></pre> <p>``` </p>"},{"location":"programming/orm_sql/#raw-sql_20","title":"Raw SQL:","text":"<p><code>CREATE TABLE your_model (     field1 INT,     field2 INT,     PRIMARY KEY (field1, field2) );</code> </p>"},{"location":"programming/orm_sql/#12-using-views","title":"12. Using Views","text":""},{"location":"programming/orm_sql/#django-orm_20","title":"Django ORM:","text":"<p>```</p>"},{"location":"programming/orm_sql/#create-a-view-in-your-database-then-create-a-model-mapped-to-this-view-ensure-db_table-points-to-the-view","title":"Create a view in your database, then create a model mapped to this view. Ensure db_table points to the view.","text":"<p>class YourViewModel(models.Model):     field1 = models.IntegerField()     field2 = models.IntegerField()</p> <pre><code>class Meta:\n    managed = False  # Django will not manage this table\n    db_table = 'your_view'\n</code></pre> <p>``` </p>"},{"location":"programming/orm_sql/#sqlalchemy_21","title":"SQLAlchemy:","text":"<p>```</p>"},{"location":"programming/orm_sql/#map-the-model-to-an-existing-view","title":"Map the model to an existing view.","text":"<p>class YourViewModel(Base):     tablename = 'your_view'     field1 = Column(Integer, primary_key=True)     field2 = Column(Integer) ``` </p>"},{"location":"programming/orm_sql/#raw-sql_21","title":"Raw SQL:","text":"<p><code>CREATE VIEW your_view AS SELECT field1, field2 FROM your_model WHERE some_criteria = TRUE;</code> </p>"},{"location":"programming/orm_sql/#13-temporary-tables","title":"13. Temporary Tables","text":""},{"location":"programming/orm_sql/#django-orm_21","title":"Django ORM:","text":"<p>```</p>"},{"location":"programming/orm_sql/#django-orm-doesnt-have-built-in-support-for-temporary-tables-youd-typically-create-them-using-raw-sql","title":"Django ORM doesn't have built-in support for temporary tables. You'd typically create them using raw SQL.","text":"<p>from django.db import connection</p> <p>with connection.cursor() as cursor:     cursor.execute('''         CREATE TEMPORARY TABLE temp_your_model AS         SELECT * FROM your_model WHERE some_criteria = TRUE;     ''') <pre><code>### SQLAlchemy:\n</code></pre></p>"},{"location":"programming/orm_sql/#use-the-standard-table-creation-but-specify-it-as-a-temporary-table","title":"Use the standard table creation but specify it as a temporary table.","text":"<p>temp_table = Table(     \"temp_your_model\", metadata,     Column('field1', Integer),     # Add other columns...     prefixes=['TEMPORARY'] ) temp_table.create(bind=engine) <pre><code>### Raw SQL:\n</code></pre> CREATE TEMPORARY TABLE temp_your_model AS SELECT * FROM your_model WHERE some_criteria = TRUE; <pre><code>## 14. Recursive Queries (Common Table Expressions)\n\n### Django ORM:\n</code></pre></p>"},{"location":"programming/orm_sql/#django-31-introduced-support-for-recursive-ctes","title":"Django 3.1 introduced support for recursive CTEs","text":"<p>from django_cte import CTEManager, CTEQuerySet</p> <p>class YourModel(models.Model):     parent = models.ForeignKey('self', null=True, on_delete=models.CASCADE)     name = models.CharField(max_length=200)</p> <pre><code>objects = CTEManager.from_queryset(CTEQuerySet)()\n</code></pre> <p>with YourModel.objects.with_cte(recursive=True) as cte:     cte_qs = cte.queryset.annotate(level=models.Value(0)).filter(name=\"root_name\")     children_qs = cte.queryset.filter(parent=cte.join()).annotate(level=cte.col.level + 1)     cte.union(cte_qs, children_qs)     results = cte.all() <pre><code>### SQLAlchemy:\n</code></pre> from sqlalchemy import select, union_all from sqlalchemy.orm import aliased</p> <p>descendants = select([     YourModel.id, YourModel.parent_id, YourModel.name ]).where(YourModel.name == 'root_name').cte(name='descendants', recursive=True)</p> <p>parent_alias = aliased(descendants) children = select([     YourModel.id, YourModel.parent_id, YourModel.name ]).join(     parent_alias, parent_alias.c.id == YourModel.parent_id )</p> <p>descendants = descendants.union_all(children) session.query(descendants).all() <pre><code>### Raw SQL:\n</code></pre> WITH RECURSIVE descendants AS (     SELECT id, parent_id, name     FROM your_model WHERE name = 'root_name'</p> <pre><code>UNION ALL\n\nSELECT m.id, m.parent_id, m.name\nFROM your_model m\nJOIN descendants d ON d.id = m.parent_id\n</code></pre> <p>) SELECT * FROM descendants; ``` </p>"},{"location":"programming/orm_sql/#15-upserts-insert-or-update","title":"15. Upserts (Insert or Update)","text":""},{"location":"programming/orm_sql/#django-orm_22","title":"Django ORM:","text":"<p>``` from django.db import IntegrityError</p> <p>try:     YourModel.objects.create(id=some_id, field1=value1) except IntegrityError:     YourModel.objects.filter(id=some_id).update(field1=value1) <pre><code>### SQLAlchemy:\n</code></pre> from sqlalchemy.dialects.postgresql import insert</p> <p>stmt = insert(YourModel).values(id=some_id, field1=value1) stmt = stmt.on_conflict_do_update(     index_elements=['id'],     set_=dict(field1=value1) ) session.execute(stmt) <pre><code>### Raw SQL:\n</code></pre> INSERT INTO your_model (id, field1) VALUES (some_id, 'value1') ON CONFLICT (id) DO UPDATE SET field1 = 'value1'; ```</p> <p>These are some deeper techniques and features that can be utilized in ORMs and SQL to optimize, enhance, and leverage powerful database features. Remember that the most suitable technique always depends on the specific problem you're solving, the database you're using, and the scale at which you operate.</p>"},{"location":"python/async/","title":"asyncio","text":""},{"location":"python/async/#1-introduction-to-asynchronous-programming","title":"1. Introduction to Asynchronous Programming","text":"<p>Asynchronous programming is a method that allows for the execution of certain tasks concurrently without blocking the main thread. Instead of waiting for one task to complete before moving on to the next, asynchronous programming allows multiple tasks to run in \"parallel\", making better use of system resources and often speeding up overall execution.</p> <p>Next topic: Traditional Multi-threading vs Asynchronous Programming.</p>"},{"location":"python/async/#2-traditional-multi-threading-vs-asynchronous-programming","title":"2. Traditional Multi-threading vs Asynchronous Programming","text":"<p>In traditional multi-threading, multiple threads run in parallel. Each thread might be executing a different task or function. While this allows for concurrent execution, it also introduces complexity with thread management, synchronization, and potential deadlocks.</p> <p>In contrast, asynchronous programming, especially in Python's context, utilizes a single-threaded event loop. Tasks are executed in this loop but can yield control back to the loop when waiting for some I/O operations, allowing other tasks to run.</p> <p>Advantages of Asynchronous Programming: - Scalability: Asynchronous programs can handle many tasks with a single thread. - Simplicity: Avoids complexities of thread synchronization and deadlocks.</p> <p>Next topic: Python's <code>asyncio</code> Basics.</p>"},{"location":"python/async/#3-pythons-asyncio-basics","title":"3. Python's <code>asyncio</code> Basics","text":""},{"location":"python/async/#31-async-await","title":"3.1. <code>async</code> &amp; <code>await</code>","text":"<p>To mark a function as asynchronous, you use the <code>async</code> keyword before <code>def</code>: <pre><code>async def my_async_function():\n    pass\n</code></pre></p> <p>To call asynchronous functions or to execute asynchronous code inside an async function, you use the <code>await</code> keyword: <pre><code>async def fetch_data():\n    data = await get_data_from_source()\n    return data\n</code></pre></p>"},{"location":"python/async/#32-event-loop","title":"3.2. Event Loop","text":"<p>The event loop is the heart of every asyncio application. It allows you to schedule asynchronous tasks and callbacks, run them, and manage their execution flow.</p> <pre><code>import asyncio\n\nasync def main():\n    print(\"Hello\")\n    await asyncio.sleep(1)\n    print(\"World\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#33-tasks-and-coroutines","title":"3.3. Tasks and Coroutines","text":"<p>Tasks are used to schedule coroutines concurrently. A coroutine is a special type of function that can yield control back to the event loop, allowing other coroutines to run.</p> <pre><code>import asyncio\n\nasync def say_hello():\n    await asyncio.sleep(1)\n    print(\"Hello\")\n\nasync def say_world():\n    print(\"World\")\n\nasync def main():\n    task1 = asyncio.create_task(say_hello())\n    task2 = asyncio.create_task(say_world())\n    await task1\n    await task2\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Asynchronous I/O with Python.</p>"},{"location":"python/async/#4-asynchronous-io-with-python","title":"4. Asynchronous I/O with Python","text":"<p>One of the primary uses for asynchronous programming is handling Input/Output (I/O) operations without blocking. I/O-bound tasks, such as network requests or reading and writing to databases, often involve waiting. Asynchronous I/O lets us perform these tasks more efficiently.</p> <p>For instance, when fetching data from multiple URLs, instead of waiting for each request to complete one after another, you can fetch from multiple URLs \"at the same time\".</p> <pre><code>import aiohttp\nimport asyncio\n\nasync def fetch_url(url):\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as response:\n            return await response.text()\n\nasync def main():\n    urls = [\"http://example.com\", \"http://example.org\", \"http://example.net\"]\n    tasks = [fetch_url(url) for url in urls]\n    results = await asyncio.gather(*tasks)\n    for url, result in zip(urls, results):\n        print(f\"Data from {url[:30]}: {len(result)} characters\")\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Advanced Techniques in Asynchronous Programming.</p>"},{"location":"python/async/#5-advanced-techniques-in-asynchronous-programming","title":"5. Advanced Techniques in Asynchronous Programming","text":""},{"location":"python/async/#51-managing-multiple-tasks-with-gather-wait","title":"5.1. Managing Multiple Tasks with <code>gather</code> &amp; <code>wait</code>","text":"<p>We've already seen <code>gather</code> in action, which waits for all tasks to complete and returns their results. However, sometimes you might want to proceed as soon as one of the tasks completes, and for that, you can use <code>asyncio.wait</code> with the <code>FIRST_COMPLETED</code> option.</p> <pre><code>import asyncio\n\nasync def task_one():\n    await asyncio.sleep(2)\n    return \"Task One Completed!\"\n\nasync def task_two():\n    await asyncio.sleep(1)\n    return \"Task Two Completed!\"\n\nasync def main():\n    tasks = [task_one(), task_two()]\n    done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n\n    for task in done:\n        print(task.result())\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#52-handling-timeouts-and-delays","title":"5.2. Handling Timeouts and Delays","text":"<p>Sometimes you might not want to wait indefinitely for a task to complete. Using <code>asyncio.wait_for</code>, you can set a timeout.</p> <pre><code>import asyncio\n\nasync def long_task():\n    await asyncio.sleep(10)\n\nasync def main():\n    try:\n        await asyncio.wait_for(long_task(), timeout=5)\n    except asyncio.TimeoutError:\n        print(\"Task took too long!\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#53-error-handling-in-async-context","title":"5.3. Error Handling in Async Context","text":"<p>Just like with synchronous code, you can use try-except blocks to handle errors in asynchronous functions.</p> <pre><code>import asyncio\n\nasync def risky_task():\n    raise ValueError(\"This is an intentional error!\")\n\nasync def main():\n    try:\n        await risky_task()\n    except ValueError as e:\n        print(f\"Caught an error: {e}\")\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Integration with Other Libraries.</p>"},{"location":"python/async/#6-integration-with-other-libraries","title":"6. Integration with Other Libraries","text":""},{"location":"python/async/#61-aiohttp-for-asynchronous-http-requests","title":"6.1. <code>aiohttp</code> for Asynchronous HTTP Requests","text":"<p>We briefly touched on <code>aiohttp</code> earlier. It's a powerful library that provides asynchronous HTTP client and server functionality. The client lets you make non-blocking requests, while the server allows you to handle incoming requests asynchronously.</p> <p>Example using <code>aiohttp</code> as a server:</p> <pre><code>from aiohttp import web\n\nasync def handle(request):\n    return web.Response(text=\"Hello, world!\")\n\napp = web.Application()\napp.router.add_get('/', handle)\n\nweb.run_app(app)\n</code></pre>"},{"location":"python/async/#62-aiomysql-aiopg-for-asynchronous-database-operations","title":"6.2. <code>aiomysql</code> &amp; <code>aiopg</code> for Asynchronous Database Operations","text":"<p>For database operations, you can use libraries like <code>aiomysql</code> for MySQL and <code>aiopg</code> for PostgreSQL. These libraries provide asynchronous interfaces to interact with databases.</p> <p>Example using <code>aiomysql</code>:</p> <pre><code>import asyncio\nimport aiomysql\n\nasync def main():\n    pool = await aiomysql.create_pool(host='127.0.0.1', port=3306, user='user', password='password', db='testdb')\n\n    async with pool.acquire() as conn:\n        async with conn.cursor() as cur:\n            await cur.execute(\"SELECT some_column FROM some_table;\")\n            print(await cur.fetchone())\n\n    pool.close()\n    await pool.wait_closed()\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Potential Pitfalls and Common Mistakes.</p>"},{"location":"python/async/#7-potential-pitfalls-and-common-mistakes","title":"7. Potential Pitfalls and Common Mistakes","text":"<p>Understanding the potential pitfalls in asynchronous programming can save developers a lot of time and prevent unexpected behaviors.</p>"},{"location":"python/async/#71-mixing-sync-and-async-code","title":"7.1. Mixing Sync and Async Code","text":"<p>One of the common mistakes is mixing synchronous code with asynchronous code without being aware of the consequences. For instance, using a blocking function inside an async function can halt the entire event loop.</p> <pre><code>import asyncio\nimport time\n\nasync def wrong_usage():\n    time.sleep(3)  # This is a blocking call\n    print(\"This will block the entire event loop\")\n\nasyncio.run(wrong_usage())\n</code></pre> <p>Always ensure that you're using non-blocking alternatives inside async functions.</p>"},{"location":"python/async/#72-forgetting-await","title":"7.2. Forgetting <code>await</code>","text":"<p>Another easy mistake is forgetting the <code>await</code> keyword when calling an async function. This results in the function not being executed, and instead, a coroutine object is returned.</p> <pre><code>async def greet():\n    return \"Hello, World!\"\n\nasync def main():\n    greeting = greet()  # Forgot await\n    print(greeting)  # This will print a coroutine object, not the greeting.\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#73-not-handling-exceptions-in-tasks","title":"7.3. Not Handling Exceptions in Tasks","text":"<p>If an exception is raised in a Task and not caught, it won't propagate immediately. Instead, it will propagate when the Task object is garbage collected, which can make debugging tricky.</p> <pre><code>import asyncio\n\nasync def raise_error():\n    raise Exception(\"Intentional Error\")\n\nasync def main():\n    task = asyncio.create_task(raise_error())\n    await asyncio.sleep(1)\n\nasyncio.run(main())\n</code></pre> <p>Always ensure you handle exceptions in your tasks, either within the task or when gathering/waiting for them.</p> <p>Next topic: Best Practices &amp; Recommendations.</p>"},{"location":"python/async/#8-best-practices-recommendations","title":"8. Best Practices &amp; Recommendations","text":"<p>When writing asynchronous code, following best practices can help maintainability, performance, and overall code quality.</p>"},{"location":"python/async/#81-use-async-and-await-consistently","title":"8.1. Use <code>async</code> and <code>await</code> Consistently","text":"<p>Ensure that you're consistently using the <code>async</code> and <code>await</code> keywords appropriately. If a function is asynchronous, mark it with <code>async</code> and ensure that its callers are aware that they're calling an async function.</p>"},{"location":"python/async/#82-favor-high-level-apis","title":"8.2. Favor High-Level APIs","text":"<p>Python's <code>asyncio</code> provides both high-level and low-level APIs. Whenever possible, favor high-level APIs as they are more user-friendly and abstract away a lot of the complexity.</p>"},{"location":"python/async/#83-use-asynchronous-context-managers","title":"8.3. Use Asynchronous Context Managers","text":"<p>Many async libraries provide asynchronous context managers, which help in ensuring that resources are properly managed. </p> <p>For example, with <code>aiohttp</code>, you can use:</p> <pre><code>async with aiohttp.ClientSession() as session:\n    ...\n</code></pre> <p>This ensures that the session is properly closed after usage.</p>"},{"location":"python/async/#84-be-wary-of-thread-safety","title":"8.4. Be Wary of Thread-Safety","text":"<p>Even though asynchronous code in Python usually runs in a single thread, if you integrate with other systems or use thread pools, be aware of thread-safety. Ensure shared resources are accessed in a thread-safe manner.</p> <p>Next topic: Conclusion and Future of Python Async.</p>"},{"location":"python/async/#9-conclusion-and-future-of-python-async","title":"9. Conclusion and Future of Python Async","text":"<p>Asynchronous programming in Python has come a long way, especially with the introduction and continuous development of <code>asyncio</code>. It provides a powerful toolset for writing efficient I/O-bound programs.</p> <p>However, like all tools, it's essential to understand its strengths and limitations, and when to use it. Not all problems are best solved with asynchronicity, and sometimes, traditional multi-threading or even multi-processing can be more appropriate.</p> <p>The future looks bright for async in Python, with continuous enhancements to <code>asyncio</code> and a growing ecosystem of asynchronous libraries. As the community gains more experience and the tooling improves, we can expect even more robust and performant asynchronous applications in Python.</p> <p>End of Topics.</p>"},{"location":"python/async/#10-advanced-queue-operations-with-asyncio","title":"10. Advanced Queue Operations with <code>asyncio</code>","text":"<p><code>asyncio</code> provides a Queue class that is similar to <code>queue.Queue</code> but designed to be used with async functions.</p>"},{"location":"python/async/#101-basic-queue-operations","title":"10.1. Basic Queue Operations","text":"<p>Queues are an essential part of many concurrent programs and can be used to pass messages between different parts of a system.</p> <pre><code>import asyncio\n\nasync def producer(queue):\n    for i in range(5):\n        await queue.put(i)\n        print(f\"Produced {i}\")\n        await asyncio.sleep(1)\n\nasync def consumer(queue):\n    for _ in range(5):\n        item = await queue.get()\n        print(f\"Consumed {item}\")\n\nqueue = asyncio.Queue()\nasyncio.run(asyncio.gather(producer(queue), consumer(queue)))\n</code></pre>"},{"location":"python/async/#102-implementing-producer-consumer-with-asyncio","title":"10.2. Implementing Producer-Consumer with <code>asyncio</code>","text":"<p>The producer-consumer pattern is a classic concurrency pattern where one or more producers add tasks to a queue, and one or more consumers take tasks from the queue and process them.</p> <pre><code>import asyncio\nimport random\n\nasync def producer(queue, name):\n    for _ in range(5):\n        item = random.randint(1, 10)\n        await asyncio.sleep(random.random())\n        await queue.put(item)\n        print(f\"Producer {name} produced {item}\")\n\nasync def consumer(queue, name):\n    while True:\n        await asyncio.sleep(random.random())\n        item = await queue.get()\n        if item is None:  # Sentinel value to exit\n            break\n        print(f\"Consumer {name} consumed {item}\")\n\nqueue = asyncio.Queue()\n\nproducers = [producer(queue, name=i) for i in range(3)]\nconsumers = [consumer(queue, name=i) for i in range(3)]\n\n# Run the producers and consumers\nasyncio.run(asyncio.gather(*producers, *consumers))\n\n# Signal the consumers to exit\nfor _ in range(3):\n    queue.put_nowait(None)\n</code></pre>"},{"location":"python/async/#103-limiting-queue-size","title":"10.3. Limiting Queue Size","text":"<p>For certain applications, you might want to limit the number of items a queue can hold. This can be useful to apply backpressure on the producer when the queue gets full.</p> <pre><code>queue = asyncio.Queue(maxsize=5)\n\nasync def bounded_producer(queue):\n    for i in range(10):\n        print(f\"Producing {i}\")\n        await queue.put(i)\n        print(f\"Produced {i}\")\n        await asyncio.sleep(0.5)\n\nasyncio.run(bounded_producer(queue))\n</code></pre> <p>When the queue reaches its maximum size, <code>queue.put</code> will block until there's room to add another item.</p> <p>Next topic: More Advanced Techniques in Asynchronous Programming.</p>"},{"location":"python/async/#11-more-advanced-techniques-in-asynchronous-programming","title":"11. More Advanced Techniques in Asynchronous Programming","text":""},{"location":"python/async/#111-priority-queues","title":"11.1. Priority Queues","text":"<p>You can use priority queues to ensure that some tasks get priority over others:</p> <pre><code>import asyncio\nimport heapq\n\nclass AsyncPriorityQueue:\n    def __init__(self):\n        self._queue = []\n        self._count = 0\n        self._event = asyncio.Event()\n\n    async def put(self, item, priority):\n        heapq.heappush(self._queue, (priority, self._count, item))\n        self._count += 1\n        self._event.set()\n\n    async def get(self):\n        while not self._queue:\n            self._event.clear()\n            await self._event.wait()\n        priority, count, item = heapq.heappop(self._queue)\n        return item\n</code></pre>"},{"location":"python/async/#112-semaphores-and-locks","title":"11.2. Semaphores and Locks","text":"<p>Semaphores and locks are synchronization primitives that can be used to protect resources:</p> <pre><code>import asyncio\n\nsem = asyncio.Semaphore(10)  # Allows 10 tasks to access a resource at a time\n\nasync def worker(num):\n    async with sem:\n        print(f\"Worker {num} has started\")\n        await asyncio.sleep(1)\n        print(f\"Worker {num} has finished\")\n\nasyncio.run(asyncio.gather(*(worker(i) for i in range(20))))\n</code></pre>"},{"location":"python/async/#113-async-streams","title":"11.3. Async Streams","text":"<p>Async streams allow you to consume or produce multiple values with async iteration:</p> <pre><code>import asyncio\n\nasync def ticker(delay, to):\n    for i in range(to):\n        yield i\n        await asyncio.sleep(delay)\n\nasync def main():\n    async for tick in ticker(1, 5):\n        print(f\"Tick: {tick}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#114-exception-propagation","title":"11.4. Exception Propagation","text":"<p>When working with tasks, handling exceptions is crucial:</p> <pre><code>import asyncio\n\nasync def raise_exception():\n    raise ValueError(\"An error occurred!\")\n\nasync def main():\n    tasks = [raise_exception(), asyncio.sleep(1)]\n    results, _ = await asyncio.wait(tasks, return_when=asyncio.FIRST_EXCEPTION)\n    for task in results:\n        try:\n            task.result()  # Will raise the ValueError\n        except ValueError as e:\n            print(f\"Caught an error: {e}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#115-using-tasks-effectively","title":"11.5. Using Tasks Effectively","text":"<p>While creating tasks is simple, managing their lifecycle and ensuring they complete without hanging your application can be tricky:</p> <pre><code>import asyncio\n\nasync def do_work():\n    await asyncio.sleep(2)\n\nasync def main():\n    task = asyncio.create_task(do_work())\n    await asyncio.sleep(1)\n    print(\"Main work done!\")\n    await task  # Ensure all spawned tasks are awaited\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Combining Async IO with Multiprocessing.</p>"},{"location":"python/async/#12-combining-async-io-with-multiprocessing","title":"12. Combining Async IO with Multiprocessing","text":"<p>While <code>asyncio</code> excels at I/O-bound tasks, it runs in a single thread and doesn't utilize multiple cores for CPU-bound tasks. For these tasks, you can combine <code>asyncio</code> with multiprocessing to achieve parallelism across cores.</p>"},{"location":"python/async/#121-basic-async-with-multiprocessing","title":"12.1. Basic Async with Multiprocessing","text":"<p>Here's a simple demonstration of running CPU-bound tasks in separate processes while using async for I/O:</p> <pre><code>import asyncio\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef cpu_bound_task(data):\n    # Simulating a CPU-bound task by calculating sum\n    return sum(data)\n\nasync def main():\n    data = [range(1000000) for _ in range(4)]\n    with ProcessPoolExecutor() as pool:\n        result = await asyncio.gather(*(loop.run_in_executor(pool, cpu_bound_task, d) for d in data))\n    print(result)\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n</code></pre>"},{"location":"python/async/#122-asynchronous-process-communication","title":"12.2. Asynchronous Process Communication","text":"<p>Communicate between processes using <code>asyncio</code> and <code>multiprocessing</code>:</p> <pre><code>import asyncio\nimport multiprocessing\n\ndef worker(q):\n    for i in range(5):\n        q.put(i)\n        print(f\"Produced {i}\")\n\nasync def async_consumer(q):\n    for _ in range(5):\n        item = await loop.run_in_executor(None, q.get)\n        print(f\"Consumed {item}\")\n\nqueue = multiprocessing.Queue()\nprocess = multiprocessing.Process(target=worker, args=(queue,))\n\nloop = asyncio.get_event_loop()\nprocess.start()\nloop.run_until_complete(async_consumer(queue))\nprocess.join()\n</code></pre>"},{"location":"python/async/#123-challenges-and-considerations","title":"12.3. Challenges and Considerations","text":"<ul> <li>Error Handling: Ensure that exceptions in worker processes are properly propagated and handled.</li> <li>Data Serialization: Remember that data sent between processes needs to be serialized and deserialized, which can introduce overhead.</li> <li>Resource Management: Ensure all processes are cleaned up to avoid resource leaks or zombie processes.</li> </ul> <p>Next topic: Advanced Patterns and Designs in Async Applications.</p>"},{"location":"python/async/#13-advanced-patterns-and-designs-in-async-applications","title":"13. Advanced Patterns and Designs in Async Applications","text":""},{"location":"python/async/#131-event-driven-architecture","title":"13.1. Event-driven Architecture","text":"<p>Using <code>asyncio</code>, you can build an event-driven system where components react to events rather than follow a strict sequential order:</p> <pre><code>class EventBus:\n    def __init__(self):\n        self._listeners = {}\n\n    def add_listener(self, event, listener):\n        if event not in self._listeners:\n            self._listeners[event] = []\n        self._listeners[event].append(listener)\n\n    async def emit(self, event, data):\n        for listener in self._listeners.get(event, []):\n            await listener(data)\n\nasync def print_on_event(data):\n    print(f\"Received event with data: {data}\")\n\nbus = EventBus()\nbus.add_listener(\"data_event\", print_on_event)\n\nasync def main():\n    await bus.emit(\"data_event\", \"Some event data\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#132-service-actor-pattern","title":"13.2. Service Actor Pattern","text":"<p>In an async world, actors can be lightweight services that hold state and provide methods to act on that state:</p> <pre><code>class ServiceActor:\n    def __init__(self):\n        self._state = 0\n\n    async def increment(self):\n        self._state += 1\n        print(f\"State incremented to {self._state}\")\n\n    async def decrement(self):\n        self._state -= 1\n        print(f\"State decremented to {self._state}\")\n\nactor = ServiceActor()\n\nasync def main():\n    await actor.increment()\n    await actor.decrement()\n\nasyncio.run(main())\n</code></pre>"},{"location":"python/async/#133-reactive-extensions-rxpy-with-async","title":"13.3. Reactive Extensions (RxPY with Async)","text":"<p><code>RxPY</code> supports asynchronous operations and can be integrated with <code>asyncio</code> for reactive programming:</p> <pre><code>import rx\nfrom rx.scheduler.eventloop import AsyncIOScheduler\nimport asyncio\n\nasync def source(observer, scheduler):\n    await asyncio.sleep(1, loop=scheduler.loop)\n    observer.on_next(42)\n    observer.on_completed()\n\nstream = rx.create(source)\nstream.subscribe(on_next=print, scheduler=AsyncIOScheduler(asyncio.get_event_loop()))\n\nasyncio.get_event_loop().run_forever()\n</code></pre> <p>Next topic: Debugging and Profiling Asynchronous Python Applications.</p>"},{"location":"python/async/#14-debugging-and-profiling-asynchronous-python-applications","title":"14. Debugging and Profiling Asynchronous Python Applications","text":"<p>Debugging and profiling asynchronous applications can be different than traditional synchronous applications. Let's look into techniques and tools available for <code>asyncio</code>:</p>"},{"location":"python/async/#141-debug-mode-in-asyncio","title":"14.1. Debug Mode in <code>asyncio</code>","text":"<p><code>asyncio</code> provides a debug mode that can help catch common mistakes:</p> <pre><code>import asyncio\n\nasync def forgot_await():\n    asyncio.sleep(1)  # Missing `await`\n\nasyncio.get_event_loop().set_debug(True)\nasyncio.run(forgot_await())\n</code></pre> <p>In debug mode, the above will print a warning indicating that a coroutine has not been awaited.</p>"},{"location":"python/async/#142-logging-unclosed-resources","title":"14.2. Logging Unclosed Resources","text":"<p>To help debug issues related to unclosed resources like sockets, you can enable logging:</p> <pre><code>import logging\n\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre> <p>This will print detailed debug information about resources that were not closed properly.</p>"},{"location":"python/async/#143-profiling-with-aio-profiler","title":"14.3. Profiling with <code>aio-profiler</code>","text":"<p><code>aio-profiler</code> is a tool specifically designed to profile asynchronous Python applications:</p> <pre><code>pip install aio-profiler\n</code></pre> <p>Using <code>aio-profiler</code>, you can visualize where your asynchronous application spends its time, helping optimize performance-critical sections.</p>"},{"location":"python/async/#144-debugging-with-ides","title":"14.4. Debugging with IDEs","text":"<p>Modern IDEs, like PyCharm, have support for debugging asynchronous Python code. You can set breakpoints, inspect variable values, and step through async code just like synchronous code.</p>"},{"location":"python/async/#145-detecting-deadlocks","title":"14.5. Detecting Deadlocks","text":"<p>If your asynchronous code appears to hang, it could be due to a deadlock. This often happens when tasks are waiting for each other in a cycle. In such cases, tools like <code>aio-deadlock-detector</code> can help identify and break such cycles.</p>"},{"location":"python/async/#146-monitoring-asynchronous-tasks","title":"14.6. Monitoring Asynchronous Tasks","text":"<p>Using the <code>asyncio.all_tasks()</code> function, you can monitor all running tasks. This can be useful to ensure no tasks are left dangling:</p> <pre><code>import asyncio\n\nasync def example_task():\n    await asyncio.sleep(1)\n\nasync def main():\n    task = asyncio.create_task(example_task())\n    print(\"Running tasks:\", asyncio.all_tasks())\n\nasyncio.run(main())\n</code></pre> <p>Next topic: Scaling and Deploying Asynchronous Applications.</p>"},{"location":"python/async/#15-scaling-and-deploying-asynchronous-applications","title":"15. Scaling and Deploying Asynchronous Applications","text":"<p>Once your asynchronous application is developed and tested, the next step is to deploy and scale it. Here are some strategies and considerations:</p>"},{"location":"python/async/#151-event-loop-implementations","title":"15.1. Event Loop Implementations","text":"<p>While the default event loop in <code>asyncio</code> is sufficient for most tasks, there are alternative implementations like <code>uvloop</code> which can offer better performance:</p> <pre><code>pip install uvloop\n</code></pre> <pre><code>import asyncio\nimport uvloop\n\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n</code></pre>"},{"location":"python/async/#152-load-balancing","title":"15.2. Load Balancing","text":"<p>Just like synchronous applications, asynchronous applications can benefit from load balancing to distribute incoming traffic among multiple instances of the application. Common load balancers like NGINX or HAProxy can be used.</p>"},{"location":"python/async/#153-distributed-systems-and-microservices","title":"15.3. Distributed Systems and Microservices","text":"<p>When scaling applications, consider breaking them into microservices. Asynchronous communication can be established between services using message queues like RabbitMQ or Kafka.</p>"},{"location":"python/async/#154-database-connections","title":"15.4. Database Connections","text":"<p>When using asynchronous databases, be aware of connection limits. Use connection pooling and avoid holding onto connections longer than necessary.</p>"},{"location":"python/async/#155-memory-and-resource-leaks","title":"15.5. Memory and Resource Leaks","text":"<p>Asynchronous applications, especially long-running ones, should be monitored for memory and resource leaks. Tools like <code>objgraph</code> or built-in Python profilers can help identify and fix such leaks.</p>"},{"location":"python/async/#156-error-monitoring-and-alerting","title":"15.6. Error Monitoring and Alerting","text":"<p>Implement monitoring and alerting to keep an eye on exceptions and errors in production. Tools like Sentry can be integrated to capture and notify about runtime errors.</p> <p>Next topic: Conclusion and Continuous Learning in Asynchronous Programming.</p>"},{"location":"python/async/#16-conclusion-and-continuous-learning-in-asynchronous-programming","title":"16. Conclusion and Continuous Learning in Asynchronous Programming","text":"<p>The landscape of asynchronous programming in Python is vast and continuously evolving. With tools like <code>asyncio</code> and the expanding ecosystem around it, developers have powerful mechanisms to write efficient, scalable, and maintainable applications.</p> <p>However, the journey doesn't end with mastering <code>asyncio</code> or any specific library. The Python community is vibrant and always innovating. It's essential to stay updated, participate in discussions, and continuously experiment with new techniques, tools, and best practices.</p> <p>Asynchronous programming, once an advanced topic, is slowly becoming a core skill for Python developers. Embrace the paradigm, understand its intricacies, and leverage it to build the next generation of responsive and performant Python applications.</p> <p>End of Topics.</p>"},{"location":"python/async/#extra-async-without-asyncio","title":"EXTRA async without asyncio","text":"<pre><code>import time\n\nclass Task:\n    def __init__(self, gen):\n        self._gen = gen\n        self._wake_up_time = 0\n\n    def run(self):\n        if time.time() &lt; self._wake_up_time:\n            return False\n        try:\n            next(self._gen)\n            return True\n        except StopIteration:\n            return False\n\n    def set_wake_up_time(self, delay):\n        self._wake_up_time = time.time() + delay\n\nclass Scheduler:\n    def __init__(self):\n        self._tasks = []\n\n    def add_task(self, task_gen):\n        self._tasks.append(Task(task_gen))\n\n    def sleep(self, current_task, delay):\n        current_task.set_wake_up_time(delay)\n        self._tasks.append(current_task)\n\n    def run(self):\n        while self._tasks:\n            current_task = self._tasks.pop(0)\n            if not current_task.run():\n                self._tasks.append(current_task)\n\n# Global scheduler instance\nscheduler = Scheduler()\n\ndef async_sleep(delay):\n    yield\n    scheduler.sleep(current_task, delay)\n    yield\n\ndef coro1():\n    print(\"Coroutine 1: Start\")\n    yield from async_sleep(2)\n    print(\"Coroutine 1: After 2 seconds\")\n\ndef coro2():\n    print(\"Coroutine 2: Start\")\n    yield from async_sleep(1)\n    print(\"Coroutine 2: After 1 second\")\n\n# Add coroutines to the scheduler and run them\nscheduler.add_task(coro1())\nscheduler.add_task(coro2())\nscheduler.run()\n</code></pre>"},{"location":"python/classes/classes/","title":"Much about Classes and Object Oriented Programming","text":"<p>Classes are used to create new kinds of objects.</p>"},{"location":"python/classes/classes/#classes-example","title":"Classes Example","text":"<pre><code>class AccountPortfolio:\n    def __init__(self):\n        self.accounts = []\n\n    def add_account(self, account):\n        self.accounts.append(account)\n\n    def total_funds(self):\n        return sum(account.inquiry() for account in self.accounts)\n\n    def __len__(self):\n        return len(self.accounts)\n\n    def __getitem__(self, index):\n        return self.accounts[index]\n\n    def __iter__(self):\n        return iter(self.accounts)\n</code></pre>"},{"location":"python/classes/classes/#usage","title":"Usage","text":"<pre><code># Example\nport = AccountPortfolio()\nport.add_account(Account('Guido', 1000.0))\nport.add_account(Account('Eva', 50.0))\n\nprint(port.total_funds())    # -&gt; 1050.0\nlen(port)                    # -&gt; 2\n\n# Print the accounts\nfor account in port:\n    print(account)\n\n# Access an individual account by index\nport[1].inquiry()            # -&gt; 50.0\n</code></pre>"},{"location":"python/classes/classes/#avoiding-inheritance-via-composition","title":"Avoiding Inheritance via Composition","text":""},{"location":"python/classes/classes/#inheritance","title":"Inheritance","text":"<pre><code>class Stack(list):\n    def push(self, item):\n        self.append(item)\n\n# Example\ns = Stack()\ns.push(1)\ns.push(2)\ns.push(3)\ns.pop()     # -&gt; 3\ns.pop()     # -&gt; 2\n</code></pre>"},{"location":"python/classes/classes/#composition","title":"Composition","text":"<pre><code>class Stack:\n    def __init__(self):\n        self._items = list()\n\n    def push(self, item):\n        self._items.append(item)\n\n    def pop(self):\n        return self._items.pop()\n\n    def __len__(self):\n        return len(self._items)\n\n# Example use\ns = Stack()\ns.push(1)\ns.push(2)\ns.push(3)\ns.pop()    # -&gt; 3\ns.pop()     # -&gt; 2\n</code></pre>"},{"location":"python/classes/classes/#passing-container-as-argument","title":"Passing Container as Argument","text":"<pre><code>class Stack:\n    def __init__(self, *, container=None):\n        if container is None:\n            container = list()\n        self._items = container\n\n    def push(self, item):\n        self._items.append(item)\n\n    def pop(self):\n        return self._items.pop()\n\n    def __len__(self):\n        return len(self._items)\n\ns = Stack(container=array.array('i'))\ns.push(42)\ns.push(23)\ns.push('a lot')     # TypeError\n</code></pre> <p>This is also an example of what\u2019s known as dependency injection. Instead of hardwiring Stack to depend on list, you can make it depend on any container a user decides to pass in, provided it implements the required interface.</p>"},{"location":"python/classes/classes/#avoid-inheritance-via-functions","title":"Avoid Inheritance via Functions","text":"<p>If there is too much plumbing going on here. If you\u2019re writing a lot of single-method classes, consider using functions instead. </p>"},{"location":"python/classes/classes/#class-based-parsing","title":"Class Based Parsing","text":"<pre><code>class DataParser:\n    def parse(self, lines):\n        records = []\n        for line in lines:\n            row = line.split(',')\n            record = self.make_record(row)\n            records.append(row)\n        return records\n\n    def make_record(self, row):\n        raise NotImplementedError()\n\nclass PortfolioDataParser(DataParser):\n    def make_record(self, row):\n        return {\n           'name': row[0],\n           'shares': int(row[1]),\n           'price': float(row[2])\n        }\n\nparser = PortfolioDataParser()\ndata = parser.parse(open('portfolio.csv'))\n</code></pre>"},{"location":"python/classes/classes/#function-based-parsing","title":"Function Based Parsing","text":"<pre><code>def parse_data(lines, make_record):\n    records = []\n    for line in lines:\n        row = line.split(',')\n        record = make_record(row)\n        records.append(row)\n    return records\n\ndef make_dict(row):\n    return {\n        'name': row[0],\n        'shares': int(row[1]),\n        'price': float(row[2])\n    }\n\ndata = parse_data(open('portfolio.csv'), make_dict)\n</code></pre>"},{"location":"python/classes/classes/#dynamic-binding-and-duck-typing","title":"Dynamic Binding and Duck Typing","text":"<p>Dynamic binding is the runtime mechanism that Python uses to find the attributes of objects. This is what allows Python to work with instances without regard for their type. In Python, variable names do not have an associated type. Thus, the attribute binding process is independent of what kind of object <code>obj</code> is. If you make a lookup, such as <code>obj.name</code>, it will work on any <code>obj</code> whatsoever that happens to have a <code>name</code> attribute. This behavior is sometimes referred to as duck typing\u2014in reference to the adage \u201cif it looks like a duck, quacks like a duck, and walks like a duck, then it\u2019s a duck.\u201d</p> <p>Python programmers often write programs that rely on this behavior. For example, if you want to make a customized version of an existing object, you can either inherit from it, or you can create a completely new object that looks and acts like it but is otherwise unrelated. This latter approach is often used to maintain loose coupling of program components. For example, code may be written to work with any kind of object whatsoever as long as it has a certain set of methods. One of the most common examples is with various iterable objects defined in the standard library. There are all sorts of objects that work with the <code>for</code> loop to produce values\u2014lists, files, generators, strings, and so on. However, none of these inherit from any kind of special <code>Iterable</code> base class. They merely implement the methods required to perform iteration\u2014and it all works.</p>"},{"location":"python/classes/classes/#dont-inherit-builtin-types","title":"Don't Inherit Builtin Types","text":"<p><code>dict</code>, <code>list</code> they are written in C and bypass <code>__setitem__</code> and <code>__getitem__</code>.</p> <p>If you want to use <code>UserDict</code>, import it like this: <code>from collections import UserDict</code>.</p>"},{"location":"python/classes/classes/#class-variables-vs-methods","title":"Class Variables vs Methods","text":"<p>In a class definition, all functions are assumed to operate on an instance, which is always passed as the first parameter <code>self</code>. However, the class itself is also an object that can carry state and be manipulated as well. As an example, you could track how many instances have been created using a class variable <code>num_accounts</code>:</p> <pre><code>class Account:\n    num_accounts = 0\n\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n        Account.num_accounts += 1\n\n    def __repr__(self):\n        return f'{type(self).__name__}({self.owner!r}, {self.balance!r})'\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        self.deposit(-amount)    # Must use self.deposit()\n\n    def inquiry(self):\n        return self.balance\n</code></pre> <p>Class variables are defined outside the normal <code>__init__()</code> method. To modify them, use the class, not <code>self</code>. For example:</p> <pre><code>&gt;&gt;&gt; a = Account('Guido', 1000.0)\n&gt;&gt;&gt; b = Account('Eva', 10.0)\n&gt;&gt;&gt; Account.num_accounts\n2\n</code></pre>"},{"location":"python/classes/classes/#classmethod-usage-alternative-way-of-creating-a-class","title":"<code>classmethod</code> Usage: Alternative Way of Creating a Class","text":"<pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    @classmethod\n    def from_xml(cls, data):\n        from xml.etree.ElementTree import XML\n        doc = XML(data)\n        return cls(doc.findtext('owner'),\n                   float(doc.findtext('amount')))\n\n# Example use\n\ndata = '''\n&lt;account&gt;\n    &lt;owner&gt;Guido&lt;/owner&gt;\n    &lt;amount&gt;1000.0&lt;/amount&gt;\n&lt;/account&gt;\n'''\na = Account.from_xml(data)\n</code></pre>"},{"location":"python/classes/classes/#configuration-of-classes","title":"Configuration of Classes","text":"<pre><code>import time\n\nclass Date:\n    datefmt = '{year}-{month:02d}-{day:02d}'\n    def __init__(self, year, month, day):\n        self.year = year\n        self.month = month\n        self.day = day\n\n    def __str__(self):\n        return self.datefmt.format(year=self.year,\n                                   month=self.month,\n                                   day=self.day)\n\n    @classmethod\n    def from_timestamp(cls, ts):\n        tm = time.localtime(ts)\n        return cls(tm.tm_year, tm.tm_mon, tm.tm_mday)\n\n    @classmethod\n    def today(cls):\n        return cls.from_timestamp(time.time())\n</code></pre> <p>This class features a class variable <code>datefmt</code> that adjusts output from the <code>__str__()</code> method. This is something that can be customized via inheritance:</p> <pre><code>class MDYDate(Date):\n    datefmt = '{month}/{day}/{year}'\n\nclass DMYDate(Date):\n    datefmt = '{day}/{month}/{year}'\n\n# Example\na = Date(1967, 4, 9)\nprint(a)       # 1967-04-09\n\nb = MDYDate(1967, 4, 9)\nprint(b)       # 4/9/1967\n\nc = DMYDate(1967, 4, 9)\nprint(c)      # 9/4/1967\n</code></pre>"},{"location":"python/classes/classes/#dictfrom_keys-example","title":"<code>dict.from_keys()</code> Example","text":"<pre><code>dict.from_keys(['a','b','c'], 0)\n# Output: {'a': 0, 'b': 0, 'c': 0}\n</code></pre>"},{"location":"python/classes/classes/#static-methods","title":"Static Methods","text":"<pre><code>class StandardPolicy:\n    @staticmethod\n    def deposit(account, amount):\n        account.balance += amount\n\n    @staticmethod\n    def withdraw(account, amount):\n        account.balance -= amount\n\n    @staticmethod\n    def inquiry(account):\n        return account.balance\n\nclass EvilPolicy(StandardPolicy):\n    @staticmethod\n    def deposit(account, amount):\n        account.balance += 0.95*amount\n\n    @staticmethod\n    def inquiry(account):\n        if random.randint(0,4) == 1:\n           return 1.10 * account.balance\n        else:\n           return account.balance\n\nclass Account:\n    def __init__(self, owner, balance, *, policy=StandardPolicy):\n        self.owner = owner\n        self.balance = balance\n        self.policy = policy\n\n    def __repr__(self):\n        return f'Account({self.policy}, {self.owner!r}, {self.balance!r})'\n\n    def deposit(self, amount):\n        self.policy.deposit(self, amount)\n\n    def withdraw(self, amount):\n        self.policy.withdraw(self, amount)\n\n    def inquiry(self):\n        return self.policy.inquiry(self)\n</code></pre>"},{"location":"python/classes/classes/#about-design-patterns","title":"About Design Patterns","text":"<p>In writing object-oriented programs, programmers sometimes get fixated on implementing named design patterns\u2014such as the strategy pattern, the flyweight pattern, the singleton pattern, and so forth. Many of these originate from the famous Design Patterns book by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides.</p> <p>If you are familiar with such patterns, the general design principles used in other languages can certainly be applied to Python. However, many of these documented patterns are aimed at working around specific issues that arise from the strict static type system of C++ or Java. The dynamic nature of Python renders a lot of these patterns obsolete, an overkill, or simply unnecessary.</p> <p>That said, there are a few overarching principles of writing good software\u2014such as striving to write code that is debuggable, testable, and extensible. Basic strategies such as writing classes with useful <code>__repr__()</code> methods, preferring composition over inheritance, and allowing dependency injection can go a long way towards these goals. Python programmers also like to work with code that can be said to be Pythonic. Usually, that means that objects obey various built-in protocols, such as iteration, containers, or context management. For example, instead of trying to implement some exotic data traversal pattern from a Java programming book, a Python programmer would probably implement it with a generator function feeding a <code>for</code> loop, or just replace the entire pattern with a few dictionary lookups.</p>"},{"location":"python/classes/classes/#properties","title":"Properties","text":"<p>As noted in the previous section, Python places no runtime restrictions on attribute values or types. However, such enforcement is possible if you put an attribute under the management of a so-called property. A property is a special kind of attribute that intercepts attribute access and handles it via user-defined methods. These methods have complete freedom to manage the attribute as they see fit. Here is an example:</p> <pre><code>import string\n\nclass Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self._balance = balance\n\n    @property\n    def owner(self):\n        return self._owner\n\n    @owner.setter\n    def owner(self, value):\n        if not isinstance(value, str):\n            raise TypeError('Expected str')\n        if not all(c in string.ascii_uppercase for c in value):\n            raise ValueError('Must be uppercase ASCII')\n        if len(value) &gt; 10:\n            raise ValueError('Must be 10 characters or less')\n        self._owner = value\n\nclass SomeClass:\n    @property\n    def attr(self):\n        print('Getting')\n\n    @attr.setter\n    def attr(self, value):\n        print('Setting', value)\n\n    @attr.deleter\n    def attr(self):\n        print('Deleting')\n\n# Example\ns = SomeClass()\ns.attr         # Getting\ns.attr = 13    # Setting\ndel s.attr     # Deleting\n</code></pre>"},{"location":"python/classes/classes/#types-interfaces-abstract-classes","title":"Types, Interfaces, Abstract Classes","text":"<pre><code>class A:\n    pass\n\nclass B(A):\n    pass\n\nclass C:\n    pass\n\na = A()           # Instance of 'A'\nb = B()           # Instance of 'B'\nc = C()           # Instance of 'C'\n\ntype(a)           # Returns the class object A\nisinstance(a, A)  # Returns True\nisinstance(b, A)  # Returns True, B derives from A\nisinstance(b, C)  # Returns False, B not derived from C\n</code></pre> <p>Note: ABC must be implemented.</p> <pre><code>from abc import ABC, abstractmethod\n\nclass Stream(ABC):\n    @abstractmethod\n    def receive(self):\n        pass\n\n    @abstractmethod\n    def send(self, msg):\n        pass\n\n    @abstractmethod\n    def close(self):\n        pass\n</code></pre>"},{"location":"python/classes/classes/#multiple-inheritance-and-mixins","title":"Multiple Inheritance and Mixins","text":""},{"location":"python/classes/classes/#interfaces-using-abc-classes","title":"Interfaces using ABC Classes","text":"<pre><code>from abc import ABC, abstractmethod\n\nclass Stream(ABC):\n    @abstractmethod\n    def receive(self):\n        pass\n\n    @abstractmethod\n    def send(self, msg):\n        pass\n\n    @abstractmethod\n    def close(self):\n        pass\n\nclass Iterable(ABC):\n    @abstractmethod\n    def __iter__(self):\n        pass\n\n\nclass MessageStream(Stream, Iterable):\n    def receive(self):\n        ...\n\n    def send(self):\n        ...\n\n    def close(self):\n        ...\n\n    def __iter__(self):\n        ...\n</code></pre> <p><code>m = MessageStream()</code></p> <p><code>isinstance(m, Stream)     # -&gt; True</code></p> <p><code>isinstance(m, Iterable)   # -&gt; True</code></p>"},{"location":"python/classes/classes/#mixin-classes","title":"Mixin Classes","text":"<p>The other use of multiple inheritance is to define mixin classes. A mixin class is a class that modifies or extends the functionality of other classes. Consider the following class definitions:</p> <pre><code>class Duck:\n    def noise(self):\n        return 'Quack'\n\n    def waddle(self):\n        return 'Waddle'\n\nclass Trombonist:\n    def noise(self):\n        return 'Blat!'\n\n    def march(self):\n        return 'Clomp'\n\nclass Cyclist:\n    def noise(self):\n        return 'On your left!'\n\n    def pedal(self):\n        return 'Pedaling'\n</code></pre> <p>These classes are completely unrelated to each other. There is no inheritance relationship and they implement different methods. However, there is a shared commonality in that they each define a <code>noise()</code> method. Using that as a guide, you could define the following classes:</p> <pre><code>class LoudMixin:\n    def noise(self):\n        return super().noise().upper()\n\nclass AnnoyingMixin:\n    def noise(self):\n        return 3 * super().noise()\n\nclass LoudDuck(LoudMixin, Duck):\n    pass\n\nclass AnnoyingTrombonist(AnnoyingMixin, Trombonist):\n    pass\n\nclass AnnoyingLoudCyclist(AnnoyingMixin, LoudMixin, Cyclist):\n    pass\n</code></pre> <p><code>d = LoudDuck()</code></p> <p><code>d.noise()  # -&gt; 'QUACK'</code></p> <p><code>t = AnnoyingTrombonist()</code></p> <p><code>t.noise()  # -&gt; 'Blat!Blat!Blat!'</code></p> <p><code>c = AnnoyingLoudCyclist()</code></p> <p><code>c.noise()  # -&gt; 'ON YOUR LEFT!ON YOUR LEFT!ON YOUR LEFT!'</code></p> <p>Since mixin classes are defined in the same way as normal classes, it is best to include the word \"Mixin\" as part of the class name. This naming convention provides a greater clarity of purpose.</p> <p>To fully understand mixins, you need to know a bit more about how inheritance and the <code>super()</code> function work.</p> <p>First, whenever you use inheritance, Python builds a linear chain of classes known as the Method Resolution Order, or MRO for short. This is available as the <code>mro</code> attribute on a class. Here are some examples for single inheritance:</p> <pre><code>class Base:\n    pass\n\nclass A(Base):\n    pass\n\nclass B(A):\n    pass\n\nBase.__mro__  # -&gt; (&lt;class 'Base'&gt;, &lt;class 'object'&gt;)\nA.__mro__     # -&gt; (&lt;class 'A'&gt;, &lt;class 'Base'&gt;, &lt;class 'object'&gt;)\nB.__mro__     # -&gt; (&lt;class 'B'&gt;, &lt;class 'A'&gt;, &lt;class 'Base'&gt;, &lt;class 'object'&gt;)\n</code></pre>"},{"location":"python/classes/classes/#class-decorators-and-class-methods","title":"Class Decorators and Class Methods","text":""},{"location":"python/classes/classes/#factory-function-that-uses-the-registry","title":"Factory function that uses the registry","text":"<pre><code>def create_decoder(mimetype):\n    return _registry[mimetype]()\n</code></pre> <pre><code>@register_decoder\nclass TextDecoder:\n    mimetypes = [ 'text/plain' ]\n    def decode(self, data):\n        ...\n</code></pre> <pre><code>@register_decoder\nclass HTMLDecoder:\n    mimetypes = [ 'text/html' ]\n    def decode(self, data):\n        ...\n</code></pre> <pre><code>@register_decoder\nclass ImageDecoder:\n    mimetypes = [ 'image/png', 'image/jpg', 'image/gif' ]\n    def decode(self, data):\n        ...\n</code></pre>"},{"location":"python/classes/classes/#example-usage","title":"Example usage","text":"<pre><code>decoder = create_decoder('image/jpg')\n</code></pre> <p>A class decorator is free to modify the contents of the class it\u2019s given. For example, it might even rewrite existing methods. This is a common alternative to mixin classes or multiple inheritance. For example, consider these decorators:</p>"},{"location":"python/classes/classes/#decorator-override-function","title":"decorator override function","text":"<pre><code>def loud(cls):\n    orig_noise = cls.noise\n    def noise(self):\n        return orig_noise(self).upper()\n    cls.noise = noise\n    return cls\n\ndef annoying(cls):\n    orig_noise = cls.noise\n    def noise(self):\n        return 3 * orig_noise(self)\n    cls.noise = noise\n    return cls\n\n@annoying\n@loud\nclass Cyclist(object):\n    def noise(self):\n        return 'On your left!'\n\n    def pedal(self):\n        return 'Pedaling'\n</code></pre>"},{"location":"python/classes/classes/#add-code-to-class-at-runtime","title":"Add code to class at runtime","text":"<pre><code>class Point:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __repr__(self):\n        return f'{type(self).__name__}({self.x!r}, {self.y!r})'\n</code></pre> <p>Writing such methods is often annoying. Perhaps a class decorator could create the method for you?</p> <pre><code>import inspect\ndef with_repr(cls):\n    args = list(inspect.signature(cls).parameters)\n    argvals = ', '.join('{self.%s!r}' % arg for arg in args)\n    code = 'def __repr__(self):\\n'\n    code += f' return f'{cls.__name__}({argvals})'\\n'\n    locs = { }\n    exec(code, locs)\n    cls.__repr__ = locs['__repr__']\n    return cls\n\n# Example\n@with_repr\nclass Point:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n</code></pre> <p>In this example, a repr() method is generated from the calling signature of the init() method. The method is created as a text string and passed to exec() to create a function. That function is attached to the class.</p> <p>Similar code generation techniques are used in parts of the standard library. For example, a convenient way to define data structures is to use a dataclass:</p> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Point:\n    x: int\n    y: int\n</code></pre> <p>A dataclass automatically creates methods such as init() and repr() from class type hints. The methods are created using exec(), similarly to the prior example. Here\u2019s how the resulting Point class works:</p> <pre><code>p = Point(2, 3)\np\n</code></pre> <p>Output: <pre><code>Point(x=2, y=3)\n</code></pre></p> <p>One downside of such an approach is poor startup performance. Dynamically creating code with <code>exec()</code> bypasses the compilation optimizations that Python normally applies to modules. Defining a large number of classes in this way may therefore significantly slow down the importing of your code.</p>"},{"location":"python/classes/classes/#supervised-inheritance-__init_subclass__","title":"Supervised Inheritance - <code>__init_subclass__</code>","text":"<p>As you saw in the previous section, sometimes you want to define a class and perform additional actions. A class decorator is one mechanism for doing this. However, a parent class can also perform extra actions on behalf of its subclasses. This is accomplished by implementing an <code>__init_subclass__(cls)</code> class method. For example:</p> <pre><code>class Base:\n    @classmethod\n    def __init_subclass__(cls):\n        print('Initializing', cls)\n\n# Example (should see 'Initializing' message for each class)\nclass A(Base):\n    pass\n\nclass B(A):\n    pass\n</code></pre> <p>If an <code>__init_subclass__()</code> method is present, it is triggered automatically upon the definition of any child class. This happens even if the child is buried deeply in an inheritance hierarchy.</p> <p>Many of the tasks commonly performed with class decorators can be performed with <code>__init_subclass__()</code> instead. For example, class registration:</p> <pre><code>class DecoderBase:\n    _registry = { }\n    @classmethod\n    def __init_subclass__(cls):\n        for mt in cls.mimetypes:\n            DecoderBase._registry[mt.mimetype] = cls\n\n# Factory function that uses the registry\ndef create_decoder(mimetype):\n    return DecoderBase._registry[mimetype]()\n\nclass TextDecoder(DecoderBase):\n    mimetypes = [ 'text/plain' ]\n    def decode(self, data):\n        ...\n\nclass HTMLDecoder(DecoderBase):\n    mimetypes = [ 'text/html' ]\n    def decode(self, data):\n        ...\n\nclass ImageDecoder(DecoderBase):\n    mimetypes = [ 'image/png', 'image/jpg', 'image/gif' ]\n    def decode(self, data):\n        ...\n</code></pre>"},{"location":"python/classes/classes/#class-initialization-with-__repr__","title":"Class Initialization with <code>__repr__</code>","text":"<pre><code>import inspect\nclass Base:\n    @classmethod\n    def __init_subclass__(cls):\n        # Create a __repr__ method\n        args = list(inspect.signature(cls).parameters)\n        argvals = ', '.join('{self.%s!r}' % arg for arg in args)\n        code = 'def __repr__(self):\\n'\n        code += f' return f'{cls.__name__}({argvals})'\\n'\n        locs = { }\n        exec(code, locs)\n        cls.__repr__ = locs['__repr__']\n\nclass Point(Base):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n</code></pre> <p>If multiple inheritance is being used, you should use <code>super()</code> to make sure all classes that implement <code>__init_subclass__()</code> get called. For example:</p> <pre><code>class A:\n    @classmethod\n    def __init_subclass__(cls):\n        print('A.init_subclass')\n        super().__init_subclass__()\n\nclass B:\n    @classmethod\n    def __init_subclass__(cls):\n        print('B.init_subclass')\n        super().__init_subclass__()\n\n# Should see output from both classes here\nclass C(A, B):\n    pass\n</code></pre>"},{"location":"python/classes/classes/#object-life-cycle-and-memory-management","title":"Object Life Cycle and Memory Management","text":"<p>When a class is defined, the resulting class is a factory for creating new instances. For example:</p> <pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n</code></pre> <p>Create some <code>Account</code> instances: <pre><code>a = Account('Guido', 1000.0)\nb = Account('Eva', 25.0)\n</code></pre></p> <p>The creation of an instance is carried out in two steps using the special method <code>__new__()</code> that creates a new instance and <code>__init__()</code> that initializes it. For example, the operation <code>a = Account('Guido', 1000.0)</code> performs these steps:</p> <pre><code>a = Account.__new__(Account, 'Guido', 1000.0)\nif isinstance(a, Account):\n    Account.__init__(a, 'Guido', 1000.0)\n</code></pre> <p>Except for the first argument which is the class instead of an instance, <code>__new__()</code> normally receives the same arguments as <code>__init__()</code>. However, the default implementation of <code>__new__()</code> just ignores them. You\u2019ll sometimes see <code>__new__()</code> invoked with just a single argument. For example, this code also works:</p> <pre><code>a = Account.__new__(Account)\nif isinstance(a, Account):\n    Account.__init__(a, 'Guido', 1000.0)\n</code></pre> <p>Direct use of the <code>__new__()</code> method is uncommon, but sometimes it\u2019s used to create instances while bypassing the invocation of the <code>__init__()</code> method. One such use is in class methods. <pre><code>class Spam:\n    @classmethod\n    def bar(cls, *args, **kwargs):\n        return cls.__new__(cls, *args, **kwargs)\n</code></pre></p> <pre><code>import time\n\nclass Date:\n    def __init__(self, year, month, day):\n        self.year = year\n        self.month = month\n        self.day = day\n\n    @classmethod\n    def today(cls):\n        t = time.localtime()\n        self = cls.__new__(cls)   # Make instance\n        self.year = t.tm_year\n        self.month = t.tm_month\n        self.day = t.tm_day\n        return self\n</code></pre> <p>Modules that perform object serialization such as <code>pickle</code> also utilize <code>new()</code> to recreate instances when objects are deserialized. This is done without ever invoking <code>init()</code>.</p> <p>Sometimes a class will define <code>new()</code> if it wants to alter some aspect of instance creation. Typical applications include instance caching, singletons, and immutability. As an example, you might want <code>Date</code> class to perform date interning\u2014that is, caching and reusing <code>Date</code> instances that have an identical year, month, and day. Here is one way that might be implemented:</p> <pre><code>class Date:\n    _cache = { }\n\n    @staticmethod\n    def __new__(cls, year, month, day):\n        self = Date._cache.get((year,month,day))\n        if not self:\n            self = super().__new__(cls)\n            self.year = year\n            self.month = month\n            self.day = day\n            Date._cache[year,month,day] = self\n        return self\n\n    def __init__(self, year, month, day):\n        pass\n</code></pre> <p>In this example, the class keeps an internal dictionary of previously created <code>Date</code> instances. When creating a new <code>Date</code>, the cache is consulted first. If a match is found, that instance is returned. Otherwise, a new instance is created and initialized.</p> <p>A subtle detail of this solution is the empty <code>init()</code> method. Even though instances are cached, every call to <code>Date()</code> still invokes <code>init()</code>. To avoid duplicated effort, the method simply does nothing\u2014instance creation actually takes place in <code>new()</code> when an instance is created the first time.</p> <p>There are ways to avoid the extra call to <code>init()</code> but it requires sneaky tricks. One way to avoid it is to have <code>new()</code> return an entirely different type instance\u2014for example, one belonging to a different class. Another solution, described later, is to use a metaclass.</p> <p>Once created, instances are managed by reference counting. If the reference count reaches zero, the instance is immediately destroyed. When the instance is about to be destroyed, the interpreter first looks for a <code>del()</code> method associated with the object and calls it. For example:</p> <pre><code>class Account(object):\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    def __del__(self):\n        print('Deleting Account')\n</code></pre> <p>Occasionally, a program will use the <code>del</code> statement to delete a reference to an object as shown. If this causes the reference count of the object to reach zero, the <code>del()</code> method is called. However, in general, the <code>del</code> statement doesn\u2019t directly call <code>del()</code> because there may be other object references living elsewhere. There are many other ways that an object might be deleted\u2014for example, reassignment of a variable name or a variable going out of scope in a function:</p> <pre><code>&gt;&gt;&gt; a = Account('Guido', 1000.0)\n&gt;&gt;&gt; a = 42\nDeleting Account\n&gt;&gt;&gt; def func():\n...     a = Account('Guido', 1000.0)\n...\n&gt;&gt;&gt; func()\nDeleting Account\n</code></pre> <p>In practice, it\u2019s rarely necessary for a class to define a <code>del()</code> method. The only exception is when the destruction of an object requires an extra cleanup action\u2014such as closing a file, shutting down a network connection, or releasing other system resources. Even in these cases, it\u2019s dangerous to rely on <code>del()</code> for a proper shutdown because there\u2019s no guarantee that this method will be called when you think it would. For clean shutdown of resources, you should give the object an explicit <code>close()</code> method. You should also make your class support the context manager protocol so it can be used with the <code>with</code> statement. Here is an example that covers all of the cases:</p> <pre><code>class SomeClass:\n    def __init__(self):\n        self.resource = open_resource()\n\n    def __del__(self):\n        self.close()\n\n    def close(self):\n        self.resource.close()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, ty, val, tb):\n        self.close()\n\n# Closed via __del__()\ns = SomeClass()\ndel s\n\n# Explicit close\ns = SomeClass()\ns.close()\n\n# Closed at the end of a context block\nwith SomeClass() as s:\n    ...\n</code></pre> <p>Again, it should be emphasized that writing a <code>del()</code> in a class is almost never necessary. Python already has garbage collection and there is simply no need to do it unless there is some extra action that needs to take place upon object destruction. Even then, you still might not need <code>del()</code> as it\u2019s possible that the object is already programmed to clean itself up properly even if you do nothing.</p> <p>As if there weren\u2019t enough dangers with reference counting and object destruction, there are certain kinds of programming patterns\u2014especially those involving parent-child relationships, graphs, or caching\u2014where objects can create a so-called reference cycle. <pre><code>class SomeClass:\n    def __del__(self):\n        print('Deleting')\n\nparent = SomeClass()\nchild = SomeClass()\n</code></pre></p>"},{"location":"python/classes/classes/#create-a-child-parent-reference-cycle","title":"Create a child-parent reference cycle","text":"<p>parent.child = child child.parent = parent</p>"},{"location":"python/classes/classes/#try-deletion-no-output-from-del-appears","title":"Try deletion (no output from del appears)","text":"<p>del parent del child</p> <p>In this example, the variable names are destroyed but you never see execution of the <code>del()</code> method. The two objects each hold internal references to each other, so there\u2019s no way for the reference count to ever drop to 0. To handle this, a special cycle-detecting garbage collector runs every so often. Eventually the objects will be reclaimed, but it\u2019s hard to predict when this might happen. If you want to force garbage collection, you can call <code>gc.collect()</code>. The <code>gc</code> module has a variety of other functions related to the cyclic garbage collector and monitoring memory.</p> <p>Because of the unpredictable timing of garbage collection, the <code>del()</code> method has a few restrictions placed on it. First, any exception that propagates out of <code>del()</code> is printed to <code>sys.stderr</code>, but otherwise ignored. Second, the <code>del()</code> method should avoid operations such as acquiring locks or other resources. Doing so could result in a deadlock when <code>del()</code> is unexpectedly fired in the middle of executing an unrelated function within the seventh inner callback circle of signal handling and threads. If you must define <code>del()</code>, keep it simple.</p> <p>weak references</p> <p>Sometimes objects are kept alive when you\u2019d much rather see them die. In an earlier example, a <code>Date</code> class was shown with internal caching of instances. One problem with this implementation is that there is no way for an instance to ever be removed from the cache. As such, the cache will grow larger and larger over time.</p> <p>One way to fix this problem is to create a weak reference using the <code>weakref</code> module. A weak reference is a way of creating a reference to an object without increasing its reference count. To work with a weak reference, you have to add an extra bit of code to check if the object being referred to still exists. Here\u2019s an example of how you create a weakref:</p> <pre><code>import weakref\na_ref = weakref.ref(a)\n</code></pre> <p>In this example, <code>a_ref</code> is a weak reference to the object <code>a</code>. You can use the weak reference to access the object, but it doesn't prevent the object from being garbage collected.</p> <pre><code>a = Account('Guido', 1000.0)\nimport weakref\na_ref = weakref.ref(a)\na_ref()\n</code></pre> <p>Support for weak references requires instances to have a mutable <code>weakref</code> attribute. Instances of user-defined classes normally have such an attribute by default. However, built-in types and certain kinds of special data structures\u2014named tuples, classes with slots\u2014do not. If you want to construct weak references to these types, you can do it by defining variants with a <code>weakref</code> attribute added:</p> <pre><code>class wdict(dict):\n    __slots__ = ('__weakref__',)\n\nw = wdict()\nw_ref = weakref.ref(w)      # Now works\n</code></pre> <p>attribute binding</p> <p>The state associated with an instance is stored in a dictionary that\u2019s accessible as the instance\u2019s <code>__dict__</code> attribute. This dictionary contains the data that\u2019s unique to each instance.</p> <p>Classes are linked to their base classes by a special attribute <code>__bases__</code>, which is a tuple of the base classes. The <code>__bases__</code> attribute is only informational. The actual runtime implementation of inheritance uses the <code>__mro__</code> attribute which is a tuple of all parent classes listed in search order. This underlying structure is the basis for all operations that get, set, or delete the attributes of instances.</p> <p>Whenever an attribute is set using <code>obj.name = value</code>, the special method <code>obj.__setattr__('name', value)</code> is invoked. If an attribute is deleted using <code>del obj.name</code>, the special method <code>obj.__delattr__('name')</code> is invoked. The default behavior of these methods is to modify or remove values from the local <code>__dict__</code> of <code>obj</code> unless the requested attribute happens to correspond to a property or descriptor. In that case, the set and delete operations will be carried out by the <code>__set__</code> and <code>__delete__</code> functions associated with the property.</p> <p>For attribute lookup such as <code>obj.name</code>, the special method <code>obj.__getattribute__('name')</code> is invoked. This method carries out the search for the attribute, which normally includes checking the properties, looking in the local <code>__dict__</code>, checking the class dictionary, and searching the MRO. If this search fails, a final attempt to find the attribute is made by invoking the <code>obj.__getattr__('name')</code> method of the class (if defined). If this fails, an <code>AttributeError</code> exception is raised.</p> <p>User-defined classes can implement their own versions of the attribute access functions, if desired. For example, here\u2019s a class that restricts the attribute names that can be set:</p> <pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    def __setattr__(self, name, value):\n        if name not in {'owner', 'balance'}:\n            raise AttributeError(f'No attribute {name}')\n        super().__setattr__(name, value)\n</code></pre>"},{"location":"python/classes/classes/#example","title":"Example","text":"<p>a = Account('Guido', 1000.0) a.balance = 940.25          # Ok a.amount = 540.2            # AttributeError. No attribute amount</p> <p>proxies, wrappers, delegations</p> <p>A common implementation technique for proxies involves the <code>getattr()</code> method. Here is a simple example:</p> <pre><code>class A:\n    def spam(self):\n        print('A.spam')\n\n    def grok(self):\n        print('A.grok')\n\n    def yow(self):\n        print('A.yow')\n\nclass LoggedA:\n    def __init__(self):\n        self._a = A()\n\n    def __getattr__(self, name):\n        print('Accessing', name)\n        # Delegate to internal A instance\n        return getattr(self._a, name)\n</code></pre> <p>In this example, the <code>LoggedA</code> class acts as a proxy for class <code>A</code>. When an attribute is accessed on an instance of <code>LoggedA</code>, the <code>__getattr__()</code> method is invoked. It prints the accessed attribute name and then delegates the attribute access to the internal instance of <code>A</code>.</p> <p>Example use:</p> <pre><code>a = LoggedA()\na.spam()       # prints 'Accessing spam' and 'A.spam'\na.yow()        # prints 'Accessing yow' and 'A.yow'\n</code></pre> <p>Delegation is sometimes used as an alternative to inheritance. Here is an example:</p> <pre><code>class A:\n    def spam(self):\n        print('A.spam')\n\n    def grok(self):\n        print('A.grok')\n\n    def yow(self):\n        print('A.yow')\n\nclass B:\n    def __init__(self):\n        self._a = A()\n\n    def grok(self):\n        print('B.grok')\n\n    def __getattr__(self, name):\n        return getattr(self._a, name)\n</code></pre> <p>In this example, class <code>B</code> holds an internal reference to an instance of <code>A</code> and delegates attribute access to it. Methods defined in class <code>B</code> override the corresponding methods in class <code>A</code>, while all other methods are delegated to the internal instance of <code>A</code>.</p> <p>Example use:</p> <pre><code>b = B()\nb.spam()      # -&gt; A.spam\nb.grok()      # -&gt; B.grok   (redefined method)\nb.yow()       # -&gt; A.yow\n</code></pre> <p>The technique of forwarding attribute lookup via <code>__getattr__()</code> is a common technique. However, be aware that it does not apply to operations mapped to special methods. For example, consider this class:</p> <pre><code>class ListLike:\n    def __init__(self):\n        self._items = list()\n\n    def __getattr__(self, name):\n        return getattr(self._items, name)\n</code></pre> <p>In this example, the <code>ListLike</code> class forwards all of the standard list methods to an inner list using <code>__getattr__()</code>. However, operations such as <code>len(a)</code> or <code>a[0]</code> fail because they are not mapped to special methods (<code>__len__()</code> and <code>__getitem__()</code>). To make those work, you would have to explicitly implement the required special methods.</p> <p>To illustrate, here's an updated <code>ListLike</code> class that implements the necessary special methods:</p> <pre><code>class ListLike:\n    def __init__(self):\n        self._items = list()\n\n    def __getattr__(self, name):\n        return getattr(self._items, name)\n\n    def __len__(self):\n        return len(self._items)\n\n    def __getitem__(self, index):\n        return self._items[index]\n\n    def __setitem__(self, index, value):\n        self._items[index] = value\n</code></pre>"},{"location":"python/classes/classes/#slots","title":"slots","text":"<p>The <code>slots</code> attribute is a definition hint that allows Python to make performance optimizations for both memory use and execution speed. It eliminates the need for a dictionary to store instance data and uses a more compact array-based data structure instead. Using <code>slots</code> can result in a substantial reduction in memory use and a modest improvement in execution time, especially in programs that create a large number of objects.</p> <p>Here are some key points about <code>slots</code>:</p> <ul> <li>The <code>slots</code> attribute lists only the instance attributes and does not include methods, properties, class variables, or any other class-level attributes.</li> <li>If a class uses <code>slots</code>, any derived class must also define <code>slots</code> (even if empty) to take advantage of the benefits. Failure to do so will result in slower performance and increased memory usage.</li> <li><code>slots</code> is not compatible with multiple inheritance. If multiple base classes with non-empty <code>slots</code> are specified, a <code>TypeError</code> will be raised.</li> <li>Code that relies on the underlying <code>__dict__</code> attribute of instances may break when <code>slots</code> is used.</li> <li><code>slots</code> has no effect on the invocation of methods such as <code>__getattribute__()</code>, <code>__getattr__()</code>, and <code>__setattr__()</code> if they are redefined in a class. However, the absence of the instance <code>__dict__</code> attribute should be considered when implementing these methods.</li> </ul>"},{"location":"python/classes/classes/#descriptors","title":"Descriptors","text":"<p>Descriptors provide a way to customize attribute access in Python by implementing the special methods <code>__get__()</code>, <code>__set__()</code>, and <code>__delete__()</code>. They are class-level objects that manage access to attributes. Properties are implemented using descriptors.</p> <p>Here's an example of a descriptor class called <code>Typed</code>:</p> <pre><code>class Typed:\n    expected_type = object\n\n    def __set_name__(self, cls, name):\n        self.key = name\n\n    def __get__(self, instance, cls):\n        if instance:\n            return instance.__dict__[self.key]\n        else:\n            return self\n\n    def __set__(self, instance, value):\n        if not isinstance(value, self.expected_type):\n            raise TypeError(f'Expected {self.expected_type}')\n        instance.__dict__[self.key] = value\n\n    def __delete__(self, instance):\n        raise AttributeError(\"Can't delete attribute\")\n</code></pre> <p>In this example, the <code>Typed</code> class defines a descriptor that performs type checking when an attribute is assigned and raises an error if an attempt is made to delete the attribute. Subclasses like <code>Integer</code>, <code>Float</code>, and <code>String</code> specialize <code>Typed</code> to match specific types.</p> <p>Descriptors are used by including them as class attributes in another class. For example:</p> <pre><code>class Account:\n    owner = String()\n    balance = Float()\n\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n</code></pre> <p>In this case, the <code>Account</code> class uses the descriptors <code>String</code> and <code>Float</code> to automatically call the appropriate <code>__get__()</code>, <code>__set__()</code>, or <code>__delete__()</code> methods when accessing the <code>owner</code> and <code>balance</code> attributes.</p> <p>Descriptors take precedence over items in the instance dictionary. Even if an instance dictionary has a matching entry, the descriptor's <code>__set__()</code> method will be invoked. For example:</p> <pre><code>a = Account('Guido', 1000.0)\na.balance = 'a lot'  # Raises TypeError: Expected &lt;class 'float'&gt;\n</code></pre> <p>The <code>__get__(instance, cls)</code> method of a descriptor takes arguments for both the instance and the class. When invoked at the class level, the instance argument is <code>None</code>. The <code>__get__()</code> method typically returns the descriptor itself if no instance is provided.</p> <pre><code>Account.balance  # Returns &lt;__main__.Float object at 0x110606710&gt;\n</code></pre>"},{"location":"python/classes/classes/#method-descriptor","title":"Method Descriptor","text":"<p>A descriptor that only implements <code>__get__()</code> is known as a method descriptor. It is mainly used to implement Python's various types of methods, such as instance methods, class methods, and static methods. The <code>__get__()</code> method of a method descriptor only gets invoked if there is no matching entry in the instance dictionary.</p> <p>Here's an example of implementing <code>@classmethod</code> and <code>@staticmethod</code> using method descriptors:</p> <pre><code>import types\n\nclass classmethod:\n    def __init__(self, func):\n        self.__func__ = func\n\n    def __get__(self, instance, cls):\n        return types.MethodType(self.__func__, cls)\n\nclass staticmethod:\n    def __init__(self, func):\n        self.__func__ = func\n\n    def __get__(self, instance, cls):\n        return self.__func__\n</code></pre> <p>Lazy Evaluation</p> <p>Method descriptors can be used to implement lazy evaluation of attributes. By only computing and assigning the attribute value when it is accessed for the first time, we can save computational resources.</p> <p>Here's an example of implementing lazy evaluation using a descriptor called <code>Lazy</code>:</p> <pre><code>class Lazy:\n    def __init__(self, func):\n        self.func = func\n\n    def __set_name__(self, cls, name):\n        self.key = name\n\n    def __get__(self, instance, cls):\n        if instance:\n            value = self.func(instance)\n            instance.__dict__[self.key] = value\n            return value\n        else:\n            return self\n</code></pre> <p>In this example, the <code>Lazy</code> descriptor is used in the <code>Rectangle</code> class to lazily compute the area and perimeter attributes:</p> <pre><code>class Rectangle:\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height\n\n    area = Lazy(lambda self: self.width * self.height)\n    perimeter = Lazy(lambda self: 2*self.width + 2*self.height)\n</code></pre> <p>When the <code>area</code> or <code>perimeter</code> attributes are accessed for the first time, the corresponding lambda function is executed to compute the value. The computed value is then stored in the instance's <code>__dict__</code> attribute for future use.</p>"},{"location":"python/classes/classes/#class-definitions","title":"Class Definitions","text":"<p>The definition of a class is a dynamic process. When you define a class using the class statement, a new dictionary is created that serves as the local class namespace. The body of the class then executes as a script within this namespace. Eventually, the namespace becomes the <code>__dict__</code> attribute of the resulting class object.</p> <p>Any legal Python statement is allowed in the body of a class. Normally, you just define functions and variables, but control flow, imports, nested classes, and everything else is allowed. For example, here is a class that conditionally defines methods:</p> <pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    if debug:\n        import logging\n        log = logging.getLogger(f'{__module__}.{__qualname__}')\n        def deposit(self, amount):\n            Account.log.debug('Depositing %f', amount)\n            self.balance += amount\n\n        def withdraw(self, amount):\n            Account.log.debug('Withdrawing %f', amount)\n            self.balance -= amount\n    else:\n        def deposit(self, amount):\n            self.balance += amount\n\n        def withdraw(self, amount):\n            self.balance -= amount\n</code></pre> <p>In this example, a global variable <code>debug</code> is being used to conditionally define methods. The <code>__module__</code> and <code>__qualname__</code> variables are predefined strings that hold information about the class name and enclosing module. These can be used by statements in the class body. In this example, they're being used to configure the logging system. There are probably cleaner ways of organizing the above code, but the key point is that you can put anything you want in a class.</p> <p>One critical point about class definition is that the namespace used to hold the contents of the class body is not a scope of variables. Any name that gets used within a method (such as <code>Account.log</code> in the above example) needs to be fully qualified.</p> <p>If a function like <code>locals()</code> is used in a class body (but not inside a method), it returns the dictionary being used for the class namespace.</p>"},{"location":"python/classes/classes/#dynamic-class-creation","title":"Dynamic Class Creation","text":"<p>Normally, classes are created using the <code>class</code> statement, but this is not a requirement. As noted in the previous section, classes are defined by executing the body of a class to populate a namespace. If you're able to populate a dictionary with your own definitions, you can make a class without ever using the <code>class</code> statement. To do that, use <code>types.new_class()</code>:</p> <pre><code>import types\n\n# Some methods (not in a class)\ndef __init__(self, owner, balance):\n    self.owner = owner\n    self.balance = balance\n\ndef deposit(self, amount):\n    self.balance -= amount\n\ndef withdraw(self, amount):\n    self.balance += amount\n\nmethods = {\n   '__init__': __init__,\n   'deposit': deposit,\n   'withdraw': withdraw,\n}\n\nAccount = types.new_class('Account', (),\n               exec_body=lambda ns: ns.update(methods))\n\n# You now have a class\na = Account('Guido', 1000.0)\na.deposit(50)\na.withdraw(25)\n</code></pre> <p>Dynamic class creation may be useful if you want to create classes from data structures or generate classes programmatically. For example, in the section on descriptors, the following classes were defined:</p> <pre><code>class Integer(Typed):\n    expected_type = int\n\nclass Float(Typed):\n    expected_type = float\n\nclass String(Typed):\n    expected_type = str\n</code></pre> <p>This code is highly repetitive. A data-driven approach can be used to generate the classes dynamically:</p> <pre><code>typed_classes = [\n   ('Integer', int),\n   ('Float', float),\n   ('String', str),\n   ('Bool', bool),\n   ('Tuple', tuple),\n]\n\nglobals().update(\n   (name, types.new_class(name, (Typed,),\n          exec_body=lambda ns: ns.update(expected_type=ty)))\n   for name, ty in typed_classes)\n</code></pre> <p>In this example, the global module namespace is being updated with dynamically created classes using <code>types.new_class()</code>. The <code>typed_classes</code> list defines the names and expected types for each class. Each class is created by calling <code>types.new_class()</code> with the class name, base classes, and an <code>exec_body</code> function that updates the namespace with the expected type. The resulting classes are then added to the global namespace using <code>globals().update()</code>.</p> <p>Sometimes you will see <code>type()</code> being used to dynamically create a class instead. For example:</p> <pre><code>Account = type('Account', (), methods)\n</code></pre> <p>This works, but it doesn\u2019t take into account some of the more advanced class machinery such as metaclasses. In modern code, try to use <code>types.new_class()</code> instead.</p>"},{"location":"python/classes/classes/#metaclasses","title":"Metaclasses","text":"<p>When you define a class in Python, the class definition itself becomes an object. Here's an example:</p> <pre><code>class Account:\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        self.balance -= amount\n</code></pre> <p>To check if <code>Account</code> is an object, you can use the <code>isinstance</code> function:</p> <pre><code>isinstance(Account, object)\n</code></pre> <p>If you think about this long enough, you will realize that if <code>Account</code> is an object, then something had to create it. This creation of the class object is controlled by a special kind of class called a metaclass. Simply put, a metaclass is a class that creates instances of classes.</p> <p>In the preceding example, the metaclass that created <code>Account</code> is a built-in class called <code>type</code>. In fact, if you check the type of <code>Account</code>, you will see that it is an instance of <code>type</code>:</p> <pre><code>type(Account)\n</code></pre> <p>It's a bit brain-bending, but it's similar to integers. For example, if you write <code>x = 42</code> and then look at <code>x.__class__</code>, you'll get <code>int</code>, which is the class that creates integers. Similarly, <code>type</code> makes instances of types or classes.</p> <p>When a new class is defined with the <code>class</code> statement, a number of things happen. First, a new namespace for the class is created. Next, the body of the class is executed in this namespace. Finally, the class name, base classes, and populated namespace are used to create the class instance. The following code illustrates the low-level steps that take place:</p> <pre><code>namespace = type.__prepare__('Account', ())\n\n# Step 2: Execute the class body\nexec('''\ndef __init__(self, owner, balance):\n    self.owner = owner\n    self.balance = balance\n\ndef deposit(self, amount):\n    self.balance += amount\n\ndef withdraw(self, amount):\n    self.balance -= amount\n''', globals(), namespace)\n\n# Step 3: Create the final class object\nAccount = type('Account', (), namespace)\n</code></pre> <p>In the definition process, there is interaction with the <code>type</code> class to create the class namespace and to create the final class object. The choice of using <code>type</code> can be customized - a class can choose to be processed by a different metaclass by specifying a different metaclass. This is done by using the <code>metaclass</code> keyword argument in inheritance:</p> <pre><code>class Account(metaclass=type):\n</code></pre> <p>If no metaclass is given, the <code>class</code> statement examines the type of the first entry in the tuple of base classes (if any) and uses that as the metaclass. Therefore, if you write <code>class Account(object)</code>, the resulting <code>Account</code> class will have the same type as <code>object</code> (which is <code>type</code>). Note that classes that don't specify any parent at all always inherit from <code>object</code>, so this still applies.</p> <p>To create a new metaclass, define a class that inherits from <code>type</code>. Within this class, you can redefine one or more methods that are used during the class creation process. Typically, this includes the <code>__prepare__()</code> method used to create the class namespace, the <code>__new__()</code> method used to create the class instance, the <code>__init__()</code> method called after a class has already been created, and the <code>__call__()</code> method used to create new instances. The following example implements a metaclass that merely prints the input arguments to each method so you can experiment:</p> <pre><code>class mytype(type):\n    # Creates the class namespace\n    @classmethod\n    def __prepare__(meta, clsname, bases):\n        print('Preparing:', clsname, bases)\n        return super().__prepare__(clsname, bases)\n\n    # Creates the class instance after body has executed\n    @staticmethod\n    def __new__(meta, clsname, bases, namespace):\n        print('Creating:', clsname, bases, namespace)\n        return super().__new__(meta, clsname, bases, namespace)\n\n    # Initializes the class instance\n    def __init__(cls, clsname, bases, namespace):\n        print('Initializing:', clsname, bases, namespace)\n        super().__init__(clsname, bases, namespace)\n\n    # Creates new instances of the class\n    def __call__(cls, *args, **kwargs):\n        print('Creating instance:', args, kwargs)\n        return super().__call__(*args, **kwargs)\n</code></pre>"},{"location":"python/classes/classes/#example_1","title":"Example","text":"<pre><code>class Base(metaclass=mytype):\n    pass\n</code></pre> <p>The definition of the <code>Base</code> produces the following output:</p> <pre><code># Preparing: Base ()\n# Creating: Base () {'__module__': '__main__', '__qualname__': 'Base'}\n# Initializing: Base () {'__module__': '__main__', '__qualname__': 'Base'}\n</code></pre> <pre><code>b = Base()\n</code></pre> <p>Creating instance: <code>()</code>.</p> <p>One tricky facet of working with metaclasses is the naming of variables and keeping track of the various entities involved. In the above code, the <code>meta</code> name refers to the metaclass itself. The <code>cls</code> name refers to a class instance created by the metaclass. Although not used here, the <code>self</code> name refers to a normal instance created by a class.</p> <p>Metaclasses propagate via inheritance. So, if you've defined a base class to use a different metaclass, all child classes will also use that metaclass. Try this example to see your custom metaclass at work:</p> <pre><code>class Account(Base):\n    def __init__(self, owner, balance):\n        self.owner = owner\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        self.balance -= amount\n\nprint(type(Account))   # -&gt; &lt;class 'mytype'&gt;\n</code></pre> <p>The primary use of metaclasses is in situations where you want to exert extreme low-level control over the class definition environment and creation process. Before proceeding, however, remember that Python already provides a lot of functionality for monitoring and altering class definitions (such as the <code>__init_subclass__()</code> method, class decorators, descriptors, mixins, and so on). Most of the time, you probably don't need a metaclass. That said, the next few examples show situations where a metaclass provides the only sensible solution.</p> <p>One use of a metaclass is in rewriting the contents of the class namespace prior to the creation of the class object. Certain features of classes are established at definition time and can't be modified later. One such feature is <code>__slots__</code>. As noted earlier, <code>__slots__</code> is a performance optimization related to the memory layout of instances. Here's a metaclass that automatically sets the <code>__slots__</code> attribute based on the calling signature of the <code>__init__()</code> method.</p> <pre><code>import inspect\n\nclass SlotMeta(type):\n    @staticmethod\n    def __new__(meta, clsname, bases, methods):\n        if '__init__' in methods:\n            sig = inspect.signature(methods['__init__'])\n            __slots__ = tuple(sig.parameters)[1:]\n        else:\n            __slots__ = ()\n        methods['__slots__'] = __slots__\n        return super().__new__(meta, clsname, bases, methods)\n\nclass Base(metaclass=SlotMeta):\n    pass\n</code></pre>"},{"location":"python/classes/classes/#example_2","title":"Example","text":"<pre><code>class Point(Base):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n</code></pre> <p>In this example, the <code>Point</code> class that's created is automatically created with slots of <code>('x', 'y')</code>. The resulting instances of <code>Point</code> now get memory savings without knowing that slots are being used. It doesn't have to be specified directly. This kind of trick is not possible with class decorators or with <code>init_subclass()</code> because those features only operate on a class after it's been created. By then, it's too late to apply the slots optimization.</p> <p>Another use of metaclasses is for altering the class definition environment. For example, duplicate definitions of a name during class definition normally result in a silent error - the second definition overwrites the first. Suppose you wanted to catch that. Here's a metaclass that does that by defining a different kind of dictionary for the class namespace:</p> <pre><code>class NoDupeDict(dict):\n    def __setitem__(self, key, value):\n        if key in self:\n            raise AttributeError(f'{key} already defined')\n        super().__setitem__(key, value)\n\nclass NoDupeMeta(type):\n    @classmethod\n    def __prepare__(meta, clsname, bases):\n        return NoDupeDict()\n\nclass Base(metaclass=NoDupeMeta):\n    pass\n</code></pre>"},{"location":"python/classes/classes/#example_3","title":"Example","text":"<pre><code>class SomeClass(Base):\n    def yow(self):\n        print('Yow!')\n\n    def yow(self, x):             # Fails. Already defined\n        print('Different Yow!')\n</code></pre> <p>This is only a small sample of what's possible. For framework builders, metaclasses offer an opportunity to tightly control what happens during class definition - allowing classes to serve as a kind of domain-specific language.</p> <p>Historically, metaclasses have been used to accomplish a variety of tasks that are now possible through other means. The <code>init_subclass()</code> method, in particular, can be used to address a wide variety of use cases where metaclasses were once applied. This includes registration of classes with a central registry, automatic decoration of methods, and code generation.</p>"},{"location":"python/classes/classes/#built-in-objects-for-instances-and-classes","title":"Built-in Objects for Instances and Classes","text":"Attribute Description <code>cls.__name__</code> Class name <code>cls.__module__</code> Module name in which the class is defined <code>cls.__qualname__</code> Fully qualified class name <code>cls.__bases__</code> Tuple of base classes <code>cls.__mro__</code> Method Resolution Order tuple <code>cls.__dict__</code> Dictionary holding class methods and variables <code>cls.__doc__</code> Documentation string <code>cls.__annotations__</code> Dictionary of class type hints <code>cls.__abstractmethods__</code> Set of abstract method names (may be undefined if there aren't any) Attribute Description <code>i.__class__</code> Class to which the instance belongs <code>i.__dict__</code> Dictionary holding instance data (if defined)"},{"location":"python/classes/data_model/","title":"Python Data Model","text":"<p>When using a framework, we spend a lot of time coding methods that are called by the framework. The same happens when we leverage the Python Data Model. The Python interpreter invokes special methods to perform basic object operations, often triggered by special syntax. The special method names are always written with leading and trailing double underscores (i.e., <code>__getitem__</code>). For example, the syntax <code>obj[key]</code> is supported by the <code>__getitem__</code> special method. In order to evaluate <code>my_collection[key]</code>, the interpreter calls <code>my_collection.getitem(key)</code>.</p> <p>The special method names allow your objects to implement, support, and interact with fundamental language constructs such as:</p> <ul> <li>Collections</li> <li>Attribute access</li> <li>Iteration (including asynchronous iteration using <code>async for</code>)</li> <li>Operator overloading</li> <li>Function and method invocation</li> <li>String representation and formatting</li> <li>Asynchronous programming using <code>await</code></li> <li>Object creation and destruction</li> <li>Managed contexts (including asynchronous context managers using <code>async with</code>)</li> </ul>"},{"location":"python/classes/data_model/#example","title":"Example","text":"<pre><code>import collections\nCard = collections.namedtuple('Card', ['rank', 'suit'])\n\nclass FrenchDeck:\n    ranks = [str(n) for n in range(2, 11)] + list('JQKA')\n    suits = 'spades diamonds clubs hearts'.split()\n\n    def __init__(self):\n        self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks]\n\n    def __len__(self):\n        return len(self._cards)\n\n    def __getitem__(self, position):\n        return self._cards[position]\n</code></pre> Special Methods Description <code>__iter__</code> Iterable <code>__len__</code> Sized <code>__contains__</code> Container Strings/bytes <code>__repr__</code> String representation <code>__str__</code> String representation <code>__format__</code> Formatting <code>__bytes__</code> Bytes representation <code>__fspath__</code> File path representation Number <code>__abs__</code> Absolute value <code>__bool__</code> Boolean value <code>__complex__</code> Complex number <code>__int__</code> Integer representation <code>__float__</code> Float representation <code>__hash__</code> Hash value <code>__index__</code> Indexing Collections <code>__len__</code> Length <code>__getitem__</code> Item access <code>__setitem__</code> Item assignment <code>__delitem__</code> Item deletion <code>__contains__</code> Membership test Iteration <code>__iter__</code> Iteration <code>__aiter__</code> Asynchronous iteration <code>__next__</code> Next item <code>__anext__</code> Asynchronous next item <code>__reversed__</code> Reversed iteration Callable or coroutine <code>__call__</code> Function or method invocation <code>__await__</code> Asynchronous await Context managers <code>__enter__</code> Context manager enter <code>__aenter__</code> Asynchronous context manager enter <code>__exit__</code> Context manager exit <code>__aexit__</code> Asynchronous context manager exit Instance creation and destruction <code>__new__</code> Object creation <code>__init__</code> Object initialization <code>__del__</code> Object destruction Attribute management <code>__getattr__</code> Attribute retrieval <code>__getattribute__</code> Attribute access <code>__setattr__</code> Attribute assignment <code>__delattr__</code> Attribute deletion <code>__dir__</code> Directory listing Attribute descriptors <code>__get__</code> Descriptor get <code>__set__</code> Descriptor set <code>__delete__</code> Descriptor deletion <code>__set_name__</code> Descriptor set name Class services <code>__prepare__</code> Class creation <code>__init_subclass__</code> Subclass initialization <code>__instancecheck__</code> Instance check <code>__subclasscheck__</code> Subclass check <p>Why <code>len</code> is not a method</p> <p><code>len</code> runs very fast when <code>x</code> is a built-in type. No method is called for built-in types in CPython; length is simply read from a field from the C struct. <code>len</code> is not called as methods, but in our Python objects, it works as normal.</p>"},{"location":"python/classes/data_model/#data-structure","title":"Data Structure","text":"<p>Every Python object in a C struct has two fields:</p> <ul> <li><code>ob_refcnt</code> and <code>ob_fval</code>: reference count and pointer value.</li> </ul>"},{"location":"python/classes/data_model/#mutable-sequences-vs-immutable","title":"Mutable Sequences vs Immutable","text":"<ul> <li>Mutable: list, bytearray, array.array, collections.deque, and memoryview.</li> <li>Immutable: tuple, str, and bytes.</li> </ul> <p>TIP In Python code, line breaks are ignored inside pairs of [], {}, or (). So you can build multiline lists, listcomps, genexps, dictionaries, and the like without using the ugly \\ line continuation escape. Also, when those delimiters are used to define a literal with a comma-separated series of items, a trailing comma will be ignored. So, for example, when coding a multi-line list literal, it is thoughtful to put a comma after the last item.</p>"},{"location":"python/classes/data_model/#list-comps-versus-map-and-filter","title":"List Comps Versus <code>map</code> and <code>filter</code>","text":"<p><code>map</code> and <code>filter</code> were faster, but nowadays they are the same.</p> <p>Tuple is not just immutable lists. It can be used as immutable lists or records with no field names (1,2) lat long.</p> <p>If you write internationalized software, <code>_</code> is not a good dummy variable because it is traditionally used as an alias to the <code>gettext.gettext</code> function, as recommended in the <code>gettext</code> module documentation. Otherwise, it\u2019s a conventional name for a placeholder variable to be ignored.</p> <p>Tuple as Immutable List 1. Clarity: You know it never changes. 2. Performance: It uses less memory.</p> <p>Are tuples more efficient than lists?</p> <p>Raymond Hettinger answers: - To evaluate a tuple, Python generates bytecode in constant one operation, but for a list, it pushes every element as a separate constant to data stacks and builds the list. - Hashable tuple: <code>tuple(t)</code> returns a reference to the same <code>t</code>. No need to copy; the list makes a copy anyway. - For fixed length, exact memory is allocated. The list has room to spare for the future. - References to items of a tuple are stored in an array with the tuple struct itself. The list holds a pointer to the array of references stored elsewhere and makes the CPU cache less effective. But it is necessary because of the need to make room.</p> <p>Slicing <code>seq[start:stop:step]</code> - Python calls <code>seq.getitem(slice(start, stop, step))</code>.</p> <p>Building a List of Objects <pre><code>my_list = [[]] * 3 # same board appended, one changes everyone changes\n\nboard = [['_'] * 3 for i in range(3)] # no problem\n</code></pre></p> <p>When List is Not the Answer If it contains the same type, maybe <code>array.array</code> will be better. You can dump it to a binary file directly, and it's memory-efficient.</p> <p>Queue Why don't use List as a queue? Because every item has to be shifted in memory.</p> <p>Use <code>collections.deque</code> instead; it is thread-safe and has the <code>maxlen</code> attribute. There are more queues: - <code>queue</code>: <code>SimpleQueue</code>, <code>Queue</code>, <code>LifoQueue</code>, and <code>PriorityQueue</code>. - <code>multiprocessing</code>: <code>SimpleQueue</code> and bounded <code>Queue</code> - very similar to those in the <code>queue</code> package but designed for interprocess communication. A specialized <code>multiprocessing.JoinableQueue</code>. - <code>asyncio</code>: Provides <code>Queue</code>, <code>LifoQueue</code>, <code>PriorityQueue</code>, and <code>JoinableQueue</code>. - <code>heap</code>: <code>heappush</code>, <code>heappop</code>.</p> <p>Flat vs Container Sequence Flat is all the same type.</p> <p><code>hash()</code> Calling <code>hash(t)</code> on a tuple is a quick way to assert that its value is fixed. A <code>TypeError</code> will be raised if <code>t</code> contains mutable items.</p> <p>Decode vs Encode Imagine <code>str</code> is human-readable bytes; don't. Bytes need decoding; string encoding.</p>"},{"location":"python/classes/descriptors/","title":"Descriptors","text":"<pre><code>class DescriptorClass:\n    def __get__(self, instance, owner):\n        if instance is None:\n            return self\n        print(\n        self.__class__.__name__,\n        instance,\n        owner)\n        return instance\n\nclass ClientClass:\n    descriptor = DescriptorClass()\n\nclient = ClientClass()\nclient.descriptor\n</code></pre>"},{"location":"python/classes/descriptors/#descriptor-methods","title":"Descriptor Methods","text":"<ul> <li> <p><code>__get__(self, instance, owner)</code>: The <code>__get__</code> method of the descriptor class. It takes three arguments: <code>self</code>, <code>instance</code> (where the descriptor is called from), and <code>owner</code> (a reference to the class object). <code>owner</code> is the same as <code>instance.__class__</code>.</p> </li> <li> <p><code>__set__(self, instance, value)</code>: The <code>__set__</code> method of the descriptor class. It is called when assigning a value to the descriptor. Example usage: <code>client.descriptor = 'value'</code>.</p> </li> <li> <p><code>__delete__(self, instance)</code>: The <code>__delete__</code> method of the descriptor class. It is called when deleting the descriptor. Example usage: <code>del client.descriptor</code>.</p> </li> <li> <p><code>__set_name__(self, owner, name)</code>: The <code>__set_name__</code> method of the descriptor class. It is called during the class creation and provides the field name.</p> </li> </ul> <pre><code>class DescriptorWithName:\n    def __init__(self, name):\n        self.name = name\n    def __get__(self, instance, value):\n        if instance is None:\n            return self\n        print(self.name, instance)\n        return instance.__dict__[self.name]\n    def __set__(self, instance, value):\n        instance.__dict__[self.name] = value\n\nclass ClientClass:\n    descriptor = DescriptorWithName(\"descriptor\")\n</code></pre>"},{"location":"python/classes/descriptors/#descriptor-types","title":"Descriptor Types","text":"<ul> <li> <p>Non-data descriptor: Implements only the <code>__get__</code> method.</p> </li> <li> <p>Data descriptor: Implements both the <code>__get__</code> and <code>__set__</code> methods.</p> </li> </ul> <p>Why is it accessing the <code>__dict__</code> attribute of the instance directly? Another good question, which also has at least two explanations. First, you might be thinking why not just do the following? <code>setattr(instance, \"descriptor\", value)</code></p> <p>Remember that this method (<code>__set__</code>) is called when we try to assign something to the attribute that is a descriptor. So, using <code>setattr()</code> will call this descriptor again, which, in turn, will call it again, and so on and so forth. This will end up in an infinite recursion.</p> <p>Why, then, is the descriptor not able to book-keep the values of the properties for all of its objects? The client class already has a reference to the descriptor. If we add a reference from the descriptor back to the client object, we are creating circular dependencies, and these objects will never be garbage-collected. Since they are pointing at each other, their reference counts will never drop below the threshold for removal, and that will cause memory leaks in our program.</p> <p>A possible alternative here is to use weak references, with the <code>weakref</code> module, and create a weak reference key dictionary if we want to do that. This implementation is explained later on in this chapter, but for the implementations within this book, we prefer to use this idiom (and not <code>weakref</code>), since it is fairly common and accepted when writing descriptors. As of now, we have studied the different kinds of descriptors, what they are, and how they work, and we even got a first idea of how we can use them to our advantage. The next section emphasizes precisely that last point: we'll see descriptors in action. From now on, we'll take a more practical approach, and see how we can use descriptors to achieve better code. After that, we'll even explore examples of good descriptors.</p>"},{"location":"python/classes/descriptors/#functions-and-methods","title":"Functions and Methods","text":"<p>The most resonating case of an object that is a descriptor is probably a function. Functions implement the <code>__get__</code> method, so they can work as methods when defined inside a class. In Python, methods are just regular functions, only they take an extra argument. By convention, the first argument of a method is named <code>self</code>, and it represents an instance of the class that the method is being defined in. Then, whatever the method does with <code>self</code> would be the same as any other function receiving the object and applying modifications to it. In other words, when we define something like this:</p> <pre><code>class MyClass:\n    def method(self, ...):\n        self.x = 1\n</code></pre> <p>Since functions implement the descriptor protocol, before calling the method, the <code>__get__</code> method is invoked first. Then, within this <code>__get__</code> method, some transformations happen before running the code on the internal callable.</p>"},{"location":"python/classes/descriptors/#function-as-descriptor","title":"Function as Descriptor","text":"<pre><code>from types import MethodType\n\nclass Method:\n    def __init__(self, name):\n        self.name = name\n    def __call__(self, instance, arg1, arg2):\n        print(f\"{self.name}: {instance} called with {arg1} and {arg2}\")\n    def __get__(self, instance, owner):\n        if instance is None:\n            return self\n        return MethodType(self, instance)\n</code></pre> <p>Since this is a very elegant solution, it's worth exploring it to keep it in mind as a Pythonic approach when defining our own objects. For instance, if we were to define our own callable, it would be a good idea to also make it a descriptor so that we can use it in classes as class attributes as well. ```</p>"},{"location":"python/classes/iterators/","title":"Iterators","text":""},{"location":"python/classes/iterators/#generators","title":"Generators","text":"<p>Generators were introduced in Python a long time ago (PEP-255), with the idea of introducing iteration in Python while improving the performance of the program (by using less memory) at the same time. The idea of a generator is to create an object that is iterable and, while it's being iterated, will produce the elements it contains, one at a time. The main use of generators is to save memory\u2014instead of having a very large list of elements in memory, holding everything at once, we have an object that knows how to produce each particular element, one at a time, as it is required. This feature enables lazy computations of heavyweight objects in memory, in a similar manner to what other functional programming languages (Haskell, for instance) provide. It would even be possible to work with infinite sequences because the lazy nature of generators enables such an option.</p>"},{"location":"python/classes/iterators/#next","title":"<code>next()</code>","text":"<p>The <code>next()</code> built-in function will advance the iterable to its next element and return it.</p>"},{"location":"python/classes/iterators/#itertools","title":"<code>itertools</code>","text":"<pre><code>def process(self):\n    for purchase in self.purchases:\n        if purchase &gt; 1000.0:\n            ...\n</code></pre> <p>This is not only non-Pythonic, but it's also rigid (and rigidity is a trait that denotes bad code). It doesn't handle changes very well. What if the number changes now? Do we pass it by parameter? What if we need more than one? What if the condition is different (less than, for instance)? Do we pass a lambda? These questions should not be answered by this object, whose sole responsibility is to compute a set of well-defined metrics over a stream of purchases represented as numbers. And, of course, the answer is no. It would be a huge mistake to make such a change (once again, clean code is flexible, and we don't want to make it rigid by coupling this object to external factors). These requirements will have to be addressed elsewhere.</p>"},{"location":"python/classes/iterators/#itertoolsislice-takes-first-ten","title":"<code>itertools.islice</code> - Takes First Ten","text":"<pre><code>from itertools import islice\n\npurchases = islice(filter(lambda p: p &gt; 1000.0, purchases), 10)\n</code></pre> <p>There is no memory penalization for filtering this way because since they are all generators, the evaluation is always lazy. This gives us the power of thinking as if we had filtered the entire set at once and then passed it to the object, but without actually fitting everything in memory. Keep in mind the trade-off mentioned at the beginning of the chapter, between memory and CPU usage. While the code might use less memory, it could take up more CPU time, but most of the times, this is acceptable when we have to process lots of objects in memory while keeping the code maintainable.</p>"},{"location":"python/classes/iterators/#repeated-iterations-with-itertoolstee","title":"Repeated Iterations with <code>itertools.tee</code>","text":"<pre><code>def process_purchases(purchases):\n    min_, max_, avg = itertools.tee(purchases, 3)\n    return min(min_), max(max_), median(avg)\n</code></pre> <p>In this example, <code>itertools.tee</code> will split the original iterable into three new ones. We will use each of these for the different kinds of iterations that we require, without needing to repeat three different loops over purchases.</p>"},{"location":"python/classes/iterators/#yielding","title":"Yielding","text":"<pre><code>def _iterate_array2d(array2d):\n    for i, row in enumerate(array2d):\n        for j, cell in enumerate(row):\n            yield (i, j), cell\n</code></pre> <pre><code>def search_nested(array, desired_value):\n    try:\n        coord = next(\n            coord\n            for (coord, cell) in _iterate_array2d(array)\n            if cell == desired_value\n        )\n    except StopIteration as e:\n        raise ValueError(f\"{desired_value} not found\") from e\n    logger.info(\"value %r found at [%i, %i]\", desired_value, *coord)\n    return coord\n</code></pre>"},{"location":"python/classes/iterators/#iterator-but-not-iterable","title":"Iterator but Not Iterable","text":"<pre><code>class SequenceIterator:\n    def __init__(self, start=0, step=1):\n        self.current = start\n        self.step = step\n    def __next__(self):\n        value = self.current\n        self.current += self.step\n        return value\n</code></pre>"},{"location":"python/classes/iterators/#sequence-are-iterables","title":"Sequence are Iterables","text":"<pre><code>class MappedRange:\n    \"\"\"Apply a transformation to a range of numbers.\"\"\"\n    def __init__(self, transformation, start, end):\n        self._transformation = transformation\n        self._wrapped = range(start, end)\n    def __getitem__(self, index):\n        value = self._wrapped.__getitem__(index)\n        result = self._transformation(value)\n        logger.info(\"Index %d: %s\", index, result)\n        return result\n    def __len__(self):\n        return len(self._wrapped)\n</code></pre>"},{"location":"python/classes/iterators/#coroutines","title":"Coroutines","text":"<ul> <li><code>.close()</code></li> <li><code>.throw()</code></li> <li><code>.send()</code></li> </ul> <p>Python takes advantage of generators in order to create coroutines. Because generators can naturally suspend, they're a convenient starting point. But generators weren't enough as they were originally thought to be, so these methods were added. This is because typically, it's not enough to just be able to suspend some part of the code; you'd also want to communicate with it (pass data and signal changes in the context).</p>"},{"location":"python/classes/iterators/#close","title":"<code>close()</code>","text":"<p>When calling this method, the generator will receive the <code>GeneratorExit</code> exception. If it's not handled, then the generator will finish without producing any more values, and its iteration will stop.</p>"},{"location":"python/classes/iterators/#throw","title":"<code>throw()</code>","text":"<p>This method will throw the exception at the line where the generator is currently suspended. If the generator handles the exception that was sent, the code in that particular <code>except</code> clause will be called; otherwise, the exception will propagate to the caller.</p> <pre><code>def stream_data(db_handler):\n    while True:\n        try:\n            yield db_handler.read_n_records(10)\n        except CustomException as e:\n            logger.info(\"controlled error %r, continuing\", e)\n        except Exception as e:\n            logger.info(\"unhandled error %r, stopping\", e)\n            db_handler.close()\n            break\n</code></pre>"},{"location":"python/classes/iterators/#sendvalue","title":"<code>send(value)</code>","text":"<pre><code>def stream_db_records(db_handler):\n    retrieved_data = None\n    previous_page_size = 10\n    try:\n        while True:\n            page_size = yield retrieved_data\n            if page_size is None:\n                page_size = previous_page_size\n            previous_page_size = page_size\n            retrieved_data = db_handler.read_n_records(page_size)\n    except GeneratorExit:\n        db_handler.close()\n</code></pre> <p>First None</p>"},{"location":"python/classes/iterators/#yield-from","title":"<code>yield from</code>","text":"<p><code>yield from iterable</code></p>"},{"location":"python/classes/iterators/#async-programming","title":"Async Programming","text":""},{"location":"python/classes/iterators/#async-context-managers","title":"Async Context Managers","text":"<pre><code>@contextlib.asynccontextmanager\nasync def db_management():\n    try:\n        await stop_database()\n        yield\n    finally:\n        await start_database()\n</code></pre> <pre><code>import asyncio\nimport random\n\nasync def coroutine():\n    await asyncio.sleep(0.1)\n    return random.randint(1, 10000)\n\nclass RecordStreamer:\n    def __init__(self, max_rows=100):\n        self._current_row = 0\n        self._max_rows = max_rows\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if self._current_row &lt; self._max_rows:\n            row = (self._current_row, await coroutine())\n            self._current_row += 1\n            return row\n        raise StopAsyncIteration\n</code></pre> <p><code>await async_iterator.__anext__()</code></p>"},{"location":"python/classes/iterators/#async-generators","title":"Async Generators","text":"<pre><code>async def record_streamer(max_rows):\n    current_row = 0\n    while current_row &lt; max_rows:\n        row = (current_row, await coroutine())\n        current_row += 1\n        yield row\n</code></pre>"},{"location":"python/context_managers/context_managers/","title":"Context Managers","text":""},{"location":"python/context_managers/context_managers/#example","title":"EXAMPLE","text":"<pre><code>class ListTransaction:\n    def __init__(self,thelist):\n        self.thelist = thelist\n\n    def __enter__(self):\n        self.workingcopy = list(self.thelist)\n        return self.workingcopy\n\n    def __exit__(self,type,value,tb):\n        if type is None:\n            self.thelist[:] = self.workingcopy\n        return False\n</code></pre>"},{"location":"python/context_managers/context_managers/#reading-files-using-context-manager-with-chunks","title":"READING FILES USING CONTEXT MANAGER WITH CHUNKS","text":"<pre><code>with open('data.txt') as file:\n    while (chunk := file.read(10000)):\n        print(chunk, end='')\n</code></pre>"},{"location":"python/data_types/data_types/","title":"Overview","text":""},{"location":"python/data_types/data_types/#literals","title":"LITERALS","text":"<p>0b101010         # Binary integer 0o52             # Octal integer 0x2a             # Hexadecimal integer</p>"},{"location":"python/data_types/data_types/#unpacking-sequences-into-variables","title":"Unpacking Sequences into Variables","text":"<p>Unpacking can be very useful for assigning multiple variables from a single sequence. Let's see some examples:</p> <pre><code>p = (4,5)\nx, y = p\nprint(x)\n</code></pre> <p>Output: <pre><code>4\n</code></pre></p>"},{"location":"python/data_types/data_types/#using-_-as-a-throwaway-variable","title":"Using _ as a Throwaway Variable","text":"<p>When unpacking, you can use <code>_</code> as a throwaway variable for certain values you're going to discard.</p> <pre><code>data = ['ACME', 50, 91.1, (2012, 12, 21)]\nname, shares, price, date = data\n_, shares, _, date = data\n</code></pre> <p>Output: <pre><code>'ACME'\n</code></pre></p>"},{"location":"python/data_types/data_types/#unpacking-n-elements","title":"Unpacking N Elements","text":"<p>You can unpack elements flexibly using the <code>*</code> symbol:</p> <pre><code>record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212')\nname, email, *phone_numbers = record\nprint(phone_numbers)\n</code></pre> <p>Output: <pre><code>['773-555-1212', '847-555-1212']\n</code></pre></p>"},{"location":"python/data_types/data_types/#string-split-example","title":"String Split Example","text":"<p>Strings can be split and unpacked easily:</p> <pre><code>line = 'nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false'\nuname, *fields, homedir, sh = line.split(':')\nprint(uname)\n</code></pre> <p>Output: <pre><code>'nobody'\n</code></pre></p>"},{"location":"python/data_types/data_types/#working-with-deques","title":"Working with Deques","text":"<p><code>collections.deque</code> provides a double-ended queue that supports adding and removing elements from both ends in O(1) time.</p> <pre><code>from collections import deque\nq = deque(maxlen=3)\nq.append(1)\nq.append(2)\nq.append(3)\nq.append(4)\nprint(q)\n</code></pre> <p>Output: <pre><code>deque([2, 3, 4])\n</code></pre></p>"},{"location":"python/data_types/data_types/#appending-to-a-queue","title":"Appending to a Queue","text":"<pre><code>q.appendleft(4)\nprint(q)\n</code></pre> <p>Output: <pre><code>deque([4, 2])\n</code></pre></p>"},{"location":"python/data_types/data_types/#finding-the-largest-or-smallest-n-items","title":"Finding the Largest or Smallest N Items","text":"<p>The <code>heapq</code> module provides functions to find the N smallest or largest items.</p> <pre><code>import heapq\n# ... [rest of the code]\nprint(cheap)\nprint(expensive)\n</code></pre>"},{"location":"python/data_types/data_types/#113-sorting-a-list-of-dictionaries-by-a-common-key","title":"1.13 Sorting a List of Dictionaries by a common key","text":"<pre><code>rows = [\n    {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003},\n    {'fname': 'David', 'lname': 'Beazley', 'uid': 1002},\n    {'fname': 'John', 'lname': 'Cleese', 'uid': 1001},\n    {'fname': 'Big', 'lname': 'Jones', 'uid': 1004}\n]\n\nfrom operator import itemgetter\n\nrows_by_fname = sorted(rows, key=itemgetter('fname'))\nrows_by_uid = sorted(rows, key=itemgetter('uid'))\nprint(rows_by_fname)\nprint(rows_by_uid)\n\nrows_by_lfname = sorted(rows, key=itemgetter('lname','fname'))\nprint(rows_by_lfname)\n</code></pre>"},{"location":"python/data_types/data_types/#115-grouping-records-based-on-a-field","title":"1.15 Grouping Records Based on a Field","text":"<pre><code>rows = [\n    ...\n]\nfrom operator import itemgetter\nfrom itertools import groupby\n...\n\nfor date, items in groupby(rows, key=itemgetter('date')):\n    print(date)\n    for i in items:\n        print('    ', i)\n</code></pre>"},{"location":"python/data_types/data_types/#116-filtering-list","title":"1.16 Filtering List","text":"<pre><code>addresses = [\n    ...\n]\ncounts = [ ... ]\n\nfrom itertools import compress\nmore5 = [n &gt; 5 for n in counts]\n\nlist(compress(addresses, more5))\n</code></pre>"},{"location":"python/data_types/data_types/#117-subset-of-dictionary","title":"1.17 Subset of Dictionary","text":"<pre><code>prices = {\n    ...\n}\n\np1 = { key:value for key, value in prices.items() if value &gt; 200 }\n...\n</code></pre> <p>... [and so on, structuring each section with a Markdown header and enclosing the code in triple backticks for code blocks]</p>"},{"location":"python/data_types/data_types/#213-aligning-text-strings","title":"2.13. Aligning Text Strings","text":"<pre><code>text = 'Hello World'\n\ntext.ljust(20)\ntext.rjust(20)\n...\n</code></pre>"},{"location":"python/data_types/data_types/#312-time-objects","title":"3.12 Time Objects","text":"<p>Working with <code>datetime.timedelta</code>:</p> <pre><code>from datetime import timedelta\n\na = timedelta(days=2, hours=6)\nb = timedelta(hours=4.5)\nc = a + b\nprint(c.days)  # 2\nprint(c.seconds)  # 37800\nprint(c.total_seconds())  # 210600.0\n</code></pre> <p>Working with <code>datetime.datetime</code>:</p> <pre><code>from datetime import datetime\n\na = datetime(2012, 9, 23)\nprint(a + timedelta(days=10))  # 2012-10-03 00:00:00\n\nb = datetime(2012, 12, 21)\nd = b - a\nprint(d)  # datetime.timedelta(days=89)\n</code></pre>"},{"location":"python/data_types/data_types/#313-finding-last-occurrence-of-a-weekday","title":"3.13 Finding Last Occurrence of a Weekday","text":"<pre><code>from datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nfrom dateutil.rrule import *\n\nweekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\ndef get_previous_byday(dayname, start_date=None):\n    # ... [rest of the function here]\n</code></pre>"},{"location":"python/data_types/data_types/#315-convert-string-into-datetime","title":"3.15 Convert String into Datetime","text":"<pre><code>from datetime import datetime\n\ntext = '2012-09-20'\ny = datetime.strptime(text, '%Y-%m-%d')\nprint(y)  # datetime.datetime(2012, 9, 20, 0, 0)\n</code></pre>"},{"location":"python/data_types/data_types/#41-manually-consuming-an-iterator","title":"4.1 Manually Consuming an Iterator","text":"<pre><code>with open('/etc/passwd') as f:\n    # ... [rest of the code here]\n</code></pre>"},{"location":"python/data_types/data_types/#43-generators","title":"4.3 Generators","text":"<pre><code>def frange(start, stop, increment):\n    # ... [rest of the function here]\n</code></pre>"},{"location":"python/data_types/data_types/#45-reversed-iterator","title":"4.5 Reversed Iterator","text":"<pre><code>class Countdown:\n    # ... [rest of the class here]\n</code></pre>"},{"location":"python/data_types/data_types/#46-generator-functions-with-extra-state","title":"4.6 Generator Functions with Extra State","text":"<pre><code>from collections import deque\n\nclass linehistory:\n    # ... [rest of the class here]\n</code></pre>"},{"location":"python/data_types/data_types/#47-taking-slice-of-an-iterator","title":"4.7 Taking Slice of an Iterator","text":"<pre><code>def count(n):\n    # ... [rest of the function here]\n</code></pre>"},{"location":"python/data_types/data_types/#48-user-database","title":"4.8 User Database","text":"<pre><code>from itertools import dropwhile\n\nwith open('/etc/passwd') as f:\n    # ... [rest of the code here]\n</code></pre>"},{"location":"python/data_types/data_types/#49-iterate-all-possible-combinations","title":"4.9 Iterate All Possible Combinations","text":"<pre><code>items = ['a', 'b', 'c']\nfrom itertools import permutations\n# ... [rest of the code here]\n</code></pre>"},{"location":"python/data_types/data_types/#411-iterating-over-multiple-sequences-simultaneously","title":"4.11 Iterating Over Multiple Sequences Simultaneously","text":"<pre><code>xpts = [1,5,4,2,10,7]\nypts = [101, 78, 37, 15, 62, 99]\n# ... [rest of the code here]\n</code></pre>"},{"location":"python/data_types/data_types/#412-using-itertoolschain","title":"4.12 Using <code>itertools.chain</code>","text":"<pre><code>from itertools import chain\n\na = [1, 2, 3, 4]\nb = ['x', 'y', 'z']\nfor x in chain(a, b):\n    print(x)\n</code></pre>"},{"location":"python/data_types/dic_set/","title":"Dict & Set","text":"<p>dict vs set what is hashable</p> <p>An object is hashable if it has a hash value which never changes during its lifetime (it needs a hash() method), and can be compared to other objects (it needs an eq() method). Hashable objects which compare equal must have the same hash value. [...]</p> <p>User-defined types are hashable by default because their hash code is their id() and the eq() method inherited from the object class simply compares the object ids. If an object implements a custom eq() which takes into account its internal state, it will be hashable only if its hash() always returns the same hash code. In practice, this requires that eq() and hash() only take into account instance attributes that never change during the life of the object. missing keys with setdefault</p> <p>d.get(k, default) my_dict.setdefault(key, []).append(new_value) missing with missinng</p> <p>o subclass dict or any other mapping type and add a missing method. Both solutions are covered next.</p> <p>The missing method is only called by getitem (i.e., for the d[k] operator). The presence of a missing method has no effect on the behavior of other methods that look up keys, such as get or contains (which implements the in operator). This is why the default_factory of defaultdict works only with getitem, as noted in the warning at the end of the previous section. subclass builtin</p> <p>A better way to create a user-defined mapping type is to subclass collections.UserDict instead of dict (as we\u2019ll do in Example 3-8). Here we subclass dict just to show that missing is supported by the built-in dict.getitem method dict variations</p> <pre><code>collections.OrderedDict\ncollections.ChainMap\nChainMap(locals(), globals(), vars(builtins))\ncollections.Counter\n</code></pre> <p>custom mapping</p> <pre><code>collections.UserDict\ntyping.TypedDict The collections.UserDict class behaves like a dict, but it is slower because it is implemented in Python, not in C. We\u2019ll cover it in more detail next\n</code></pre> <p>Set Theory</p> <p>Set elements must be hashable. The set type is not hashable, so you can\u2019t build a set with nested set instances. But frozenset is hashable, so you can have frozenset elements inside a set.</p> <p>n CPython built for a 64-bit CPU, each bucket in a set has two fields: a 64-bit hash code, and a 64-bit pointer to the element value\u2014which is a Python object stored elsewhere in memory. Because buckets have a fixed size, access to an individual bucket is done by offset. There is no field for the indexes from 0 to 7 The hash() built-in function works directly with built-in types and falls back to calling hash for user-defined types. If two objects compare equal, their hash codes must also be equal, otherwise the hash table algorithm does not work. For example, because 1 == 1.0 is True, hash(1) == hash(1.0) must also be True, even though the internal representation of an int and a float are very different. Also, to be effective as hash table indexes, hash codes should scatter around the index space as much as possible. This means that, ideally, objects that are similar but not equal should have hash codes that differ widely. Example 3-17 is the output of a script to compare the bit patterns of hash codes. Note how the hashes of 1 and 1.0 are the same, but those of 1.0001, 1.0002, and 1.0003 are very different. salt value of hash</p> <p>Starting with Python 3.3, a random salt value is included when computing hash codes for str, bytes, and datetime objects, as documented in Issue 13703\u2014Hash collision security issue. The salt value is constant within a Python process but varies between interpreter runs. With PEP-456, Python 3.4 adopted the SipHash cryptographic function to compute hash codes for str and bytes objects. The random salt and SipHash are security measures to prevent DoS attacks. Details are in a note in the documentation for the hash special method. hasing in python</p> <p>As mentioned earlier, the hash table for a set starts with 8 empty buckets. As elements are added, Python makes sure at least \u2153 of the buckets are empty\u2014doubling the size of the hash table when more space is needed. The hash code field of each bucket is initialized with -1, which means \u201cno hash code\u201d</p> <p>iven the literal {'Mon', 'Tue', 'Wed', 'Thu', 'Fri'}, Python gets the hash code for the first element, 'Mon'. For example, here is a realistic hash code for 'Mon'\u2014you\u2019ll probably get a different result because of the random salt Python uses to compute the hash code of string</p> <p>Python takes the modulus of the hash code with the table size to find a hash table index. Here the table size is 8, and the modulus is 3:</p> <p>Probing consists of computing the index from the hash, then looking at the corresponding bucket in the hash table. In this case, Python looks at the bucket at offset 3 and finds -1 in the hash code field, marking an empty bucke</p> <p>Python stores the hash code of the new element, 4199492796428269555, in the hash code field at offset 3, and a pointer to the string object 'Mon' in the element field. Figure 3-5 shows the current state of the hash table</p> <p>For the second element, 'Tue', steps 1, 2, 3 above are repeated. The hash code for 'Tue' is 2414279730484651250, and the resulting index is 2.</p> <p>When adding 'Wed' to the set, Python computes the hash -5145319347887138165 and index 3. Python probes bucket 3 and sees that it is already taken. But the hash code stored there, 4199492796428269555 is different. As discussed in \u201cHashes and equality\u201d, if two objects have different hashes, then their value is also different. This is an index collision. Python then probes the next bucket and finds it empty. So 'Wed' ends up at index 4, as shown in Figure 3-7.</p> <p>Adding the next element, 'Thu', is boring: there\u2019s no collision, and it lands in its natural bucket, at index 7. Placing 'Fri' is more interesting. Its hash, 7021641685991143771 implies index 3, which is taken by 'Mon'. Probing the next bucket\u20144\u2014 Python finds the hash for 'Wed' stored there. The hash codes don\u2019t match, so this is another index collision. Python probes the next bucket. It\u2019s empty, so 'Fri' ends up at index 5. The end state of the hash table is shown in Figure 3-8.</p> <p>ahsh table for the set {'Mon', 'Tue', 'Wed', 'Thu', 'Fri'}. It is now 62.5% full\u2014close to the \u2154 threshold.</p>"},{"location":"python/data_types/list_tuple/","title":"List & Tuple","text":""},{"location":"python/data_types/list_tuple/#list-comprehension","title":"LIST COMPREHENSION","text":"<pre><code>[expression for item1 in iterable1 if condition1\n            for item2 in iterable2 if condition2\n ]\n</code></pre>"},{"location":"python/data_types/object/","title":"Object","text":"<p>Variables Are Not Boxes</p> <p>In 1997, I took a summer course on Java at MIT. The professor, Lynn Andrea Stein\u2014an award-winning computer science educator who currently teaches at Olin College of Engineering\u2014made the point that the usual \u201cvariables as boxes\u201d metaphor actually hinders the understanding of reference variables in OO languages. Python variables are like reference variables in Java, so it\u2019s better to think of them as labels attached to objects sentiel obj</p> <p>END_OF_DATA = object()</p>"},{"location":"python/data_types/object/#many-lines","title":"... many lines","text":"<p>def traverse(...):</p>"},{"location":"python/data_types/object/#more-lines","title":"... more lines","text":"<p>if node is END_OF_DATA:     raise StopIteration</p>"},{"location":"python/data_types/object/#etc","title":"etc.","text":"<p>Copies Are Shallow by Default Function Parameters as References</p> <p>In CPython, the primary algorithm for garbage collection is reference counting. Essentially, each object keeps count of how many references point to it. As soon as that refcount reaches zero, the object is immediately destroyed: CPython calls the del method on the object (if defined) and then frees the memory allocated to the object. In CPython 2.0, a generational garbage collection algorithm was added to detect groups of objects involved in reference cycles\u2014which may be unreachable even with outstanding references to them, when all the mutual references are contained within the group. Other implementations of Python have more sophisticated garbage collectors that do not rely on reference counting, which means the del method may not be called immediately when there are no more references to the object. See \u201cPyPy, Garbage Collection,</p> <p>wref = weakref.ref(a_set)</p> <p>weakref.finalize to register a callback function to be called when an object is destroyed The WeakValueDictionary Skit</p> <p>The class WeakValueDictionary implements a mutable mapping where the values are weak references to objects. When a referred object is garbage collected elsewhere in the program, the corresponding key is automatically removed from WeakValueDictionary. This is commonly used for caching. Our demonstration of a WeakValueDictionary is inspired by the classic Cheese Shop skit by Monty Python, in which a customer asks for more than 40 kinds of cheese, including cheddar and mozzarella, but none are in stock.</p> <p>import weakref</p> <pre><code>        stock = weakref.WeakValueDictionary() catalog = [Cheese('Red Leicester'), Cheese('Tilsit'), ... Cheese('Brie'), Cheese('Parmesan')] ... for cheese in catalog: ... stock[cheese.kind] = cheese ... sorted(stock.keys()) ['Brie', 'Parmesan', 'Red Leicester', 'Tilsit'] del catalog sorted(stock.keys()) ['Parmesan'] del cheese sorted(stock.keys())\n</code></pre> <p>A temporary variable may cause an object to last longer than expected by holding a reference to it. This is usually not a problem with local variables: they are destroyed when the function returns. But in Example 6-19, the for loop variable cheese is a global variable and will never go away unless explicitly deleted</p> <p>Not every Python object may be the target, or referent, of a weak reference. Basic list and dict instances may not be referents, but a plain subclass of either can solve this problem easily</p> <p>class MyList(list): \"\"\"list subclass whose instances may be weakly referenced\"\"\" a_list = MyList(range(10)) a_list can be the target of a weak reference</p> <p>wref_to_a_list = weakref.ref(a_list)</p> <p>I was surprised to learn that, for a tuple t, t[:] does not make a copy, but returns a reference to the same object</p>"},{"location":"python/decorators/decorators/","title":"Decorators","text":"<pre><code>@dataclass\nclass Serializer:\n    def __init__(self,dict_values):\n        self.values = dict_values\n\n\n    def serialize(self,object):\n        return [ trans(getattr(object,field))for field,trans in self.values.items()]\n\n\n\n\nclass Serialize:\n\n    def __init__(self,**trans) -&gt; None:\n        self.serializer = Serializer(trans)\n\n\n    def __call__(self,object):\n        print(object) ## Event\n\n        def wrapper(instance):# Intance\n            return self.serializer.serialize(instance)\n\n        object.serialize=wrapper\n\n        return object\n\n\n\ndef serialize(**trans):\n    serializer = Serializer(trans)\n    def wrapper(class_obj):\n        def inner(instance):\n            return  serializer.serialize(instance)\n        class_obj.serialize=inner\n        return class_obj\n    return wrapper\n\n\n\n\n@serialize(username=str,password=str,ip=str)\n@dataclass\nclass Event:\n    username:int\n    password:int\n    ip:int\n\n\nx=Event(11,33,444)\n\nprint(x.serialize())\n</code></pre>"},{"location":"python/decorators/decorators/#wrapper-coroutines","title":"wrapper coroutines","text":"<pre><code>import inspect\ndef timing(callable):\n  @wraps(callable)\n  def wrapped(*args, **kwargs):\n    start = time.time()\n    result = callable(*args, **kwargs)\n    latency = time.time() - start\n    return {\"latency\": latency, \"result\": result}\n  @wraps(callable)\n  async def wrapped_coro(*args, **kwargs):\n    start = time.time()\n    result = await callable(*args, **kwargs)\n    latency = time.time() - start\n    return {\"latency\": latency, \"result\": result}\n  if inspect.iscoroutinefunction(callable):\n  return wrapped_coro\nreturn wrapped\n</code></pre>"},{"location":"python/decorators/decorators/#extended-syntax-for-decorators","title":"extended syntax for decorators","text":"<pre><code>def _log(f, *args, **kwargs):\n    print(f\"calling {f.__qualname__!r} with {args=} and {kwargs=}\")\n    return f(*args, **kwargs)\n\n@(lambda f: lambda *args, **kwargs: _log(f, *args, **kwargs))\ndef func(x):\n  return x + 1\n</code></pre>"},{"location":"python/decorators/decorators/#same-decorator-for-function-and-class","title":"same decorator for function and class","text":"<pre><code>from functools import wraps\n\nfrom types import MethodType\n\n\nclass inject_db_driver:\n\n    def __init__(self,function):\n        self.function = function\n        wraps(self.function)(self)\n\n\n    def __call__(self,dbstring):\n        print(dbstring)\n        return self.function(lambda dbstring: dbstring)\n\n    def __get__(self, instance,owner):\n        print(\"dd\")\n        if instance is None:\n            return self\n\n        print(MethodType(self.function,instance))\n\n        return self.__class__(MethodType(self.function,instance))\n\n\n@inject_db_driver\ndef run_query(driver):\n    return \"test\"\n\n\nclass DataHandler:\n    @inject_db_driver\n    def run_query(self,driver):\n        return \"test\"\n\n\n# run_query(\"dato\")\n\nx=DataHandler()\nx.run_query(\"dato\")\n</code></pre>"},{"location":"python/decorators/decorators/#composition-over-inheritance","title":"composition over inheritance","text":"<pre><code>from dataclasses import dataclass\nclass BaseResolverMixin:\n    def __getattr__(self, attr: str):\n        if attr.startswith(\"resolve_\"):\n            *_, actual_attr = attr.partition(\"resolve_\")\n        else:\n            actual_attr = attr\n        try:\n            return self.__dict__[actual_attr]\n        except KeyError as e:\n            raise AttributeError from e\n@dataclass\nclass Customer(BaseResolverMixin):\n    customer_id: str\n    name: str\n    address: str\n\n\n\n\n#######\n\ndef _resolver_method(self, attr):\n    if attr.startswith(\"resolve_\"):\n        *_, actual_attr = attr.partition(\"resolve_\")\n    else:\n        actual_attr = attr\n    try:\n        return self.__dict__[actual_attr]\n    except KeyError as e:\n        raise AttributeError from e\n\n\n\ndef with_resolver(cls):\n    cls.__getattr__=_resolver_method\n    return cls\n\n\n@dataclass\n@with_resolver\nclass Customer(BaseResolverMixin):\n    customer_id: str\n    name: str\n    address: str\n</code></pre>"},{"location":"python/functions/","title":"Functions","text":""},{"location":"python/functions/#recursion","title":"RECURSION","text":"<p>current limit sys.getrecursionlimit() default is 1000 set limit sys.setrecursionlimit()</p>"},{"location":"python/functions/#lambda-functions","title":"LAMBDA FUNCTIONS","text":"<p><pre><code>x = 2\nf = lambda y: x * y\nx = 3\ng = lambda y: x * y\n</code></pre> print(f(10))       # --&gt; prints 30 print(g(10))       # --&gt; prints 30</p>"},{"location":"python/functions/#todo-late-binding","title":"TODO late binding","text":""},{"location":"python/functions/#inner-functions","title":"INNER FUNCTIONS","text":"<p>nonlocal cannot be used to refer to a global variable\u2014it must reference a local variable in an outer scope. Thus, if a function is assigning to a global, you should still use the global declaration</p> <p>Use of nested functions and nonlocal declarations is not a common programming style. For example, inner functions have no outside visibility, which can complicate testing and debugging. Nevertheless, nested functions are sometimes useful for breaking</p>"},{"location":"python/functions/#inspection","title":"INSPECTION","text":"<pre><code>f.__name__\nFunction name\nf.__qualname__\nFully qualified name (if nested)\nf.__module__\nName of module in which defined\nf.__doc__\nDocumentation string\nf.__annotations__\nType hints\nf.__globals__\nDictionary that is the global namespace\nf.__closure__\nClosure variables (if any)\nf.__code__\n</code></pre>"},{"location":"python/functions/#check-function-parameters","title":"CHECK  FUNCTION PARAMETERS","text":"<pre><code>import inspect\ndef func(x: int, y:float, debug=False) -&gt; float:\n    pass\nsig = inspect.signature(func)\nassert inspect.signature(func1) == inspect.signature(func2)\n</code></pre>"},{"location":"python/functions/#get-current-frame-locals","title":"GET CURRENT FRAME LOCALS","text":"<pre><code>def spam(x, y):\n    z = x + y\n    grok(z)\ndef grok(a):\n    b = a * 10\n    # outputs: {'a':5, 'b':50 }\n    print(inspect.currentframe().f_locals)\n</code></pre> <pre><code>f.f_back\nPrevious stack frame (toward the caller)\nf.f_code\nCode object being executed\nf.f_locals\nDictionary of local variables (locals())\nf.f_globals\nDictionary used for global variables (globals())\nf.f_builtins\nDictionary used for built-in names\nf.f_lineno\nLine number\nf.f_lasti\nCurrent instruction. This is an index into the bytecode string of f_code.\nf.f_trace\nFunction called at start of each source code line\n</code></pre>"},{"location":"python/modules/builtins/","title":"Builtins","text":""},{"location":"python/modules/builtins/#absx","title":"<code>abs(x)</code>","text":"<p>Returns the absolute value of <code>x</code>.</p>"},{"location":"python/modules/builtins/#alls","title":"<code>all(s)</code>","text":"<p>Returns <code>True</code> if all of the values in the iterable <code>s</code> evaluate as <code>True</code>. Returns <code>True</code> if <code>s</code> is empty.</p>"},{"location":"python/modules/builtins/#anys","title":"<code>any(s)</code>","text":"<p>Returns <code>True</code> if any of the values in the iterable <code>s</code> evaluate as <code>True</code>. Returns <code>False</code> if <code>s</code> is empty.</p>"},{"location":"python/modules/builtins/#asciix","title":"<code>ascii(x)</code>","text":"<p>Creates a printable representation of the object <code>x</code> just like the <code>repr()</code>, but only uses ASCII characters in the result. Non-ASCII characters are turned into appropriate escape sequences. This can be used to view Unicode strings in a terminal or shell that doesn\u2019t support Unicode.</p>"},{"location":"python/modules/builtins/#binx","title":"<code>bin(x)</code>","text":"<p>Returns a string with the binary representation of the integer <code>x</code>.</p>"},{"location":"python/modules/builtins/#boolx","title":"<code>bool([x])</code>","text":"<p>Type representing Boolean values <code>True</code> and <code>False</code>. If used to convert <code>x</code>, it returns <code>True</code> if <code>x</code> evaluates to true using the usual truth-testing semantics\u2014that is, nonzero number, nonempty list, and so on. Otherwise, <code>False</code> is returned. <code>False</code> is also the default value returned if <code>bool()</code> is called without any arguments. The <code>bool</code> class inherits from <code>int</code>, so the Boolean values <code>True</code> and <code>False</code> can be used as integers with values <code>1</code> and <code>0</code> in mathematical calculations.</p>"},{"location":"python/modules/builtins/#breakpoint","title":"<code>breakpoint()</code>","text":"<p>Sets a manual debugger breakpoint. When encountered, control will transfer to <code>pdb</code>, the Python debugger.</p>"},{"location":"python/modules/builtins/#bytearrayx","title":"<code>bytearray([x])</code>","text":"<p>A type representing a mutable array of bytes. When creating an instance, <code>x</code> may either be an iterable sequence of integers in the range 0 to 255, an 8-bit string or bytes literal, or an integer that specifies the size of the byte array (in which case every entry will be initialized to 0).</p>"},{"location":"python/modules/builtins/#bytearrays-encoding","title":"<code>bytearray(s, encoding)</code>","text":"<p>An alternative calling convention for creating a <code>bytearray</code> instance from characters in a string <code>s</code> where <code>encoding</code> specifies the character encoding to use in the conversion.</p>"},{"location":"python/modules/builtins/#bytesx","title":"<code>bytes([x])</code>","text":"<p>A type representing an immutable array of bytes.</p>"},{"location":"python/modules/builtins/#bytess-encoding","title":"<code>bytes(s, encoding)</code>","text":"<p>An alternate calling convention for creating bytes from a string <code>s</code> where <code>encoding</code> specifies the encoding to use in conversion.</p> <p>Table 10.1 shows operations supported by both bytes and byte arrays.</p> <p>Table 10.1: Operations on Bytes and Bytearrays</p> Operation Description <code>s + t</code> Concatenates if <code>t</code> is bytes. <code>s * n</code> Replicates if <code>n</code> is an integer. <code>s % x</code> Formats bytes. <code>x</code> is tuple. <code>s[i]</code> Returns element <code>i</code> as an integer. <code>s[i:j]</code> Returns a slice. <code>s[i:j:stride]</code> Returns an extended slice. <code>len(s)</code> Number of bytes in <code>s</code>. <code>s.capitalize()</code> Capitalizes the first character. <code>s.center(width [, pad])</code> Centers the string in a field of length <code>width</code>. <code>pad</code> is a padding character. <code>s.count(sub [, start [, end]])</code> Counts occurrences of the specified substring <code>sub</code>. <code>s.decode([encoding [, errors]])</code> Decodes a byte string into text (bytes type only). <code>s.endswith(suffix [, start [, end]])</code> Checks the end of the string for a suffix. <code>s.expandtabs([tabsize])</code> Replaces tabs with spaces. <code>s.find(sub [, start [, end]])</code> Finds the first occurrence of the specified substring <code>sub</code>. <code>s.hex()</code> Converts to a hexadecimal string. <code>s.index(sub [, start [, end]])</code> Finds the first occurrence or error in the specified substring <code>sub</code>. <code>s.isalnum()</code> Checks whether all characters are alphanumeric. <code>s.isalpha()</code> Checks whether all characters are alphabetic. <code>s.isascii()</code> Checks whether all characters are ASCII. <code>s.isdigit()</code> Checks whether all characters are digits. <code>s.islower()</code> Checks whether all characters are lowercase. <code>s.isspace()</code> Checks whether all characters are whitespace. <code>s.istitle()</code> Checks whether the string is a title-cased string (first letter of each word capitalized). <code>s.isupper()</code> Checks whether all characters are uppercase. <code>s.join(t)</code> Joins a sequence of strings <code>t</code> using a delimiter <code>s</code>. <code>s.ljust(width [, fill])</code> Left-aligns <code>s</code> in a string of size <code>width</code>. <code>fill</code> is a padding character. <code>s.lower()</code> Converts to lowercase. <code>s.lstrip([chrs])</code> Removes leading whitespace or characters supplied in <code>chrs</code>. <code>s.maketrans(x [, y [, z]])</code> Makes a translation table for <code>s.translate()</code>. <code>s.partition(sep)</code> Partitions a string based on a separator string <code>sep</code>. Returns a tuple <code>(head, sep, tail)</code> or <code>(s, '', '')</code> if <code>sep</code> isn\u2019t found. <code>s.removeprefix(prefix)</code> Returns <code>s</code> with a given prefix removed if present. <code>s.removesuffix(suffix)</code> Returns <code>s</code> with a given suffix removed if present. <code>s.replace(old, new [, maxreplace])</code> Replaces a substring. <code>s.rfind(sub [, start [, end]])</code> Finds the last occurrence of a substring. <code>s.rindex(sub [, start [, end]])</code> Finds the last occurrence or raises an error. <code>s.rjust(width [, fill])</code> Right-aligns <code>s</code> in a string of length <code>width</code>. <code>fill</code> is a padding character. <code>s.rpartition(sep)</code> Partitions <code>s</code> based on a separator <code>sep</code>, but searches from the end of the string. <code>s.rsplit([sep [, maxsplit]])</code> Splits a string from the end of the string using <code>sep</code> as a delimiter. <code>maxsplit</code> is the maximum number of splits to perform. If <code>maxsplit</code> is omitted, the result is identical to the <code>split()</code> method. <code>s.rstrip([chrs])</code> Removes trailing whitespace or characters supplied in <code>chrs</code>. <code>s.split([sep [, maxsplit]])</code> Splits a string using <code>sep</code> as a delimiter. <code>maxsplit</code> is the maximum number of splits to perform. <code>s.splitlines([keepends])</code> Splits a string into a list of lines. If <code>keepends</code> is <code>1</code>, trailing newlines are preserved. <code>s.startswith(prefix [, start [, end]])</code> Checks whether a string starts with <code>prefix</code>. <code>s.strip([chrs])</code> Removes leading and trailing whitespace or characters supplied in <code>chrs</code>. <code>s.swapcase()</code> Converts uppercase to lowercase, and vice versa. <code>s.title()</code> Returns a title-cased version of the string. <code>s.translate(table [, deletechars])</code> Translates a string using a character translation table <code>table</code>, removing characters in <code>deletechars</code>. <code>s.upper()</code> Converts a string to uppercase. <code>s.zfill(width)</code> Pads a string with zeros on the left up to the specified <code>width</code>. <p>Byte arrays additionally support the methods in Table 10.2.</p> <p>Table 10.2: Additional Operations on Byte Arrays</p> Operation Description <code>s[i] = v</code> Item assignment. <code>s[i:j] = t</code> Slice assignment. <code>s[i:j:stride] = t</code> Extended slice assignment. <code>del s[i]</code> Item deletion. <code>del s[i:j]</code> Slice deletion. <code>del s[i:j:stride]</code> Extended slice deletion. <code>s.append(x)</code> Appends a new byte to the end. <code>s.clear()</code> Clears the byte array. <code>s.copy()</code> Makes a copy. <code>s.extend(t)</code> Extends <code>s</code> with bytes from <code>t</code>. <code>s.insert(n, x)</code> Inserts byte <code>x</code> at index <code>n</code>. <code>s.pop([n])</code> Removes and returns byte at index <code>n</code>. <code>s.remove(x)</code> Removes first occurrence of byte <code>x</code>. <code>s.reverse()</code> Reverses the byte array in-place."},{"location":"python/modules/builtins/#callableobj","title":"<code>callable(obj)</code>","text":"<p>Returns <code>True</code> if <code>obj</code> is callable as a function.</p>"},{"location":"python/modules/builtins/#chrx","title":"<code>chr(x)</code>","text":"<p>Converts the integer <code>x</code> representing a Unicode code-point into a single-character string.</p>"},{"location":"python/modules/builtins/#callableobj_1","title":"callable(obj)","text":"<p>Returns True if <code>obj</code> is callable as a function.</p>"},{"location":"python/modules/builtins/#chrx_1","title":"chr(x)","text":"<p>Converts the integer <code>x</code> representing a Unicode code-point into a single-character string.</p>"},{"location":"python/modules/builtins/#classmethodfunc","title":"classmethod(func)","text":"<p>This decorator creates a class method for the function <code>func</code>. It is typically only used inside class definitions where it is implicitly invoked using <code>@classmethod</code>. Unlike a normal method, a class method receives the class as the first argument, not an instance.</p>"},{"location":"python/modules/builtins/#compilestring-filename-kind","title":"compile(string, filename, kind)","text":"<p>Compiles <code>string</code> into a code object for use with <code>exec()</code> or <code>eval()</code>. <code>string</code> is a string containing valid Python code. If this code spans multiple lines, the lines must be terminated by a single newline ('\\n') and not platform-specific variants (for example, '\\r\\n' on Windows). <code>filename</code> is a string containing the name of the file in which the string was defined (if any). <code>kind</code> is 'exec' for a sequence of statements, 'eval' for a single expression, or 'single' for a single executable statement. The resulting code object that is returned can be directly passed to <code>exec()</code> or <code>eval()</code> in place of a string.</p>"},{"location":"python/modules/builtins/#complexreal-imag","title":"complex([real [, imag]])","text":"<p>Type representing a complex number with real and imaginary components, <code>real</code> and <code>imag</code>, which can be supplied as any numeric type. If <code>imag</code> is omitted, the imaginary component is set to zero. If <code>real</code> is passed as a string, the string is parsed and converted to a complex number. In this case, <code>imag</code> should be omitted. If <code>real</code> is any other kind of object, the value of <code>real.complex()</code> is returned. If no arguments are given, <code>0j</code> is returned.</p> <p>Table 10.3: Attributes of complex</p> Attribute/Method Description <code>z.real</code> Real component <code>z.imag</code> Imaginary component <code>z.conjugate()</code> Conjugates as a complex number <p>Click here to view code image.</p>"},{"location":"python/modules/builtins/#delattrobject-attr","title":"delattr(object, attr)","text":"<p>Deletes an attribute of an object. <code>attr</code> is a string. Same as <code>del object.attr</code>.</p> <p>Click here to view code image.</p>"},{"location":"python/modules/builtins/#dictm-or-dictkey1value1-key2value2","title":"dict([m]) or dict(key1=value1, key2=value2, ...)","text":"<p>Type representing a dictionary. If no argument is given, an empty dictionary is returned. If <code>m</code> is a mapping object (such as another dictionary), a new dictionary having the same keys and same values as <code>m</code> is returned. For example, if <code>m</code> is a dictionary, <code>dict(m)</code> makes a shallow copy of it. If <code>m</code> is not a mapping, it must support iteration in which a sequence of <code>(key, value)</code> pairs is produced. These pairs are used to populate the dictionary. <code>dict()</code> can also be called with keyword arguments. For example, <code>dict(foo=3, bar=7)</code> creates the dictionary <code>{'foo': 3, 'bar': 7}</code>.</p> <p>Table 10.4: Operations on Dictionaries</p> Operation Description <code>m | n</code> Merges <code>m</code> and <code>n</code> into a single dictionary. <code>len(m)</code> Returns the number of items in <code>m</code>. <code>m[k]</code> Returns the item of <code>m</code> with key <code>k</code>. <code>m[k]=x</code> Sets <code>m[k]</code> to <code>x</code>. <code>del m[k]</code> Removes <code>m[k]</code> from <code>m</code>. <code>k in m</code> Returns <code>True</code> if <code>k</code> is a key in <code>m</code>. <code>m.clear()</code> Removes all items from <code>m</code>. <code>m.copy()</code> Makes a shallow copy of <code>m</code>. <code>m.fromkeys(s [, value])</code> Creates a new dictionary with keys from sequence <code>s</code> and values all set to <code>value</code>. <code>m.get(k [, v])</code> Returns <code>m[k]</code> if found; otherwise, returns <code>v</code>. <code>m.items()</code> Returns <code>(key, value)</code> pairs. <code>m.keys()</code> Returns the keys. <code>m.pop(k [, default])</code> Returns <code>m[k]</code> if found and removes it from <code>m</code>; otherwise, returns <code>default</code> if supplied or raises <code>KeyError</code> if not. <code>m.popitem()</code> Removes a random <code>(key, value)</code> pair from <code>m</code> and returns it as a tuple. <code>m.setdefault(k [, v])</code> Returns <code>m[k]</code> if found; otherwise, returns <code>v</code> and sets <code>m[k] = v</code>. <code>m.update(b)</code> Adds all objects from <code>b</code> to <code>m</code>. <code>m.values()</code> Returns the values."},{"location":"python/modules/builtins/#dirobject","title":"dir([object])","text":"<p>Returns a sorted list of attribute names. If <code>object</code> is a module, it contains the list of symbols defined in that module. If <code>object</code> is a type or class object, it returns a list of attribute names. The names are typically obtained from the object\u2019s <code>dict</code> attribute if defined, but other sources may be used. If no argument is given, the names in the current local symbol table are returned. It should be noted that this function is primarily used for informational purposes (for example, used interactively at the command line). It should not be used for formal program analysis because the information obtained may be incomplete. Also, user-defined classes can define a special method <code>dir()</code> that alters the result of this function.</p>"},{"location":"python/modules/builtins/#divmoda-b","title":"divmod(a, b)","text":"<p>Returns the quotient and remainder of long division as a tuple. For integers, the value <code>(a // b, a % b)</code> is returned. For floats, <code>(math.floor(a / b), a % b)</code> is returned. This function may not be called with complex numbers.</p> <p>Click here to view code image.</p>"},{"location":"python/modules/builtins/#enumerateiter-start0","title":"enumerate(iter, start=0)","text":"<p>Given an iterable object, <code>iter</code>, returns a new iterator (of type <code>enumerate</code>) that produces tuples containing a count and the value produced from <code>iter</code>. For example, if <code>iter</code> produces <code>a, b, c</code>, then <code>enumerate(iter)</code> produces <code>(0,a)</code>, <code>(1,b)</code>, <code>(2,c)</code>. The optional <code>start</code> changes the initial value of the count.</p> <p>Click here to view code image.</p>"},{"location":"python/modules/builtins/#evalexpr-globals-locals","title":"eval(expr [, globals [, locals]])","text":"<p>Evaluates an expression. <code>expr</code> is a string or a code object created by <code>compile()</code>. <code>globals</code> and <code>locals</code> are mapping objects that define the global and local namespaces, respectively, for the operation. If omitted, the expression is evaluated using the values of <code>globals()</code> and <code>locals()</code> as executed in the caller\u2019s environment. It is most common for <code>globals</code> and <code>locals</code> to be specified as dictionaries, but advanced applications can supply custom mapping objects.</p> <p>Click here to view code image.</p>"},{"location":"python/modules/builtins/#execcode-global-locals","title":"exec(code [, global [, locals]])","text":"<p>Executes Python statements. <code>code</code> is a string, bytes, or a code object created by <code>compile()</code>. <code>globals</code> and <code>locals</code> define the global and local namespaces, respectively, for the operation. If omitted, the code is executed using the values of <code>globals()</code> and <code>locals()</code> as executed in the caller\u2019s environment.</p> <p>Click here to view code image.</p>"},{"location":"python/modules/builtins/#filterfunction-iterable","title":"filter(function, iterable)","text":"<p>Creates an iterator that returns the items in <code>iterable</code> for which <code>function(item)</code> evaluates as <code>True</code>.</p>"},{"location":"python/modules/builtins/#floatx","title":"float([x])","text":"<p>Type representing a floating-point number. If <code>x</code> is a number, it is converted to a float. If <code>x</code> is a string, it is parsed into a float. For all other objects, <code>x.float()</code> is invoked. If no argument is supplied, <code>0.0</code> is returned.</p> <p>Table 10.5: Methods and Attributes of Floats</p> Attribute/Method Description <code>x.real</code> Real component when used as a complex. <code>x.imag</code> Imaginary component when used as a complex. <code>x.conjugate()</code> Conjugates as a complex number. <code>x.as_integer_ratio()</code> Converts to numerator/denominator pair. <code>x.hex()</code> Creates a hexadecimal representation. <code>x.is_integer()</code> Tests if an exact integer value. <code>float.fromhex(s)</code> Creates from a hexadecimal string. A class method."},{"location":"python/modules/builtins/#python-built-in-functions","title":"Python Built-in Functions","text":""},{"location":"python/modules/builtins/#bytessource-encoding-errors","title":"<code>bytes([source[, encoding[, errors]]])</code>","text":"<p>Constructs a new <code>bytes</code> object. The <code>source</code> parameter can be used to initialize the <code>bytes</code> object from a sequence of integers or another object that implements the buffer protocol. If <code>source</code> is specified, the encoding and errors parameters must not be specified.</p>"},{"location":"python/modules/builtins/#callableobj_2","title":"<code>callable(obj)</code>","text":"<p>Returns <code>True</code> if <code>obj</code> is callable as a function.</p>"},{"location":"python/modules/builtins/#chrx_2","title":"<code>chr(x)</code>","text":"<p>Converts the integer <code>x</code> representing a Unicode code-point into a single-character string.</p>"},{"location":"python/modules/builtins/#classmethodfunc_1","title":"<code>classmethod(func)</code>","text":"<p>This decorator creates a class method for the function <code>func</code>. It is typically only used inside class definitions where it is implicitly invoked using <code>@classmethod</code>. Unlike a normal method, a class method receives the class as the first argument, not an instance.</p>"},{"location":"python/modules/builtins/#compilestring-filename-kind_1","title":"<code>compile(string, filename, kind)</code>","text":"<p>Compiles <code>string</code> into a code object for use with <code>exec()</code> or <code>eval()</code>. <code>string</code> is a string containing valid Python code. If this code spans multiple lines, the lines must be terminated by a single newline (<code>'\\n'</code>) and not platform-specific variants (for example, <code>'\\r\\n'</code> on Windows). <code>filename</code> is a string containing the name of the file in which the string was defined (if any). <code>kind</code> is <code>'exec'</code> for a sequence of statements, <code>'eval'</code> for a single expression, or <code>'single'</code> for a single executable statement. The resulting code object that is returned can be directly passed to <code>exec()</code> or <code>eval()</code> in place of a string.</p>"},{"location":"python/modules/builtins/#complexreal-imag_1","title":"<code>complex([real [, imag]])</code>","text":"<p>Type representing a complex number with real and imaginary components, <code>real</code> and <code>imag</code>, which can be supplied as any numeric type. If <code>imag</code> is omitted, the imaginary component is set to zero. If <code>real</code> is passed as a string, the string is parsed and converted to a complex number. In this case, <code>imag</code> should be omitted. If <code>real</code> is any other kind of object, the value of <code>real.complex()</code> is returned. If no arguments are given, <code>0j</code> is returned.</p>"},{"location":"python/modules/builtins/#delattrobject-attr_1","title":"<code>delattr(object, attr)</code>","text":"<p>Deletes an attribute of an object. <code>attr</code> is a string. Same as <code>del object.attr</code>.</p>"},{"location":"python/modules/builtins/#dictm-or-dictkey1value1-key2value2_1","title":"<code>dict([m])</code> or <code>dict(key1=value1, key2=value2, ...)</code>","text":"<p>Type representing a dictionary. If no argument is given, an empty dictionary is returned. If <code>m</code> is a mapping object (such as another dictionary), a new dictionary having the same keys and same values as <code>m</code> is returned. For example, if <code>m</code> is a dictionary, <code>dict(m)</code> makes a shallow copy of it. If <code>m</code> is not a mapping, it must support iteration in which a sequence of <code>(key, value)</code> pairs is produced. These pairs are used to populate the dictionary. <code>dict()</code> can also be called with keyword arguments. For example, <code>dict(foo=3, bar=7)</code> creates the dictionary <code>{'foo': 3, 'bar': 7}</code>.</p>"},{"location":"python/modules/builtins/#dirobject_1","title":"<code>dir([object])</code>","text":"<p>Returns a sorted list of attribute names. If <code>object</code> is a module, it contains the list of symbols defined in that module. If <code>object</code> is a type or class object, it returns a list of attribute names. The names are typically obtained from the object\u2019s <code>dict</code> attribute if defined, but other sources may be used. If no argument is given, the names in the current local symbol table are returned. It should be noted that this function is primarily used for informational purposes (for example, used interactively at a Python prompt).</p>"},{"location":"python/modules/builtins/#divmodx-y","title":"<code>divmod(x, y)</code>","text":"<p>Returns a pair of numbers <code>(q, r)</code> such that <code>x = y * q + r</code>. If <code>x</code> and <code>y</code> are integers, the return value is also an integer. For example, <code>divmod(7, 3)</code> returns <code>(2, 1)</code>, where <code>2</code> is the quotient and <code>1</code> is the remainder.</p>"},{"location":"python/modules/builtins/#enumerateiterable-start","title":"<code>enumerate(iterable[, start])</code>","text":"<p>Returns an iterator that generates pairs consisting of an index and an item from the <code>iterable</code>. The <code>start</code> parameter is an optional integer that specifies the starting value of the index. By default, it is <code>0</code>.</p>"},{"location":"python/modules/builtins/#evalexpression-globals-locals","title":"<code>eval(expression[, globals[, locals]])</code>","text":"<p>Evaluates the <code>expression</code> in the given <code>globals</code> and <code>locals</code> namespaces. <code>expression</code> can be a string or a code object. If <code>globals</code> is specified, it must be a dictionary. If <code>locals</code> is specified, it can be any mapping object. If both <code>globals</code> and <code>locals</code> are omitted, the expression is evaluated in the context of the current global and local namespaces.</p>"},{"location":"python/modules/builtins/#execobject-globals-locals","title":"<code>exec(object[, globals[, locals]])</code>","text":"<p>Evaluates the <code>object</code> as a Python expression or statement. <code>object</code> can be a string or a code object. If <code>globals</code> is specified, it must be a dictionary. If <code>locals</code> is specified, it can be any mapping object. If both <code>globals</code> and <code>locals</code> are omitted, the code is executed in the context of the current global and local namespaces.</p>"},{"location":"python/modules/builtins/#filterfunction-iterable_1","title":"<code>filter(function, iterable)</code>","text":"<p>Creates an iterator that produces the values from <code>iterable</code> for which <code>function</code> returns <code>True</code>. If <code>function</code> is <code>None</code>, the <code>identity</code> function is assumed, which returns <code>True</code> for all elements of the iterable. If <code>iterable</code> is a string, the resulting iterator produces the individual characters of the string.</p>"},{"location":"python/modules/builtins/#floatx_1","title":"<code>float([x])</code>","text":"<p>Type representing a floating-point number. If no argument is given, <code>0.0</code> is returned. If <code>x</code> is a number, it is converted to a floating-point number. If <code>x</code> is a string, it is parsed and converted to a floating-point number.</p>"},{"location":"python/modules/builtins/#formatvalue-format_spec","title":"<code>format(value[, format_spec])</code>","text":"<p>Converts <code>value</code> to a formatted string according to the format specification string in <code>format_spec</code>. This operation invokes <code>value.format()</code>, which is free to interpret the format specification as it sees fit. For simple types of data, the format specifier typically includes an alignment character of <code>&lt;</code>, <code>&gt;</code>, or <code>^</code>, a number (which indicates the field width), and a character code of <code>d</code>, <code>f</code>, or <code>s</code> for integer, floating point, or string values, respectively. For example, a format specification of <code>'d'</code> formats an integer, a specification of <code>'8d'</code> right-aligns an integer in an 8-character field, and <code>'&lt;8d'</code> left-aligns an integer in an 8-character field. More details on <code>format()</code> and format specifiers can be found in Chapter 9.</p>"},{"location":"python/modules/builtins/#frozensetiterable","title":"<code>frozenset([iterable])</code>","text":"<p>Type representing an immutable set object populated with values taken from <code>iterable</code>. The values must also be immutable. If no argument is given, an empty set is returned. A <code>frozenset</code> supports all of the operations found on sets except for any operations that mutate a set in-place.</p>"},{"location":"python/modules/builtins/#getattrobject-name-default","title":"<code>getattr(object, name[, default])</code>","text":"<p>Returns the value of a named attribute of an object. <code>name</code> is a string containing the attribute name. <code>default</code> is an optional value to return if no such attribute exists;</p> <p>Table 10.8 shows operations on sets.</p> <p>Table 10.8 Set Operations and Methods</p> <p>Operation</p> <p>Description</p> <p>s | t</p> <p>Union</p> <p>s &amp; t</p> <p>Intersection</p> <p>s - t</p> <p>Difference</p> <p>s ^ t</p> <p>Symmetric difference</p> <p>len(s)</p> <p>Returns number of items in s.</p> <p>s.add(item)</p> <p>Adds item to s. Has no effect if item is already in s.</p> <p>s.clear()</p> <p>Removes all items from s.</p> <p>s.copy()</p> <p>Makes a copy of s.</p> <p>s.difference(t)</p> <p>Set difference. Returns all the items in s, but not in t.</p> <p>s.difference_update(t)</p> <p>Removes all the items from s that are also in t.</p> <p>s.discard(item)</p> <p>Removes item from s. If item is not a member of s, nothing happens.</p> <p>s.intersection(t)</p> <p>Intersection. Returns all the items that are both in s and in t.</p> <p>s.intersection_update(t)</p> <p>Computes the intersection of s and t and leaves the result in s.</p> <p>s.isdisjoint(t)</p> <p>Returns True if s and t have no items in common.</p> <p>s.issubset(t)</p> <p>Returns True if s is a subset of t.</p> <p>s.issuperset(t)</p> <p>Returns True if s is a superset of t.</p> <p>s.pop()</p> <p>Returns an arbitrary set element and removes it from s.</p> <p>s.remove(item)</p> <p>Removes item from s. If item is not a member, KeyError is raised.</p> <p>s.symmetric_difference(t)</p> <p>Symmetric difference. Returns all the items that are in s or t, but not in both sets.</p> <p>s.symmetric_difference_update(t)</p> <p>Computes the symmetric difference of s and t and leaves the result in s.</p> <p>s.union(t)</p> <p>Union. Returns all items in s or t.</p> <p>s.update(t)</p> <p>Adds all the items in t to s. t may be another set, a sequence, or any object that supports iteration.</p> <p>Click here to view code image</p> <p>setattr(object, name, value) Sets an attribute of an object. name is a string. Same as object.name = value.</p> <p>Click here to view code image</p> <p>slice([start,] stop [, step]) Returns a slice object representing integers in the specified range. Slice objects are also generated by the extended slice syntax a[i:i:k].</p> <p>Click here to view code image</p> <p>sorted(iterable, *, key=keyfunc, reverse=reverseflag) Creates a sorted list from items in iterable. The keyword argument key is a single-argument function that transforms values before they are compared. The keyword argument reverse is a Boolean flag that specifies whether or not the resulting list is sorted in reverse order. The key and reverse arguments must be specified using keywords\u2014for example, sorted(a, key=get_name).</p> <p>staticmethod(func) Creates a static method for use in classes. This function is usually used as a @staticmethod decorator.</p> <p>str([object]) Type representing a string. If object is supplied, a string representation of its value is created by calling its str() method. This is the same string that you see when you print the object. If no argument is given, an empty string is created.</p> <p>Table 10.9 shows methods defined on strings.</p> <p>Table 10.9 String Operators and Methods</p> <p>Operation</p> <p>Description</p> <p>s + t</p> <p>Concatenates strings if t is a string.</p> <p>s * n</p> <p>Replicates a string if n is an integer.</p> <p>s % x</p> <p>Formats a string. x is tuple.</p> <p>s[i]</p> <p>Returns element i of a string.</p> <p>s[i:j]</p> <p>Returns a slice.</p> <p>s[i:j:stride]</p> <p>Returns an extended slice.</p> <p>len(s)</p> <p>Number of elements in s.</p> <p>s.capitalize()</p> <p>Capitalizes the first character.</p> <p>s.casefold()</p> <p>Converts s to a string usable for a caseless comparison.</p> <p>s.center(width [, pad])</p> <p>Centers the string in a field of length width. pad is a padding character.</p> <p>s.count(sub [, start [, end]])</p> <p>Counts occurrences of the specified substring sub.</p> <p>s.decode([encoding [, errors]])</p> <p>Decodes a byte string into text (bytes type only).</p> <p>s.encode([encoding [, errors]])</p> <p>Returns an encoded version of the string (str type only).</p> <p>s.endswith(suffix [, start [, end]])</p> <p>Checks the end of the string for a suffix.</p> <p>s.expandtabs([tabsize])</p> <p>Replaces tabs with spaces.</p> <p>s.find(sub [, start [, end]])</p> <p>Finds the first occurrence of the specified substring sub.</p> <p>s.format(args, *kwargs)</p> <p>Formats s (str type only).</p> <p>s.format_map(m)</p> <p>Formats s with substitutions taking from the mapping m (str type only).</p> <p>s.index(sub [, start [, end]])</p> <p>Finds the first occurrence or error in the specified substring sub.</p> <p>s.isalnum()</p> <p>Checks whether all characters are alphanumeric.</p> <p>s.isalpha()</p> <p>Checks whether all characters are alphabetic.</p> <p>s.isascii()</p> <p>Checks whether all characters are ASCII.</p> <p>s.isdecimal()</p> <p>Checks whether all characters are decimal characters. Does not match superscript, subscripts, or other special digits.</p> <p>s.isdigit()</p> <p>Checks whether all characters are digits. Matches superscripts and superscripts, but not vulgar fractions.</p> <p>s.isidentifier()</p> <p>Checks whether s is a valid Python identifier.</p> <p>s.islower()</p> <p>Checks whether all characters are lowercase.</p> <p>s.isnumeric()</p> <p>Checks whether all characters are numeric. Matches all forms of numeric characters such as vulgar fractions, Roman numerals, etc.</p> <p>s.isprintable()</p> <p>Checks whether all characters are printable.</p> <p>s.isspace()</p> <p>Checks whether all characters are whitespace.</p> <p>s.istitle()</p> <p>Checks whether the string is a title-cased string (first letter of each word capitalized).</p> <p>s.isupper()</p> <p>Checks whether all characters are uppercase.</p> <p>s.join(t)</p> <p>Joins a sequence of strings t using a delimiter s.</p> <p>s.ljust(width [, fill])</p> <p>Left-aligns s in a string of size width.</p> <p>s.lower()</p> <p>Converts to lowercase.</p> <p>s.lstrip([chrs])</p> <p>Removes leading whitespace or characters supplied in chrs.</p> <p>s.maketrans(x [, y [, z]])</p> <p>Makes a translation table for s.translate().</p> <p>s.partition(sep)</p> <p>Partitions a string based on a separator string sep. Returns a tuple (head, sep, tail) or (s, '', '') if sep isn\u2019t found.</p> <p>s.removeprefix(prefix)</p> <p>Returns s with a given prefix removed if present.</p> <p>s.removesuffix(suffix)</p> <p>Returns s with a given suffix removed if present.</p> <p>s.replace(old, new [, maxreplace])</p> <p>Replaces a substring.</p> <p>s.rfind(sub [, start [, end]])</p> <p>Finds the last occurrence of a substring.</p> <p>s.rindex(sub [, start [, end]])</p> <p>Finds the last occurrence or raises an error.</p> <p>s.rjust(width [, fill])</p> <p>Right-aligns s in a string of length width.</p> <p>s.rpartition(sep)</p> <p>Partitions s based on a separator sep, but searches from the end of the string.</p> <p>s.rsplit([sep [, maxsplit]])</p> <p>Splits a string from the end of the string using sep as a delimiter. maxsplit is the maximum number of splits to perform. If maxsplit is omitted, the result is identical to the split() method.</p> <p>s.rstrip([chrs])</p> <p>Removes trailing whitespace or characters supplied in chrs.</p> <p>s.split([sep [, maxsplit]])</p> <p>Splits a string using sep as a delimiter. maxsplit is the maximum number of splits to perform.</p> <p>s.splitlines([keepends])</p> <p>Splits a string into a list of lines. If keepends is 1, trailing newlines are preserved.</p> <p>s.startswith(prefix [, start [, end]])</p> <p>Checks whether a string starts with a prefix.</p> <p>s.strip([chrs])</p> <p>Removes leading and trailing whitespace or characters supplied in chrs.</p> <p>s.swapcase()</p> <p>Converts uppercase to lowercase, and vice versa.</p> <p>s.title()</p> <p>Returns a title-cased version of the string.</p> <p>s.translate(table [, deletechars])</p> <p>Translates a string using a character translation table table, removing characters in deletechars.</p> <p>s.upper()</p> <p>Converts a string to uppercase.</p> <p>s.zfill(width)</p> <p>Pads a string with zeros on the left up to the specified width.</p> <p>sum(items [,initial]) Computes the sum of a sequence of items taken from the iterable object items. initial provides the starting value and defaults to 0. This function usually only works with numbers.</p> <p>super() Returns an object that represents the collective superclasses of the class in which its used. The primary purpose of this object is to invoke methods in base classes. Here\u2019s an example:</p> <p>Click here to view code image</p> <p>class B(A): def foo(self): super().foo() # Invoke foo() defined by superclasses.</p> <p>tuple([items]) Type representing a tuple. If supplied, items is an iterable object that is used to populate the tuple. However, if items is already a tuple, it\u2019s returned unmodified. If no argument is given, an empty tuple is returned.</p> <p>Table 10.10 shows methods defined on tuples.</p> <p>Table 10.10 Tuple Operators and Methods</p> <p>Operation</p> <p>Description</p> <p>s + t</p> <p>Concatenation if t is a list.</p> <p>s * n</p> <p>Replication if n is an integer.</p> <p>s[i]</p> <p>Returns element i of a s.</p> <p>s[i:j]</p> <p>Returns a slice.</p> <p>s[i:j:stride]</p> <p>Returns an extended slice.</p> <p>len(s)</p> <p>Number of elements in s.</p> <p>s.append(x)</p> <p>Appends a new element, x, to the end of s.</p> <p>s.count(x)</p> <p>Counts occurrences of x in s.</p> <p>s.index(x [, start [, stop]])</p> <p>Returns the smallest i where s[i] == x. start and stop optionally specify the starting and ending index for the search.</p> <p>type(object) The base class of all types in Python. When called as a function, returns the type of object. This type is the same as the object\u2019s class. For common types such as integers, floats, and lists, the type will refer to one of the other built-in classes such as int, float, list, and so forth. For user-defined objects, the type is the associated class. For objects related to Python\u2019s internals, you will typically get a reference to one of the classes defined in the types module.</p> <p>vars([object]) Returns the symbol table of object (usually found in its dict attribute). If no argument is given, a dictionary corresponding to the local namespace is returned. The dictionary returned by this function should be assumed to be read-only. It\u2019s not safe to modify its contents.</p> <p>zip([s1 [, s2 [, ... ]]]) Creates an iterator that produces tuples containing one item each from s1, s2, and so on. The nth tuple is (s1[n], s2[n], ... ). The resulting iterator stops when the shortest input is exhausted. If no arguments are given, the iterator produces no values.</p> <p>10.2 Built-in Exceptions This section describes the built-in exceptions used to report different kinds of errors.</p> <p>10.2.1 Exception Base Classes The following exceptions serve as base classes for all the other exceptions:</p> <p>BaseException The root class for all exceptions. All built-in exceptions are derived from this class.</p> <p>Exception The base class for all program-related exceptions. That includes all built-in exceptions except for SystemExit, GeneratorExit, and KeyboardInterrupt. User-defined exceptions should inherit from Exception.</p> <p>ArithmeticError The base class for arithmetic exceptions, including OverflowError, ZeroDivisionError, and FloatingPointError.</p> <p>LookupError The base class for indexing and key errors, including IndexError and KeyError.</p> <p>EnvironmentError The base class for errors that occur outside Python. Is a synonym for OSError.</p> <p>The preceding exceptions are never raised explicitly. However, they can be used to catch certain classes of errors. For instance, the following code would catch any sort of numerical error:</p> <p>Click here to view code image</p> <p>try: # Some operation ... except ArithmeticError as e: # Math error 10.2.2 Exception Attributes Instances of an exception e have a few standard attributes that can be useful to inspect and/or manipulate it in certain applications.</p> <p>e.args The tuple of arguments supplied when raising the exception. In most cases, this is a one-item tuple with a string describing the error. For EnvironmentError exceptions, the value is a 2-tuple or 3-tuple containing an integer error number, string error message, and an optional filename. The contents of this tuple might be useful if you need to recreate the exception in a different context\u2014for example, to raise an exception in a different Python interpreter process.</p> <p>e.cause Previous exception when using explicit chained exceptions.</p> <p>e.context Previous exception for implicitly chained exceptions.</p> <p>e.traceback Traceback object associated with the exception.</p> <p>10.2.3 Predefined Exception Classes The following exceptions are raised by programs:</p> <p>AssertionError Failed assert statement.</p> <p>AttributeError Failed attribute reference or assignment.</p> <p>BufferError Memory buffer expected.</p> <p>EOFError End of file. Generated by the built-in functions input() and raw_input(). It should be noted that most other I/O operations such as the read() and readline() methods of files return an empty string to signal EOF instead of raising an exception.</p> <p>FloatingPointError Failed floating-point operation. It should be noted that floating-point exception handling is a tricky problem and this exception only gets raised if Python has been configured and built in a way that enables it. It is more common for floating-point errors to silently produce results such as float('nan') or float('inf'). A subclass of ArithmeticError.</p> <p>GeneratorExit Raised inside a generator function to signal termination. This happens when a generator is destroyed prematurely (before all generator values are consumed) or the close() method of a generator is called. If a generator ignores this exception, the generator is terminated, and the exception is silently ignored.</p> <p>IOError Failed I/O operation. The value is an IOError instance with the attributes errno, strerror, and filename. errno is an integer error number, strerror is a string error message, and filename is an optional filename. A subclass of EnvironmentError.</p> <p>ImportError Raised when an import statement can\u2019t find a module or when from can\u2019t find a name in a module.</p> <p>IndentationError Indentation error. A subclass of SyntaxError.</p> <p>IndexError Sequence subscript out of range. A subclass of LookupError.</p> <p>KeyError Key not found in a mapping. A subclass of LookupError.</p> <p>KeyboardInterrupt Raised when the user hits the interrupt key (usually Ctrl+C).</p> <p>MemoryError Recoverable out-of-memory error.</p> <p>ModuleNotFoundError Module can\u2019t be found by the import statement.</p> <p>NameError Name not found in local or global namespaces.</p> <p>NotImplementedError Unimplemented feature. Can be raised by base classes that require derived classes to implement certain methods. A subclass of RuntimeError.</p> <p>OSError Operating system error. Primarily raised by functions in the os module. The following exceptions are subclasses: BlockingIOError, BrokenPipeError, ChildProcessError, ConnectionAbortedError, ConnectionError, ConnectionRefusedError, ConnectionResetError, FileExistsError, FileNotFoundError, InterruptedError, IsADirectoryError, NotADirectoryError, PermissionError, ProcessLookupError, TimeoutError.</p> <p>OverflowError Result of an integer value being too large to be represented. This exception usually only arises if large integer values are passed to objects that internally rely upon fixed-precision machine integers in their implementation. For example, this error can arise with range or xrange objects if you specify starting or ending values that exceed 32 bits in size. A subclass of ArithmeticError.</p> <p>RecursionError Recursion limit exceeded.</p> <p>ReferenceError Result of accessing a weak reference after the underlying object has been destroyed (see the weakref module).</p> <p>RuntimeError A generic error not covered by any of the other categories.</p> <p>StopIteration Raised to signal the end of iteration. This normally happens in the next() method of an object or in a generator function.</p> <p>StopAsyncIteration Raised to signal the end of asynchronous iteration. Only applicable in the context of async functions and generators.</p> <p>SyntaxError Parser syntax error. Instances have the attributes filename, lineno, offset, and text, which can be used to gather more information.</p> <p>SystemError Internal error in the interpreter. The value is a string indicating the problem.</p> <p>SystemExit Raised by the sys.exit() function. The value is an integer indicating the return code. If it\u2019s necessary to exit immediately, os._exit() can be used.</p> <p>TabError Inconsistent tab usage. Generated when Python is run with the -tt option. A subclass of SyntaxError.</p> <p>TypeError Occurs when an operation or function is applied to an object of an inappropriate type.</p> <p>UnboundLocalError Unbound local variable referenced. This error occurs if a variable is referenced before it\u2019s defined in a function. A subclass of NameError.</p> <p>UnicodeError Unicode encoding or decoding error. A subclass of ValueError. The following exceptions are subclasses: UnicodeEncodeError, UnicodeDecodeError, UnicodeTranslateError.</p> <p>ValueError Generated when the argument to a function or operation is the right type but an inappropriate value.</p> <p>WindowsError Generated by failed system calls on Windows. A subclass of OSError.</p> <p>ZeroDivisionError Dividing by zero. A subclass of ArithmeticError.</p> <p>10.3 Standard Library Python comes with a sizable standard library. Many of these modules have been previously described in the book. Reference material can be found at https://docs.python.org/library. That material is not repeated here.</p> <p>The modules listed below are notable because they are generally useful for a wide variety of applications and for Python programming in general.</p> <p>10.3.1 collections Module The collections module supplements Python with a variety of additional container objects that can be quite useful for working with data\u2014such as a double-ended queue (deque), dictionaries that automatically initialize missing items (defaultdict), and counters for tabulation (Counter).</p> <p>10.3.2 datetime Module The datetime module is where you find functions related to dates, times, and computations involving those things.</p> <p>10.3.3 itertools Module The itertools module provides a variety of useful iteration patterns\u2014chaining iterables together, iterating over product sets, permutations, grouping, and similar operations.</p> <p>10.3.4 inspect Module The inspect module provides functions for inspecting the internals of code-related elements such as functions, classes, generators, and coroutines. It\u2019s commonly used in metaprogramming by functions that define decorators and similar features.</p> <p>10.3.5 math Module The math module provides common mathematical functions such as sqrt(), cos(), and sin().</p> <p>10.3.6 os Module The os module is where you find low-level functions related to the host operating system\u2014processes, files, pipes, permissions, and similar features.</p> <p>10.3.7 random Module The random module provides various functions related to random number generation.</p> <p>10.3.8 re Module The re module provides support for working with text via regular expression pattern matching.</p> <p>10.3.9 shutil Module The shutil module has functions for performing common tasks related to the shell, such as copying files and directories.</p> <p>10.3.10 statistics Module The statistics module provides functions for computing common statistical values such as means, medians, and standard deviation.</p> <p>10.3.11 sys Module The sys module contains a variety of attributes and methods related to the runtime environment of Python itself. This includes command-line options, standard I/O streams, the import path, and similar features.</p> <p>10.3.12 time Module The time module is where you find various functions related to system time, such as getting the value of the system clock, sleeping, and the number of elapsed CPU seconds.</p> <p>10.3.13 turtle Module Turtle graphics. You know, for kids.</p> <p>10.3.14 unittest Module The unittest module provides built-in support for writing unit tests. Python itself is tested using unittest. However, many programmers prefer using third-party libraries such as pytest for testing. This author concurs.</p>"},{"location":"python/modules/io/","title":"IO","text":"<p>data representation</p>"},{"location":"python/modules/io/#specify-a-bytes-literal-note-b-prefix","title":"Specify a bytes literal (note: b' prefix)","text":"<p>a = b'hello'</p>"},{"location":"python/modules/io/#specify-bytes-from-a-list-of-integers","title":"Specify bytes from a list of integers","text":"<p>b = bytes([0x68, 0x65, 0x6c, 0x6c, 0x6f])</p>"},{"location":"python/modules/io/#create-and-populate-a-bytearray-from-parts","title":"Create and populate a bytearray from parts","text":"<p>c = bytearray() c.extend(b'world')   # d = 'world' c.append(0x21)       # d = 'world!'</p>"},{"location":"python/modules/io/#access-byte-values","title":"Access byte values","text":"<p>print(a[0])     # --&gt; prints 104</p> <p>for x in b:     # Outputs 104 101 108 108 111    print(x)</p> <p>a = b'hello'     # bytes b = 'hello'      # text c = 'world'      # text</p> <p>print(a == b)    # -&gt; False d = a + c        # TypeError: can't concat str to bytes e = b + c        # -&gt; 'helloworld' (both are strings)</p> <p>text encoding and decoding</p> <p>a = 'hello'             # Text b = a.encode('utf-8')   # Encode to bytes</p> <p>c = b'world'            # Bytes d = c.decode('utf-8')   # Decode to text</p> <p>'ascii'</p> <p>Character values in the range [0x00, 0x7f].</p> <p>'latin1'</p> <p>Character values in the range [0x00, 0xff]. Also known as 'iso-8859-1'.</p> <p>'utf-8'</p> <p>Variable-length encoding that allows all Unicode characters to be represented.</p> <p>'cp1252'</p> <p>A common text encoding on Windows.</p> <p>'macroman'</p> <p>A common text encoding on Macintosh.</p> <p>text and byte formatting</p> <p>x = 123.456 format(x, '0.2f')       # '123.46' format(x, '10.4f')      # '  123.4560' format(x, '&lt;10.2f')    # '123.46***'</p> <p>name = 'Elwood' r = format(name, '&lt;10')     # r = 'Elwood    ' r = format(name, '&gt;10')     # r = '    Elwood' r = format(name, '^10')     # r = '  Elwood  ' r = format(name, '^10')    # r = 'Elwood*'</p> <p>d</p> <p>Decimal integer or long integer.</p> <p>b</p> <p>Binary integer or long integer.</p> <p>o</p> <p>Octal integer or long integer.</p> <p>x</p> <p>Hexadecimal integer or long integer.</p> <p>X</p> <p>Hexadecimal integer (uppercase letters).</p> <p>f, F</p> <p>Floating point as [-]m.dddddd.</p> <p>e</p> <p>Floating point as [-]m.dddddde\u00b1xx.</p> <p>E</p> <p>Floating point as [-]m.ddddddE\u00b1xx.</p> <p>g, G</p> <p>Use e or E for exponents less than [nd]4 or greater than the precision; otherwise use f.</p> <p>n</p> <p>Same as g except that the current locale setting determines the decimal point character.</p> <p>%</p> <p>Multiplies a number by 100 and displays it using f format followed by a % sign.</p> <p>s</p> <p>String or any object. The formatting code uses str() to generate strings.</p> <p>c</p> <p>Single character.</p> <p>x = 42 r = format(x, '10d')        # r = '        42' r = format(x, '10x')        # r = '        2a' r = format(x, '10b')        # r = '    101010' r = format(x, '010b')       # r = '0000101010'</p> <p>y = 3.1415926 r = format(y, '10.2f')      # r = '      3.14' r = format(y, '10.2e')      # r = '  3.14e+00' r = format(y, '+10.2f')     # r = '     +3.14' r = format(y, '+010.2f')    # r = '+000003.14' r = format(y, '+10.2%')     # r = '  +314.16%'</p> <p>f'Value is {x:0.2f}'        # 'Value is 123.46' f'Value is {x:10.4f}'       # 'Value is   123.4560' f'Value is {2x:&lt;10.2f}'   # 'Value is 246.91****'</p> <p>f'{x!r:spec}'      # Calls (repr(x).format('spec')) f'{x!s:spec}'      # Calls (str(x).format('spec'))</p> <p>'Value is {:0.2f}' .format(x)            # 'Value is 123.46' 'Value is {0:10.2f}' .format(x)          # 'Value is   123.4560' 'Value is {val:&lt;10.2f}' .format(val=x)  # 'Value is 123.46***'</p> <p>Unlike f-strings, the arg value of a specifier cannot be an arbitrary expression, so it\u2019s not quite as expressive. However, the format() method can perform limited attribute lookup, indexing, and nested substitutions. For example:</p> <p>y = 3.1415926 width = 8 precision=3</p> <p>r = 'Value is {0:{1}.{2}f}'.format(y, width, precision)</p> <p>d = {    'name': 'IBM',    'shares': 50,    'price': 490.1 } r = '{0[shares]:d} shares of {0[name]} at {0[price]:0.2f}'.format(d)</p>"},{"location":"python/modules/io/#r-50-shares-of-ibm-at-49010","title":"r = '50 shares of IBM at 490.10'","text":"<p>command line arguments</p> <p>def main(argv):     if len(argv) != 3:         raise SystemExit(               f'Usage : python {argv[0]} inputfile outputfile\\n')     inputfile  = argv[1]     outputfile = argv[2]     ...</p> <p>if name == 'main':     import sys     main(sys.argv)</p> <p>import argparse</p> <p>def main(argv):     p = argparse.ArgumentParser(description='This is some program')</p> <pre><code># A positional argument\np.add_argument('infile')\n\n# An option taking an argument\np.add_argument('-o','--output', action='store')\n\n# An option that sets a boolean flag\np.add_argument('-d','--debug', action='store_true', default=False)\n\n# Parse the command line\nargs = p.parse_args(args=argv)\n\n# Retrieve the option settings\ninfile    = args.infile\noutput    = args.output\ndebugmode = args.debug\n\nprint(infile, output, debugmode)\n</code></pre> <p>if name == 'main':     import sys     main(sys.argv[1:])</p> <p>env variables</p> <p>import os path = os.environ['PATH'] user = os.environ['USER'] editor = os.environ['EDITOR'] val = os.environ['SOMEVAR']</p> <p>buffering</p> <p>By default, files are opened with I/O buffering enabled. With I/O buffering, I/O operations are performed in larger chunks to avoid excessive system calls. For example, write operations would start filling an internal memory buffer and output would only actually occur when the buffer is filled up. This behavior can be changed by giving a buffering argument to open(). For example</p> <p>with open('data.bin', 'wb', buffering=0) as file:     file.write(data)     file.write(data)     file.write(data)     file.flush()       # Make sure all data is written from buffers</p> <p>text mode enxoding</p> <p>with open('file.txt', 'rt',           encoding='utf-8', errors='replace') as file:     data = file.read()</p> <p>newline</p> <p>With text files, one complication is the encoding of newline characters. Newlines are encoded as '\\n', '\\r\\n', or '\\r' depending on the host operating system\u2014for example, '\\n' on UNIX and '\\r\\n' on Windows. By default, Python translates all of these line endings to a standard '\\n' character when reading. On writing, newline characters are translated back to the default line ending used on the system. The behavior is sometimes referred to as \u201cuniversal newline mode\u201d in Python documentation.</p> <p>file = open('somefile.txt', 'rt', newline='\\r\\n')</p> <p>behind in scenes</p> <p>The open() function serves as a kind of high-level factory function for creating instances of different I/O classes. These classes embody the different file modes, encodings, and buffering behaviors. They are also composed together in layers. The following classes are defined in the io module:</p> <p>Click here to view code image</p> <p>FileIO(filename, mode='r', closefd=True, opener=None) Opens a file for raw unbuffered binary I/O. filename is any valid filename accepted by the open() function. Other arguments have the same meaning as for open().</p> <p>Click here to view code image</p> <p>BufferedReader(file [, buffer_size]) BufferedWriter(file [, buffer_size]) BufferedRandom(file,[, buffer_size]) Implements a buffered binary I/O layer for a file. file is an instance of FileIO. buffer_size specifies the internal buffer size to use. The choice of class depends on whether or not the file is reading, writing, or updating data. The optional buffer_size argument specifies the internal buffer size used.</p> <p>Click here to view code image</p> <p>TextIOWrapper(buffered, [encoding, [errors [, newline [, line_buffering [, write_through]]]]]) Implements text mode I/O. buffered is a buffered binary mode file, such as BufferedReader or BufferedWriter. The encoding, errors, and newline arguments have the same meaning as for open(). line_buffering is a Boolean flag that forces I/O to be flushed on newline characters (False by default). write_through is a Boolean flag that forces all writes to be flushed (False by default).</p> <p>Here is an example that shows how a text-mode file is constructed, layer-by-layer:</p> <p>Click here to view code image</p> <pre><code>        raw = io.FileIO('filename.txt', 'r') # Raw-binary mode buffer = io.BufferedReader(raw) # Binary buffered reader file = io.TextIOWrapper(buffer, encoding='utf-8') # Text mode\n</code></pre> <p>file methods</p> <p>f.readable()</p> <p>Returns True if file can be read.</p> <p>f.read([n])</p> <p>Reads at most n bytes.</p> <p>f.readline([n])</p> <p>Reads a single line of input up to n characters. If n is omitted, this method reads the entire line.</p> <p>f.readlines([size])</p> <p>Reads all the lines and returns a list. size optionally specifies the approximate number of characters to read on the file before stopping.</p> <p>f.readinto(buffer)</p> <p>Reads data into a memory buffer.</p> <p>f.writable()</p> <p>Returns True if file can be written.</p> <p>f.write(s)</p> <p>Writes string s.</p> <p>f.writelines(lines)</p> <p>Writes all strings in iterable lines.</p> <p>f.close()</p> <p>Closes the file.</p> <p>f.seekable()</p> <p>Returns True if file supports random-access seeking.</p> <p>f.tell()</p> <p>Returns the current file pointer.</p> <p>f.seek(offset [, where])</p> <p>Seeks to a new file position.</p> <p>f.isatty()</p> <p>Returns True if f is an interactive terminal.</p> <p>f.flush()</p> <p>Flushes the output buffers.</p> <p>f.truncate([size])</p> <p>Truncates the file to at most size bytes.</p> <p>f.fileno()</p> <p>Returns an integer file descriptor. file attributes</p> <p>f.closed</p> <p>Boolean value indicates the file state: False if the file is open, True if closed.</p> <p>f.mode</p> <p>The I/O mode for the file.</p> <p>f.name</p> <p>Name of the file if created using open(). Otherwise, it will be a string indicating the source of the file.</p> <p>f.newlines</p> <p>The newline representation actually found in the file. The value is either None if no newlines have been encountered, a string containing '\\n', '\\r', or '\\r\\n', or a tuple containing all the different newline encodings seen.</p> <p>f.encoding</p> <p>A string that indicates file encoding, if any (for example, 'latin-1' or 'utf-8'). The value is None if no encoding is being used.</p> <p>f.errors</p> <p>The error handling policy.</p> <p>f.write_through</p> <p>Boolean value indicating if writes on a text file pass data directly to the underlying binary level file without buffering. stdin, stdout, stderr</p> <p>import sys sys.stdout.write('Enter your name : ') name = sys.stdin.readline()</p> <p>If necessary, the values of sys.stdout, sys.stdin, and sys.stderr can be replaced with other file objects, in which case the print() and input() functions will use the new values. Should it ever be necessary to restore the original value of sys.stdout, it should be saved first. The original values of sys.stdout, sys.stdin, and sys.stderr at interpreter startup are also available in sys.stdout, sys.stdin, and sys.stderr, respectively.</p> <p>directories</p> <p>import os</p> <p>names = os.listdir('dirname') for name in names:     print(name)</p> <p>print</p> <p>print('The values are', x, y, z)</p>"},{"location":"python/modules/io/#suppress-the-newline","title":"Suppress the newline","text":"<p>print('The values are', x, y, z, end='') To redirect the output to a file, use the file keyword argument:</p>"},{"location":"python/modules/io/#redirect-to-file-object-f","title":"Redirect to file object f","text":"<p>print('The values are', x, y, z, file=f) To change the separator character between items, use the sep keyword argument:</p>"},{"location":"python/modules/io/#put-commas-between-the-values","title":"Put commas between the values","text":"<p>print('The values are', x, y, z, sep=',')</p> <p>consume input</p> <p>use advance generator for io</p> <p>def line_receiver():     data = bytearray()     line = None     linecount = 0     while True:         part = yield line         linecount += part.count(b'\\n')         data.extend(part)         if linecount &gt; 0:             index = data.index(b'\\n')             line = bytes(data[:index+1])             data = data[index+1:]             linecount -= 1         else:             line = None</p> <p>r = line_receiver() r.send(None)    # Necessary first step r.send(b'hello') r.send(b'world\\nit ') b'hello world\\n' r.send(b'works!') r.send(b'\\n') b'it works!\\n'' </p> <p>An interesting side effect of this approach is that it externalizes the actual I/O operations that must be performed to get the input data. Specifically, the implementation of line_receiver() contains no I/O operations at all! This means that it could be used in different contexts. For example, with sockets:</p> <p>r = line_receiver() data = None while True:     while not (line:=r.send(data)):         data = sock.recv(8192)</p> <pre><code># Process the line\n...\n</code></pre> <p>r = line_receiver() data = None while True:     while not (line:=r.send(data)):         data = file.read(10000)</p> <pre><code># Process the line\n...\n</code></pre> <p>async def reader(ch):     r = line_receiver()     data = None     while True:         while not (line:=r.send(data)):             data = await ch.receive(8192)</p> <p>object serializations</p> <p>Sometimes it\u2019s necessary to serialize the representation of an object so it can be transmitted over the network, saved to a file, or stored in a database. One way to do this is to convert data into a standard encoding such as JSON or XML. There is also a common Python-specific data serialization format called Pickle.</p> <p>The pickle module serializes an object into a stream of bytes that can be used to reconstruct the object at a later point in time. The interface to pickle is simple, consisting of two operations, dump() and load(). For example, the following code writes an object to a file:</p> <p>import pickle obj = SomeObject() with open(filename, 'wb') as file:    pickle.dump(obj, file)      # Save object on f To restore the object, use:</p> <p>Click here to view code image</p> <p>with open(filename, 'rb') as file:     obj = pickle.load(file)   # Restore the object</p> <p>It is not normally necessary for user-defined objects to do anything extra to work with pickle. However, certain kinds of objects can\u2019t be pickled. These tend to be objects that incorporate runtime state\u2014open files, threads, closures, generators, and so on. To handle these tricky cases, a class can define the special methods getstate() and setstate().</p> <p>The getstate() method, if defined, will be called to create a value representing the state of an object. The value returned by getstate() is typically a string, tuple, list, or dictionary. The setstate() method receives this value during unpickling and should restore the state of an object from it.</p> <p>do not unpickle unknow data blocking operations and concurency</p> <p>A fundamental aspect of I/O is the concept of blocking. By its very nature, I/O is connected to the real world. It often involves waiting for input or devices to be ready. For example, code that reads data on the network might perform a receive operation on a socket like this:</p> <p>data = sock.recv(8192)</p> <p>def reader1(sock):     while (data := sock.recv(8192)):         print('reader1 got:', data)</p> <p>def reader2(sock):     while (data := sock.recv(8192)):         print('reader2 got:', data)</p>"},{"location":"python/modules/io/#problem-how-to-make-reader1-and-reader2","title":"Problem: How to make reader1() and reader2()","text":""},{"location":"python/modules/io/#run-at-the-same-time","title":"run at the same time?","text":"<p>The rest of this section outlines a few different approaches to solving this problem. However, it is not meant to be a full tutorial on concurrency. For that, you will need to consult other resources.</p> <p>nonblocking io</p> <p>def run(sock1, sock2):     sock1.setblocking(False)     sock2.setblocking(False)     while True:         reader1(sock1)         reader2(sock2) In practice, relying only on nonblocking I/O is clumsy and inefficient. For example, the core of this program is the run() function at the end. It will run in a inefficient busy loop as it constantly tries to read on the sockets. This works, but it is not a good design.</p> <p>IO polling</p> <p>Instead of relying upon exceptions and spinning, it is possible to poll I/O channels to see if data is available. The select or selectors module can be used for this purpose. For example, here\u2019s a slightly modified version of the run() function:</p> <p>from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE</p> <p>def run(sock1, sock2):     selector = DefaultSelector()     selector.register(sock1, EVENT_READ, data=reader1)     selector.register(sock2, EVENT_READ, data=reader2)     # Wait for something to happen     while True:         for key, evt in selector.select():             func = key.data             func(key.fileobj)</p> <p>In this code, the loop dispatches either reader1() or reader2() function as a callback whenever I/O is detected on the appropriate socket. The selector.select() operation itself blocks, waiting for I/O to occur. Thus, unlike the previous example, it won\u2019t make the CPU furiously spin.</p> <p>This approach to I/O is the foundation of many so-called \u201casync\u201d frameworks such as asyncio, although you usually don\u2019t see the inner workings of the event loop. threading</p> <p>import threading</p> <p>def reader1(sock):     while (data := sock.recv(8192)):         print('reader1 got:', data)</p> <p>def reader2(sock):     while (data := sock.recv(8192)):         print('reader2 got:', data)</p> <p>t1 = threading.Thread(target=reader1, args=[sock1]).start() t2 = threading.Thread(target=reader2, args=[sock2]).start()</p>"},{"location":"python/modules/io/#start-the-threads","title":"Start the threads","text":"<p>t1.start() t2.start()</p>"},{"location":"python/modules/io/#wait-for-the-threads-to-finish","title":"Wait for the threads to finish","text":"<p>t1.join() t2.join()</p> <p>asyncio</p> <p>import asyncio</p> <p>async def reader1(sock):     loop = asyncio.get_event_loop()     while (data := await loop.sock_recv(sock, 8192)):         print('reader1 got:', data)</p> <p>async def reader2(sock):     loop = asyncio.get_event_loop()     while (data := await loop.sock_recv(sock, 8192)):         print('reader2 got:', data)</p> <p>async def main(sock1, sock2):     loop = asyncio.get_event_loop()     t1 = loop.create_task(reader1(sock1))     t2 = loop.create_task(reader2(sock2))</p> <pre><code># Wait for the tasks to finish\nawait t1\nawait t2\n</code></pre> <p>...</p>"},{"location":"python/modules/io/#run-it","title":"Run it","text":"<p>asyncio.run(main(sock1, sock2))</p> <p>asyncio tcp socket</p> <p>import asyncio from socket import *</p> <p>async def echo_server(address):     loop = asyncio.get_event_loop()     sock = socket(AF_INET, SOCK_STREAM)     sock.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)     sock.bind(address)     sock.listen(5)     sock.setblocking(False)     print('Server listening at', address)     with sock:         while True:             client, addr = await loop.sock_accept(sock)             print('Connection from', addr)             loop.create_task(echo_client(loop, client))</p> <p>async def echo_client(loop, client):     with client:         while True:             data = await loop.sock_recv(client, 10000)             if not data:                 break             await loop.sock_sendall(client, b'Got:' + data)     print('Connection closed')</p> <p>if name == 'main':     loop = asyncio.get_event_loop()     loop.create_task(echo_server(loop, ('', 25000)))     loop.run_forever()</p> <p>To test this code, use a program such as nc or telnet to connect to port 25000 on your machine. The code should echo back the text that you type. If you connect more than once using multiple terminal windows, you\u2019ll find that the code can handle all of the connections concurrently.</p> <p>Most applications using asyncio will probably operate at a higher level than sockets. However, in such applications, you will still have to make use of special async functions and interact with the underlying event loop in some manner. binascii</p> <p>converts binary data into text repr</p> <p>binascii.b2a_hex(b'hello') b'68656c6c6f'</p> <pre><code>        binascii.a2b_hex() b'hello' binascii.b2a_base64(b'hello') b'aGVsbG8=\\n' binascii.a2b_base64()\n</code></pre> <p>cgi module</p> <p>    To register, please provide a contact name and email address.    </p> Your name: Your email: <p>Here\u2019s a CGI script that receives the form data on the other end:</p> <p>Click here to view code image</p>"},{"location":"python/modules/io/#usrbinenv-python","title":"!/usr/bin/env python","text":"<p>import cgi try:     form = cgi.FieldStorage()     name = form.getvalue('name')     email = form.getvalue('email')     # Validate the responses and do whatever     ...     # Produce an HTML result (or redirect)     print('Status: 302 Moved\\r')     print('Location: https://www.mywebsite.com/thanks.html\\r')     print('\\r') except Exception as e:     print('Status: 501 Error\\r')     print('Content-type: text/plain\\r')     print('\\r')     print('Some kind of error occurred.\\r') Will writing such a CGI script get you a job at an Internet startup? Probably not. Will it solve your actual problem? Likely.</p> <p>configparser</p> <p>; A comment [section1] name1 = value1 name2 = value2</p> <p>[section2] ; Alternative syntax name1: value1 name2: value2</p> <p>cfg = configparser.ConfigParser() cfg.read('conig.ini')</p>"},{"location":"python/modules/io/#extract-values","title":"Extract values","text":"<p>a = cfg.get('section1', 'name1') b = cfg.get('section2', 'name2')</p> <p>errorno</p> <p>so much error handlerrs fcntl module</p> <p>low level io tool</p> <p>open file with lock to avoid concurent open</p> <p>import fcntl</p> <p>with open('somefile', 'r') as file:      try:          fcntl.flock(file.fileno(), fcntl.LOCK_EX)          # Use the file          ...      finally:          fcntl.flock(file.fileno(), fcntl.LOCK_UN)</p> <p>hashlib</p> <p>The hashlib module provides functions for computing cryptographic hash values such as MD5 and SHA-1. The following example illustrates how to use the module:</p> <p>Click here to view code image</p> <pre><code>        h = hashlib.new('sha256') h.update(b'Hello') # Feed data h.update(b'World') h.digest() b'\\xa5\\x91\\xa6\\xd4\\x0b\\xf4 @J\\x01\\x173\\xcf\\xb7\\xb1\\x90\\xd6,e\\xbf\\x0b\\xcd\\xa3+W\\xb2w\\xd9\\xad\\x9f\\x14n h.hexdigest() 'a591a6d40bf420404a011733cfb7b190d62c65bf0bcda32b57b277d9ad9f146e' h.digest_size 32\n</code></pre> <p>https package io</p> <p>The io module primarily contains the definitions of classes used to implement the file objects as returned by the open() function. It is not so common to access those classes directly. However, the module also contains a pair of classes that are useful for \u201cfaking\u201d a file in the form of strings and bytes. This can be useful for testing and other applications where you need to provide a \u201cfile\u201d but have obtained data in a different way.</p> <p>The StringIO() class provides a file-like interface on top of strings. For example, here is how you can write output to a string:</p> <p>import io file = io.StringIO() greeting(file)</p>"},{"location":"python/modules/io/#get-the-resulting-output","title":"Get the resulting output","text":"<p>output = file.getvalue()</p> <p>logging</p> <p>The logging module is the de facto standard module used for reporting program diagnostics and for print-style debugging. It can be used to route output to a log file and provides a large number of configuration options. A common practice is to write code that creates a Logger instance and issues messages on it like this:</p> <p>Click here to view code image</p> <p>import logging log = logging.getLogger(name)</p>"},{"location":"python/modules/io/#function-that-uses-logging","title":"Function that uses logging","text":"<p>def func(args):     log.debug('A debugging message')     log.info('An informational message')     log.warning('A warning message')     log.error('An error message')     log.critical('A critical message')</p>"},{"location":"python/modules/io/#configuration-of-logging-occurs-one-at-program-startup","title":"Configuration of logging (occurs one at program startup)","text":"<p>if name == 'main':     logging.basicConfig(          level=logging.WARNING,          filename='output.log'     )</p> <p>There are five built-in levels of logging ordered by increasing severity. When configuring the logging system, you specify a level that acts as a filter. Only messages at that level or greater severity are reported. Logging provides a large number of configuration options, mostly related to the back-end handling of the log messages. Usually you don\u2019t need to know about that when writing application code\u2014you use debug(), info(), warning(), and similar methods on some given Logger instance. Any special configuration takes place during program startup in a special location (such as a main() function or the main code block).</p> <p>pathlib</p> <p>from pathlib import Path</p> <p>filename = Path('/Users/beazley/old/data.csv') Once you have an instance filename of Path, you can perform various operations on it to manipulate the filename. For example:</p> <p>Click here to view code image</p> <p>filename.name 'data.csv' filename.parent Path('/Users/beazley/old') filename.parent / 'newfile.csv' Path('/Users/beazley/old/newfile.csv') filename.parts ('/', 'Users', 'beazley', 'old', 'data.csv') filename.with_suffix('.csv.clean') Path('/Users/beazley/old/data.csv.clean') </p> <p>import pathlib</p> <p>def compute_usage(filename):     pathname = pathlib.Path(filename)     if pathname.is_file():         return pathname.stat().st_size     elif pathname.is_dir():         return sum(path.stat().st_size                    for path in pathname.rglob('*')                    if path.is_file())         return pathname.stat().st_size     else:         raise RuntimeError('Unsupported file kind')</p> <p>re</p> <p>regex shutil</p> <p>some shell commadns</p> <p>import shutil</p> <p>shutil.copy(srcfile, dstfile) To move a file:</p> <p>Click here to view code image</p> <p>shutil.move(srcfile, dstfile) To copy a directory tree:</p> <p>Click here to view code image</p> <p>shutil.copytree(srcdir, dstdir) To remove a directory tree:</p> <p>shutil.rmtree(pathname) The shutil module is often used as a safer and more portable alternative to directly executing shell commands with the os.system() function. select</p> <p>The select module is used for simple polling of multiple I/O streams. That is, it can be used to watch a collection of file descriptors for incoming data or for the ability to receive outgoing data. The following example shows typical usage:</p> <p>import select</p>"},{"location":"python/modules/io/#collections-of-objects-representing-file-descriptors-must-be","title":"Collections of objects representing file descriptors.  Must be","text":""},{"location":"python/modules/io/#integers-or-objects-with-a-fileno-method","title":"integers or objects with a fileno() method.","text":"<p>want_to_read = [ ... ] want_to_write = [ ... ] check_exceptions = [ ... ]</p>"},{"location":"python/modules/io/#timeout-or-none","title":"Timeout (or None)","text":"<p>timeout = None</p>"},{"location":"python/modules/io/#poll-for-io","title":"Poll for I/O","text":"<p>can_read, can_write, have_exceptions = \\     select.select(want_to_read, want_to_write, check_exceptions, timeout)</p>"},{"location":"python/modules/io/#perform-io-operations","title":"Perform I/O operations","text":"<p>for file in can_read:     do_read(file) for file in can_write:     do_write(file)</p>"},{"location":"python/modules/io/#handle-exceptions","title":"Handle exceptions","text":"<p>for file in have_exceptions:     handle_exception(file)</p> <p>smtlib</p> <p>import smtplib</p> <p>fromaddr = 'someone@some.com' toaddrs = ['recipient@other.com' ] amount = 123.45 msg = f'''From: {fromaddr}\\r \\r Pay {amount} bitcoin or else.  We're watching.\\r '''</p> <p>server = smtplib.SMTP('localhost') serv.sendmail(fromaddr, toaddrs, msg) serv.quit()</p> <p>socket</p> <p>use telnet or nc</p> <p>from socket import socket, AF_INET, SOCK_STREAM</p> <p>sock = socket(AF_INET, SOCK_STREAM) sock.connect(('python.org', 80)) sock.send(b'GET /index.html HTTP/1.0\\r\\n\\r\\n') parts = [] while True:     part = sock.recv(10000)     if not part:         break     parts.append(part) response = b''.join(part) print(part)</p> <p>struct</p> <p>The struct module is used to convert data between Python and binary data structures, represented as Python byte strings. These data structures are often used when interacting with functions written in C, binary file formats, network protocols, or binary communication over serial ports.</p> <p>As an example, suppose you need to construct a binary message with its format described by a C data structure:</p> <p>Click here to view code image Message format: All values are 'big endian'</p> <p>struct Message { unsigned short msgid; // 16 bit unsigned integer unsigned int sequence; // 32 bit sequence number float x; // 32 bit float float y; // 32 bit float } subprocess</p> <p>import subprocess</p>"},{"location":"python/modules/io/#run-the-netstat-a-command-and-collect-its-output","title":"Run the 'netstat -a' command and collect its output","text":"<p>try:     out = subprocess.check_output(['netstat', '-a']) except subprocess.CalledProcessError as e:     print('It failed:', e) The data returned by check_output() is presented as bytes. If you want to convert it to text, make sure you apply a proper decoding:</p> <p>Click here to view code image</p> <p>text = out.decode('utf-8') It is also possible to set up a pipe and to interact with a subprocess in a more detailed manner. To do that, use the Popen class like this:</p> <p>Click here to view code image</p> <p>import subprocess</p> <p>p = subprocess.Popen(['wc'],                      stdin=subprocess.PIPE,                      stdout=subprocess.PIPE)</p>"},{"location":"python/modules/io/#send-data-to-the-subprocess","title":"Send data to the subprocess","text":"<p>p.stdin.write(b'hello world\\nthis is a test\\n') p.stdin.close()</p>"},{"location":"python/modules/io/#read-data-back","title":"Read data back","text":"<p>out = p.stdout.read() print(out)</p> <p>tmpfile</p> <p>temp files textwrap</p> <p>wrapped = textwrap.wrap(text, width=81) print('\\n'.join(wrapped))</p> <p>threading</p> <p>threads</p> <p>import threading import time</p> <p>def countdown(n):     while n &gt; 0:         print('T-minus', n)         n -= 1         time.sleep(1)</p> <p>t = threading.Thread(target=countdown, args=[10]) t.start() t.join()      # Wait for the thread to finish If you\u2019re never going to wait for the thread to finish, make it daemonic by supplying an extra daemon flag like this:</p> <p>Click here to view code image</p> <p>t = threading.Thread(target=countdown, args=[10], daemon=True)</p>"},{"location":"python/modules/io/#to-stop","title":"to stop","text":"<p>import threading import time</p> <p>must_stop = False</p> <p>def countdown(n):     while n &gt; 0 and not must_stop:         print('T-minus', n)         n -= 1         time.sleep(1)</p> <p>thread lock</p> <p>import threading</p> <p>class Counter:     def init(self):         self.value = 0         self.lock = threading.Lock()</p> <pre><code>def increment(self):\n    with self.lock:\n         self.value += 1\n\ndef decrement(self):\n    with self.lock:\n         self.value -= 1\n</code></pre> <p>threading event</p> <p>def step1(evt):     print('Step 1')     time.sleep(5)     evt.set()</p> <p>def step2(evt):     evt.wait()     print('Step 2')</p> <p>evt = threading.Event() threading.Thread(target=step1, args=[evt]).start() threading.Thread(target=step2, args=[evt]).start()</p> <p>thread queue</p> <p>import threading import queue import time</p> <p>def producer(q):     for i in range(10):         print('Producing:', i)         q.put(i)     print('Done')     q.put(None)</p> <p>def consumer(q):     while True:         item = q.get()         if item is None:             break         print('Consuming:', item)     print('Goodbye')</p> <p>q = queue.Queue() threading.Thread(target=producer, args=[q]).start() threading.Thread(target=consumer, args=[q]).start()</p> <p>time</p> <p>The time module is used to access system time-related functions. The following selected functions are the most useful:</p> <p>sleep(seconds) Make Python sleep for a given number of seconds, given as a floating point.</p> <p>time() Return the current system time in UTC as a floating-point number. This is the number of seconds since the epoch (usually January 1, 1970 for UNIX systems). Use localtime() to convert it into a data structure suitable for extracting useful information.</p> <p>localtime([secs]) Return a struct_time object representing the local time on the system or the time represented by the floating-point value secs passed as an argument. The resulting struct has attributes tm_year, tm_mon, tm_mday, tm_hour, tm_min, tm_sec, tm_wday, tm_yday, and tm_isdst.</p> <p>gmtime([secs]) The same as localtime() except that the resulting structure represents the time in UTC (or Greenwich Mean Time).</p> <p>ctime([secs]) Convert a time represented as seconds to a text string suitable for printing. Useful for debugging and logging.</p> <p>asctime(tm) Convert a time structure as represented by localtime() into a text string suitable for printing.</p> <p>The datetime module is more generally used for representing dates and times for the purpose of performing date-related computations and dealing with timezones. urllib</p> <p>from urllib.request import urlopen u = urlopen('http://www.python.org') data = u.read()</p> <p>If you want to encode form parameters, you can use urllib.parse.urlencode() as shown here:</p> <p>Click here to view code image</p> <p>from urllib.parse import urlencode from urllib.request import urlopen</p> <p>form = {    'name': 'Mary A. Python',    'email': 'mary123@python.org' }</p> <p>data = urlencode(form) u = urlopen('http://httpbin.org/post', data.encode('utf-8')) response = u.read() The urlopen() function works fine for basic webpages and APIs involving HTTP or HTTPS. However, it becomes quite awkward to use if access also involves cookies, advanced authentication schemes, and other layers. Frankly, most Python programmers would use a third-party library such as requests or httpx to handle these situations. You should too.</p> <p>The urllib.parse subpackage has additional functions for manipulating URLs themselves. For example, the urlparse() function can be used to pull apart a URL:</p> <p>Click here to view code image</p> <p>url = 'http://httpbin.org/get?name=Dave&amp;n=42' from urllib.parse import urlparse urlparse(url) ParseResult(scheme='http', netloc='httpbin.org', path='/get', params='', query='name=Dave&amp;n=42', fragment='') </p> <p>unicodedata</p> <p>for unicode strings</p> <p>unicodedata.normalize(option) xml</p> <p>from xml.etree.ElementTree import ElementTree</p> <p>doc = ElementTree(file='recipe.xml') title = doc.find('title') print(title.text)</p>"},{"location":"python/modules/io/#alternative-just-get-element-text","title":"Alternative (just get element text)","text":"<p>print(doc.findtext('description'))</p>"},{"location":"python/modules/io/#iterate-over-multiple-elements","title":"Iterate over multiple elements","text":"<p>for item in doc.findall('ingredients/item'):     num = item.get('num')     units = item.get('units', '')     text = item.text.strip()     print(f'{num} {units} {text}')</p> <p>I/O is a fundamental part of writing any useful program. Given its popularity, Python is able to work with literally any data format, encoding, or document structure that\u2019s in use. Although the standard library might not support it, you will almost certainly find a third-party module to solve your problem.</p> <p>In the big picture, it may be more useful to think about the edges of your application. At the outer boundary between your program and reality, it\u2019s common to encounter issues related to data encoding. This is especially true for textual data and Unicode. Much of the complexity in Python\u2019s I/O handling\u2014supporting different encoding, error handling policies, and so on\u2014is aimed at this specific problem. It\u2019s also critical to keep in mind that textual data and binary data are strictly separated. Knowing what you\u2019re working with helps in understanding the big picture.</p> <p>A secondary consideration in I/O is the overall evaluation model. Python code is currently separated into two worlds\u2014normal synchronous code and asynchronous code usually associated with the asyncio module (characterized by the use of async functions and the async/await syntax). Asynchronous code almost always requires using dedicated libraries that are capable of operating in that environment. This, in turn, forces your hand on writing your application code in the \u201casync\u201d style as well. Honestly, you should probably avoid asynchronous coding unless you absolutely know that you need it\u2014and if you\u2019re not really sure, then you almost certainly don\u2019t. Most of the well-adjusted Python-speaking universe codes in a normal synchronous style that is far easier to reason about, debug, and test. You should choose that.</p>"},{"location":"python/modules/modules/","title":"Overview","text":"<p>module</p> <p>d.py - is module Module caching</p> <p>import works only one time, but you can reload if needed u can import global variables with from the</p> <p>from d import GLOABL_VARIABLE control * import</p> <p>define all=[\"func\",\"SomeClass\"] circula import</p>"},{"location":"python/modules/modules/#modapy","title":"moda.py","text":"<p>import modb</p> <p>def func_a():     modb.func_b()</p> <p>class Base:     pass</p>"},{"location":"python/modules/modules/#-","title":"----------------------------","text":""},{"location":"python/modules/modules/#modbpy","title":"modb.py","text":"<p>import moda</p> <p>def func_b():     print('B')</p> <p>class Child(moda.Base):     pass</p> <p>There is a strange import order dependency in this code. Using import modb first works fine, but if you put import moda first, it blows up with an error about moda.Base being undefined.</p> <p>To understand what is happening, you have to follow the control flow. import moda starts executing the file moda.py. The first statement it encounters is import modb. Thus, control switches over to modb.py. The first statement in that file is import moda. Instead of entering a recursive cycle, that import is satisfied by the module cache and control continues on to the next statement in modb.py. This is good\u2014circular imports don\u2019t cause Python to deadlock or enter a new spacetime dimension. However, at this point in execution, module moda has only been partially evaluated. When control reaches the class Child(moda.Base) statement, it blows up. The required Base class hasn\u2019t been defined yet.</p> <p>One way to fix this problem is to move the import modb statement someplace else. For example, you could move the import into func_a() where the definition is actually needed: module reloading</p> <p>importlib.realod(requests) no c/ c++ extenstions compilation pychache</p> <p>When modules are first imported, they are compiled into an interpreter bytecode. This code is written to a .pyc file within a special pycache directory. This directory is usually found in the same directory as the original .py file. When the same import occurs again on a different run of the program, the compiled bytecode is loaded instead. This significantly speeds up the import process.</p> <p>The caching of bytecode is an automatic process that you almost never need to worry about. Files are automatically regenerated if the original source code changes. It just works.</p> <p>That said, there are still reasons to know about this caching and compilation process. First, sometimes Python files get installed (often accidentally) in an environment where users don\u2019t have operating system permissions to create the required pycache directory. Python will still work, but every import now loads the original source code and compiles it to bytecode. Program loading will be a lot slower than it needs to be. Similarly, in deploying or packaging a Python application, it may be advantageous to include the compiled bytecode, as that may significantly speed up program startup.</p> <p>The other good reason to know about module caching is that some programming techniques interfere with it. Advanced metaprogramming techniques involving dynamic code generation and the exec() function defeat the benefits of bytecode caching. A notable example is the use of dataclasses:</p> <p>Click here to view code image</p> <p>from dataclasses import dataclass</p> <p>@dataclass class Point: x: float y: float Dataclasses work by generating method functions as text fragments and executing them using exec(). None of this generated code is cached by the import system. For a single class definition, you won\u2019t notice. However, if you have a module consisting of 100 dataclasses, you might find that it imports nearly 20 times slower than a comparable module where you just wrote out the classes in the normal, if less compact, way. module search</p> <p>env PYTHONPATH=/some/path python3 script.py</p> <p>import sys sys.path.append('mymodules.zip') import foo, bar</p> <p>python execute directory</p> <p>myapp/ foo.py bar.py main.py You can run Python on it by typing python3 myapp. Execution will start in the main.py file. This also works if you turn the myapp directory into a ZIP archive. Typing python3 myapp.zip will look for a top-level main.py file and execute it if found. package</p> <p>graphics/ init.py primitive/ init.py lines.py fill.py text.py ... graph2d/ init.py plot2d.py ... graph3d/ init.py plot3d.py ... formats/ init.py gif.py png.py tiff.py jpeg.py</p> <p>Whenever any part of a package is first imported, code in the init.py file executes first (if it exists). As noted, this file may be empty, but it can also contain code to perform package-specific initializations. If importing a deeply nested submodule, all init.py files encountered in traversal of the directory structure are executed. Thus, the statement import graphics.primitive.fill would first execute the init.py file in the graphics/ directory followed by the init.py file in the primitive/ directory.</p> <p>Astute Python users might observe that a package still seems to work if init.py files are omitted. This is true\u2014you can use a directory of Python code as a package even if it contains no init.py. However, what\u2019s not obvious is that a directory with a missing init.py file actually defines a different kind of package known as namespace package. This is an advanced feature sometimes used by very large libraries and frameworks to implement broken plugin systems. In the opinion of the author, this is rarely what you want\u2014you should always create proper init.py files when creating a package. runninc packgage submodule as script</p> <p>from ..primitive import lines, text</p> <p>class Plot2D:     ...</p> <p>if name == 'main':     print('Testing Plot2D')     p = Plot2D()     ... If you try to run it directly, you get a crash complaining about relative import statements:</p> <p>Click here to view code image</p> <p>bash $ python3 graphics/graph2d/plot2d.py Traceback (most recent call last):   File 'graphics/graph2d/plot2d.py', line 1, in      from ..primitive import line, text ValueError: attempted relative import beyond top-level package bash $ You can\u2019t move into the package directory and run it there either: <p>Click here to view code image</p> <p>bash $ cd graphics/graph2d/ bash $ python3 plot2d.py Traceback (most recent call last):   File 'plot2d.py', line 1, in      from ..primitive import line, text ValueError: attempted relative import beyond top-level package bash $ <p>bash $ python3 -m graphics.graph2d.plot2d Testing Plot2D bash $ -m specifies a module or package as the main program. Python will run the module with the proper environment to make sure that imports work. Many of Python\u2019s built-in packages have \u201csecret\u201d features that can be used via -m. One of the most well-known is using python3 -m http.server to run a web server from the current directory.</p> <p>You can provide similar functionality with your own packages. If the name supplied to python -m name corresponds to a package directory, Python looks for the presence of a main.py in that directory and runs that as the scrip control package namespace</p> <p>The primary purpose of a package is to serve as a top-level container for code. Sometimes users will import the top-level name and nothing else. For example:</p> <p>import graphics This import doesn\u2019t specify any particular submodule. Nor does it make any other part of the package accessible. For example, you\u2019ll find that code like this fails:</p> <p>Click here to view code image</p> <p>import graphics graphics.primitive.fill.floodfill(img,x,y,color) # Fails! When only a top-level package import is given, the only file that imports is the associated init.py file. In this example, it\u2019s the file graphics/init.py file.</p> <p>The primary purpose of an init.py file is to build and/or manage the contents of the top-level package namespace. Often, this involves importing selected functions, classes, and other objects from lower-level submodules. For example, if the graphics package in this example consists of hundreds of low-level functions but most of those details are encapsulated into a handful of high-level classes, then the init.py file might choose to expose just those classes:</p> <p>Click here to view code image graphics/init.py</p> <p>from .graph2d.plot2d import Plot2D from .graph3d.plot3d import Plot3D With this init.py file, the names Plot2D and Plot3D would appear at the top level of the package. A user could then use those names as if graphics were a simple module:</p> <p>Click here to view code image</p> <p>from graphics import Plot2D plt = Plot2D(100, 100) plt.clear() ... This is often much more convenient for the user because they don\u2019t have to know how you\u2019ve actually organized your code. In some sense, you\u2019re putting a higher layer of abstraction on top of your code structure. Many of the modules in the Python standard library are constructed in this manner. For example, the popular collections module is actually a package. The collections/init.py file consolidates definitions from a few different places and presents them to the user as a single consolidated namespace. package exports</p> <p>One issue concerns the interaction between an init.py file and low-level submodules. For example, the user of a package might only want to concern themselves with objects and functions that live in the top-level package namespace. However, the implementor of a package might be concerned with the problem of organizing code into maintainable submodules.</p> <p>To better manage this organizational complexity, package submodules often declare an explicit list of exports by defining an all variable. This is a list of names that should be pushed up one level in the package namespace. For example:</p> <p>Click here to view code image</p>"},{"location":"python/modules/modules/#graphicsgraph2dplot2dpy","title":"graphics/graph2d/plot2d.py","text":"<p>all = ['Plot2D']</p> <p>class Plot2D:     ... The associated init.py file then imports its submodules using an * import like this:</p> <p>Click here to view code image</p>"},{"location":"python/modules/modules/#graphicsgraph2dinitpy","title":"graphics/graph2d/init.py","text":""},{"location":"python/modules/modules/#only-loads-names-explicitly-listed-in-all-variables","title":"Only loads names explicitly listed in all variables","text":"<p>from .plot2d import *</p>"},{"location":"python/modules/modules/#propagate-the-all-up-to-next-level-if-desired","title":"Propagate the all up to next level (if desired)","text":"<p>all = plot2d.all This lifting process then continues all the way to the top-level package init.py. for example:</p> <p>Click here to view code image</p>"},{"location":"python/modules/modules/#graphicsinitpy","title":"graphics/init.py","text":"<p>from .graph2d import * from .graph3d import *</p>"},{"location":"python/modules/modules/#consolidate-exports","title":"Consolidate exports","text":"<p>all = [     graph2d.all,     graph3d.all ]</p> <p>The gist is that every component of a package explicitly states its exports using the all variable. The init.py files then propagate the exports upwards. In practice, it can get complicated, but this approach avoids the problem of hard-wiring specific export names into the init.py file. Instead, if a submodule wants to export something, its name gets listed in just one place\u2014the all variable. Then, by magic, it propagates up to its proper place in the package namespace.</p> <p>It is worth noting that although using * imports in user code is frowned upon, it is widespread practice in package init.py files. The reason it works in packages is that it is usually much more controlled and contained\u2014being driven by the contents of the all variables and not a free-wheeling attitude of \u201clet\u2019s just import everything.\u201d module objects</p> <p>name</p> <p>Full module name</p> <p>doc</p> <p>Documentation string</p> <p>dict</p> <p>Module dictionary</p> <p>file</p> <p>Filename where defined</p> <p>package</p> <p>Name of enclosing package (if any)</p> <p>path</p> <p>List of subdirectories to search for submodules of a package.</p> <p>annotations</p> <p>Module-level type hints</p> <p>8.16 Deploying Python Packages The final frontier of modules and packages is the problem of giving your code to others. This is a large topic that has been the focus of active ongoing development over many years. I won\u2019t try to document a process that\u2019s bound to be out-of-date by the time you read this. Instead, direct your attention to the documentation at https://packaging.python.org/tutorials/packaging-projects.</p> <p>For the purposes of day-to-day development, the most important thing is to keep your code isolated as a self-contained project. All of your code should live in a proper package. Try to give your package a unique name so that it doesn\u2019t conflict with other possible dependencies. Consult the Python package index at https://pypi.org to pick a name. In structuring your code, try to keep things simple. As you\u2019ve seen, there are many highly sophisticated things that can be done with the module and package system. There is a time and place for that, but it should not be your starting point.</p> <p>With absolute simplicity in mind, the most minimalistic way to distribute pure Python code is to use the setuptools module or the built-in distutils module. Suppose you have written some code and it\u2019s in a project that looks like this:</p> <p>Click here to view code image</p> <p>spam-project/ README.txt Documentation.txt spam/ # A package of code init.py foo.py bar.py runspam.py # A script to run as: python runspam.py To create a distribution, create a file setup.py in the topmost directory (spam-project/ in this example). In this file, put the following code:</p> <p>Click here to view code image setup.py</p> <p>from setuptools import setup</p> <p>setup(name = 'spam', version = '0.0' packages = ['spam'], scripts = ['runspam.py'], ) In the setup() call, packages is a list of all package directories, and scripts is a list of script files. Any of these arguments may be omitted if your software does not have them (for example, if there are no scripts). name is the name of your package, and version is the version number as a string. The call to setup() supports a variety of other parameters that supply various metadata about your package. See the full list at https://docs.python.org/3/distutils/apiref.html.</p> <p>Creating a setup.py file is enough to create a source distribution of your software. Type the following shell command to make a source distribution:</p> <p>Click here to view code image</p> <p>bash $ python setup.py sdist ... bash $ This creates an archive file, such as spam-1.0.tar.gz or spam-1.0.zip, in the directory spam/dist. This is the file you would give to others to install your software. To install, a user can use a command such as pip. For example:</p> <p>Click here to view code image</p> <p>shell $ python3 -m pip install spam-1.0.tar.gz This installs the software into the local Python distribution and makes it available for general use. The code will normally be installed into a directory called site-packages in the Python library. To find the exact location of this directory, inspect the value of sys.path. Scripts are normally installed into the same directory as the Python interpreter itself.</p> <p>If the first line of a script starts with #! and contains the text python, the installer will rewrite the line to point to the local installation of Python. Thus, if your scripts have been hardcoded to a specific Python location, such as /usr/local/bin/python, they should still work when installed on other systems where Python is in a different location.</p> <p>It must be stressed that the use of setuptools as described here is absolutely minimal. Larger projects may involve C/C++ extensions, complicated package structures, examples, and more. Covering all of the tools and possible ways to deploy such code is beyond the scope of this book. You should consult various resources on https://python.org and https://pypi.org for the most up-to-date advice.</p> <p>8.17 The Penultimate Word: Start with a Package When first starting a new program, it is easy to start with a simple single Python file. For example, you might write a script called program.py and start with that. Although this will work fine for throwaway programs and short tasks, your \u201cscript\u201d may start growing and adding features. Eventually, you might want to split it into multiple files. It\u2019s at that point that problems often arise.</p> <p>In light of this, it makes sense to get in the habit of starting all programs as a package from the onset. For example, instead of making a file called program.py, you should make a program package directory called program:</p> <p>program/ init.py main.py Put your starting code in main.py and run your program using a command such as python -m program. As you need more code, add new files to your package and use package-relative imports. An advantage of using a package is that all of your code remains isolated. You can name the files whatever you want and not worry about collisions with other packages, standard library modules, or code written by your coworkers. Although setting up a package requires a bit more work at the start, it will likely save you a lot of headaches later.</p> <p>8.18 The Final Word: Keep It Simple There is a lot of more advanced wizardry associated with the module and package system than what has been shown here. Consult the tutorial \u201cModules and Packages: Live and Let Die!\u201d at https://dabeaz.com/modulepackage/index.html to get an idea of what\u2019s possible.</p> <p>All things considered, however, you\u2019re probably better off not doing any advanced module hacking. Managing modules, packages, and software distribution has always been a source of pain in the Python community. Much of the pain is a direct consequence of people applying hacks to the module system. Don\u2019t do that. Keep it simple and find the power to just say \u201cno\u201d when your coworkers propose to modify import to work with the blockchain.</p>"},{"location":"python/structure/","title":"Overview","text":""},{"location":"python/structure/#what-is-an-object","title":"What is an Object","text":"<p>Every piece of data stored in a program is an object. Each object has an identity, a type (also known as its class), and a value. For example, when you write <code>a = 42</code>, an integer object is created with the value of 42. The identity of the object is a number representing its location in memory, and <code>a</code> is a label that refers to this specific location. The type of an object defines its internal data representation and supported methods. An object can be mutable or immutable, and it can hold references to other objects.</p> <p>Objects are characterized by their attributes, which are accessed using the dot operator (<code>.</code>). An attribute can be a simple data value or a function called a method. Inheritance allows the creation of subtype objects that inherit features from the original type and can have additional or redefined methods.</p> <p>Type checks in a program may not always be useful due to performance impact and complex object hierarchies. For example, the <code>isinstance(items, list)</code> statement may not work for objects that have a list-like interface but don't directly inherit from the built-in list type.</p>"},{"location":"python/structure/#first-class-object","title":"First-Class Object","text":"<p>All objects in Python are considered first-class objects. This means they can be assigned to names, stored as variables, passed as arguments, returned from functions, compared with other objects, and more. They can be treated as data and manipulated in various ways.</p>"},{"location":"python/structure/#reference-counting-and-garbage-collection","title":"Reference Counting and Garbage Collection","text":"<p>Python manages objects through automatic garbage collection. Objects are reference-counted, meaning their reference count increases when they are assigned to names or placed in data structures. The reference count decreases when references go out of scope, are reassigned, or deleted. When an object's reference count reaches zero, it is garbage-collected.</p> <p>In some cases, circular dependencies among objects can lead to delayed destruction. The cyclic garbage collector detects and deletes these inaccessible objects periodically. Manual deletion of objects may be necessary in certain situations, and the <code>gc</code> module provides functions to control the garbage collection process.</p>"},{"location":"python/structure/#object-protocol","title":"Object Protocol","text":"<p>Python's behavior is determined by dynamic processes involving special methods known as \"magic\" methods. These methods are automatically triggered by the interpreter during program execution. Special methods are denoted by double underscores (<code>__</code>) before and after the method name.</p> <p>Different categories of objects have associated special methods called \"protocols.\" For example, container objects define methods like <code>__len__()</code>, <code>__getitem__()</code>, <code>__setitem__()</code>, and <code>__delitem__()</code> to implement container operations such as indexing and slicing. Iterators implement the <code>__iter__()</code> and <code>__next__()</code> methods to enable iteration.</p> <p>Other protocols include class attribute protocol, function protocol, context manager protocol, repr and doc protocol, and spread with <code>*</code>.</p>"},{"location":"python/structure/#container-protocols","title":"Container Protocols","text":"<p>Container objects implement various special methods to support container operations:</p> <pre><code>a = [1, 2, 3, 4, 5, 6]\nlen(a)               # a.__len__()\nx = a[2]             # x = a.__getitem__(2)\na[1] = 7             # a.__setitem__(1,7)\ndel a[2]             # a.__delitem__(2)\n5 in a               # a.__contains__(5)\n</code></pre> <p>Slicing operations are implemented using <code>__getitem__()</code>, <code>__setitem__()</code>, and <code>__delitem__()</code> methods. Slices are represented by special slice instances.</p>"},{"location":"python/structure/#iterator-protocol","title":"Iterator Protocol","text":"<p>Objects that support iteration implement the iterator protocol:</p> <pre><code>obj = iter(iterable)  # obj = iterable.__iter__()\nnext(obj)             # obj.__next__()\n</code></pre> <p>The <code>iter()</code> method returns an iterator object, which has a <code>__next__()</code> method to retrieve the next object in the iteration. The <code>for</code> statement implicitly performs iteration using these methods.</p>"},{"location":"python/structure/#class-attribute-protocol","title":"Class Attribute Protocol","text":"<p>Objects define class attribute methods for accessing, setting, and deleting attributes:</p> <pre><code>obj.__getattribute__(self, name)    # Returns the attribute self.name\nobj.__getattr__(self, name)         # Returns the attribute self.name (if not found through __getattribute__())\nobj.__setattr__(self, name, value)  # Sets the attribute self.name = value\nobj.__delattr__(self, name)         # Deletes the attribute self.name\n</code></pre>"},{"location":"python/structure/#function-protocol","title":"Function Protocol","text":"<p>Objects can emulate functions by implementing the <code>__call__()</code> method. When an object provides this method, it can be invoked like a function:</p> <pre><code>obj(arg1, arg2, ...)  # obj.__call__(arg1, arg2, ...)\n</code></pre> <p>Many built-in types and libraries support function calls by implementing <code>__call__()</code>.</p>"},{"location":"python/structure/#context-manager-protocol","title":"Context Manager Protocol","text":"<p>Context managers define the methods <code>__enter__()</code> and <code>__exit__()</code> (or <code>__aenter__()</code> and <code>__aexit__</code> for async context managers). These methods are used for resource management and provide a convenient way to set up and clean up resources within a block of code.</p>"},{"location":"python/structure/#repr-and-doc","title":"Repr and Doc","text":"<p>Objects can define the <code>__repr__()</code> method to control how they are represented when using <code>print()</code> or <code>str()</code>. The <code>__doc__</code> attribute stores docstrings associated with the object.</p>"},{"location":"python/structure/#spread-with","title":"Spread with *","text":"<p>The <code>*</code> operator can be used to pass sequences or mappings as arguments to functions:</p> <pre><code>def func(x, y, z):\n    ...\n\ns = (1, 2, 3)\nresult = func(*s)  # Pass a sequence as arguments\n\nd = { 'x': 1, 'y': 2, 'z': 3 }\nresult = func(**d)  # Pass a mapping as keyword arguments\n</code></pre>"},{"location":"python/structure/code_design/","title":"Code Design","text":""},{"location":"python/structure/code_design/#design-by-contract","title":"Design by Contract","text":"<p>Design by Contract is a programming approach that focuses on enforcing rules and constraints during the communication of software components. It involves the use of contracts that define preconditions, postconditions, invariants, and side effects.</p> <ul> <li>Preconditions: Checks performed before running a function to ensure that the requirements are met.</li> <li>Postconditions: Checks performed after the execution of a function to validate if the expected result is achieved.</li> <li>Invariants: Rules or constraints that remain true throughout the execution of the code.</li> <li>Side Effects: Mentioned in the code, they describe any changes or actions that occur beyond the return value of a function.</li> </ul>"},{"location":"python/structure/code_design/#defensive-programming","title":"Defensive Programming","text":"<p>Defensive programming involves writing code that protects itself from invalid inputs or unexpected behavior. It includes error handling techniques such as:</p> <ul> <li>Value substitution: Using default values or environment variables (<code>os.getenv(\"DPORT\", 5432)</code>).</li> <li>Error logging: Capturing and logging errors for debugging and analysis.</li> <li>Exception handling: Properly handling exceptions with well-defined scopes to reduce the impact of errors.</li> </ul> <p>Best practices for error handling include avoiding traceback to end users, avoiding empty <code>except</code> blocks, and including the original exception for better debugging.</p>"},{"location":"python/structure/code_design/#cohesion-and-coupling","title":"Cohesion and Coupling","text":"<p>Cohesion and coupling are concepts related to how objects or components in a codebase depend on each other.</p> <ul> <li>Cohesion: Describes the degree to which a component or class focuses on a single responsibility or functionality. High cohesion means that a component is focused and has a clear purpose.</li> <li>Coupling: Refers to the interdependence between components or classes. High coupling indicates tight dependencies, which can lead to issues such as limited code reuse, ripple effects of changes, and a low level of abstraction.</li> </ul>"},{"location":"python/structure/code_design/#dry-and-oaoo","title":"DRY and OAOO","text":"<p>DRY (Don't Repeat Yourself) and OAOO (Once and Only Once) are principles that promote code efficiency and maintainability.</p> <ul> <li>DRY: Encourages avoiding code duplication by abstracting common functionality into reusable components or functions.</li> <li>OAOO: Advocates for implementing a particular behavior or logic in a single place to ensure consistency and reduce the chance of introducing errors through duplicated code.</li> </ul>"},{"location":"python/structure/code_design/#yagni-and-kis","title":"YAGNI and KIS","text":"<ul> <li>YAGNI: Stands for \"You Ain't Gonna Need It.\" It advises developers to avoid over-engineering or adding unnecessary features to their codebase. Only implement what is needed at the present moment to avoid complexity and potential issues.</li> <li>KIS: Stands for \"Keep It Simple.\" It emphasizes simplicity in design and implementation. When designing a software component, aim for the minimal solution that effectively solves the problem without introducing unnecessary complexity.</li> </ul>"},{"location":"python/structure/code_design/#eafp-and-lbyl","title":"EAFP and LBYL","text":"<ul> <li>EAFP: Stands for \"Easier to Ask Forgiveness than Permission.\" This programming approach suggests trying an operation and handling any resulting exceptions rather than checking for preconditions or permissions before executing the operation.</li> <li>LBYL: Stands for \"Look Before You Leap.\" It involves checking preconditions or permissions before executing an operation to avoid exceptions or errors. An example is checking if a file exists before attempting to open it.</li> </ul> <p>Example:</p>"},{"location":"python/structure/code_design/#eafp","title":"EAFP","text":"<pre><code>try:\n    with open(filename) as f:\n        # Code for file processing\nexcept FileNotFoundError as e:\n    logger.error(e)\n</code></pre>"},{"location":"python/structure/code_design/#lbyl","title":"LBYL","text":"<pre><code>if os.path.exists(filename):\n    with open(filename) as f:\n        # Code for file processing\n</code></pre>"},{"location":"python/structure/practices/","title":"Practices","text":""},{"location":"python/structure/practices/#bad","title":"BAD","text":"<ul> <li>try to not use global statement.</li> </ul>"},{"location":"python/structure/structure/","title":"Structure","text":""},{"location":"python/structure/structure/#memorize-some-tips","title":"Memorize Some Tips","text":""},{"location":"python/structure/structure/#literals","title":"Literals","text":"<p>Literals are used to represent fixed values in Python. Here are some examples:</p> <ul> <li>Integer literals: <code>42</code>, <code>0b101010</code> (binary), <code>0o52</code> (octal), <code>0x2a</code> (hexadecimal)</li> <li>Numeric literals can also include underscores for readability: <code>123_456_789</code>, <code>0x1234_5678</code>, <code>0b111_00_101</code>, <code>123.789_012</code></li> </ul>"},{"location":"python/structure/structure/#operations-for-iterables","title":"Operations for Iterables","text":"<ul> <li>Iteration: <code>for vars in s:</code></li> <li>Variable unpacking: <code>v1, v2, ... = s</code></li> <li>Membership: <code>x in s</code>, <code>x not in s</code></li> <li>Expansion in list, tuple, or set literals: <code>[a, *s, b]</code>, <code>(a, *s, b)</code>, <code>{a, *s, b}</code></li> <li>Throw variable: <code>throw variable like that</code></li> <li>Example: <code>a,_,b=[1,2,3]</code></li> </ul>"},{"location":"python/structure/structure/#set-operations","title":"Set Operations","text":"<p>Set operations allow manipulating sets in Python:</p> <pre><code>names1 = { 'IBM', 'MSFT', 'AA' }\nnames2 = set(['IBM', 'MSFT', 'HPE', 'IBM', 'CAT'])\n\na = names1 | names2      # Union: {'IBM', 'MSFT', 'HPE', 'AA', 'CAT'}\nb = names1 &amp; names2      # Intersection: {'IBM', 'MSFT'}\nc = names1 - names2      # Difference: {'AA'}\nd = names2 - names1      # Difference: {'HPE', 'CAT'}\ne = names1 ^ names2      # Symmetric Difference: {'HPE', 'AA', 'CAT'}\n</code></pre>"},{"location":"python/structure/structure/#discard","title":"Discard()","text":"<p>The <code>discard()</code> method is used to remove an item from a set:</p> <pre><code>s.discard('SCOX')  # Remove 'SCOX' if it exists.\n</code></pre>"},{"location":"python/structure/structure/#dictionary-operations","title":"Dictionary Operations","text":"<p>Dictionaries offer various operations for manipulating key-value pairs:</p> <ul> <li>Get with default value: <code>p = prices.get('IBM', 0.0)</code></li> <li>Delete: <code>del prices['GOOG']</code></li> <li>Keys can be tuples: <code>prices[('IBM', '2015-02-03')] = 91.23</code></li> </ul>"},{"location":"python/structure/structure/#list-comprehension","title":"List Comprehension","text":"<p>List comprehension provides a concise way to create lists based on existing lists or other iterables:</p> <pre><code>[expression for item1 in iterable1 if condition1\n            for item2 in iterable2 if condition2\n            ...\n            for itemN in iterableN if conditionN]\n</code></pre> <p>This syntax is equivalent to the following code:</p> <pre><code>result = []\nfor item1 in iterable1:\n    if condition1:\n        for item2 in iterable2:\n            if condition2:\n                ...\n                for itemN in iterableN:\n                    if conditionN:\n                        result.append(expression)\n</code></pre>"},{"location":"python/structure/structure/#generator-expression","title":"Generator Expression","text":"<p>Generator expressions are used to create generator objects, which generate values on the fly without storing them in memory:</p> <pre><code>nums = [1, 2, 3, 4]\nsquares = (x*x for x in nums)\n\n&gt;&gt;&gt; squares\n&lt;generator object at 0x590a8&gt;\n&gt;&gt;&gt; next(squares)\n1\n&gt;&gt;&gt; next(squares)\n4\n</code></pre>"},{"location":"python/structure/structure/#python-enumerate","title":"Python Enumerate","text":"<p>The <code>enumerate()</code> function is used to iterate over a sequence while keeping track of the index:</p> <pre><code>for i, x in enumerate(s, start=100):\n    statements\n</code></pre>"},{"location":"python/structure/structure/#zip","title":"Zip","text":"<p>The <code>zip()</code> function is used to iterate over multiple sequences simultaneously:</p> <pre><code>for x, y in zip(s, t):\n    statements\n</code></pre> <p>The <code>zip()</code> function returns an iterable of tuples.</p>"},{"location":"python/structure/structure/#exception-base-roots","title":"Exception Base Roots","text":"<ul> <li><code>BaseException</code>: The root class for all exceptions.</li> <li><code>Exception</code>: Base class for all program-related errors.</li> <li><code>ArithmeticError</code>: Base class for all math-related errors.</li> <li><code>ImportError</code>: Base class for import-related errors.</li> <li><code>LookupError</code>: Base class for all container lookup errors.</li> <li><code>OSError</code>: Base class for all system-related errors. <code>IOError</code> and <code>EnvironmentError</code> are aliases.</li> <li><code>ValueError</code>: Base class for value-related errors, including Unicode-related errors.</li> <li><code>UnicodeError</code>: Base class for Unicode string encoding-related errors.</li> <li><code>AssertionError</code>: Raised when an <code>assert</code> statement fails.</li> <li><code>AttributeError</code>: Raised when a bad attribute lookup is performed on an object.</li> <li><code>EOFError</code>: Raised when the end of a file is reached.</li> <li><code>MemoryError</code>: Raised when a recoverable out-of-memory error occurs.</li> <li><code>NameError</code>: Raised when a name is not found in the local or global namespace.</li> <li><code>NotImplementedError</code>: Raised for an unimplemented feature.</li> <li><code>RuntimeError</code>: A generic \"something bad happened\" error.</li> <li><code>TypeError</code>: Raised when an operation is applied to an object of the wrong type.</li> <li><code>UnboundLocalError</code>: Raised when a local variable is used before a value is assigned.</li> <li><code>SystemExit</code>: Raised to indicate program exit.</li> <li><code>KeyboardInterrupt</code>: Raised when a program is interrupted via Control-C.</li> <li><code>StopIteration</code>: Raised to signal the end of iteration.</li> </ul>"},{"location":"python/structure/structure/#new-exception","title":"New Exception","text":"<p>You can create your own custom exceptions by defining a new class that inherits from the <code>Exception</code> class. Here's an example:</p> <pre><code>class NetworkError(Exception):\n    pass\n\nraise NetworkError('Cannot find host')\n</code></pre>"},{"location":"python/structure/structure/#chained-exception","title":"Chained Exception","text":"<p>You can raise a different exception while preserving the original exception using the <code>from</code> keyword. Here's an example:</p> <pre><code>try:\n    # Some code that may raise an exception\nexcept Exception as e:\n    raise ValueError('An error occurred') from e\n</code></pre> <p>This creates a new <code>ValueError</code> exception with the original exception <code>e</code> chained to it.</p> Exception Name Description BaseException The root class for all exceptions. Exception Base class for all program-related errors. ArithmeticError Base class for all math-related errors. ImportError Base class for import-related errors. LookupError Base class for all container lookup errors. OSError Base class for all system-related errors. ValueError Base class for value-related errors. UnicodeError Base class for Unicode string encoding errors. AssertionError Raised when an assert statement fails. AttributeError Raised when a bad attribute lookup is performed. EOFError Raised when the end of a file is reached. MemoryError Raised when a recoverable out-of-memory error occurs. NameError Raised when a name is not found in the local or global namespace. NotImplementedError Raised for an unimplemented feature. RuntimeError A generic \"something bad happened\" error. TypeError Raised when an operation is applied to an object of the wrong type. UnboundLocalError Raised when a local variable is used before a value is assigned. SystemExit Raised to indicate program exit. KeyboardInterrupt Raised when a program is interrupted via Control-C. StopIteration Raised to signal the end of iteration. <pre><code>class ApplicationError(Exception): pass\n\ndef do_something(): x = int('N/A') # raises ValueError\n\ndef spam(): try: do_something() except Exception as e: raise ApplicationError('It failed') from e\n\n## Exception handling advice\n</code></pre>"},{"location":"python/structure/structure/#eargs","title":"e.args","text":"<p>The tuple of arguments supplied when raising the exception. In most cases, this is a one-item tuple with a string describing the error. For OSError exceptions, the value is a 2-tuple or 3-tuple containing an integer error number, string error message, and an optional filename.</p>"},{"location":"python/structure/structure/#ecause","title":"e.cause","text":"<p>Previous exception if the exception was intentionally raised in response to handling another exception. See the later section on chained exceptions.</p>"},{"location":"python/structure/structure/#econtext","title":"e.context","text":"<p>Previous exception if the exception was raised while handling another exception.</p>"},{"location":"python/structure/structure/#etraceback","title":"e.traceback","text":"<p>Stack traceback object associated with the exception.</p> <pre><code>try:\n    # do something\nexcept (TypeError, ValueError) as e:\n    # Handle Type or Value errors\n</code></pre> <pre><code>try:\n    file = open('foo.txt', 'rt')\nexcept FileNotFoundError as e:\n    print(f'Unable to open foo: {e}')\n    data = ''\nelse:\n    data = file.read()\n    file.close()\n</code></pre> <pre><code>file = open('foo.txt', 'rt')\ntry:\n    # Do some stuff\n    ...\nfinally:\n    file.close()\n</code></pre> <p>Exception handling is one of the most difficult things to get right in larger programs. However, there are a few rules of thumb that make it easier.</p> <p>The first rule is to not catch exceptions that can\u2019t be handled at that specific location in the code. Consider a function like this:</p> <pre><code>def read_data(filename):\n    with open(filename, 'rt') as file:\n        rows = []\n        for line in file:\n            row = line.split()\n            rows.append((row[0], int(row[1]), float(row[2])))\n    return rows\n</code></pre> <p>Suppose the <code>open()</code> function fails due to a bad filename. Is this an error that should be caught with a try-except statement in this function? Probably not. If the caller gives a bad filename, there is no sensible way to recover. There is no file to open, no data to read, and nothing else that\u2019s possible. It\u2019s better to let the operation fail and report an exception back to the caller. Avoiding an error check in <code>read_data()</code> doesn\u2019t mean that the exception would never be handled anywhere\u2014it just means that it\u2019s not the role of <code>read_data()</code> to do it. Perhaps the code that prompted a user for a filename would handle this exception.</p> <p>This advice might seem contrary to the experience of programmers accustomed to languages that rely upon special error codes or wrapped result types. In those languages, great care is made to make sure you always check return codes for errors on all operations. You don\u2019t do this in Python. If an operation can fail and there\u2019s nothing you can do to recover, it\u2019s better to just let it fail. The exception will propagate to upper levels of the program where it is usually the responsibility of some other code to handle it.</p> <p>On the other hand, a function might be able to recover from bad data. For example:</p> <pre><code>def read_data(filename):\n    with open(filename, 'rt') as file:\n        rows = []\n        for line in file:\n            row = line.split()\n            try:\n                rows.append((row[0], int(row[1]), float(row[2])))\n            except ValueError as e:\n                print('Bad row:', row)\n                print('Reason:', e)\n    return rows\n</code></pre> <p>When catching errors, try to make your except clauses as narrow as reasonable. The above code could have been written to catch all errors by using <code>except Exception</code>. However, doing that would make the code catch legitimate programming errors that probably shouldn\u2019t be ignored. Don\u2019t do that\u2014it will make debugging difficult.</p> <p>Finally, if you\u2019re explicitly raising an exception, consider making your own exception types. For example:</p> <pre><code># Code Termination\n# exit code\n\n# can be used instead of exit()\n\nraise SystemExit()                      # Exit with no error message\nraise SystemExit(\"Something is wrong\")  # Exit with error\n</code></pre>"},{"location":"python/structure/structure/#exception-hierarchy","title":"Exception Hierarchy","text":"<ul> <li>BaseException</li> <li>SystemExit</li> <li>KeyboardInterrupt</li> <li>GeneratorExit</li> <li>Exception<ul> <li>StopIteration</li> <li>StopAsyncIteration</li> <li>ArithmeticError<ul> <li>FloatingPointError</li> <li>OverflowError</li> <li>ZeroDivisionError</li> </ul> </li> <li>AssertionError</li> <li>AttributeError</li> <li>BufferError</li> <li>EOFError</li> <li>ImportError<ul> <li>ModuleNotFoundError</li> </ul> </li> <li>LookupError<ul> <li>IndexError</li> <li>KeyError</li> </ul> </li> <li>MemoryError</li> <li>NameError<ul> <li>UnboundLocalError</li> </ul> </li> <li>OSError<ul> <li>BlockingIOError</li> <li>ChildProcessError</li> <li>ConnectionError<ul> <li>BrokenPipeError</li> <li>ConnectionAbortedError</li> <li>ConnectionRefusedError</li> <li>ConnectionResetError</li> </ul> </li> <li>FileExistsError</li> <li>FileNotFoundError</li> <li>InterruptedError</li> <li>IsADirectoryError</li> <li>NotADirectoryError</li> <li>PermissionError</li> <li>ProcessLookupError</li> <li>TimeoutError</li> </ul> </li> <li>ReferenceError</li> <li>RuntimeError<ul> <li>NotImplementedError</li> <li>RecursionError</li> </ul> </li> <li>SyntaxError<ul> <li>IndentationError<ul> <li>TabError</li> </ul> </li> </ul> </li> <li>SystemError</li> <li>TypeError</li> <li>ValueError<ul> <li>UnicodeError<ul> <li>UnicodeDecodeError</li> <li>UnicodeEncodeError</li> <li>UnicodeTranslateError</li> </ul> </li> </ul> </li> <li>Warning<ul> <li>DeprecationWarning</li> <li>PendingDeprecationWarning</li> <li>RuntimeWarning</li> <li>SyntaxWarning</li> <li>UserWarning</li> <li>FutureWarning</li> <li>ImportWarning</li> <li>UnicodeWarning</li> <li>BytesWarning</li> <li>EncodingWarning</li> <li>ResourceWarning <pre><code>## Class Definitions\n\n```python\nclass NetworkError(Exception):\n    pass\n\nclass DeviceError(Exception):\n    def __init__(self, errno, msg):\n        self.args = (errno, msg)\n        self.errno = errno\n        self.errmsg = msg\n</code></pre></li> </ul> </li> </ul> </li> </ul>"},{"location":"python/structure/structure/#context-manager","title":"Context Manager","text":"<pre><code>class ListTransaction:\n    def __init__(self, thelist):\n        self.thelist = thelist\n\n    def __enter__(self):\n        self.workingcopy = list(self.thelist)\n        return self.workingcopy\n\n    def __exit__(self, type, value, tb):\n        if type is None:\n            self.thelist[:] = self.workingcopy\n        return False\n</code></pre> <p>This class allows you to make a sequence of modifications to an existing list. However, the modifications only take effect if no exceptions occur. Otherwise, the original list is left unmodified.</p> <pre><code>items = [1, 2, 3]\nwith ListTransaction(items) as working:\n    working.append(4)\n    working.append(5)\n\nprint(items)  # Produces [1, 2, 3, 4, 5]\n\ntry:\n    with ListTransaction(items) as working:\n        working.append(6)\n        working.append(7)\n        raise RuntimeError(\"We're hosed!\")\n</code></pre>"},{"location":"python/structure/structure/#python-optimized-mode","title":"Python Optimized Mode","text":"<p>If you run Python with the <code>-o</code> option, it will run in optimized mode, but it won't check assertions.</p>"},{"location":"python/structure/structure/#what-is-object-in-python","title":"What is Object in Python","text":"<p>Every piece of data stored in a program is an object. Each object has an identity, a type (also known as its class), and a value. For example, when you write <code>a = 42</code>, an integer object is created with the value of 42. The identity of the object is a number representing its location in memory. <code>a</code> is a label that refers to this specific location, although the label is not part of the object itself. The type of an object, also known as the object's class, defines the object's internal data representation as well as supported methods. When an object of a particular type is created, that object is called an instance of that type. After an instance is created, its identity does not change. If an object's value can be modified, the object is said to be mutable. If the value cannot be modified, the object is said to be immutable. An object that holds references to other objects is said to be a container. Objects are characterized by their attributes. An attribute is a value associated with an object that is accessed using the dot operator (<code>.</code>). An attribute might be a simple data value, such as a number. However, an attribute could also be a function that is invoked to carry out some operation. Such functions are called methods.</p> <p>The following example illustrates access to attributes:</p> <pre><code>obj.attribute\n</code></pre> <p>A subtype is a type defined by inheritance. It carries all of the features of the original type plus additional and/or redefined methods. Inheritance is discussed in more detail in Chapter 7.</p> <p>Although type checks can be added to a program, this is often not as useful as you might imagine. For one, excessive checking impacts performance. Second, programs don't always define objects that neatly fit into a nice type hierarchy. For instance, if the purpose of the <code>isinstance(items, list)</code> statement above is to test whether <code>items</code> is \"list-like,\" it won't work with objects that have the same programming interface as a list but don't directly inherit from the built-in list type (one example is <code>deque</code> from the <code>collections</code> module).</p>"},{"location":"python/structure/structure/#reference-counting-and-garbage-collection","title":"Reference Counting and Garbage Collection","text":"<p>Python manages objects through automatic garbage collection. All objects are reference-counted. An object's reference count is increased whenever it's assigned to a new name or placed in a data structure that references it. An object's reference count is decreased by the <code>del</code> statement or whenever a reference goes out of scope or is reassigned.</p> <p>When an object's reference count reaches zero, it is garbage-collected. However, in some cases, a circular dependency may exist in a collection of objects that are no longer in use. In such cases, the destruction of the objects will be delayed until a cycle detector executes to find and delete the inaccessible objects. The exact behavior can be fine-tuned and controlled using functions in the <code>gc</code> standard library module. The <code>gc.collect()</code> function can be used to immediately invoke the cyclic garbage collector.</p>"},{"location":"python/structure/structure/#first-class-object","title":"First-Class Object","text":"<p>All objects in Python are said to be first-class. This means that all objects that can be assigned to a name can also be treated as data. As data, objects can be stored as variables, passed as arguments, returned from functions, compared against other objects, and more.</p>"},{"location":"python/structure/structure/#object-protocol-and-data-abstraction","title":"Object Protocol and Data Abstraction","text":"<p>Unlike a compiler for a static language, Python does not verify correct program behavior in advance. Instead, the behavior of an object is determined by a dynamic process that involves the dispatch of so-called \"special\" or \"magic\" methods. The names of these special methods are always preceded and followed by double underscores (<code>__</code>). The methods are automatically triggered by the interpreter as a program executes. For example, the operation <code>x * y</code> is carried out by a method <code>x.__mul(y)</code>. The names of these methods and their corresponding operators are hard-wired. The behavior of any given object depends entirely on the set of special methods that it implements.</p> <p>The next few sections describe the special methods associated with different categories of core interpreter features. These categories are sometimes called \"protocols.\" An object, including a user-defined class, may define any combination of these features to make the object behave in different ways. <pre><code>### Generate Markdown Table for Dunder\n\n| Method                      | Description                                 |\n|-----------------------------|---------------------------------------------|\n| `__init__(self, *args, **kwargs)` | Initializes an instance.             |\n| `__del__(self)`                    | Called when an instance is being destroyed.|\n| `__repr__(self)`                   | Creates a string representation.           |\n| `__new__(self)`                    | Creates a new instance.                    |\n\n### Object Management Methods\n\n| Method                 | Description                  |\n|------------------------|------------------------------|\n| `__add__(self, other)` | Adds two objects together.    |\n| `__sub__(self, other)` | Subtracts one object from another. |\n| `__mul__(self, other)` | Multiplies two objects.       |\n| `__truediv__(self, other)` | Divides one object by another. |\n| `__floordiv__(self, other)` | Performs floor division.    |\n| `__mod__(self, other)` | Performs modulo operation.    |\n| `__matmul__(self, other)` | Performs matrix multiplication. |\n\n\n\nIf `__bool__()` is undefined, then `__len__()` is used as a fallback. If both `__bool__()` and `__len__()` are undefined, an object is simply considered to be True.\n\nThe `__eq__()` method is used to determine basic equality for use with the `==` and `!=` operators. The default implementation of `__eq__()` compares objects by identity using the `is` operator. The `__ne__()` method, if present, can be used to implement special processing for `!=`, but is usually not required as long as `__eq__()` is implemented.\n\nMatrices, returning a matrix with the results. If comparison is not possible, the methods should return the built-in object `NotImplemented`. This is not the same as the `NotImplementedError`.\n\nIt is not necessary for an ordered object to implement all of the comparison operations in Table 4.3. If you want to be able to sort objects or use functions such as `min()` or `max()`, then `__lt__()` must be minimally defined. If you are adding comparison operators to a user-defined class, the `@total_ordering` class decorator in the `functools` module may be of some use. It can generate all of the methods as long as you minimally implement `__eq__()` and one of the other comparisons.\n\nThe `__hash__()` method is defined on instances that are to be placed into a set or be used as keys in a mapping (dictionary). The value returned is an integer that should be the same for two instances that compare as equal. Moreover, `__eq__()` should always be defined together with `__hash__()` because the two methods work together. The value returned by `__hash__()` is typically used as an internal implementation detail of various data structures. However, it\u2019s possible for two different objects to have the same hash value. Therefore, `__eq__()` is necessary to resolve potential collisions.\n\nConversion Protocols\n\n- `__str__(self)`: Conversion to a string\n- `__bytes__(self)`: Conversion to bytes\n- `__format__(self, format_spec)`: Creates a formatted representation\n- `__bool__(self)`: bool(self)\n- `__int__(self)`: int(self)\n- `__float__(self)`: float(self)\n- `__complex__(self)`: __index__(self) Conversion to an integer index [self]\n\nExamples of formatting:\n\n- `f'{x:spec}'`: Calls `x.__format__('spec')`\n- `format(x, 'spec')`: Calls `x.__format__('spec')`\n- `'x is {0:spec}'.format(x)`: Calls `x.__format__('spec')`\n\nThe `__index__()` method performs an integer conversion of an object when it\u2019s used in an operation that requires an integer value. This includes indexing in sequence operations. For example, if `items` is a list, performing an operation such as `items[x]` will attempt to execute `items[x.__index__()]` if `x` is...\n\nContainer Protocols\n\n- `__len__(self)`: Returns length\n- `__getitem__(self, key)`: Returns `self[key]`\n- `__setitem__(self, key, value)`: Sets `self[key] = value`\n- `__delitem__(self, key)`: Deletes `self[key]`\n- `__contains__(self, obj)`: `obj in self`\n\nHere\u2019s an example:\n\n```python\na = [1, 2, 3, 4, 5, 6]\nlen(a)               # a.__len__()\nx = a[2]             # x = a.__getitem__(2)\na[1] = 7             # a.__setitem__(1, 7)\ndel a[2]             # a.__delitem__(2)\n5 in a               # a.__contains__(5)\n</code></pre></p> <p>Slicing operations such as <code>x = s[i:j]</code> are also implemented using <code>__getitem__()</code>, <code>__setitem__()</code>, and <code>__delitem__()</code>. For slices, a special slice instance is passed as the key. This instance has attributes that describe the range of the slice being requested. For example:</p> <pre><code>a = [1, 2, 3, 4, 5, 6]\nx = a[1:5]           # x = a.__getitem__(slice(1, 5, None))\na[1:3] = [10, 11, 12]  # a.__setitem__(slice(1, 3, None), [10, 11, 12])\ndel a[1:4]           # a.__delitem__(slice(1, 4, None))\n</code></pre> <p>The slicing features of Python are more powerful than many programmers realize. For example, the following variations of extended slicing are all supported and may be useful for working with multidimensional data structures such as matrices and arrays:</p> <pre><code>a = m[0:100:10]          # Strided slice (step=10)\nb = m[1:10, 3:20]        # Multidimensional slice\nc = m[0:100:10, 50:75:5] # Multiple dimensions with strides\nm[0:5, 5:10] = n         # Extended slice assignment\ndel m[:10, 15:]          # Extended slice deletion\n</code></pre>"},{"location":"python/structure/structure/#iterator-protocol","title":"Iterator Protocol","text":"<p>If an instance, <code>obj</code>, supports iteration, it provides a method, <code>obj.iter()</code>, that returns an iterator. An iterator <code>iter</code>, in turn, implements a single method, <code>iter.next()</code>, that returns the next object or raises <code>StopIteration</code> to signal the end of iteration. These methods are used by the implementation of the <code>for</code> statement as well as other operations that implicitly perform iteration. For example, the statement <code>for x in s</code> is carried out by performing these steps:</p> <pre><code>_iter = s.__iter__()\nwhile True:\n    try:\n         x = _iter.__next__()\n    except StopIteration:\n         break\n    # Do statements in body of for loop\n</code></pre> <p>Sample Iterator</p> <pre><code>class FRange:\n    def __init__(self, start, stop, step):\n        self.start = start\n        self.stop = stop\n        self.step = step\n\n    def __iter__(self):\n        x = self.start\n        while x &lt; self.stop:\n            yield x\n            x += self.step\n\n# Example use:\nnums = FRange(0.0, 1.0, 0.1)\nfor x in nums:\n    print(x)     # 0.0, 0.1, 0.2, 0.3, ...\n</code></pre>"},{"location":"python/structure/structure/#attribute-access","title":"Attribute Access","text":"<ul> <li><code>__getattribute__(self, name)</code>: Returns the attribute <code>self.name</code></li> <li><code>__getattr__(self, name)</code>: Returns the attribute <code>self.name</code> if it\u2019s not found through <code>__getattribute__()</code></li> <li><code>__setattr__(self, name, value)</code>: Sets the attribute <code>self.name = value</code></li> <li><code>__delattr__(self, name)</code></li> </ul>"},{"location":"python/structure/structure/#function-protocol","title":"Function Protocol","text":"<p>An object can emulate a function by providing the <code>__call__()</code> method. If an object, <code>x</code>, provides this method, it can be invoked like a function. That is, <code>x(arg1, arg2, ...)</code> invokes <code>x.__call__(arg1, arg2, ...)</code>. There are many built-in types that support function calls. For example, types implement <code>__call__()</code> to create new instances. Bound methods implement <code>__call__()</code> to pass the <code>self</code> argument to instance methods. Library functions such as <code>functools.partial()</code> also create objects that emulate functions.</p>"},{"location":"python/structure/structure/#context-manager-protocol","title":"Context Manager Protocol","text":"<p>The <code>with</code> statement allows a sequence of statements to execute under the control of an instance known as a context manager. The general syntax is as follows:</p> <pre><code>with context [ as var]:\n     statements\n</code></pre> <p>A context object shown here is expected to implement the</p>"},{"location":"python/structure/structure/#use-repr","title":"Use <code>repr</code>","text":"<p>Just use <code>repr</code> it's good for debugging in the REPL.</p>"},{"location":"python/structure/structure/#docs","title":"Docs","text":"<p>Docstring is stored in the <code>__doc__</code> attribute. The documentation string is stored in the <code>doc</code> attribute of the function. It\u2019s often accessed by IDEs to provide interactive help. Functions can also be annotated with type hints. For example:</p>"},{"location":"python/structure/structure/#passing-arguments","title":"Passing Arguments","text":"<p>You can pass arguments like this:</p> <pre><code>def func(x, y, z):\n    ...\ns = (1, 2, 3)\n# Pass a sequence as arguments\nresult = func(*s)\n# Pass a mapping as keyword arguments\nd = { 'x':1, 'y':2, 'z':3 }\nresult = func(**d)\n</code></pre>"},{"location":"python/structure/structure/#tuple-example","title":"Tuple Example","text":"<pre><code>from typing import NamedTuple\n\nclass ParseResult(NamedTuple):\n    name: str\n    value: str\n\ndef parse_value(text):\n    '''\n    Split text of the form name=val into (name, val)\n    '''\n    parts = text.split('=', 1)\n    return ParseResult(parts[0].strip(), parts[1].strip())\n\nr = parse_value('url=http://www.python.org')\nprint(r.name, r.value)\n</code></pre>"},{"location":"python/structure/structure/#avoid-using-global-statement","title":"Avoid Using Global Statement","text":"<p>It should be noted that use of the global statement is usually considered poor Python style. If you\u2019re writing code where a function needs to mutate state behind the scenes, consider using a class definition and modify state by mutating an instance or class variable instead. For example:</p> <pre><code>class Config:\n    x = 42\n\ndef func():\n    Config.x = 13\n</code></pre> <p>Python allows nested function definitions. Here\u2019s an example:</p>"},{"location":"python/structure/structure/#inner-functions","title":"Inner Functions","text":"<p><code>nonlocal</code> cannot be used to refer to a global variable\u2014it must reference a local variable in an outer scope. Thus, if a function is assigning to a global, you should still use the global declaration.</p> <p>Use of nested functions and <code>nonlocal</code> declarations is not a common programming style. For example, inner functions have no outside visibility, which can complicate testing and debugging. Nevertheless, nested functions are sometimes useful for breaking recursion.</p> <ul> <li>Current limit: <code>sys.getrecursionlimit()</code> default is 1000</li> <li>Set limit: <code>sys.setrecursionlimit()</code></li> </ul>"},{"location":"python/structure/structure/#lambda-functions","title":"Lambda Functions","text":"<pre><code>x = 2\nf = lambda y: x * y\nx = 3\ng = lambda y: x * y\nprint(f(10))       # --&gt; prints 30\nprint(g(10))       # --&gt; prints 30\n</code></pre> <p>This is called late binding.</p> <pre><code>x = 2\nf = lambda y, x=x: x * y\nx = 3\ng = lambda y, x=x: x * y\n</code></pre>"},{"location":"python/structure/structure/#higher-order-functions","title":"Higher-Order Functions","text":"<p>Python supports the concept of higher-order functions. This means that functions can be passed as arguments to other functions, placed in data structures, and returned by a function as a result. Functions are said to be first-class objects, meaning there is no difference between how you might handle a function and any other kind of data.</p>"},{"location":"python/structure/structure/#function-as-callback-with-parameters","title":"Function as Callback with Parameters","text":"<pre><code>after(10, lambda: add(2, 3))\n\nfrom functools import partial\nafter(10, partial(add, 2, 3))\n</code></pre> <p>Since partials are fully evaluated, the callables created by <code>partial()</code> are objects that can be serialized into bytes, saved in files, and even transmitted across network connections (for example, using the <code>pickle</code> standard library module). This is not possible with a lambda function. Thus, in applications where functions are passed around, possibly to Python interpreters running in different processes or on different machines, you\u2019ll find <code>partial()</code> to be a bit more adaptable. As an aside, partial function application is closely related to a </p>"},{"location":"python/structure/structure/#decorators","title":"Decorators","text":"<p>Shorthand of Decorators</p> <pre><code>func = decorate(func)\n</code></pre> <pre><code>from functools import wraps\n\ndef trace(func):\n    @wraps(func)\n    def call(*args, **kwargs):\n        print('Calling', func.__name__)\n        return func(*args, **kwargs)\n    return call\n</code></pre> <p>The <code>@wraps()</code> decorator copies various function metadata to the replacement function. In this case, metadata from the given function <code>func()</code> is copied to the returned wrapper function <code>call()</code>.</p> <p>Multiple Decorators</p> <pre><code>@decorator1\n@decorator2\ndef func(x):\n    pass\n</code></pre> <p>The above code is equivalent to:</p> <pre><code>func = decorator1(decorator2(func))\n</code></pre>"},{"location":"python/structure/structure/#function-inspections","title":"Function Inspections","text":"<ul> <li><code>f.__name__</code>: Function name</li> <li><code>f.__qualname__</code>: Fully qualified name (if nested)</li> <li><code>f.__module__</code>: Name of module in which defined</li> <li><code>f.__doc__</code>: Documentation string</li> <li><code>f.__annotations__</code>: Type hints</li> <li><code>f.__globals__</code>: Dictionary that is the global namespace</li> <li><code>f.__closure__</code>: Closure variables (if any)</li> <li><code>f.__code__</code>: Underlying code object</li> </ul>"},{"location":"python/structure/structure/#check-if-two-function-parameters-are-the-same","title":"Check if Two Function Parameters are the Same","text":"<pre><code>import inspect\n\ndef func(x: int, y: float, debug=False) -&gt; float:\n    pass\n\nsig = inspect.signature(func)\n\nassert inspect.signature(func1) == inspect.signature(func2)\n</code></pre> <p>Attributes are not visible within the function body\u2014they are not local variables and do not appear as names in the execution environment. The main use of function attributes is to store extra metadata. Sometimes frameworks or various metaprogramming techniques utilize function tagging\u2014that is, attaching attributes to functions. One example is the <code>@abstractmethod</code> decorator that\u2019s used on methods within abstract base classes.</p> <pre><code>def func():\n    statements\n\nfunc.secure = 1\nfunc.private = 1\n</code></pre>"},{"location":"python/structure/structure/#frame-attributes","title":"Frame Attributes","text":"<ul> <li><code>f.f_back</code>: Previous stack frame (toward the caller)</li> <li><code>f.f_code</code>: Code object being executed</li> <li><code>f.f_locals</code>: Dictionary of local variables (<code>locals()</code>)</li> <li><code>f.f_globals</code>: Dictionary used for global variables (<code>globals()</code>)</li> <li><code>f.f_builtins</code>: Dictionary used for built-in names</li> <li><code>f.f_lineno</code>: Line number</li> <li><code>f.f_lasti</code>: Current instruction. This is an index into the bytecode string of <code>f_code</code>.</li> <li><code>f.f_trace</code>: Function called at the start of each source code line</li> </ul> <pre><code>import inspect\nfrom collections import ChainMap\n\ndef debug(*varnames):\n    f = inspect.currentframe().f_back  # Previous stack\n    vars = ChainMap(f.f_locals, f.f_globals)\n    print(f'{f.f_code.co_filename}:{f.f_lineno}')\n    for name in varnames:\n        print(f'    {name} = {vars[name]!r}')\n\n# Example use\ndef func(x, y):\n    z = x + y\n    debug('x', 'y')  # Shows x and y along with file/line\n</code></pre>"},{"location":"python/structure/structure/#dynamic-code-execution","title":"Dynamic Code Execution","text":"<pre><code>exec(str [, globals [, locals]])\n</code></pre> <pre><code>globs = {'x': 7,\n         'y': 10,\n         'birds': ['Parrot', 'Swallow', 'Albatross']\n         }\nlocs = {}\nexec('z = 3 * x + 4 * y', globs, locs)\nexec('for b in birds: print(b)', globs, locs)\n</code></pre> <pre><code>def make_init(*names):\n    parms = ','.join(names)\n    code = f'def __init__(self, {parms}):\\n'\n    for name in names:\n        code += f' self.{name} = {name}\\n'\n    d = {}\n    exec(code, d)\n    return d['__init__']\n\n# Example use\nclass Vector:\n    __init__ = make_init('x', 'y', 'z')\n</code></pre>"},{"location":"python/structure/structure/#positional-and-named-arguments","title":"Positional and Named Arguments","text":"<pre><code>def func(x, y, /):\n    pass\n\nfunc(1, 2)     # Ok\nfunc(1, y=2)   # Error\n</code></pre>"},{"location":"python/structure/structure/#name-and-docstring","title":"Name and Docstring","text":"<ul> <li><code>__name__</code></li> <li><code>__doc__</code></li> </ul>"},{"location":"python/structure/structure/#argument-passing","title":"Argument Passing","text":"<p>Everything is passed by reference, but extra care is needed only for mutable types. Pass ready parameters to functions.</p> <pre><code>def func(x, y, z):\n    ...\n\ns = (1, 2, 3)\n# Pass a sequence as arguments\nresult = func(*s)\n# Pass a mapping as keyword arguments\nd = {'x': 1, 'y': 2, 'z': 3}\nresult = func(**d)\n</code></pre>"},{"location":"python/structure/structure/#namedtuple","title":"NamedTuple","text":"<pre><code>from typing import NamedTuple\n\nclass ParseResult(NamedTuple):\n    name: str\n    value: str\n\ndef parse_value(text):\n    '''\n    Split text of the form name=val into (name, val)\n    '''\n    parts = text.split('=', 1)\n    return ParseResult(parts[0].strip(), parts[1].strip())\n</code></pre>"},{"location":"python/structure/structure/#late-binding","title":"Late Binding","text":"<pre><code>def func():\n    n += 1    # Error: UnboundLocalError\n</code></pre> <pre><code>x = 42\n\ndef func():\n    print(x)    # Fails. UnboundLocalError\n    x = 13\n</code></pre>"},{"location":"python/structure/structure/#async-function","title":"Async Function","text":"<p>Use of <code>await</code> is only valid within an enclosing async function definition. It\u2019s also a required part of making async functions execute. If you leave off the <code>await</code>, you\u2019ll find that the code breaks. The requirement of using <code>await</code> hints at a general usage issue with asynchronous functions. Namely, their different evaluation model prevents them from being used in combination with other parts of Python. Specifically, it is never possible to write code like <code>print(await twice(2))</code>\u2014at least not without an intervening <code>await</code> or <code>async</code> keyword.</p> <pre><code>async def twice(x):\n    return 2 * x\n\ndef main():\n    print(twice(2))         # Error. Doesn't execute the function\n    print(await twice(2))   # Error. Can't use await here.\n</code></pre>"},{"location":"python/structure/structure/#yield-and-return","title":"<code>yield</code> and <code>return</code>","text":"<pre><code>def func():\n    try:\n        next(f)\n    except StopIteration as e:\n        yield 37\n        return 42\n</code></pre> <pre><code>def countdown(n):\n    print('Counting down from', n)\n    try:\n        while n &gt; 0:\n            yield n\n            n = n - 1\n    finally:\n        print('Only made it to', n)\n</code></pre> <p>Generators are guaranteed to execute the <code>finally</code> block code even if the generator is not fully consumed\u2014it will execute when the abandoned generator is garbage-collected. Similarly, any cleanup code involving a context manager is also guaranteed to execute.</p>"},{"location":"python/structure/structure/#yield-from","title":"<code>yield from</code>","text":"<pre><code>def countup(stop):\n    n = 1\n    while n &lt;= stop:\n        yield n\n        n += 1\n\ndef countdown(start):\n    n = start\n    while n &gt; 0:\n        yield n\n        n -= 1\n\ndef up_and_down(n):\n    yield from countup(n)\n    yield from countdown(n)\n</code></pre> <p><code>yield from</code> is especially useful when writing code that must recursively iterate through nested iterables.</p> <pre><code>def flatten(items):\n    for i in items:\n        if isinstance(i, list):\n            yield from flatten(i)\n        else:\n            yield i\n</code></pre>"},{"location":"python/structure/structure/#avoiding-recursion-limit","title":"Avoiding Recursion Limit","text":"<pre><code>def flatten(items):\n    stack = [iter(items)]\n    while stack:\n        try:\n            item = next(stack[-1])\n            if isinstance(item, list):\n                stack.append(iter(item))\n            else:\n                yield item\n        except StopIteration:\n            stack.pop()\n</code></pre>"},{"location":"python/structure/structure/#sending-values-to-enhanced-generators-coroutines","title":"Sending Values to Enhanced Generators (Coroutines)","text":"<pre><code>def receiver():\n    print('Ready to receive')\n    while True:\n        n = yield\n        print('Got', n)\n</code></pre> <pre><code>r = receiver()\nr.send(None)        # Advances to the first yield\nprint(r.send(1))\nprint(r.send(2))\nprint(r.send('Hello'))\n</code></pre>"},{"location":"python/structure/structure/#check-throw-and-close-method-in-internet","title":"Check <code>throw()</code> and <code>close()</code> Method in Internet","text":""},{"location":"python/structure/structure/#enhanced-generators","title":"Enhanced Generators","text":"<p>Enhanced generators are an odd programming construct. Unlike a simple generator which naturally feeds a for loop, there is no core language feature that drives an enhanced generator. Why, then, would you ever want a function that needs values to be sent to it? Is it purely academic? Historically, enhanced generators have been used in the context of concurrency libraries\u2014especially those based on asynchronous I/O. In that context, they\u2019re usually referred to as coroutines or generator-based coroutines. However, much of that functionality has been folded into the <code>async</code> and <code>await</code> features of Python. There is little practical reason to use <code>yield</code> for that specific use case. That said, there are still some practical applications. Like generators, an enhanced generator can be used to implement different kinds of evaluation and control flow. One example is the <code>@contextmanager</code> decorator found in the <code>contextlib</code> module.</p> <pre><code>class Manager:\n    def __enter__(self):\n        return somevalue\n    def __exit__(self, ty, val, tb):\n        if ty:\n            # An exception occurred\n            ...\n            # Return True/ if handled. False otherwise\n</code></pre> <p>With the <code>@contextmanager</code> generator, everything prior to the <code>yield</code> statement executes when the manager enters (via the <code>enter()</code> method). Everything after the <code>yield</code> executes when the manager exits (via the <code>exit()</code> method). If an error took place, it is reported as an exception on the <code>yield</code> statement. Here's a book on the internet where you can find more information about this topic.</p>"},{"location":"python/structure/structure/#final-words-a-brief-history-of-generators-and-looking-forward","title":"Final Words: A Brief History of Generators and Looking Forward","text":"<p>Generators are one of Python\u2019s more interesting success stories. They are also part of a greater story concerning iteration. Iteration is one of the most common programming tasks of all. In early versions of Python, iteration was implemented via sequence indexing and the <code>__getitem__()</code> method. This later evolved into the current iteration protocol based on <code>__iter__()</code> and <code>__next__()</code> methods. Generators appeared shortly thereafter as a more convenient way to implement an iterator. In modern Python, there is almost no reason to ever implement an iterator using anything other than a generator. Even on iterable objects that you might define yourself, the <code>__iter__()</code> method itself is conveniently implemented in this way.</p> <p>In later versions of Python, generators took on a new role as they evolved enhanced features related to coroutines\u2014the <code>send()</code> and <code>throw()</code> methods. These were no longer limited to iteration but opened up possibilities for using generators in other contexts. Most notably, this formed the basis of many so-called async frameworks used for network programming and concurrency. However, as asynchronous programming has evolved, most of this has transformed into later features that use the <code>async</code>/<code>await</code> syntax. Thus, it\u2019s not so common to see generator functions used outside of the context of iteration\u2014their original purpose. In fact, if you find yourself defining a generator function and you\u2019re not sure why, it\u2019s worth questioning whether or not it\u2019s necessary.</p>"},{"location":"python/structure/structure/#function-introspection","title":"Function Introspection","text":"<p>Here are some useful function introspection attributes:</p> <ul> <li><code>f.__name__</code>: Function name</li> <li><code>f.__qualname__</code>: Fully qualified name</li> <li><code>f.__module__</code>: Module name</li> <li><code>f.__doc__</code>: Docstring</li> <li><code>f.__annotations__</code>: Type hints</li> <li><code>f.__globals__</code>: Dictionary of global namespace</li> <li><code>f.__closure__</code>: Closure variables</li> <li><code>f.__code__</code>: Code object</li> </ul>"}]}