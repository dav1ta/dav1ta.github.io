
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../algorithms/">
      
      
        <link rel="next" href="../orm_sql/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.4">
    
    
      
        <title>AI - Elibrary</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction-to-ai-and-its-subfields" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Elibrary" class="md-header__button md-logo" aria-label="Elibrary" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Elibrary
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              AI
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Elibrary" class="md-nav__button md-logo" aria-label="Elibrary" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Elibrary
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Classes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Classes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/classes/classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/classes/data_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/classes/descriptors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Descriptors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/classes/iterators/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iterators
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/context_managers/context_managers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Context Managers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Data Types
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Data Types
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/data_types/data_types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/data_types/dic_set/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dict & Set
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/data_types/list_tuple/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    List & Tuple
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/data_types/object/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Object
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/decorators/decorators/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Decorators
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6" >
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Modules
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            Modules
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/modules/builtins/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Builtins
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/modules/io/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/modules/modules/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7" >
        
          
          <label class="md-nav__link" for="__nav_2_7" id="__nav_2_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Structure
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_7">
            <span class="md-nav__icon md-icon"></span>
            Structure
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/structure/code_design/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Design
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/structure/dessign_patterns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Design Patterns
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/structure/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/structure/practices/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/structure/solid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SOLID
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/structure/structure/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Structure
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_8" id="__nav_2_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Async
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8">
            <span class="md-nav__icon md-icon"></span>
            Async
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/async/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    asyncio
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/testing/pytest_fixtures.py" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Testing
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Docker
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Docker
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../docker/docker-compose/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docker Compose
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Postgres
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Postgres
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../postgresql/tricks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perfomance tricks
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    GitLab
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            GitLab
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../gitlab/install/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Kubernetes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Kubernetes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/architecture/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Architecture
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/backup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Backup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/deployments/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deployments
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/image-security/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Security
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/lifecycle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lifecycle
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/maintanence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Maintenance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/monitoring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Monitoring
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/namespaces/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Namespaces
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/newtwork/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Network
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/pods/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pods
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/replicasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ReplicaSets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/roles/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Roles
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/security/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Security
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/services/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Services
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kubernetes/sheduler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scheduler
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Programming
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Programming
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../code_review/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Review
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../algorithms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Algorithms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    AI
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    AI
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#history-and-evolution-of-ai" class="md-nav__link">
    <span class="md-ellipsis">
      History and Evolution of AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#subfields-of-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Subfields of AI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Subfields of AI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#machine-learning-ml" class="md-nav__link">
    <span class="md-ellipsis">
      Machine Learning (ML)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-learning-dl" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Learning (DL)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#natural-language-processing-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Natural Language Processing (NLP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning (RL)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mathematical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-algebra" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Algebra
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linear Algebra">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vectors-matrices-and-tensors" class="md-nav__link">
    <span class="md-ellipsis">
      Vectors, Matrices, and Tensors
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probability-and-statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Probability and Statistics
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#calculus" class="md-nav__link">
    <span class="md-ellipsis">
      Calculus
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-to-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction to Deep Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concept-of-artificial-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Concept of Artificial Neural Networks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#forward-propagation-and-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      Forward Propagation and Backpropagation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#types-of-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Types of Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Types of Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-layer-perceptrons-mlp" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Layer Perceptrons (MLP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-networks-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks (CNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-networks-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Recurrent Neural Networks (RNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short-Term Memory (LSTM)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-deep-learning-models" class="md-nav__link">
    <span class="md-ellipsis">
      Training Deep Learning Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specific-deep-learning-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      Specific Deep Learning Architectures
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cnn-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resnet-residual-network" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet (Residual Network)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg-visual-geometry-group" class="md-nav__link">
    <span class="md-ellipsis">
      VGG (Visual Geometry Group)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inception" class="md-nav__link">
    <span class="md-ellipsis">
      Inception
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-model" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#natural-language-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Natural Language Processing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basics-of-nlp-and-text-representation-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Basics of NLP and Text Representation Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Basics of NLP and Text Representation Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bag-of-words" class="md-nav__link">
    <span class="md-ellipsis">
      Bag of Words
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf" class="md-nav__link">
    <span class="md-ellipsis">
      TF-IDF
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      Word Embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-nlp-models-and-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced NLP Models and Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced NLP Models and Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnns-and-lstms" class="md-nav__link">
    <span class="md-ellipsis">
      RNNs and LSTMs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-model_1" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#language-models-like-gpt-and-bert" class="md-nav__link">
    <span class="md-ellipsis">
      Language Models like GPT and BERT
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-of-agents-environment-states-actions-and-rewards" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts of Agents, Environment, States, Actions, and Rewards
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-based-vs-model-free-reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Model-Based vs Model-Free Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algorithms-q-learning-sarsa-and-dqn" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithms: Q-Learning, SARSA, and DQN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#calculus-extended" class="md-nav__link">
    <span class="md-ellipsis">
      CALCULUS EXTENDED
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CALCULUS EXTENDED">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dot-product" class="md-nav__link">
    <span class="md-ellipsis">
      Dot Product
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-multiplication" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix Multiplication
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eigendecomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Eigendecomposition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vectormatrix-norms" class="md-nav__link">
    <span class="md-ellipsis">
      Vector/Matrix Norms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse-of-a-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Inverse of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular-value-decomposition-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Singular Value Decomposition (SVD)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vectormatrix-norms_1" class="md-nav__link">
    <span class="md-ellipsis">
      Vector/Matrix Norms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse-of-a-matrix_1" class="md-nav__link">
    <span class="md-ellipsis">
      Inverse of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular-value-decomposition-svd_1" class="md-nav__link">
    <span class="md-ellipsis">
      Singular Value Decomposition (SVD)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonal-vectors-and-matrices" class="md-nav__link">
    <span class="md-ellipsis">
      Orthogonal Vectors and Matrices
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rank-of-a-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Rank of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trace-of-a-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Trace of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#determinant-of-a-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Determinant of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-transpose" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix Transpose
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introduction-to-linear-transformations" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction to Linear Transformations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-factorization" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix Factorization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensors-in-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Tensors in Deep Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cost-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Cost Functions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent-and-optimizers" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Descent and Optimizers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overfitting-underfitting-and-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      Overfitting, Underfitting and Regularization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-example-building-a-deep-neural-network-for-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Example: Building a Deep Neural Network for Image Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-networks-cnn_1" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks (CNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-networks-rnn_1" class="md-nav__link">
    <span class="md-ellipsis">
      Recurrent Neural Networks (RNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm_1" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short-Term Memory (LSTM)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specific-deep-learning-architectures_1" class="md-nav__link">
    <span class="md-ellipsis">
      Specific Deep Learning Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Specific Deep Learning Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cnn-architectures_1" class="md-nav__link">
    <span class="md-ellipsis">
      CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resnet-residual-network_1" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet (Residual Network)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg-visual-geometry-group_1" class="md-nav__link">
    <span class="md-ellipsis">
      VGG (Visual Geometry Group)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inception_1" class="md-nav__link">
    <span class="md-ellipsis">
      Inception
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-model_2" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans_1" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specific-deep-learning-architectures_2" class="md-nav__link">
    <span class="md-ellipsis">
      Specific Deep Learning Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Specific Deep Learning Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cnn-architectures_2" class="md-nav__link">
    <span class="md-ellipsis">
      CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resnet-residual-network_2" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet (Residual Network)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg-visual-geometry-group_2" class="md-nav__link">
    <span class="md-ellipsis">
      VGG (Visual Geometry Group)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inception_2" class="md-nav__link">
    <span class="md-ellipsis">
      Inception
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-model_3" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans_2" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-model-continued" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model - Continued
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans-continued" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs) - Continued
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#basics-of-nlp-and-text-representation-techniques-continued" class="md-nav__link">
    <span class="md-ellipsis">
      Basics of NLP and Text Representation Techniques - Continued
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Basics of NLP and Text Representation Techniques - Continued">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bag-of-words_1" class="md-nav__link">
    <span class="md-ellipsis">
      Bag of Words
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf_1" class="md-nav__link">
    <span class="md-ellipsis">
      TF-IDF
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-embeddings_1" class="md-nav__link">
    <span class="md-ellipsis">
      Word Embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-nlp-models-and-techniques-continued" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced NLP Models and Techniques - Continued
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced NLP Models and Techniques - Continued">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnns-and-lstms-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      RNNs and LSTMs in NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-transformers-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Using Transformers in NLP
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reinforcement-learning_1" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basics-of-reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Basics of Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Reinforcement Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deep Reinforcement Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#q-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Q-Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-q-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Q-Networks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Gradients
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../orm_sql/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ORM
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#history-and-evolution-of-ai" class="md-nav__link">
    <span class="md-ellipsis">
      History and Evolution of AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#subfields-of-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Subfields of AI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Subfields of AI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#machine-learning-ml" class="md-nav__link">
    <span class="md-ellipsis">
      Machine Learning (ML)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-learning-dl" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Learning (DL)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#natural-language-processing-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Natural Language Processing (NLP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning (RL)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mathematical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-algebra" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Algebra
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linear Algebra">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vectors-matrices-and-tensors" class="md-nav__link">
    <span class="md-ellipsis">
      Vectors, Matrices, and Tensors
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probability-and-statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Probability and Statistics
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#calculus" class="md-nav__link">
    <span class="md-ellipsis">
      Calculus
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-to-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction to Deep Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concept-of-artificial-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Concept of Artificial Neural Networks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#forward-propagation-and-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      Forward Propagation and Backpropagation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#types-of-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Types of Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Types of Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-layer-perceptrons-mlp" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Layer Perceptrons (MLP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-networks-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks (CNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-networks-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Recurrent Neural Networks (RNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short-Term Memory (LSTM)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-deep-learning-models" class="md-nav__link">
    <span class="md-ellipsis">
      Training Deep Learning Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specific-deep-learning-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      Specific Deep Learning Architectures
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cnn-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resnet-residual-network" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet (Residual Network)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg-visual-geometry-group" class="md-nav__link">
    <span class="md-ellipsis">
      VGG (Visual Geometry Group)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inception" class="md-nav__link">
    <span class="md-ellipsis">
      Inception
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-model" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#natural-language-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Natural Language Processing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basics-of-nlp-and-text-representation-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Basics of NLP and Text Representation Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Basics of NLP and Text Representation Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bag-of-words" class="md-nav__link">
    <span class="md-ellipsis">
      Bag of Words
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf" class="md-nav__link">
    <span class="md-ellipsis">
      TF-IDF
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      Word Embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-nlp-models-and-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced NLP Models and Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced NLP Models and Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnns-and-lstms" class="md-nav__link">
    <span class="md-ellipsis">
      RNNs and LSTMs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-model_1" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#language-models-like-gpt-and-bert" class="md-nav__link">
    <span class="md-ellipsis">
      Language Models like GPT and BERT
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-of-agents-environment-states-actions-and-rewards" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts of Agents, Environment, States, Actions, and Rewards
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-based-vs-model-free-reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Model-Based vs Model-Free Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algorithms-q-learning-sarsa-and-dqn" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithms: Q-Learning, SARSA, and DQN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#calculus-extended" class="md-nav__link">
    <span class="md-ellipsis">
      CALCULUS EXTENDED
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CALCULUS EXTENDED">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dot-product" class="md-nav__link">
    <span class="md-ellipsis">
      Dot Product
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-multiplication" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix Multiplication
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eigendecomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Eigendecomposition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vectormatrix-norms" class="md-nav__link">
    <span class="md-ellipsis">
      Vector/Matrix Norms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse-of-a-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Inverse of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular-value-decomposition-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Singular Value Decomposition (SVD)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vectormatrix-norms_1" class="md-nav__link">
    <span class="md-ellipsis">
      Vector/Matrix Norms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse-of-a-matrix_1" class="md-nav__link">
    <span class="md-ellipsis">
      Inverse of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular-value-decomposition-svd_1" class="md-nav__link">
    <span class="md-ellipsis">
      Singular Value Decomposition (SVD)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonal-vectors-and-matrices" class="md-nav__link">
    <span class="md-ellipsis">
      Orthogonal Vectors and Matrices
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rank-of-a-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Rank of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trace-of-a-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Trace of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#determinant-of-a-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Determinant of a Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-transpose" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix Transpose
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introduction-to-linear-transformations" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction to Linear Transformations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-factorization" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix Factorization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensors-in-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Tensors in Deep Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cost-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Cost Functions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent-and-optimizers" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Descent and Optimizers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overfitting-underfitting-and-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      Overfitting, Underfitting and Regularization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-example-building-a-deep-neural-network-for-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Example: Building a Deep Neural Network for Image Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-networks-cnn_1" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks (CNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-networks-rnn_1" class="md-nav__link">
    <span class="md-ellipsis">
      Recurrent Neural Networks (RNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm_1" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short-Term Memory (LSTM)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specific-deep-learning-architectures_1" class="md-nav__link">
    <span class="md-ellipsis">
      Specific Deep Learning Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Specific Deep Learning Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cnn-architectures_1" class="md-nav__link">
    <span class="md-ellipsis">
      CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resnet-residual-network_1" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet (Residual Network)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg-visual-geometry-group_1" class="md-nav__link">
    <span class="md-ellipsis">
      VGG (Visual Geometry Group)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inception_1" class="md-nav__link">
    <span class="md-ellipsis">
      Inception
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-model_2" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans_1" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specific-deep-learning-architectures_2" class="md-nav__link">
    <span class="md-ellipsis">
      Specific Deep Learning Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Specific Deep Learning Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cnn-architectures_2" class="md-nav__link">
    <span class="md-ellipsis">
      CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resnet-residual-network_2" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet (Residual Network)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg-visual-geometry-group_2" class="md-nav__link">
    <span class="md-ellipsis">
      VGG (Visual Geometry Group)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inception_2" class="md-nav__link">
    <span class="md-ellipsis">
      Inception
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-model_3" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans_2" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-model-continued" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Model - Continued
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans-continued" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs) - Continued
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#basics-of-nlp-and-text-representation-techniques-continued" class="md-nav__link">
    <span class="md-ellipsis">
      Basics of NLP and Text Representation Techniques - Continued
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Basics of NLP and Text Representation Techniques - Continued">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bag-of-words_1" class="md-nav__link">
    <span class="md-ellipsis">
      Bag of Words
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf_1" class="md-nav__link">
    <span class="md-ellipsis">
      TF-IDF
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-embeddings_1" class="md-nav__link">
    <span class="md-ellipsis">
      Word Embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-nlp-models-and-techniques-continued" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced NLP Models and Techniques - Continued
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced NLP Models and Techniques - Continued">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnns-and-lstms-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      RNNs and LSTMs in NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-transformers-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Using Transformers in NLP
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reinforcement-learning_1" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basics-of-reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Basics of Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Reinforcement Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deep Reinforcement Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#q-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Q-Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-q-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Q-Networks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Gradients
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="introduction-to-ai-and-its-subfields">Introduction to AI and its Subfields</h1>
<p>Artificial Intelligence (AI) has become a cornerstone of modern technology and is shaping the future of numerous industries such as healthcare, finance, entertainment, and transportation. In this section, we'll delve into the history and evolution of AI and explore its various subfields.</p>
<h2 id="history-and-evolution-of-ai">History and Evolution of AI</h2>
<p>The concept of AI isn't new. It dates back to ancient times, where myths and stories talked about artificial beings endowed with intelligence. However, the real pursuit of AI began in the mid-20th century.</p>
<p>John McCarthy, widely known as the "father of AI", coined the term 'Artificial Intelligence' in 1956. Early AI research focused on problem-solving and symbolic methods. It wasn't until the 1990s and 2000s, with the advent of machine learning and subsequently deep learning, that we've seen the explosion of AI applications we have today.</p>
<h2 id="subfields-of-ai">Subfields of AI</h2>
<p>Artificial Intelligence is a broad field and comprises several subfields. Here are a few key ones:</p>
<h3 id="machine-learning-ml">Machine Learning (ML)</h3>
<p>Machine learning is a subset of AI that gives computers the ability to learn without being explicitly programmed. This learning is achieved by training algorithms on data. Machine learning includes various techniques like linear regression, decision trees, and support vector machines.</p>
<h3 id="deep-learning-dl">Deep Learning (DL)</h3>
<p>Deep Learning is a subset of machine learning that uses artificial neural networks with several layers (hence the term "deep"). These models are inspired by the human brain and are designed to replicate the way humans learn.</p>
<h3 id="natural-language-processing-nlp">Natural Language Processing (NLP)</h3>
<p>NLP is a subfield of AI that focuses on the interaction between computers and humans through language. It involves several tasks, including language translation, sentiment analysis, and speech recognition.</p>
<h3 id="reinforcement-learning-rl">Reinforcement Learning (RL)</h3>
<p>Reinforcement Learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to achieve a goal. The agent learns from the consequences of its actions, rather than from being taught explicitly.</p>
<p>In the upcoming sections, we will explore these topics in depth, providing you with a comprehensive understanding of each field and how they contribute to the larger AI landscape.</p>
<h2 id="mathematical-foundations">Mathematical Foundations</h2>
<p>Before we delve deep into AI and Machine Learning, it's crucial to understand the mathematical foundations that form the basis of these technologies. This section will help you revise some basics and learn new concepts in linear algebra, probability, statistics, and calculus. No worries if you haven't done math for a while, we'll start with the basics and gradually progress to more advanced topics.</p>
<h2 id="linear-algebra">Linear Algebra</h2>
<p>Linear algebra is fundamental in the field of machine learning. Concepts like vectors, matrices, and tensors form the data structures in machine learning, while operations such as dot product, matrix multiplication, and eigendecomposition are essential for understanding how machine learning algorithms work.</p>
<h3 id="vectors-matrices-and-tensors">Vectors, Matrices, and Tensors</h3>
<p>Vectors are a sequence of numbers, matrices are 2D arrays of numbers, and tensors are n-dimensional arrays with n&gt;2. In Python, you can create vectors, matrices, and tensors using the numpy library.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="c1"># Creating a vector</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vector:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="c1"># Creating a matrix</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="c1"># Creating a tensor</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>              <span class="p">[[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">]],</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>              <span class="p">[[</span><span class="mi">19</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="p">[</span><span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">27</span><span class="p">]]])</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>(Note: More advanced linear algebra topics will be continued...)</p>
<h2 id="probability-and-statistics">Probability and Statistics</h2>
<p>Probability theory is the mathematical foundation of statistical machine learning. Concepts like random variables, probability distributions, expectation, and variance give us the tools to model the uncertainty inherent in machine learning algorithms.</p>
<p>Statistics is the discipline that allows us to make inferences and decisions under uncertainty. Descriptive statistics summarize and organize characteristics of a data set. Inferential statistics, on the other hand, allow us to make inferences and predictions based on data.</p>
<p>(Note: More advanced probability and statistics topics will be continued...)</p>
<h2 id="calculus">Calculus</h2>
<p>Calculus, especially differential calculus, plays a vital role in machine learning. Many machine learning algorithms involve optimization. To find the optimal solution, we need to understand concepts like derivatives and gradients.</p>
<p>(Note: More advanced calculus topics will be continued...)</p>
<p>This concludes the introduction to mathematical foundations for AI. The upcoming sections will dive deeper into each of these areas, equipping you with the necessary mathematical knowledge to excel in AI.</p>
<h2 id="introduction-to-deep-learning">Introduction to Deep Learning</h2>
<p>Deep Learning is a subset of machine learning that makes the computation of complex functions feasible by using artificial neural networks with many layers (hence the term "deep"). These methods have dramatically improved the state-of-the-art in fields like image recognition and speech recognition.</p>
<h2 id="concept-of-artificial-neural-networks">Concept of Artificial Neural Networks</h2>
<p>The fundamental building block of deep learning is the artificial neural network. These networks are inspired by the structure of the human brain, where interconnected neurons work together to process and learn from information.</p>
<p>A neural network consists of layers of nodes, where each node in a layer is connected to all nodes in the previous and next layers. Each connection has a weight, which the network adjusts during learning to minimize the difference between its predictions and actual values.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-1-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-1-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-1-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-1-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-1-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-1-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-1-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-1-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-1-10">10</a></span>
<span class="normal"><a href="#__codelineno-1-11">11</a></span>
<span class="normal"><a href="#__codelineno-1-12">12</a></span>
<span class="normal"><a href="#__codelineno-1-13">13</a></span>
<span class="normal"><a href="#__codelineno-1-14">14</a></span>
<span class="normal"><a href="#__codelineno-1-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="c1"># A simple example of creating a neural network using the keras library</span>
<a id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<a id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<a id="__codelineno-1-4" name="__codelineno-1-4"></a>
<a id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="c1"># Initialize the constructor</span>
<a id="__codelineno-1-6" name="__codelineno-1-6"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-1-7" name="__codelineno-1-7"></a>
<a id="__codelineno-1-8" name="__codelineno-1-8"></a><span class="c1"># Add an input layer </span>
<a id="__codelineno-1-9" name="__codelineno-1-9"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,)))</span>
<a id="__codelineno-1-10" name="__codelineno-1-10"></a>
<a id="__codelineno-1-11" name="__codelineno-1-11"></a><span class="c1"># Add one hidden layer </span>
<a id="__codelineno-1-12" name="__codelineno-1-12"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<a id="__codelineno-1-13" name="__codelineno-1-13"></a>
<a id="__codelineno-1-14" name="__codelineno-1-14"></a><span class="c1"># Add an output layer </span>
<a id="__codelineno-1-15" name="__codelineno-1-15"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
<h2 id="forward-propagation-and-backpropagation">Forward Propagation and Backpropagation</h2>
<p>Forward propagation is the process by which the neural network generates predictions. It starts from the input layer and moves through the hidden layers, applying the weights and activation functions, until it reaches the output layer.</p>
<p>Backpropagation, on the other hand, is the method used to update the weights in the neural network. After forward propagation, the network calculates the error between its prediction and the actual value. This error is then propagated backward through the network, adjusting the weights along the way.</p>
<p>(Note: More detailed explanation on forward propagation and backpropagation will be continued...)</p>
<h2 id="types-of-neural-networks">Types of Neural Networks</h2>
<p>There are several types of neural networks used in deep learning, including:</p>
<h3 id="multi-layer-perceptrons-mlp">Multi-Layer Perceptrons (MLP)</h3>
<p>MLP, also known as vanilla neural networks, are the simplest form of artificial neural network. They consist of at least three layers: an input layer, an output layer, and one or more hidden layers.</p>
<h3 id="convolutional-neural-networks-cnn">Convolutional Neural Networks (CNN)</h3>
<p>CNNs are primarily used for image processing, pattern recognition, and image classification. They consist of convolutional and pooling layers, followed by fully connected layers.</p>
<h3 id="recurrent-neural-networks-rnn">Recurrent Neural Networks (RNN)</h3>
<p>RNNs are designed to recognize patterns in sequences of data, such as text, genomes, handwriting, or the spoken word. Unlike traditional neural networks, RNNs have "memory" in the sense that information cycles through a loop, allowing information to persist.</p>
<h3 id="long-short-term-memory-lstm">Long Short-Term Memory (LSTM)</h3>
<p>LSTMs are a special kind of RNN that are capable of learning long-term dependencies. They're widely used in tasks that require remembering information for long periods.</p>
<p>(Note: More detailed information on types of neural networks will be continued...)</p>
<h2 id="training-deep-learning-models">Training Deep Learning Models</h2>
<p>Training a deep learning model involves feeding data through the network (forward propagation), calculating the error, and then adjusting the weights to minimize this error (backpropagation). This process is repeated for a number of iterations or until the model's performance is satisfactory.</p>
<p>(Note: More advanced topics on training deep learning models will be continued...)</p>
<p>This concludes the introduction to deep learning. The subsequent sections will elaborate more on these topics, allowing you to understand and apply deep learning techniques effectively.</p>
<h2 id="specific-deep-learning-architectures">Specific Deep Learning Architectures</h2>
<p>In deep learning, different architectures of neural networks are suitable for different types of tasks. In this section, we'll explore a few significant deep learning architectures including CNNs, Transformers, and GANs.</p>
<h2 id="cnn-architectures">CNN Architectures</h2>
<p>Convolutional Neural Networks (CNNs) have been instrumental in the field of computer vision. Over the years, researchers have proposed numerous CNN architectures. Let's look at a few:</p>
<h3 id="resnet-residual-network">ResNet (Residual Network)</h3>
<p>ResNet, introduced by Microsoft, is famous for its "skip connection" feature, allowing it to have over a hundred layers without suffering from the vanishing gradient problem.</p>
<h3 id="vgg-visual-geometry-group">VGG (Visual Geometry Group)</h3>
<p>VGG, developed by the Visual Geometry Group at Oxford, is known for its uniform architecture. It's straightforward and great at generalization but it's also resource-heavy.</p>
<h3 id="inception">Inception</h3>
<p>The Inception network, also known as GoogLeNet, was developed by researchers at Google. It introduced the inception module, a building block that, among other things, allows for more efficient computation and deeper networks.</p>
<p>(Note: More detailed explanation on CNN architectures will be continued...)</p>
<h2 id="transformer-model">Transformer Model</h2>
<p>The Transformer model, introduced in the paper "Attention is All You Need", is a type of neural network architecture primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models handle variable-length input using only attention mechanisms, leading to more parallelizable computation.</p>
<p>(Note: More detailed explanation on Transformer model will be continued...)</p>
<h2 id="generative-adversarial-networks-gans">Generative Adversarial Networks (GANs)</h2>
<p>Generative Adversarial Networks (GANs) are a class of AI algorithms used in unsupervised machine learning, which involves two neural networks competing against each other. GANs can generate new data that follows the same patterns as the training set. This feature makes them useful in a variety of applications, including image synthesis, semantic image editing, style transfer, and image super-resolution.</p>
<p>(Note: More detailed explanation on GANs will be continued...)</p>
<p>The architectures mentioned above have led to substantial improvements in tasks such as image recognition, object detection, and language understanding. The upcoming sections will delve deeper into these architectures, helping you understand the inner workings and how to implement them.</p>
<h2 id="natural-language-processing">Natural Language Processing</h2>
<p>Natural Language Processing (NLP) is a branch of AI that helps computers understand, interpret and manipulate human language. This section will introduce you to the basics of NLP and various text representation techniques, as well as more advanced NLP models and techniques.</p>
<h2 id="basics-of-nlp-and-text-representation-techniques">Basics of NLP and Text Representation Techniques</h2>
<p>Processing natural language data involves several steps, starting from basic tokenization to complex parsing and semantic analysis. After processing, we often need to represent the text in a form that can be input to a machine learning or deep learning model.</p>
<h3 id="bag-of-words">Bag of Words</h3>
<p>Bag of Words (BoW) is a simple and commonly used way to represent text for use in machine learning, which ignores syntax and even word order, but is effective for several tasks.</p>
<h3 id="tf-idf">TF-IDF</h3>
<p>Term Frequency-Inverse Document Frequency (TF-IDF) is another way to represent text. It gives more weight to the more important words (i.e., words that are frequent in a document but not across documents).</p>
<h3 id="word-embeddings">Word Embeddings</h3>
<p>Word Embeddings are dense vector representations where words with similar meanings are mapped to similar vectors.</p>
<p>(Note: More advanced topics on text representation techniques will be continued...)</p>
<h2 id="advanced-nlp-models-and-techniques">Advanced NLP Models and Techniques</h2>
<h3 id="rnns-and-lstms">RNNs and LSTMs</h3>
<p>Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are effective for tasks involving sequential data, and they have been widely used in NLP for tasks such as text generation, sentiment analysis, and machine translation.</p>
<h3 id="transformer-model_1">Transformer Model</h3>
<p>The Transformer model, as previously discussed, is a type of architecture that uses self-attention mechanisms and has become the go-to model for many NLP tasks.</p>
<h4 id="language-models-like-gpt-and-bert">Language Models like GPT and BERT</h4>
<p>GPT (Generative Pre-trained Transformer) and BERT (Bidirectional Encoder Representations from Transformers) are large language models that have achieved state-of-the-art results on a variety of NLP tasks.</p>
<p>(Note: More detailed topics on advanced NLP models and techniques will be continued...)</p>
<p>This concludes the introduction to Natural Language Processing. The following sections will dive deeper into these areas, equipping you with the knowledge and skills needed to tackle various NLP tasks.</p>
<h2 id="reinforcement-learning">Reinforcement Learning</h2>
<p>Reinforcement Learning (RL) is an aspect of machine learning where an agent learns to behave in an environment, by performing certain actions and observing the results/rewards of those actions. This section will introduce key concepts in reinforcement learning and some fundamental algorithms.</p>
<h2 id="concepts-of-agents-environment-states-actions-and-rewards">Concepts of Agents, Environment, States, Actions, and Rewards</h2>
<p>In RL, an agent takes actions in an environment to achieve a goal. The environment presents a state to the agent, the agent takes action based on this state, and then the environment presents a new state and a reward to the agent. The agent's objective is to learn to take actions that maximize the cumulative reward over time.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-2-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-2-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-2-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-2-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-2-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-2-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-2-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-2-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-2-10">10</a></span>
<span class="normal"><a href="#__codelineno-2-11">11</a></span>
<span class="normal"><a href="#__codelineno-2-12">12</a></span>
<span class="normal"><a href="#__codelineno-2-13">13</a></span>
<span class="normal"><a href="#__codelineno-2-14">14</a></span>
<span class="normal"><a href="#__codelineno-2-15">15</a></span>
<span class="normal"><a href="#__codelineno-2-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="c1"># An illustrative example using OpenAI&#39;s gym library.</span>
<a id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="kn">import</span> <span class="nn">gym</span>
<a id="__codelineno-2-3" name="__codelineno-2-3"></a>
<a id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="c1"># Create the environment</span>
<a id="__codelineno-2-5" name="__codelineno-2-5"></a><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">)</span>
<a id="__codelineno-2-6" name="__codelineno-2-6"></a>
<a id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="c1"># Initialize state</span>
<a id="__codelineno-2-8" name="__codelineno-2-8"></a><span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-2-9" name="__codelineno-2-9"></a>
<a id="__codelineno-2-10" name="__codelineno-2-10"></a><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
<a id="__codelineno-2-11" name="__codelineno-2-11"></a>    <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>  <span class="c1"># You can visualize the environment using render</span>
<a id="__codelineno-2-12" name="__codelineno-2-12"></a>    <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Here we&#39;re just sampling random actions</span>
<a id="__codelineno-2-13" name="__codelineno-2-13"></a>    <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>  <span class="c1"># The agent takes a step in the environment</span>
<a id="__codelineno-2-14" name="__codelineno-2-14"></a>    <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
<a id="__codelineno-2-15" name="__codelineno-2-15"></a>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode finished after </span><span class="si">{}</span><span class="s2"> timesteps&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-2-16" name="__codelineno-2-16"></a>        <span class="k">break</span>
</code></pre></div></td></tr></table></div>
<h2 id="model-based-vs-model-free-reinforcement-learning">Model-Based vs Model-Free Reinforcement Learning</h2>
<p>In model-based RL, the agent has a model of the environment, i.e., it knows or learns the probabilities of landing in any state given the current state and action. In model-free RL, the agent doesn't have this knowledge and must learn entirely from trial-and-error.</p>
<h2 id="algorithms-q-learning-sarsa-and-dqn">Algorithms: Q-Learning, SARSA, and DQN</h2>
<p>There are various algorithms for implementing reinforcement learning. Q-Learning and SARSA (State-Action-Reward-State-Action) are fundamental model-free methods that learn the value of taking each action in each state. Deep Q-Network (DQN) extends Q-Learning to large state-action spaces by using neural networks to approximate the Q-function.</p>
<p>(Note: More detailed topics on RL algorithms will be continued...)</p>
<p>This introduction provides a glimpse into the fascinating world of Reinforcement Learning. Subsequent sections will elaborate further on these topics, providing a deeper understanding and practical applications of various RL techniques.</p>
<h2 id="calculus-extended">CALCULUS EXTENDED</h2>
<h3 id="dot-product">Dot Product</h3>
<p>The dot product, or scalar product, is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors) and returns a single number. It is an essential operation in machine learning as it measures the similarity between vectors.</p>
<p>In Python, you can compute the dot product between two vectors using the <code>numpy.dot()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1">1</a></span>
<span class="normal"><a href="#__codelineno-3-2">2</a></span>
<span class="normal"><a href="#__codelineno-3-3">3</a></span>
<span class="normal"><a href="#__codelineno-3-4">4</a></span>
<span class="normal"><a href="#__codelineno-3-5">5</a></span>
<span class="normal"><a href="#__codelineno-3-6">6</a></span>
<span class="normal"><a href="#__codelineno-3-7">7</a></span>
<span class="normal"><a href="#__codelineno-3-8">8</a></span>
<span class="normal"><a href="#__codelineno-3-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-3-2" name="__codelineno-3-2"></a>
<a id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="c1"># Define two vectors</span>
<a id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<a id="__codelineno-3-6" name="__codelineno-3-6"></a>
<a id="__codelineno-3-7" name="__codelineno-3-7"></a><span class="c1"># Compute the dot product</span>
<a id="__codelineno-3-8" name="__codelineno-3-8"></a><span class="n">dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
<a id="__codelineno-3-9" name="__codelineno-3-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dot Product:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">dot_product</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="matrix-multiplication">Matrix Multiplication</h3>
<p>Matrix multiplication, also known as the matrix dot product, is a binary operation that produces a matrix from two matrices. It's a fundamental operation in machine learning and deep learning, often used for transforming data, training models, and more.</p>
<p>In Python, you can compute the matrix multiplication between two matrices using the <code>numpy.matmul()</code> or <code>numpy.dot()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1">1</a></span>
<span class="normal"><a href="#__codelineno-4-2">2</a></span>
<span class="normal"><a href="#__codelineno-4-3">3</a></span>
<span class="normal"><a href="#__codelineno-4-4">4</a></span>
<span class="normal"><a href="#__codelineno-4-5">5</a></span>
<span class="normal"><a href="#__codelineno-4-6">6</a></span>
<span class="normal"><a href="#__codelineno-4-7">7</a></span>
<span class="normal"><a href="#__codelineno-4-8">8</a></span>
<span class="normal"><a href="#__codelineno-4-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-4-2" name="__codelineno-4-2"></a>
<a id="__codelineno-4-3" name="__codelineno-4-3"></a><span class="c1"># Define two matrices</span>
<a id="__codelineno-4-4" name="__codelineno-4-4"></a><span class="n">m1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<a id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="n">m2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<a id="__codelineno-4-6" name="__codelineno-4-6"></a>
<a id="__codelineno-4-7" name="__codelineno-4-7"></a><span class="c1"># Compute the matrix multiplication</span>
<a id="__codelineno-4-8" name="__codelineno-4-8"></a><span class="n">mat_mul</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">)</span>
<a id="__codelineno-4-9" name="__codelineno-4-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matrix Multiplication:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mat_mul</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="eigendecomposition">Eigendecomposition</h3>
<p>Eigendecomposition is the factorization of a matrix into a canonical form, whereby the matrix is represented in terms of its eigenvalues and eigenvectors. Only diagonalizable matrices can be factorized in this way. This is a common operation used for dimensionality reduction techniques like PCA.</p>
<p>In Python, you can perform the eigendecomposition of a matrix using the <code>numpy.linalg.eig()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-5-1">1</a></span>
<span class="normal"><a href="#__codelineno-5-2">2</a></span>
<span class="normal"><a href="#__codelineno-5-3">3</a></span>
<span class="normal"><a href="#__codelineno-5-4">4</a></span>
<span class="normal"><a href="#__codelineno-5-5">5</a></span>
<span class="normal"><a href="#__codelineno-5-6">6</a></span>
<span class="normal"><a href="#__codelineno-5-7">7</a></span>
<span class="normal"><a href="#__codelineno-5-8">8</a></span>
<span class="normal"><a href="#__codelineno-5-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-5-2" name="__codelineno-5-2"></a>
<a id="__codelineno-5-3" name="__codelineno-5-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-5-4" name="__codelineno-5-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-5-5" name="__codelineno-5-5"></a>
<a id="__codelineno-5-6" name="__codelineno-5-6"></a><span class="c1"># Compute the eigendecomposition</span>
<a id="__codelineno-5-7" name="__codelineno-5-7"></a><span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-5-8" name="__codelineno-5-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvalues:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">eigenvalues</span><span class="p">)</span>
<a id="__codelineno-5-9" name="__codelineno-5-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvectors:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="vectormatrix-norms">Vector/Matrix Norms</h3>
<p>A vector norm is a measure of the "length" of a vector. For a matrix, the norm is a measure of "magnitude". The most common norm, often simply called "the norm" of a vector, is the L2 norm or Euclidean norm.</p>
<p>In Python, you can calculate the norm of a vector or matrix using the <code>numpy.linalg.norm()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-6-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-6-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-6-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-6-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-6-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-6-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-6-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-6-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-6-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-6-10">10</a></span>
<span class="normal"><a href="#__codelineno-6-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-6-2" name="__codelineno-6-2"></a>
<a id="__codelineno-6-3" name="__codelineno-6-3"></a><span class="c1"># Define a vector and a matrix</span>
<a id="__codelineno-6-4" name="__codelineno-6-4"></a><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-6-5" name="__codelineno-6-5"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<a id="__codelineno-6-6" name="__codelineno-6-6"></a>
<a id="__codelineno-6-7" name="__codelineno-6-7"></a><span class="c1"># Compute the L2 norm (Euclidean norm)</span>
<a id="__codelineno-6-8" name="__codelineno-6-8"></a><span class="n">v_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<a id="__codelineno-6-9" name="__codelineno-6-9"></a><span class="n">m_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-6-10" name="__codelineno-6-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vector L2 norm:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">v_norm</span><span class="p">)</span>
<a id="__codelineno-6-11" name="__codelineno-6-11"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matrix Frobenius norm:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">m_norm</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="inverse-of-a-matrix">Inverse of a Matrix</h3>
<p>The inverse of a matrix A is a matrix denoted as A^-1, such that when A is multiplied by A^-1 the result is the identity matrix I. Not all matrices have an inverse. This concept is crucial for solving systems of linear equations.</p>
<p>In Python, you can compute the inverse of a matrix using the <code>numpy.linalg.inv()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-7-1">1</a></span>
<span class="normal"><a href="#__codelineno-7-2">2</a></span>
<span class="normal"><a href="#__codelineno-7-3">3</a></span>
<span class="normal"><a href="#__codelineno-7-4">4</a></span>
<span class="normal"><a href="#__codelineno-7-5">5</a></span>
<span class="normal"><a href="#__codelineno-7-6">6</a></span>
<span class="normal"><a href="#__codelineno-7-7">7</a></span>
<span class="normal"><a href="#__codelineno-7-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-7-2" name="__codelineno-7-2"></a>
<a id="__codelineno-7-3" name="__codelineno-7-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-7-4" name="__codelineno-7-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-7-5" name="__codelineno-7-5"></a>
<a id="__codelineno-7-6" name="__codelineno-7-6"></a><span class="c1"># Compute the inverse of the matrix</span>
<a id="__codelineno-7-7" name="__codelineno-7-7"></a><span class="n">m_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-7-8" name="__codelineno-7-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Inverse of Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">m_inv</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="singular-value-decomposition-svd">Singular Value Decomposition (SVD)</h3>
<p>SVD is a factorization of a real or complex matrix. It has many practical applications in signal processing and statistics. In machine learning, it's often used for dimensionality reduction, noise reduction, and recommendation systems.</p>
<p>In Python, you can perform the SVD of a matrix using the <code>numpy.linalg.svd()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-8-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-8-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-8-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-8-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-8-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-8-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-8-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-8-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-8-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-8-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-8-2" name="__codelineno-8-2"></a>
<a id="__codelineno-8-3" name="__codelineno-8-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-8-4" name="__codelineno-8-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-8-5" name="__codelineno-8-5"></a>
<a id="__codelineno-8-6" name="__codelineno-8-6"></a><span class="c1"># Compute the Singular Value Decomposition</span>
<a id="__codelineno-8-7" name="__codelineno-8-7"></a><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-8-8" name="__codelineno-8-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;U:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
<a id="__codelineno-8-9" name="__codelineno-8-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;S:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
<a id="__codelineno-8-10" name="__codelineno-8-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;VT:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">VT</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="vectormatrix-norms_1">Vector/Matrix Norms</h3>
<p>A vector norm is a measure of the "length" of a vector. For a matrix, the norm is a measure of "magnitude". The most common norm, often simply called "the norm" of a vector, is the L2 norm or Euclidean norm.</p>
<p>In Python, you can calculate the norm of a vector or matrix using the <code>numpy.linalg.norm()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-9-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-9-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-9-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-9-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-9-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-9-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-9-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-9-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-9-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-9-10">10</a></span>
<span class="normal"><a href="#__codelineno-9-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-9-2" name="__codelineno-9-2"></a>
<a id="__codelineno-9-3" name="__codelineno-9-3"></a><span class="c1"># Define a vector and a matrix</span>
<a id="__codelineno-9-4" name="__codelineno-9-4"></a><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-9-5" name="__codelineno-9-5"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<a id="__codelineno-9-6" name="__codelineno-9-6"></a>
<a id="__codelineno-9-7" name="__codelineno-9-7"></a><span class="c1"># Compute the L2 norm (Euclidean norm)</span>
<a id="__codelineno-9-8" name="__codelineno-9-8"></a><span class="n">v_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<a id="__codelineno-9-9" name="__codelineno-9-9"></a><span class="n">m_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-9-10" name="__codelineno-9-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vector L2 norm:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">v_norm</span><span class="p">)</span>
<a id="__codelineno-9-11" name="__codelineno-9-11"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matrix Frobenius norm:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">m_norm</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="inverse-of-a-matrix_1">Inverse of a Matrix</h3>
<p>The inverse of a matrix A is a matrix denoted as A^-1, such that when A is multiplied by A^-1 the result is the identity matrix I. Not all matrices have an inverse. This concept is crucial for solving systems of linear equations.</p>
<p>In Python, you can compute the inverse of a matrix using the <code>numpy.linalg.inv()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-10-1">1</a></span>
<span class="normal"><a href="#__codelineno-10-2">2</a></span>
<span class="normal"><a href="#__codelineno-10-3">3</a></span>
<span class="normal"><a href="#__codelineno-10-4">4</a></span>
<span class="normal"><a href="#__codelineno-10-5">5</a></span>
<span class="normal"><a href="#__codelineno-10-6">6</a></span>
<span class="normal"><a href="#__codelineno-10-7">7</a></span>
<span class="normal"><a href="#__codelineno-10-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-10-2" name="__codelineno-10-2"></a>
<a id="__codelineno-10-3" name="__codelineno-10-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-10-4" name="__codelineno-10-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-10-5" name="__codelineno-10-5"></a>
<a id="__codelineno-10-6" name="__codelineno-10-6"></a><span class="c1"># Compute the inverse of the matrix</span>
<a id="__codelineno-10-7" name="__codelineno-10-7"></a><span class="n">m_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-10-8" name="__codelineno-10-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Inverse of Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">m_inv</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="singular-value-decomposition-svd_1">Singular Value Decomposition (SVD)</h3>
<p>SVD is a factorization of a real or complex matrix. It has many practical applications in signal processing and statistics. In machine learning, it's often used for dimensionality reduction, noise reduction, and recommendation systems.</p>
<p>In Python, you can perform the SVD of a matrix using the <code>numpy.linalg.svd()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-11-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-11-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-11-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-11-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-11-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-11-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-11-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-11-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-11-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-11-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-11-2" name="__codelineno-11-2"></a>
<a id="__codelineno-11-3" name="__codelineno-11-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-11-4" name="__codelineno-11-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-11-5" name="__codelineno-11-5"></a>
<a id="__codelineno-11-6" name="__codelineno-11-6"></a><span class="c1"># Compute the Singular Value Decomposition</span>
<a id="__codelineno-11-7" name="__codelineno-11-7"></a><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-11-8" name="__codelineno-11-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;U:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
<a id="__codelineno-11-9" name="__codelineno-11-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;S:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
<a id="__codelineno-11-10" name="__codelineno-11-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;VT:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">VT</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="orthogonal-vectors-and-matrices">Orthogonal Vectors and Matrices</h3>
<p>Two vectors are orthogonal to each other if their dot product equals zero. An orthogonal matrix is a square matrix whose columns and rows are orthogonal unit vectors (i.e., orthonormal vectors).</p>
<p>In Python, you can check the orthogonality of two vectors or matrices:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-12-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-12-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-12-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-12-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-12-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-12-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-12-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-12-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-12-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-12-10">10</a></span>
<span class="normal"><a href="#__codelineno-12-11">11</a></span>
<span class="normal"><a href="#__codelineno-12-12">12</a></span>
<span class="normal"><a href="#__codelineno-12-13">13</a></span>
<span class="normal"><a href="#__codelineno-12-14">14</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-12-2" name="__codelineno-12-2"></a>
<a id="__codelineno-12-3" name="__codelineno-12-3"></a><span class="c1"># Define two orthogonal vectors</span>
<a id="__codelineno-12-4" name="__codelineno-12-4"></a><span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-12-5" name="__codelineno-12-5"></a><span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-12-6" name="__codelineno-12-6"></a>
<a id="__codelineno-12-7" name="__codelineno-12-7"></a><span class="c1"># Their dot product should be zero</span>
<a id="__codelineno-12-8" name="__codelineno-12-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dot Product:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">))</span>
<a id="__codelineno-12-9" name="__codelineno-12-9"></a>
<a id="__codelineno-12-10" name="__codelineno-12-10"></a><span class="c1"># Define an orthogonal matrix</span>
<a id="__codelineno-12-11" name="__codelineno-12-11"></a><span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<a id="__codelineno-12-12" name="__codelineno-12-12"></a>
<a id="__codelineno-12-13" name="__codelineno-12-13"></a><span class="c1"># Its transpose should be equal to its inverse</span>
<a id="__codelineno-12-14" name="__codelineno-12-14"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Q Transpose equals Q Inverse:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">)))</span>
</code></pre></div></td></tr></table></div>
<h3 id="rank-of-a-matrix">Rank of a Matrix</h3>
<p>The rank of a matrix is the maximum number of linearly independent column vectors in the matrix. It's a fundamental concept in linear algebra, giving the dimension of the vector space generated (or spanned) by its columns.</p>
<p>In Python, you can calculate the rank of a matrix using the <code>numpy.linalg.matrix_rank()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-13-1">1</a></span>
<span class="normal"><a href="#__codelineno-13-2">2</a></span>
<span class="normal"><a href="#__codelineno-13-3">3</a></span>
<span class="normal"><a href="#__codelineno-13-4">4</a></span>
<span class="normal"><a href="#__codelineno-13-5">5</a></span>
<span class="normal"><a href="#__codelineno-13-6">6</a></span>
<span class="normal"><a href="#__codelineno-13-7">7</a></span>
<span class="normal"><a href="#__codelineno-13-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-13-2" name="__codelineno-13-2"></a>
<a id="__codelineno-13-3" name="__codelineno-13-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-13-4" name="__codelineno-13-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-13-5" name="__codelineno-13-5"></a>
<a id="__codelineno-13-6" name="__codelineno-13-6"></a><span class="c1"># Compute the rank of the matrix</span>
<a id="__codelineno-13-7" name="__codelineno-13-7"></a><span class="n">rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-13-8" name="__codelineno-13-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Rank of Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="trace-of-a-matrix">Trace of a Matrix</h3>
<p>The trace of an n-by-n square matrix A is the sum of the elements on the main diagonal. The trace of a matrix is invariant under rotation (i.e., it remains the same if the matrix is rotated).</p>
<p>In Python, you can calculate the trace of a matrix using the <code>numpy.trace()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-14-1">1</a></span>
<span class="normal"><a href="#__codelineno-14-2">2</a></span>
<span class="normal"><a href="#__codelineno-14-3">3</a></span>
<span class="normal"><a href="#__codelineno-14-4">4</a></span>
<span class="normal"><a href="#__codelineno-14-5">5</a></span>
<span class="normal"><a href="#__codelineno-14-6">6</a></span>
<span class="normal"><a href="#__codelineno-14-7">7</a></span>
<span class="normal"><a href="#__codelineno-14-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-14-2" name="__codelineno-14-2"></a>
<a id="__codelineno-14-3" name="__codelineno-14-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-14-4" name="__codelineno-14-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-14-5" name="__codelineno-14-5"></a>
<a id="__codelineno-14-6" name="__codelineno-14-6"></a><span class="c1"># Compute the trace of the matrix</span>
<a id="__codelineno-14-7" name="__codelineno-14-7"></a><span class="n">trace</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-14-8" name="__codelineno-14-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Trace of Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">trace</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="determinant-of-a-matrix">Determinant of a Matrix</h3>
<p>The determinant is a special number that can be calculated from a square matrix. It provides important information about the matrix and can be used to solve systems of equations, to find the inverse of a matrix, and to describe the geometric transformations caused by the matrix.</p>
<p>In Python, you can compute the determinant of a matrix using the <code>numpy.linalg.det()</code> function:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-15-1">1</a></span>
<span class="normal"><a href="#__codelineno-15-2">2</a></span>
<span class="normal"><a href="#__codelineno-15-3">3</a></span>
<span class="normal"><a href="#__codelineno-15-4">4</a></span>
<span class="normal"><a href="#__codelineno-15-5">5</a></span>
<span class="normal"><a href="#__codelineno-15-6">6</a></span>
<span class="normal"><a href="#__codelineno-15-7">7</a></span>
<span class="normal"><a href="#__codelineno-15-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-15-2" name="__codelineno-15-2"></a>
<a id="__codelineno-15-3" name="__codelineno-15-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-15-4" name="__codelineno-15-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<a id="__codelineno-15-5" name="__codelineno-15-5"></a>
<a id="__codelineno-15-6" name="__codelineno-15-6"></a><span class="c1"># Compute the determinant of the matrix</span>
<a id="__codelineno-15-7" name="__codelineno-15-7"></a><span class="n">det</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-15-8" name="__codelineno-15-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Determinant of Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">det</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="matrix-transpose">Matrix Transpose</h3>
<p>Transposing a matrix is the process of swapping the row and column indices of each element, essentially reflecting the elements across the main diagonal. It's a fundamental operation in linear algebra and finds many uses in computations related to machine learning.</p>
<p>In Python, you can compute the transpose of a matrix using the <code>numpy.transpose()</code> function or <code>T</code> attribute:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-16-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-16-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-16-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-16-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-16-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-16-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-16-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-16-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-16-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-16-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-16-2" name="__codelineno-16-2"></a>
<a id="__codelineno-16-3" name="__codelineno-16-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-16-4" name="__codelineno-16-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-16-5" name="__codelineno-16-5"></a>
<a id="__codelineno-16-6" name="__codelineno-16-6"></a><span class="c1"># Compute the transpose of the matrix</span>
<a id="__codelineno-16-7" name="__codelineno-16-7"></a><span class="n">m_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-16-8" name="__codelineno-16-8"></a><span class="c1"># or</span>
<a id="__codelineno-16-9" name="__codelineno-16-9"></a><span class="n">m_t</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">T</span>
<a id="__codelineno-16-10" name="__codelineno-16-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Transpose of Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">m_t</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="introduction-to-linear-transformations">Introduction to Linear Transformations</h3>
<p>Linear transformations are a cornerstone of linear algebra. They are functions that map one vector space to another, preserving the operations of vector addition and scalar multiplication. In the context of machine learning, linear transformations are often used for feature scaling, dimensionality reduction, etc.</p>
<p>For instance, let's scale a vector by a factor of 2 and rotate it by 90 degrees:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-17-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-17-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-17-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-17-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-17-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-17-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-17-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-17-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-17-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-17-10">10</a></span>
<span class="normal"><a href="#__codelineno-17-11">11</a></span>
<span class="normal"><a href="#__codelineno-17-12">12</a></span>
<span class="normal"><a href="#__codelineno-17-13">13</a></span>
<span class="normal"><a href="#__codelineno-17-14">14</a></span>
<span class="normal"><a href="#__codelineno-17-15">15</a></span>
<span class="normal"><a href="#__codelineno-17-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-17-2" name="__codelineno-17-2"></a>
<a id="__codelineno-17-3" name="__codelineno-17-3"></a><span class="c1"># Define a vector</span>
<a id="__codelineno-17-4" name="__codelineno-17-4"></a><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-17-5" name="__codelineno-17-5"></a>
<a id="__codelineno-17-6" name="__codelineno-17-6"></a><span class="c1"># Scaling transformation</span>
<a id="__codelineno-17-7" name="__codelineno-17-7"></a><span class="n">scale_factor</span> <span class="o">=</span> <span class="mi">2</span>
<a id="__codelineno-17-8" name="__codelineno-17-8"></a><span class="n">v_scaled</span> <span class="o">=</span> <span class="n">scale_factor</span> <span class="o">*</span> <span class="n">v</span>
<a id="__codelineno-17-9" name="__codelineno-17-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scaled Vector:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">v_scaled</span><span class="p">)</span>
<a id="__codelineno-17-10" name="__codelineno-17-10"></a>
<a id="__codelineno-17-11" name="__codelineno-17-11"></a><span class="c1"># Rotation transformation</span>
<a id="__codelineno-17-12" name="__codelineno-17-12"></a><span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">radians</span><span class="p">(</span><span class="mi">90</span><span class="p">)</span>  <span class="c1"># convert degrees to radians</span>
<a id="__codelineno-17-13" name="__codelineno-17-13"></a><span class="n">rotation_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)],</span> 
<a id="__codelineno-17-14" name="__codelineno-17-14"></a>                            <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span>  <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)]])</span>  <span class="c1"># rotation matrix</span>
<a id="__codelineno-17-15" name="__codelineno-17-15"></a><span class="n">v_rotated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rotation_matrix</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a id="__codelineno-17-16" name="__codelineno-17-16"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Rotated Vector:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">v_rotated</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="matrix-factorization">Matrix Factorization</h3>
<p>Matrix Factorization techniques are usually a step in dimensionality reduction or latent semantic analysis. They are essential in recommendation systems, where they are used to predict user interaction with items.</p>
<p>For example, Singular Value Decomposition (SVD) is a type of matrix factorization. In Python, you can use the <code>numpy.linalg.svd()</code> function to factorize a matrix:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-18-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-18-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-18-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-18-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-18-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-18-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-18-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-18-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-18-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-18-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="__codelineno-18-2" name="__codelineno-18-2"></a>
<a id="__codelineno-18-3" name="__codelineno-18-3"></a><span class="c1"># Define a matrix</span>
<a id="__codelineno-18-4" name="__codelineno-18-4"></a><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-18-5" name="__codelineno-18-5"></a>
<a id="__codelineno-18-6" name="__codelineno-18-6"></a><span class="c1"># Compute the Singular Value Decomposition</span>
<a id="__codelineno-18-7" name="__codelineno-18-7"></a><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-18-8" name="__codelineno-18-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;U:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
<a id="__codelineno-18-9" name="__codelineno-18-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;S:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
<a id="__codelineno-18-10" name="__codelineno-18-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;VT:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">VT</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="tensors-in-deep-learning">Tensors in Deep Learning</h3>
<p>A tensor is a container that can house data in N dimensions. They are a generalization of matrices. In the context of tensors, dimensions are often called "axes."</p>
<p>In deep learning, we use tensors pretty much exclusively, as they are a primary data structure that you'll work with as inputs, outputs, and transformations.</p>
<p>In Python, using libraries such as TensorFlow or PyTorch, you can create and manipulate tensors:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-19-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-19-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-19-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-19-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-19-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-19-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-19-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-19-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-19-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-19-10">10</a></span>
<span class="normal"><a href="#__codelineno-19-11">11</a></span>
<span class="normal"><a href="#__codelineno-19-12">12</a></span>
<span class="normal"><a href="#__codelineno-19-13">13</a></span>
<span class="normal"><a href="#__codelineno-19-14">14</a></span>
<span class="normal"><a href="#__codelineno-19-15">15</a></span>
<span class="normal"><a href="#__codelineno-19-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1"></a><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<a id="__codelineno-19-2" name="__codelineno-19-2"></a>
<a id="__codelineno-19-3" name="__codelineno-19-3"></a><span class="c1"># Create a tensor</span>
<a id="__codelineno-19-4" name="__codelineno-19-4"></a><span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<a id="__codelineno-19-5" name="__codelineno-19-5"></a>
<a id="__codelineno-19-6" name="__codelineno-19-6"></a><span class="c1"># Multiply tensors</span>
<a id="__codelineno-19-7" name="__codelineno-19-7"></a><span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<a id="__codelineno-19-8" name="__codelineno-19-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor multiplication:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
<a id="__codelineno-19-9" name="__codelineno-19-9"></a>
<a id="__codelineno-19-10" name="__codelineno-19-10"></a><span class="c1"># Reduce_sum</span>
<a id="__codelineno-19-11" name="__codelineno-19-11"></a><span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<a id="__codelineno-19-12" name="__codelineno-19-12"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor reduce_sum:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
<a id="__codelineno-19-13" name="__codelineno-19-13"></a>
<a id="__codelineno-19-14" name="__codelineno-19-14"></a><span class="c1"># Expand dimensions</span>
<a id="__codelineno-19-15" name="__codelineno-19-15"></a><span class="n">expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-19-16" name="__codelineno-19-16"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Expanded tensor shape:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">expanded</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h2 id="activation-functions">Activation Functions</h2>
<p>In an artificial neural network, an activation function defines the output of a neuron given an input or set of inputs. Activation functions are vital for a neural network to learn and make sense of something really complicated.</p>
<p>Commonly used activation functions include:</p>
<ul>
<li>
<p><strong>Sigmoid</strong>: This activation function squashes values into a range between 0 and 1. It is especially useful for models where we have to predict the probability as an output.</p>
</li>
<li>
<p><strong>Tanh</strong>: The hyperbolic tangent function is similar to the sigmoid but squashes values between -1 and 1.</p>
</li>
<li>
<p><strong>ReLU</strong>: The Rectified Linear Unit is the most widely used activation function. It gives an output x if x is positive and 0 otherwise.</p>
</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-20-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-20-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-20-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-20-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-20-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-20-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-20-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-20-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-20-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-20-10">10</a></span>
<span class="normal"><a href="#__codelineno-20-11">11</a></span>
<span class="normal"><a href="#__codelineno-20-12">12</a></span>
<span class="normal"><a href="#__codelineno-20-13">13</a></span>
<span class="normal"><a href="#__codelineno-20-14">14</a></span>
<span class="normal"><a href="#__codelineno-20-15">15</a></span>
<span class="normal"><a href="#__codelineno-20-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1"></a><span class="c1"># An example of using different activation functions in a neural network</span>
<a id="__codelineno-20-2" name="__codelineno-20-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Activation</span>
<a id="__codelineno-20-3" name="__codelineno-20-3"></a>
<a id="__codelineno-20-4" name="__codelineno-20-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-20-5" name="__codelineno-20-5"></a>
<a id="__codelineno-20-6" name="__codelineno-20-6"></a><span class="c1"># Using ReLU</span>
<a id="__codelineno-20-7" name="__codelineno-20-7"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
<a id="__codelineno-20-8" name="__codelineno-20-8"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<a id="__codelineno-20-9" name="__codelineno-20-9"></a>
<a id="__codelineno-20-10" name="__codelineno-20-10"></a><span class="c1"># Using sigmoid</span>
<a id="__codelineno-20-11" name="__codelineno-20-11"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
<a id="__codelineno-20-12" name="__codelineno-20-12"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
<a id="__codelineno-20-13" name="__codelineno-20-13"></a>
<a id="__codelineno-20-14" name="__codelineno-20-14"></a><span class="c1"># Using tanh</span>
<a id="__codelineno-20-15" name="__codelineno-20-15"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
<a id="__codelineno-20-16" name="__codelineno-20-16"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;tanh&#39;</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
<h2 id="cost-functions">Cost Functions</h2>
<p>A cost function, also known as a loss function, measures how well the neural network predictions match the actual values. During training, the neural network aims to minimize this cost function.</p>
<p>Commonly used cost functions include Mean Squared Error for regression tasks and Cross Entropy Loss for classification tasks.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-21-1">1</a></span>
<span class="normal"><a href="#__codelineno-21-2">2</a></span>
<span class="normal"><a href="#__codelineno-21-3">3</a></span>
<span class="normal"><a href="#__codelineno-21-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1"></a><span class="c1"># An example of compiling a model with a cost function</span>
<a id="__codelineno-21-2" name="__codelineno-21-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.losses</span> <span class="kn">import</span> <span class="n">BinaryCrossentropy</span>
<a id="__codelineno-21-3" name="__codelineno-21-3"></a>
<a id="__codelineno-21-4" name="__codelineno-21-4"></a><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h2 id="gradient-descent-and-optimizers">Gradient Descent and Optimizers</h2>
<p>Gradient descent is an optimization algorithm used to minimize the cost function. It works by iteratively adjusting the parameters (weights) of the model in the direction that minimally increases the cost function.</p>
<p>In practice, variations of gradient descent such as Stochastic Gradient Descent (SGD), RMSprop, or Adam are commonly used.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-22-1">1</a></span>
<span class="normal"><a href="#__codelineno-22-2">2</a></span>
<span class="normal"><a href="#__codelineno-22-3">3</a></span>
<span class="normal"><a href="#__codelineno-22-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1"></a><span class="c1"># An example of compiling a model with Adam optimizer</span>
<a id="__codelineno-22-2" name="__codelineno-22-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<a id="__codelineno-22-3" name="__codelineno-22-3"></a>
<a id="__codelineno-22-4" name="__codelineno-22-4"></a><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
<h2 id="overfitting-underfitting-and-regularization">Overfitting, Underfitting and Regularization</h2>
<p>In machine learning, overfitting occurs when a model learns the detail and noise in the training data to the extent that it performs poorly on new, unseen data. Underfitting, on the other hand, occurs when a model is too simple to learn the underlying structure of the data.</p>
<p>Regularization techniques are used to prevent overfitting. This includes methods like L1 and L2 regularization and dropout.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-23-1">1</a></span>
<span class="normal"><a href="#__codelineno-23-2">2</a></span>
<span class="normal"><a href="#__codelineno-23-3">3</a></span>
<span class="normal"><a href="#__codelineno-23-4">4</a></span>
<span class="normal"><a href="#__codelineno-23-5">5</a></span>
<span class="normal"><a href="#__codelineno-23-6">6</a></span>
<span class="normal"><a href="#__codelineno-23-7">7</a></span>
<span class="normal"><a href="#__codelineno-23-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1"></a><span class="c1"># An example of using dropout regularization</span>
<a id="__codelineno-23-2" name="__codelineno-23-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span>
<a id="__codelineno-23-3" name="__codelineno-23-3"></a>
<a id="__codelineno-23-4" name="__codelineno-23-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-23-5" name="__codelineno-23-5"></a>
<a id="__codelineno-23-6" name="__codelineno-23-6"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<a id="__codelineno-23-7" name="__codelineno-23-7"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<a id="__codelineno-23-8" name="__codelineno-23-8"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
<h2 id="practical-example-building-a-deep-neural-network-for-image-classification">Practical Example: Building a Deep Neural Network for Image Classification</h2>
<p>Let's implement a deep neural network for classifying images from the CIFAR-10 dataset. This dataset contains 60,000 32x32 color images in 10 different classes.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-24-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-24-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-24-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-24-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-24-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-24-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-24-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-24-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-24-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-24-10">10</a></span>
<span class="normal"><a href="#__codelineno-24-11">11</a></span>
<span class="normal"><a href="#__codelineno-24-12">12</a></span>
<span class="normal"><a href="#__codelineno-24-13">13</a></span>
<span class="normal"><a href="#__codelineno-24-14">14</a></span>
<span class="normal"><a href="#__codelineno-24-15">15</a></span>
<span class="normal"><a href="#__codelineno-24-16">16</a></span>
<span class="normal"><a href="#__codelineno-24-17">17</a></span>
<span class="normal"><a href="#__codelineno-24-18">18</a></span>
<span class="normal"><a href="#__codelineno-24-19">19</a></span>
<span class="normal"><a href="#__codelineno-24-20">20</a></span>
<span class="normal"><a href="#__codelineno-24-21">21</a></span>
<span class="normal"><a href="#__codelineno-24-22">22</a></span>
<span class="normal"><a href="#__codelineno-24-23">23</a></span>
<span class="normal"><a href="#__codelineno-24-24">24</a></span>
<span class="normal"><a href="#__codelineno-24-25">25</a></span>
<span class="normal"><a href="#__codelineno-24-26">26</a></span>
<span class="normal"><a href="#__codelineno-24-27">27</a></span>
<span class="normal"><a href="#__codelineno-24-28">28</a></span>
<span class="normal"><a href="#__codelineno-24-29">29</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1"></a><span class="c1"># Import necessary libraries</span>
<a id="__codelineno-24-2" name="__codelineno-24-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">cifar10</span>
<a id="__codelineno-24-3" name="__codelineno-24-3"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<a id="__codelineno-24-4" name="__codelineno-24-4"></a>
<a id="__codelineno-24-5" name="__codelineno-24-5"></a><span class="c1"># Load data</span>
<a id="__codelineno-24-6" name="__codelineno-24-6"></a><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<a id="__codelineno-24-7" name="__codelineno-24-7"></a>
<a id="__codelineno-24-8" name="__codelineno-24-8"></a><span class="c1"># Normalize pixel values to be between 0 and 1</span>
<a id="__codelineno-24-9" name="__codelineno-24-9"></a><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>
<a id="__codelineno-24-10" name="__codelineno-24-10"></a>
<a id="__codelineno-24-11" name="__codelineno-24-11"></a><span class="c1"># Convert class vectors to binary class matrices</span>
<a id="__codelineno-24-12" name="__codelineno-24-12"></a><span class="n">y_train</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<a id="__codelineno-24-13" name="__codelineno-24-13"></a><span class="n">y_test</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<a id="__codelineno-24-14" name="__codelineno-24-14"></a>
<a id="__codelineno-24-15" name="__codelineno-24-15"></a><span class="c1"># Define the model architecture</span>
<a id="__codelineno-24-16" name="__codelineno-24-16"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-24-17" name="__codelineno-24-17"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<a id="__codelineno-24-18" name="__codelineno-24-18"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<a id="__codelineno-24-19" name="__codelineno-24-19"></a>
<a id="__codelineno-24-20" name="__codelineno-24-20"></a><span class="c1"># Compile the model</span>
<a id="__codelineno-24-21" name="__codelineno-24-21"></a><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<a id="__codelineno-24-22" name="__codelineno-24-22"></a>
<a id="__codelineno-24-23" name="__codelineno-24-23"></a><span class="c1"># Train the model</span>
<a id="__codelineno-24-24" name="__codelineno-24-24"></a><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<a id="__codelineno-24-25" name="__codelineno-24-25"></a>
<a id="__codelineno-24-26" name="__codelineno-24-26"></a><span class="c1"># Evaluate the model</span>
<a id="__codelineno-24-27" name="__codelineno-24-27"></a><span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-24-28" name="__codelineno-24-28"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test loss:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-24-29" name="__codelineno-24-29"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
<h2 id="advanced-neural-networks">Advanced Neural Networks</h2>
<p>With the foundation of neural networks covered, we can now delve into more advanced architectures. Let's look at Convolutional Neural Networks and Recurrent Neural Networks in detail.</p>
<h3 id="convolutional-neural-networks-cnn_1">Convolutional Neural Networks (CNN)</h3>
<p>CNNs are primarily used for image processing, pattern recognition, and image classification. They are designed to automatically and adaptively learn spatial hierarchies of features from tasks with grid-like topology.</p>
<p>A CNN consists of an input and an output layer, as well as multiple hidden layers. The hidden layers of a CNN typically consist of convolutional layers, pooling layers, fully connected layers, and normalization layers.</p>
<p>Here is a simple example of a CNN architecture using Keras:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-25-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-25-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-25-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-25-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-25-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-25-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-25-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-25-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-25-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-25-10">10</a></span>
<span class="normal"><a href="#__codelineno-25-11">11</a></span>
<span class="normal"><a href="#__codelineno-25-12">12</a></span>
<span class="normal"><a href="#__codelineno-25-13">13</a></span>
<span class="normal"><a href="#__codelineno-25-14">14</a></span>
<span class="normal"><a href="#__codelineno-25-15">15</a></span>
<span class="normal"><a href="#__codelineno-25-16">16</a></span>
<span class="normal"><a href="#__codelineno-25-17">17</a></span>
<span class="normal"><a href="#__codelineno-25-18">18</a></span>
<span class="normal"><a href="#__codelineno-25-19">19</a></span>
<span class="normal"><a href="#__codelineno-25-20">20</a></span>
<span class="normal"><a href="#__codelineno-25-21">21</a></span>
<span class="normal"><a href="#__codelineno-25-22">22</a></span>
<span class="normal"><a href="#__codelineno-25-23">23</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Flatten</span>
<a id="__codelineno-25-2" name="__codelineno-25-2"></a>
<a id="__codelineno-25-3" name="__codelineno-25-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-25-4" name="__codelineno-25-4"></a>
<a id="__codelineno-25-5" name="__codelineno-25-5"></a><span class="c1"># The first convolution layer</span>
<a id="__codelineno-25-6" name="__codelineno-25-6"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<a id="__codelineno-25-7" name="__codelineno-25-7"></a>
<a id="__codelineno-25-8" name="__codelineno-25-8"></a><span class="c1"># The first pooling layer</span>
<a id="__codelineno-25-9" name="__codelineno-25-9"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<a id="__codelineno-25-10" name="__codelineno-25-10"></a>
<a id="__codelineno-25-11" name="__codelineno-25-11"></a><span class="c1"># The second convolution layer</span>
<a id="__codelineno-25-12" name="__codelineno-25-12"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<a id="__codelineno-25-13" name="__codelineno-25-13"></a>
<a id="__codelineno-25-14" name="__codelineno-25-14"></a><span class="c1"># The second pooling layer</span>
<a id="__codelineno-25-15" name="__codelineno-25-15"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<a id="__codelineno-25-16" name="__codelineno-25-16"></a>
<a id="__codelineno-25-17" name="__codelineno-25-17"></a><span class="c1"># Flattening the 2D arrays for fully connected layers</span>
<a id="__codelineno-25-18" name="__codelineno-25-18"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<a id="__codelineno-25-19" name="__codelineno-25-19"></a>
<a id="__codelineno-25-20" name="__codelineno-25-20"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<a id="__codelineno-25-21" name="__codelineno-25-21"></a>
<a id="__codelineno-25-22" name="__codelineno-25-22"></a><span class="c1"># The output layer</span>
<a id="__codelineno-25-23" name="__codelineno-25-23"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
<h3 id="recurrent-neural-networks-rnn_1">Recurrent Neural Networks (RNN)</h3>
<p>RNNs are a type of artificial neural network designed to recognize patterns in sequences of data, such as text, genomes, handwriting, or the spoken word. They are called recurrent because they perform the same task for every element of a sequence, with the output depending on the previous computations.</p>
<p>One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task. If you want to predict the next word in a sentence you better know which words came before it.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-26-1">1</a></span>
<span class="normal"><a href="#__codelineno-26-2">2</a></span>
<span class="normal"><a href="#__codelineno-26-3">3</a></span>
<span class="normal"><a href="#__codelineno-26-4">4</a></span>
<span class="normal"><a href="#__codelineno-26-5">5</a></span>
<span class="normal"><a href="#__codelineno-26-6">6</a></span>
<span class="normal"><a href="#__codelineno-26-7">7</a></span>
<span class="normal"><a href="#__codelineno-26-8">8</a></span>
<span class="normal"><a href="#__codelineno-26-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">SimpleRNN</span>
<a id="__codelineno-26-2" name="__codelineno-26-2"></a>
<a id="__codelineno-26-3" name="__codelineno-26-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-26-4" name="__codelineno-26-4"></a>
<a id="__codelineno-26-5" name="__codelineno-26-5"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<a id="__codelineno-26-6" name="__codelineno-26-6"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">32</span><span class="p">))</span>
<a id="__codelineno-26-7" name="__codelineno-26-7"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
<a id="__codelineno-26-8" name="__codelineno-26-8"></a>
<a id="__codelineno-26-9" name="__codelineno-26-9"></a><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
<h3 id="long-short-term-memory-lstm_1">Long Short-Term Memory (LSTM)</h3>
<p>LSTM is a special kind of RNN capable of learning long-term dependencies. They work tremendously well on a large variety of problems, and are now widely used. LSTM networks are well-suited to classifying, processing and making predictions based on time series data.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-27-1">1</a></span>
<span class="normal"><a href="#__codelineno-27-2">2</a></span>
<span class="normal"><a href="#__codelineno-27-3">3</a></span>
<span class="normal"><a href="#__codelineno-27-4">4</a></span>
<span class="normal"><a href="#__codelineno-27-5">5</a></span>
<span class="normal"><a href="#__codelineno-27-6">6</a></span>
<span class="normal"><a href="#__codelineno-27-7">7</a></span>
<span class="normal"><a href="#__codelineno-27-8">8</a></span>
<span class="normal"><a href="#__codelineno-27-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<a id="__codelineno-27-2" name="__codelineno-27-2"></a>
<a id="__codelineno-27-3" name="__codelineno-27-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-27-4" name="__codelineno-27-4"></a>
<a id="__codelineno-27-5" name="__codelineno-27-5"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<a id="__codelineno-27-6" name="__codelineno-27-6"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">))</span>
<a id="__codelineno-27-7" name="__codelineno-27-7"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
<a id="__codelineno-27-8" name="__codelineno-27-8"></a>
<a id="__codelineno-27-9" name="__codelineno-27-9"></a><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
<h2 id="specific-deep-learning-architectures_1">Specific Deep Learning Architectures</h2>
<p>Deep learning has led to the development of a variety of innovative neural network architectures that are tailored to different types of tasks. Let's delve deeper into these architectures and understand their mechanics.</p>
<h3 id="cnn-architectures_1">CNN Architectures</h3>
<p>Convolutional Neural Networks (CNNs) have been at the forefront of many breakthroughs in the field of computer vision. Different CNN architectures have been proposed over the years. </p>
<h4 id="resnet-residual-network_1">ResNet (Residual Network)</h4>
<p>Introduced by Microsoft, the ResNet architecture is unique due to its "skip connection" feature. This allows the model to have a large number of layers (even over 100) without suffering from the vanishing gradient problem.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-28-1">1</a></span>
<span class="normal"><a href="#__codelineno-28-2">2</a></span>
<span class="normal"><a href="#__codelineno-28-3">3</a></span>
<span class="normal"><a href="#__codelineno-28-4">4</a></span>
<span class="normal"><a href="#__codelineno-28-5">5</a></span>
<span class="normal"><a href="#__codelineno-28-6">6</a></span>
<span class="normal"><a href="#__codelineno-28-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">ResNet50</span>
<a id="__codelineno-28-2" name="__codelineno-28-2"></a>
<a id="__codelineno-28-3" name="__codelineno-28-3"></a><span class="c1"># Initialize a ResNet50 model with pre-trained weights</span>
<a id="__codelineno-28-4" name="__codelineno-28-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>
<a id="__codelineno-28-5" name="__codelineno-28-5"></a>
<a id="__codelineno-28-6" name="__codelineno-28-6"></a><span class="c1"># If you want to customize</span>
<a id="__codelineno-28-7" name="__codelineno-28-7"></a><span class="n">base_model</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="vgg-visual-geometry-group_1">VGG (Visual Geometry Group)</h4>
<p>The VGG architecture, developed by the Visual Geometry Group at Oxford, stands out due to its uniformity. It is simple, and great at generalization, but can be resource-heavy.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-29-1">1</a></span>
<span class="normal"><a href="#__codelineno-29-2">2</a></span>
<span class="normal"><a href="#__codelineno-29-3">3</a></span>
<span class="normal"><a href="#__codelineno-29-4">4</a></span>
<span class="normal"><a href="#__codelineno-29-5">5</a></span>
<span class="normal"><a href="#__codelineno-29-6">6</a></span>
<span class="normal"><a href="#__codelineno-29-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">VGG16</span>
<a id="__codelineno-29-2" name="__codelineno-29-2"></a>
<a id="__codelineno-29-3" name="__codelineno-29-3"></a><span class="c1"># Initialize a VGG16 model with pre-trained weights</span>
<a id="__codelineno-29-4" name="__codelineno-29-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>
<a id="__codelineno-29-5" name="__codelineno-29-5"></a>
<a id="__codelineno-29-6" name="__codelineno-29-6"></a><span class="c1"># If you want to customize</span>
<a id="__codelineno-29-7" name="__codelineno-29-7"></a><span class="n">base_model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="inception_1">Inception</h4>
<p>Inception, also known as GoogLeNet, was developed by researchers at Google. The inception module, a unique building block of this architecture, allows for more efficient computation and deeper networks.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-30-1">1</a></span>
<span class="normal"><a href="#__codelineno-30-2">2</a></span>
<span class="normal"><a href="#__codelineno-30-3">3</a></span>
<span class="normal"><a href="#__codelineno-30-4">4</a></span>
<span class="normal"><a href="#__codelineno-30-5">5</a></span>
<span class="normal"><a href="#__codelineno-30-6">6</a></span>
<span class="normal"><a href="#__codelineno-30-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">InceptionV3</span>
<a id="__codelineno-30-2" name="__codelineno-30-2"></a>
<a id="__codelineno-30-3" name="__codelineno-30-3"></a><span class="c1"># Initialize an InceptionV3 model with pre-trained weights</span>
<a id="__codelineno-30-4" name="__codelineno-30-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>
<a id="__codelineno-30-5" name="__codelineno-30-5"></a>
<a id="__codelineno-30-6" name="__codelineno-30-6"></a><span class="c1"># If you want to customize</span>
<a id="__codelineno-30-7" name="__codelineno-30-7"></a><span class="n">base_model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="transformer-model_2">Transformer Model</h3>
<p>The Transformer model is primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models use only attention mechanisms to handle variable-length input, making computation more parallelizable.</p>
<p>The most famous implementation of the Transformer model is probably the BERT (Bidirectional Encoder Representations from Transformers) model by Google.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-31-1">1</a></span>
<span class="normal"><a href="#__codelineno-31-2">2</a></span>
<span class="normal"><a href="#__codelineno-31-3">3</a></span>
<span class="normal"><a href="#__codelineno-31-4">4</a></span>
<span class="normal"><a href="#__codelineno-31-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertModel</span><span class="p">,</span> <span class="n">BertTokenizer</span>
<a id="__codelineno-31-2" name="__codelineno-31-2"></a>
<a id="__codelineno-31-3" name="__codelineno-31-3"></a><span class="c1"># Load pre-trained model and tokenizer</span>
<a id="__codelineno-31-4" name="__codelineno-31-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
<a id="__codelineno-31-5" name="__codelineno-31-5"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="generative-adversarial-networks-gans_1">Generative Adversarial Networks (GANs)</h3>
<p>Generative Adversarial Networks (GANs) involve two neural networks competing against each other in unsupervised machine learning tasks. GANs can generate new data that mimics the patterns of the training set. </p>
<p>Let's look at an example of implementing a simple GAN architecture:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-32-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-32-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-32-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-32-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-32-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-32-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-32-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-32-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-32-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-32-10">10</a></span>
<span class="normal"><a href="#__codelineno-32-11">11</a></span>
<span class="normal"><a href="#__codelineno-32-12">12</a></span>
<span class="normal"><a href="#__codelineno-32-13">13</a></span>
<span class="normal"><a href="#__codelineno-32-14">14</a></span>
<span class="normal"><a href="#__codelineno-32-15">15</a></span>
<span class="normal"><a href="#__codelineno-32-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span>
<a id="__codelineno-32-2" name="__codelineno-32-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<a id="__codelineno-32-3" name="__codelineno-32-3"></a>
<a id="__codelineno-32-4" name="__codelineno-32-4"></a><span class="c1"># The generator network</span>
<a id="__codelineno-32-5" name="__codelineno-32-5"></a><span class="n">g_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">])</span>
<a id="__codelineno-32-6" name="__codelineno-32-6"></a><span class="n">G</span> <span class="o">=</span> <span class="n">model_generator</span><span class="p">(</span><span class="n">g_input</span><span class="p">)</span>
<a id="__codelineno-32-7" name="__codelineno-32-7"></a><span class="n">G</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<a id="__codelineno-32-8" name="__codelineno-32-8"></a>
<a id="__codelineno-32-9" name="__codelineno-32-9"></a><span class="c1"># The discriminator network</span>
<a id="__codelineno-32-10" name="__codelineno-32-10"></a><span class="n">d_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-32-11" name="__codelineno-32-11"></a><span class="n">D</span> <span class="o">=</span> <span class="n">model_discriminator</span><span class="p">(</span><span class="n">d_input</span><span class="p">)</span>
<a id="__codelineno-32-12" name="__codelineno-32-12"></a><span class="n">D</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<a id="__codelineno-32-13" name="__codelineno-32-13"></a>
<a id="__codelineno-32-14" name="__codelineno-32-14"></a><span class="c1"># The GAN</span>
<a id="__codelineno-32-15" name="__codelineno-32-15"></a><span class="n">GAN</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">g_input</span><span class="p">,</span> <span class="n">D</span><span class="p">(</span><span class="n">G</span><span class="p">(</span><span class="n">g_input</span><span class="p">)))</span>
<a id="__codelineno-32-16" name="__codelineno-32-16"></a><span class="n">GAN</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<p>This code creates a simple GAN using Keras' functional API. The generator network <code>G</code> takes random noise as input and generates an image, while the discriminator network <code>D</code> takes an image (real or generated) as input and outputs a probability indicating how "real" the image is. The GAN model <code>GAN</code> chains the generator and the discriminator together: given random noise, it outputs the discriminator's assessment of the realism of the generated image.</p>
<p>Each of the architectures mentioned above has played a significant role in driving advancements in tasks such as image recognition, object detection, and language understanding. By delving deeper into these architectures, you will better understand their mechanics and learn how to leverage them in your own projects.</p>
<h2 id="specific-deep-learning-architectures_2">Specific Deep Learning Architectures</h2>
<p>Deep learning has led to the development of a variety of innovative neural network architectures that are tailored to different types of tasks. Let's delve deeper into these architectures and understand their mechanics.</p>
<h3 id="cnn-architectures_2">CNN Architectures</h3>
<p>Convolutional Neural Networks (CNNs) have been at the forefront of many breakthroughs in the field of computer vision. Different CNN architectures have been proposed over the years. </p>
<h4 id="resnet-residual-network_2">ResNet (Residual Network)</h4>
<p>Introduced by Microsoft, the ResNet architecture is unique due to its "skip connection" feature. This allows the model to have a large number of layers (even over 100) without suffering from the vanishing gradient problem.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-33-1">1</a></span>
<span class="normal"><a href="#__codelineno-33-2">2</a></span>
<span class="normal"><a href="#__codelineno-33-3">3</a></span>
<span class="normal"><a href="#__codelineno-33-4">4</a></span>
<span class="normal"><a href="#__codelineno-33-5">5</a></span>
<span class="normal"><a href="#__codelineno-33-6">6</a></span>
<span class="normal"><a href="#__codelineno-33-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">ResNet50</span>
<a id="__codelineno-33-2" name="__codelineno-33-2"></a>
<a id="__codelineno-33-3" name="__codelineno-33-3"></a><span class="c1"># Initialize a ResNet50 model with pre-trained weights</span>
<a id="__codelineno-33-4" name="__codelineno-33-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>
<a id="__codelineno-33-5" name="__codelineno-33-5"></a>
<a id="__codelineno-33-6" name="__codelineno-33-6"></a><span class="c1"># If you want to customize</span>
<a id="__codelineno-33-7" name="__codelineno-33-7"></a><span class="n">base_model</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="vgg-visual-geometry-group_2">VGG (Visual Geometry Group)</h4>
<p>The VGG architecture, developed by the Visual Geometry Group at Oxford, stands out due to its uniformity. It is simple, and great at generalization, but can be resource-heavy.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-34-1">1</a></span>
<span class="normal"><a href="#__codelineno-34-2">2</a></span>
<span class="normal"><a href="#__codelineno-34-3">3</a></span>
<span class="normal"><a href="#__codelineno-34-4">4</a></span>
<span class="normal"><a href="#__codelineno-34-5">5</a></span>
<span class="normal"><a href="#__codelineno-34-6">6</a></span>
<span class="normal"><a href="#__codelineno-34-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">VGG16</span>
<a id="__codelineno-34-2" name="__codelineno-34-2"></a>
<a id="__codelineno-34-3" name="__codelineno-34-3"></a><span class="c1"># Initialize a VGG16 model with pre-trained weights</span>
<a id="__codelineno-34-4" name="__codelineno-34-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>
<a id="__codelineno-34-5" name="__codelineno-34-5"></a>
<a id="__codelineno-34-6" name="__codelineno-34-6"></a><span class="c1"># If you want to customize</span>
<a id="__codelineno-34-7" name="__codelineno-34-7"></a><span class="n">base_model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="inception_2">Inception</h4>
<p>Inception, also known as GoogLeNet, was developed by researchers at Google. The inception module, a unique building block of this architecture, allows for more efficient computation and deeper networks.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-35-1">1</a></span>
<span class="normal"><a href="#__codelineno-35-2">2</a></span>
<span class="normal"><a href="#__codelineno-35-3">3</a></span>
<span class="normal"><a href="#__codelineno-35-4">4</a></span>
<span class="normal"><a href="#__codelineno-35-5">5</a></span>
<span class="normal"><a href="#__codelineno-35-6">6</a></span>
<span class="normal"><a href="#__codelineno-35-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">InceptionV3</span>
<a id="__codelineno-35-2" name="__codelineno-35-2"></a>
<a id="__codelineno-35-3" name="__codelineno-35-3"></a><span class="c1"># Initialize an InceptionV3 model with pre-trained weights</span>
<a id="__codelineno-35-4" name="__codelineno-35-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>
<a id="__codelineno-35-5" name="__codelineno-35-5"></a>
<a id="__codelineno-35-6" name="__codelineno-35-6"></a><span class="c1"># If you want to customize</span>
<a id="__codelineno-35-7" name="__codelineno-35-7"></a><span class="n">base_model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="transformer-model_3">Transformer Model</h3>
<p>The Transformer model is primarily used in the field of natural language processing (NLP). Unlike traditional recurrent neural networks, Transformer models use only attention mechanisms to handle variable-length input, making computation more parallelizable.</p>
<p>The most famous implementation of the Transformer model is probably the BERT (Bidirectional Encoder Representations from Transformers) model by Google.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-36-1">1</a></span>
<span class="normal"><a href="#__codelineno-36-2">2</a></span>
<span class="normal"><a href="#__codelineno-36-3">3</a></span>
<span class="normal"><a href="#__codelineno-36-4">4</a></span>
<span class="normal"><a href="#__codelineno-36-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertModel</span><span class="p">,</span> <span class="n">BertTokenizer</span>
<a id="__codelineno-36-2" name="__codelineno-36-2"></a>
<a id="__codelineno-36-3" name="__codelineno-36-3"></a><span class="c1"># Load pre-trained model and tokenizer</span>
<a id="__codelineno-36-4" name="__codelineno-36-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
<a id="__codelineno-36-5" name="__codelineno-36-5"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="generative-adversarial-networks-gans_2">Generative Adversarial Networks (GANs)</h3>
<p>Generative Adversarial Networks (GANs) involve two neural networks competing against each other in unsupervised machine learning tasks. GANs can generate new data that mimics the patterns of the training set. </p>
<p>Let's look at an example of implementing a simple GAN architecture:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-37-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-37-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-37-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-37-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-37-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-37-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-37-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-37-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-37-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-37-10">10</a></span>
<span class="normal"><a href="#__codelineno-37-11">11</a></span>
<span class="normal"><a href="#__codelineno-37-12">12</a></span>
<span class="normal"><a href="#__codelineno-37-13">13</a></span>
<span class="normal"><a href="#__codelineno-37-14">14</a></span>
<span class="normal"><a href="#__codelineno-37-15">15</a></span>
<span class="normal"><a href="#__codelineno-37-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span>
<a id="__codelineno-37-2" name="__codelineno-37-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<a id="__codelineno-37-3" name="__codelineno-37-3"></a>
<a id="__codelineno-37-4" name="__codelineno-37-4"></a><span class="c1"># The generator network</span>
<a id="__codelineno-37-5" name="__codelineno-37-5"></a><span class="n">g_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">])</span>
<a id="__codelineno-37-6" name="__codelineno-37-6"></a><span class="n">G</span> <span class="o">=</span> <span class="n">model_generator</span><span class="p">(</span><span class="n">g_input</span><span class="p">)</span>
<a id="__codelineno-37-7" name="__codelineno-37-7"></a><span class="n">G</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<a id="__codelineno-37-8" name="__codelineno-37-8"></a>
<a id="__codelineno-37-9" name="__codelineno-37-9"></a><span class="c1"># The discriminator network</span>
<a id="__codelineno-37-10" name="__codelineno-37-10"></a><span class="n">d_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-37-11" name="__codelineno-37-11"></a><span class="n">D</span> <span class="o">=</span> <span class="n">model_discriminator</span><span class="p">(</span><span class="n">d_input</span><span class="p">)</span>
<a id="__codelineno-37-12" name="__codelineno-37-12"></a><span class="n">D</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<a id="__codelineno-37-13" name="__codelineno-37-13"></a>
<a id="__codelineno-37-14" name="__codelineno-37-14"></a><span class="c1"># The GAN</span>
<a id="__codelineno-37-15" name="__codelineno-37-15"></a><span class="n">GAN</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">g_input</span><span class="p">,</span> <span class="n">D</span><span class="p">(</span><span class="n">G</span><span class="p">(</span><span class="n">g_input</span><span class="p">)))</span>
<a id="__codelineno-37-16" name="__codelineno-37-16"></a><span class="n">GAN</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<p>This code creates a simple GAN using Keras' functional API. The generator network <code>G</code> takes random noise as input and generates an image, while the discriminator network <code>D</code> takes an image (real or generated) as input and outputs a probability indicating how "real" the image is. The GAN model <code>GAN</code> chains the generator and the discriminator together: given random noise, it outputs the discriminator's assessment of the realism of the generated image.</p>
<p>Each of the architectures mentioned above has played a significant role in driving advancements in tasks such as image recognition, object detection, and language understanding. By delving deeper into these architectures, you will better understand their mechanics and learn how to leverage them in your own projects.</p>
<p>User
ცონტინუე
ChatGPT</p>
<p>vbnet</p>
<h3 id="transformer-model-continued">Transformer Model - Continued</h3>
<p>One of the main innovations of the Transformer model is the self-attention mechanism. Self-attention, sometimes called intra-attention, is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. In simple terms, self-attention allows the model to consider other words in the sentence when processing a word.</p>
<p>To illustrate this, let's delve a bit more into the BERT (Bidirectional Encoder Representations from Transformers) model. BERT has brought about a revolution in the way we approach NLP tasks. Its bidirectional training, which is essentially a read of the entire sentence rather than word-by-word, makes it stand out.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-38-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-38-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-38-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-38-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-38-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-38-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-38-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-38-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-38-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-38-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">AdamW</span>
<a id="__codelineno-38-2" name="__codelineno-38-2"></a>
<a id="__codelineno-38-3" name="__codelineno-38-3"></a><span class="c1"># Assume we&#39;re training on a binary classification problem</span>
<a id="__codelineno-38-4" name="__codelineno-38-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
<a id="__codelineno-38-5" name="__codelineno-38-5"></a>    <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span> <span class="c1"># Use the 12-layer BERT model, with an uncased vocab.</span>
<a id="__codelineno-38-6" name="__codelineno-38-6"></a>    <span class="n">num_labels</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="c1"># The number of output labels--2 for binary classification.</span>
<a id="__codelineno-38-7" name="__codelineno-38-7"></a><span class="p">)</span>
<a id="__codelineno-38-8" name="__codelineno-38-8"></a>
<a id="__codelineno-38-9" name="__codelineno-38-9"></a><span class="c1"># AdamW is a class from the huggingface library, it is the optimizer we&#39;re using</span>
<a id="__codelineno-38-10" name="__codelineno-38-10"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>In this example, we use the BERT model for a simple binary classification task. We initialize the model with pre-trained weights and then specify that we're dealing with a binary classification problem (thus, <code>num_labels = 2</code>).</p>
<h3 id="generative-adversarial-networks-gans-continued">Generative Adversarial Networks (GANs) - Continued</h3>
<p>Let's now take a look at a specific GAN architecture, the DCGAN (Deep Convolutional GAN). DCGAN applies convolutional neural networks to the GAN architecture, which is particularly successful in generating high-quality images.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-39-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-39-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-39-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-39-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-39-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-39-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-39-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-39-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-39-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-39-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">Conv2DTranspose</span>
<a id="__codelineno-39-2" name="__codelineno-39-2"></a>
<a id="__codelineno-39-3" name="__codelineno-39-3"></a><span class="c1"># Generator in DCGAN</span>
<a id="__codelineno-39-4" name="__codelineno-39-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-39-5" name="__codelineno-39-5"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">128</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
<a id="__codelineno-39-6" name="__codelineno-39-6"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<a id="__codelineno-39-7" name="__codelineno-39-7"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Reshape</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">128</span><span class="p">)))</span>
<a id="__codelineno-39-8" name="__codelineno-39-8"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2DTranspose</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<a id="__codelineno-39-9" name="__codelineno-39-9"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<a id="__codelineno-39-10" name="__codelineno-39-10"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2DTranspose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
<p>In this example, the generator network starts with a dense layer that reshapes its input into a 7x7x128 tensor. It then uses two <code>Conv2DTranspose</code> layers (a type of layer that performs up-convolution) to upscale this tensor into a 28x28x1 image. This network uses <code>LeakyReLU</code> activation functions and outputs images with pixel values in the range [-1, 1] (as indicated by the <code>tanh</code> activation function).</p>
<h3 id="basics-of-nlp-and-text-representation-techniques-continued">Basics of NLP and Text Representation Techniques - Continued</h3>
<p>To better understand the techniques used to represent text data, let's look at some Python code examples:</p>
<h4 id="bag-of-words_1">Bag of Words</h4>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-40-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-40-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-40-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-40-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-40-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-40-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-40-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-40-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-40-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-40-10">10</a></span>
<span class="normal"><a href="#__codelineno-40-11">11</a></span>
<span class="normal"><a href="#__codelineno-40-12">12</a></span>
<span class="normal"><a href="#__codelineno-40-13">13</a></span>
<span class="normal"><a href="#__codelineno-40-14">14</a></span>
<span class="normal"><a href="#__codelineno-40-15">15</a></span>
<span class="normal"><a href="#__codelineno-40-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-40-1" name="__codelineno-40-1"></a><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<a id="__codelineno-40-2" name="__codelineno-40-2"></a>
<a id="__codelineno-40-3" name="__codelineno-40-3"></a><span class="c1"># Initialize the CountVectorizer</span>
<a id="__codelineno-40-4" name="__codelineno-40-4"></a><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<a id="__codelineno-40-5" name="__codelineno-40-5"></a>
<a id="__codelineno-40-6" name="__codelineno-40-6"></a><span class="c1"># Corpus of data</span>
<a id="__codelineno-40-7" name="__codelineno-40-7"></a><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;This is the first document.&#39;</span><span class="p">,</span>
<a id="__codelineno-40-8" name="__codelineno-40-8"></a>          <span class="s1">&#39;This document is the second document.&#39;</span><span class="p">,</span>
<a id="__codelineno-40-9" name="__codelineno-40-9"></a>          <span class="s1">&#39;And this is the third one.&#39;</span><span class="p">,</span>
<a id="__codelineno-40-10" name="__codelineno-40-10"></a>          <span class="s1">&#39;Is this the first document?&#39;</span><span class="p">]</span>
<a id="__codelineno-40-11" name="__codelineno-40-11"></a>
<a id="__codelineno-40-12" name="__codelineno-40-12"></a><span class="c1"># Fit and transform the corpus</span>
<a id="__codelineno-40-13" name="__codelineno-40-13"></a><span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<a id="__codelineno-40-14" name="__codelineno-40-14"></a>
<a id="__codelineno-40-15" name="__codelineno-40-15"></a><span class="c1"># Convert to array and print the result</span>
<a id="__codelineno-40-16" name="__codelineno-40-16"></a><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</code></pre></div></td></tr></table></div>
<p>In this example, we use the <code>CountVectorizer</code> class from the <code>sklearn.feature_extraction.text</code> module, which implements the Bag of Words method. The <code>fit_transform</code> function learns the vocabulary dictionary and returns a Document-Term matrix.</p>
<h4 id="tf-idf_1">TF-IDF</h4>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-41-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-41-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-41-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-41-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-41-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-41-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-41-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-41-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-41-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-41-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-41-1" name="__codelineno-41-1"></a><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<a id="__codelineno-41-2" name="__codelineno-41-2"></a>
<a id="__codelineno-41-3" name="__codelineno-41-3"></a><span class="c1"># Initialize the TfidfVectorizer</span>
<a id="__codelineno-41-4" name="__codelineno-41-4"></a><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<a id="__codelineno-41-5" name="__codelineno-41-5"></a>
<a id="__codelineno-41-6" name="__codelineno-41-6"></a><span class="c1"># Fit and transform the corpus</span>
<a id="__codelineno-41-7" name="__codelineno-41-7"></a><span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<a id="__codelineno-41-8" name="__codelineno-41-8"></a>
<a id="__codelineno-41-9" name="__codelineno-41-9"></a><span class="c1"># Convert to array and print the result</span>
<a id="__codelineno-41-10" name="__codelineno-41-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</code></pre></div></td></tr></table></div>
<p>Here, we use the <code>TfidfVectorizer</code> class, also from the <code>sklearn.feature_extraction.text</code> module. It converts a collection of raw documents to a matrix of TF-IDF features.</p>
<h4 id="word-embeddings_1">Word Embeddings</h4>
<p>For word embeddings, we often use pre-trained models. One of the most common is Word2Vec, trained on a large corpus of text. Gensim is a popular library for using Word2Vec in Python.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-42-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-42-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-42-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-42-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-42-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-42-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-42-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-42-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-42-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-42-10">10</a></span>
<span class="normal"><a href="#__codelineno-42-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-42-1" name="__codelineno-42-1"></a><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>
<a id="__codelineno-42-2" name="__codelineno-42-2"></a>
<a id="__codelineno-42-3" name="__codelineno-42-3"></a><span class="c1"># Assuming that &#39;sentences&#39; is a list of lists of tokens </span>
<a id="__codelineno-42-4" name="__codelineno-42-4"></a><span class="c1"># For example: sentences = [[&#39;this&#39;, &#39;is&#39;, &#39;the&#39;, &#39;first&#39;, &#39;sentence&#39;, &#39;for&#39;, &#39;word2vec&#39;],</span>
<a id="__codelineno-42-5" name="__codelineno-42-5"></a><span class="c1">#                           [&#39;this&#39;, &#39;is&#39;, &#39;the&#39;, &#39;second&#39;, &#39;sentence&#39;]]</span>
<a id="__codelineno-42-6" name="__codelineno-42-6"></a>
<a id="__codelineno-42-7" name="__codelineno-42-7"></a><span class="c1"># Train a Word2Vec model</span>
<a id="__codelineno-42-8" name="__codelineno-42-8"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-42-9" name="__codelineno-42-9"></a>
<a id="__codelineno-42-10" name="__codelineno-42-10"></a><span class="c1"># Get the vector for a word</span>
<a id="__codelineno-42-11" name="__codelineno-42-11"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="s1">&#39;sentence&#39;</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
<p>This script trains a Word2Vec model on a small corpus and prints the vector for the word 'sentence'.</p>
<h3 id="advanced-nlp-models-and-techniques-continued">Advanced NLP Models and Techniques - Continued</h3>
<h4 id="rnns-and-lstms-in-nlp">RNNs and LSTMs in NLP</h4>
<p>RNNs are particularly suitable for handling sequence data. Let's look at an example of an LSTM for text generation:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-43-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-43-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-43-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-43-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-43-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-43-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-43-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-43-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-43-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-43-10">10</a></span>
<span class="normal"><a href="#__codelineno-43-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-43-1" name="__codelineno-43-1"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<a id="__codelineno-43-2" name="__codelineno-43-2"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span>
<a id="__codelineno-43-3" name="__codelineno-43-3"></a><span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">RMSprop</span>
<a id="__codelineno-43-4" name="__codelineno-43-4"></a>
<a id="__codelineno-43-5" name="__codelineno-43-5"></a><span class="c1"># Assume that &#39;maxlen&#39; is the sequence length, &#39;chars&#39; is the list of unique characters, and &#39;char_indices&#39; and &#39;indices_char&#39; are dictionaries mapping characters to their indices and vice versa</span>
<a id="__codelineno-43-6" name="__codelineno-43-6"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-43-7" name="__codelineno-43-7"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">))))</span>
<a id="__codelineno-43-8" name="__codelineno-43-8"></a><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<a id="__codelineno-43-9" name="__codelineno-43-9"></a>
<a id="__codelineno-43-10" name="__codelineno-43-10"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<a id="__codelineno-43-11" name="__codelineno-43-11"></a><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>This script creates an LSTM model for text generation. It assumes that you've already preprocessed the text into sequences of characters and created mappings of characters to numeric indices.</p>
<h4 id="using-transformers-in-nlp">Using Transformers in NLP</h4>
<p>As discussed before, the transformer model, specifically BERT and GPT, has been very effective in various NLP tasks. For example, we can use the BERT model for text classification as follows:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-44-1">1</a></span>
<span class="normal"><a href="#__codelineno-44-2">2</a></span>
<span class="normal"><a href="#__codelineno-44-3">3</a></span>
<span class="normal"><a href="#__codelineno-44-4">4</a></span>
<span class="normal"><a href="#__codelineno-44-5">5</a></span>
<span class="normal"><a href="#__codelineno-44-6">6</a></span>
<span class="normal"><a href="#__codelineno-44-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-44-1" name="__codelineno-44-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">AdamW</span>
<a id="__codelineno-44-2" name="__codelineno-44-2"></a>
<a id="__codelineno-44-3" name="__codelineno-44-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
<a id="__codelineno-44-4" name="__codelineno-44-4"></a>    <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span>
<a id="__codelineno-44-5" name="__codelineno-44-5"></a>    <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-44-6" name="__codelineno-44-6"></a><span class="p">)</span>
<a id="__codelineno-44-7" name="__codelineno-44-7"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>This script loads a pre-trained BERT model for a binary classification task. It uses the AdamW optimizer with a learning rate of 2e-5.</p>
<h2 id="reinforcement-learning_1">Reinforcement Learning</h2>
<p>Reinforcement Learning (RL) is another significant area of Machine Learning where an agent learns to behave in an environment, by performing certain actions and observing the rewards/results which it gets from those actions.</p>
<h2 id="basics-of-reinforcement-learning">Basics of Reinforcement Learning</h2>
<p>The key components of Reinforcement Learning are as follows:</p>
<ul>
<li>
<p><strong>Environment</strong>: This is the world through which the agent moves. The environment takes the agent's current state and action as input, and returns the agent's reward and next state.</p>
</li>
<li>
<p><strong>Agent</strong>: This is the algorithm that learns from trial and error.</p>
</li>
<li>
<p><strong>State</strong>: This is the current situation of the agent.</p>
</li>
<li>
<p><strong>Action</strong>: What the agent can do.</p>
</li>
<li>
<p><strong>Reward</strong>: Feedback from the environment.</p>
</li>
</ul>
<p>Here is a simple example of an RL implementation using Python and the <code>gym</code> library, which is a popular toolkit for developing and comparing RL algorithms:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-45-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-45-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-45-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-45-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-45-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-45-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-45-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-45-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-45-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-45-10">10</a></span>
<span class="normal"><a href="#__codelineno-45-11">11</a></span>
<span class="normal"><a href="#__codelineno-45-12">12</a></span>
<span class="normal"><a href="#__codelineno-45-13">13</a></span>
<span class="normal"><a href="#__codelineno-45-14">14</a></span>
<span class="normal"><a href="#__codelineno-45-15">15</a></span>
<span class="normal"><a href="#__codelineno-45-16">16</a></span>
<span class="normal"><a href="#__codelineno-45-17">17</a></span>
<span class="normal"><a href="#__codelineno-45-18">18</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-45-1" name="__codelineno-45-1"></a><span class="kn">import</span> <span class="nn">gym</span>
<a id="__codelineno-45-2" name="__codelineno-45-2"></a>
<a id="__codelineno-45-3" name="__codelineno-45-3"></a><span class="c1"># Create the CartPole game environment</span>
<a id="__codelineno-45-4" name="__codelineno-45-4"></a><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
<a id="__codelineno-45-5" name="__codelineno-45-5"></a>
<a id="__codelineno-45-6" name="__codelineno-45-6"></a><span class="c1"># Number of episodes</span>
<a id="__codelineno-45-7" name="__codelineno-45-7"></a><span class="k">for</span> <span class="n">i_episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
<a id="__codelineno-45-8" name="__codelineno-45-8"></a>    <span class="c1"># Reset state</span>
<a id="__codelineno-45-9" name="__codelineno-45-9"></a>    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-45-10" name="__codelineno-45-10"></a>    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
<a id="__codelineno-45-11" name="__codelineno-45-11"></a>        <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
<a id="__codelineno-45-12" name="__codelineno-45-12"></a>        <span class="c1"># Take a random action</span>
<a id="__codelineno-45-13" name="__codelineno-45-13"></a>        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<a id="__codelineno-45-14" name="__codelineno-45-14"></a>        <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
<a id="__codelineno-45-15" name="__codelineno-45-15"></a>        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
<a id="__codelineno-45-16" name="__codelineno-45-16"></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode finished after </span><span class="si">{}</span><span class="s2"> timesteps&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-45-17" name="__codelineno-45-17"></a>            <span class="k">break</span>
<a id="__codelineno-45-18" name="__codelineno-45-18"></a><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<p>In this example, we're using a simple game environment called "CartPole-v1". The agent takes random actions in the environment and receives feedback.</p>
<p>(Note: More advanced topics on reinforcement learning will be continued...)</p>
<h2 id="deep-reinforcement-learning">Deep Reinforcement Learning</h2>
<p>Deep Reinforcement Learning (DRL) combines neural networks with reinforcement learning. The neural network takes in observations, processes them, and outputs actions to take. These actions are then used in the reinforcement learning component.</p>
<h3 id="q-learning">Q-Learning</h3>
<p>Q-Learning is a values based algorithm in reinforcement learning. Value based algorithms update the value function based on the Bellman Equation. The algorithm helps the agent to decide what action to take under what circumstances.</p>
<h3 id="deep-q-networks">Deep Q-Networks</h3>
<p>Deep Q-Networks (DQN) is the combination of Q-Learning and Deep Learning. In DQN, we use a neural network to approximate the Q-value function, and the network is trained to output the maximum expected future rewards for each action, given a specific state.</p>
<h3 id="policy-gradients">Policy Gradients</h3>
<p>Policy Gradients (PG) are a type of reinforcement learning algorithm that directly optimizes the policy—the function that decides what actions to take—by estimating the gradient of the expected rewards.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy"], "search": "../../assets/javascripts/workers/search.c011b7c0.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.7389ff0e.min.js"></script>
      
    
  </body>
</html>